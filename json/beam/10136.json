[{"authorTime":"2019-08-25 01:06:33","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":18,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2019-11-20 22:28:02","endLine":134,"groupId":"7554","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/d2/6a3587ced39cdcdc5cfec518de51dea1c9e6d3.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/DoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"B"},{"authorDate":"2019-08-25 01:06:33","commitOrder":18,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    if (stateful) {\n      Object key = null;\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2019-08-25 01:06:33","endLine":186,"groupId":"21474","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/ee/2a5812fe89b6735b44a394f886ed78f1bacd9e.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    if (stateful) {\n      Object key = null;\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"NB"}],"commitId":"18059eecad850b6e30bc7e376e70937915dd11fb","commitMessage":"@@@Merge pull request #9866: [BEAM-8470] Create a new Spark runner based on Spark Structured streaming framework\n\n","date":"2019-11-20 22:28:02","modifiedFileCount":"3","status":"M","submitter":"Alexey Romanenko"},{"authorTime":"2020-08-26 05:07:32","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":19,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2019-11-20 22:28:02","endLine":134,"groupId":"7554","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/d2/6a3587ced39cdcdc5cfec518de51dea1c9e6d3.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/DoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"N"},{"authorDate":"2020-08-26 05:07:32","commitOrder":19,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    Object key = null;\n\n    if (stateful) {\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            key,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2020-08-26 05:07:32","endLine":188,"groupId":"21474","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/77/ddff25b95fdd1a982511f1dbc03bb058a5f468.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    if (stateful) {\n      Object key = null;\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"M"}],"commitId":"59ee4fb49514a0e00ad6c198fb07f385f2e1cb7c","commitMessage":"@@@Merge pull request #12514: [BEAM-9850] Key should be available in @OnTimer methods (Spark Runner)\n\n","date":"2020-08-26 05:07:32","modifiedFileCount":"2","status":"M","submitter":"Isma?l Mej?a"},{"authorTime":"2021-04-15 09:15:30","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":20,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2019-11-20 22:28:02","endLine":134,"groupId":"7554","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/d2/6a3587ced39cdcdc5cfec518de51dea1c9e6d3.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/DoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"N"},{"authorDate":"2021-04-15 09:15:30","commitOrder":20,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn, options.get());\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    Object key = null;\n\n    if (stateful) {\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            key,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2021-04-15 09:15:30","endLine":191,"groupId":"21474","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/f1/9369cc4de5e643aed8f7fc0ffe7bb56cb989a4.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    Object key = null;\n\n    if (stateful) {\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            key,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"M"}],"commitId":"d57dee10909a85e98695ee4b99a95f6d33d4a1fb","commitMessage":"@@@[BEAM-11914] Add PipelineOptions as DoFn @Setup parameters (#14155)\n\n","date":"2021-04-15 09:15:30","modifiedFileCount":"34","status":"M","submitter":"xinyuiscool"},{"authorTime":"2021-04-15 09:15:30","codes":[{"authorDate":"2021-08-05 17:59:06","commitOrder":21,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn, serializableOptions.get());\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2021-08-05 17:59:06","endLine":137,"groupId":"10136","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/cc/ddf62cf4639a8fede7a661253d39f0f21f2762.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn);\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            serializableOptions.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs, broadcastStateData)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            new NoOpStepContext(),\n            inputCoder,\n            outputCoderMap,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new ProcessContext<>(\n            doFn, doFnRunnerWithMetrics, outputManager, Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/DoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"M"},{"authorDate":"2021-04-15 09:15:30","commitOrder":21,"curCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn, options.get());\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    Object key = null;\n\n    if (stateful) {\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            key,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","date":"2021-04-15 09:15:30","endLine":191,"groupId":"10136","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"call","params":"(Iterator<WindowedValue<InputT>>iter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/f1/9369cc4de5e643aed8f7fc0ffe7bb56cb989a4.src","preCode":"  public Iterator<Tuple2<TupleTag<?>, WindowedValue<?>>> call(Iterator<WindowedValue<InputT>> iter)\n      throws Exception {\n    if (!wasSetupCalled && iter.hasNext()) {\n      DoFnInvokers.tryInvokeSetupFor(doFn, options.get());\n      wasSetupCalled = true;\n    }\n\n    DoFnOutputManager outputManager = new DoFnOutputManager();\n\n    final InMemoryTimerInternals timerInternals;\n    final StepContext context;\n    \r\n    Object key = null;\n\n    if (stateful) {\n      if (iter.hasNext()) {\n        WindowedValue<InputT> currentValue = iter.next();\n        key = ((KV) currentValue.getValue()).getKey();\n        iter = Iterators.concat(Iterators.singletonIterator(currentValue), iter);\n      }\n      final InMemoryStateInternals<?> stateInternals = InMemoryStateInternals.forKey(key);\n      timerInternals = new InMemoryTimerInternals();\n      context =\n          new StepContext() {\n            @Override\n            public StateInternals stateInternals() {\n              return stateInternals;\n            }\n\n            @Override\n            public TimerInternals timerInternals() {\n              return timerInternals;\n            }\n          };\n    } else {\n      timerInternals = null;\n      context = new SparkProcessContext.NoOpStepContext();\n    }\n\n    final DoFnRunner<InputT, OutputT> doFnRunner =\n        DoFnRunners.simpleRunner(\n            options.get(),\n            doFn,\n            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),\n            outputManager,\n            mainOutputTag,\n            additionalOutputTags,\n            context,\n            inputCoder,\n            outputCoders,\n            windowingStrategy,\n            doFnSchemaInformation,\n            sideInputMapping);\n\n    DoFnRunnerWithMetrics<InputT, OutputT> doFnRunnerWithMetrics =\n        new DoFnRunnerWithMetrics<>(stepName, doFnRunner, metricsAccum);\n\n    return new SparkProcessContext<>(\n            doFn,\n            doFnRunnerWithMetrics,\n            outputManager,\n            key,\n            stateful ? new TimerDataIterator(timerInternals) : Collections.emptyIterator())\n        .processPartition(iter)\n        .iterator();\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"N"}],"commitId":"2144cab210d4608d10a0855eeef45ce4e113e074","commitMessage":"@@@Merge pull request #15218 from echauchot/BEAM-7093-spark3-fix-for-SS-runner\n\nMerge pull request #15218: [BEAM-7093] Migrate spark structured streaming runner to spark 3","date":"2021-08-05 17:59:06","modifiedFileCount":"3","status":"M","submitter":"Etienne Chauchot"}]
