[{"authorTime":"2017-04-25 22:43:42","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":2,"curCode":"  private Map<W, W> mergeWindows(WindowingStrategy<InputT, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<InputT, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","date":"2019-11-20 22:28:02","endLine":213,"groupId":"10043","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"mergeWindows","params":"(WindowingStrategy<InputT@W>windowingStrategy@Set<W>windows)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/6a/f4669640d5c6ecb5c69e923f4aaf3b60ff3e47.src","preCode":"  private Map<W, W> mergeWindows(WindowingStrategy<InputT, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<InputT, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/AggregatorCombiner.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":201,"status":"B"},{"authorDate":"2017-04-25 22:43:42","commitOrder":2,"curCode":"  private Map<W, W> mergeWindows(\n      WindowingStrategy<Object, W> windowingStrategy,\n      Set<W> windows) throws Exception {\n    WindowFn<Object, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","date":"2017-04-25 22:43:42","endLine":135,"groupId":"10043","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"mergeWindows","params":"(WindowingStrategy<Object@W>windowingStrategy@Set<W>windows)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/b9/04bfe895d10f3c1e55f75e81ecfab83a198cf6.src","preCode":"  private Map<W, W> mergeWindows(\n      WindowingStrategy<Object, W> windowingStrategy,\n      Set<W> windows) throws Exception {\n    WindowFn<Object, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","realPath":"runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/HashingFlinkCombineRunner.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"NB"}],"commitId":"18059eecad850b6e30bc7e376e70937915dd11fb","commitMessage":"@@@Merge pull request #9866: [BEAM-8470] Create a new Spark runner based on Spark Structured streaming framework\n\n","date":"2019-11-20 22:28:02","modifiedFileCount":"3","status":"M","submitter":"Alexey Romanenko"},{"authorTime":"2021-02-27 12:29:06","codes":[{"authorDate":"2021-02-27 12:29:06","commitOrder":3,"curCode":"  private Map<W, W> mergeWindows(WindowingStrategy<InputT, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<InputT, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (!windowingStrategy.needsMerge()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","date":"2021-02-27 12:29:06","endLine":249,"groupId":"10146","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"mergeWindows","params":"(WindowingStrategy<InputT@W>windowingStrategy@Set<W>windows)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/fd/759d6bdadb89ea4db4b6adb1fdfd06b4b84c82.src","preCode":"  private Map<W, W> mergeWindows(WindowingStrategy<InputT, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<InputT, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/translation/batch/AggregatorCombiner.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":237,"status":"M"},{"authorDate":"2021-02-27 12:29:06","commitOrder":3,"curCode":"  private Map<W, W> mergeWindows(WindowingStrategy<Object, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<Object, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (!windowingStrategy.needsMerge()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","date":"2021-02-27 12:29:06","endLine":151,"groupId":"10146","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"mergeWindows","params":"(WindowingStrategy<Object@W>windowingStrategy@Set<W>windows)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/6c/f9ac7c62c1cf4831cd673d71984f43dee57ed3.src","preCode":"  private Map<W, W> mergeWindows(WindowingStrategy<Object, W> windowingStrategy, Set<W> windows)\n      throws Exception {\n    WindowFn<Object, W> windowFn = windowingStrategy.getWindowFn();\n\n    if (windowingStrategy.getWindowFn().isNonMerging()) {\n      \r\n      return Collections.emptyMap();\n    }\n\n    Map<W, W> windowToMergeResult = new HashMap<>();\n    windowFn.mergeWindows(new MergeContextImpl(windowFn, windows, windowToMergeResult));\n    return windowToMergeResult;\n  }\n","realPath":"runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/HashingFlinkCombineRunner.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"M"}],"commitId":"4764c0a6bc641525699150b6489f115f8cecf7e7","commitMessage":"@@@Merge pull request #14059: [BEAM-11866] Remove InvalidWindows from Java SDK.  instead track \"already merged\" bit\n\n","date":"2021-02-27 12:29:06","modifiedFileCount":"26","status":"M","submitter":"Kenn Knowles"}]
