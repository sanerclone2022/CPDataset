[{"authorTime":"2019-02-26 20:16:40","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":6,"curCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","date":"2019-11-20 22:28:02","endLine":64,"groupId":"1831","id":1,"instanceNumber":1,"isCurCommit":1,"methodName":"renderAll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/de/146c60f97df046fc778d889a40d9cfd1e46f6d.src","preCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/metrics/SparkBeamMetric.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"B"},{"authorDate":"2019-02-26 20:16:40","commitOrder":6,"curCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","date":"2019-02-26 20:16:40","endLine":61,"groupId":"1831","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"renderAll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/b4/e62a16ea94103c17d538633ea728b15dc82e2a.src","preCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/metrics/SparkBeamMetric.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"NB"}],"commitId":"18059eecad850b6e30bc7e376e70937915dd11fb","commitMessage":"@@@Merge pull request #9866: [BEAM-8470] Create a new Spark runner based on Spark Structured streaming framework\n\n","date":"2019-11-20 22:28:02","modifiedFileCount":"3","status":"M","submitter":"Alexey Romanenko"},{"authorTime":"2021-02-04 07:18:26","codes":[{"authorDate":"2019-11-20 22:28:02","commitOrder":7,"curCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","date":"2019-11-20 22:28:02","endLine":64,"groupId":"10164","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"renderAll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/de/146c60f97df046fc778d889a40d9cfd1e46f6d.src","preCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/structuredstreaming/metrics/SparkBeamMetric.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"N"},{"authorDate":"2021-02-04 07:18:26","commitOrder":7,"curCode":"  static Map<String, ?> renderAll(MetricResults metricResults) {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","date":"2021-02-04 07:18:26","endLine":62,"groupId":"10164","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"renderAll","params":"(MetricResultsmetricResults)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-beam-10-0.7/blobInfo/CC_OUT/blobs/02/745c927c7ed18f5586b6835e3132767b8a2b0d.src","preCode":"  Map<String, ?> renderAll() {\n    Map<String, Object> metrics = new HashMap<>();\n    MetricResults metricResults =\n        asAttemptedOnlyMetricResults(MetricsAccumulator.getInstance().value());\n    MetricQueryResults metricQueryResults = metricResults.allMetrics();\n    for (MetricResult<Long> metricResult : metricQueryResults.getCounters()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted());\n    }\n    for (MetricResult<DistributionResult> metricResult : metricQueryResults.getDistributions()) {\n      DistributionResult result = metricResult.getAttempted();\n      metrics.put(renderName(metricResult) + \".count\", result.getCount());\n      metrics.put(renderName(metricResult) + \".sum\", result.getSum());\n      metrics.put(renderName(metricResult) + \".min\", result.getMin());\n      metrics.put(renderName(metricResult) + \".max\", result.getMax());\n      metrics.put(renderName(metricResult) + \".mean\", result.getMean());\n    }\n    for (MetricResult<GaugeResult> metricResult : metricQueryResults.getGauges()) {\n      metrics.put(renderName(metricResult), metricResult.getAttempted().getValue());\n    }\n    return metrics;\n  }\n","realPath":"runners/spark/src/main/java/org/apache/beam/runners/spark/metrics/SparkBeamMetric.java","repoName":"beam","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"654ad2bd47a34c71c6e0d1c0c4ce0a9cda32ac87","commitMessage":"@@@Merge pull request #13743 from tszerszen/sparkmetrics\n\n[BEAM-11213] Display Beam Metrics in Spark History Server","date":"2021-02-04 07:18:26","modifiedFileCount":"4","status":"M","submitter":"Kyle Weaver"}]
