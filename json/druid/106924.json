[{"authorTime":"2019-09-26 23:04:33","codes":[{"authorDate":"2019-09-26 23:04:33","commitOrder":1,"curCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn() throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(GroupByQueryConfig.CTX_KEY_VECTORIZE, true))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","date":"2019-09-26 23:04:33","endLine":126,"groupId":"7664","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testVectorAggretatorUsingGroupByQueryOnDoubleColumn","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a7/1c6f0efa3ccb1d9c0d5899f8aaf4b053c350aa.src","preCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn() throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(GroupByQueryConfig.CTX_KEY_VECTORIZE, true))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"B"},{"authorDate":"2019-09-26 23:04:33","commitOrder":1,"curCode":"  public void testAggretatorUsingTimeseriesQuery() throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","date":"2019-09-26 23:04:33","endLine":158,"groupId":"7668","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testAggretatorUsingTimeseriesQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a7/1c6f0efa3ccb1d9c0d5899f8aaf4b053c350aa.src","preCode":"  public void testAggretatorUsingTimeseriesQuery() throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":129,"status":"B"}],"commitId":"9f1f5e115c0595e208c0f59e12bf2a5e26ed0c29","commitMessage":"@@@doubleMean aggregator to be used at query time (#8459)\n\n* doubleMean aggregator for computing mean\n\n* make docs\n\n* build fixes\n\n* address review comment: handle null args\n","date":"2019-09-26 23:04:33","modifiedFileCount":"6","status":"B","submitter":"Himanshu"},{"authorTime":"2020-06-17 19:52:02","codes":[{"authorDate":"2020-06-17 19:52:02","commitOrder":2,"curCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn(boolean doVectorize) throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(GroupByQueryConfig.CTX_KEY_VECTORIZE, doVectorize))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","date":"2020-06-17 19:52:02","endLine":141,"groupId":"7664","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testVectorAggretatorUsingGroupByQueryOnDoubleColumn","params":"(booleandoVectorize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/0d57b09cdd1b0bf4e2aad24a46c86372971859.src","preCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn() throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(GroupByQueryConfig.CTX_KEY_VECTORIZE, true))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":121,"status":"M"},{"authorDate":"2020-06-17 19:52:02","commitOrder":2,"curCode":"  public void testAggretatorUsingTimeseriesQuery(boolean doVectorize) throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .context(ImmutableMap.of(QueryContexts.VECTORIZE_KEY, doVectorize))\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","date":"2020-06-17 19:52:02","endLine":175,"groupId":"7668","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testAggretatorUsingTimeseriesQuery","params":"(booleandoVectorize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/0d57b09cdd1b0bf4e2aad24a46c86372971859.src","preCode":"  public void testAggretatorUsingTimeseriesQuery() throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"M"}],"commitId":"7569ee3ec6e8955bb704f9b8ab2e88a344d1ed52","commitMessage":"@@@All aggregators should check if column can be vectorize (#10026)\n\n* All aggregators should use vectorization-aware column processor\n\n* All aggregators should use vectorization-aware column processor\n\n* fix canVectorize\n\n* fix canVectorize\n\n* add tests\n\n* revert back default\n\n* address comment\n\n* address comments\n\n* address comment\n\n* address comment","date":"2020-06-17 19:52:02","modifiedFileCount":"17","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2020-06-17 19:52:02","codes":[{"authorDate":"2020-09-29 09:48:34","commitOrder":3,"curCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn(boolean doVectorize) throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(QueryContexts.VECTORIZE_KEY, doVectorize))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","date":"2020-09-29 09:48:34","endLine":141,"groupId":"106924","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testVectorAggretatorUsingGroupByQueryOnDoubleColumn","params":"(booleandoVectorize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/74/6fdbdc0dcf8f76f9b12f27a8e007e392674694.src","preCode":"  public void testVectorAggretatorUsingGroupByQueryOnDoubleColumn(boolean doVectorize) throws Exception\n  {\n    GroupByQuery query = new GroupByQuery.Builder()\n        .setDataSource(\"test\")\n        .setGranularity(Granularities.ALL)\n        .setInterval(\"1970/2050\")\n        .setAggregatorSpecs(\n            new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL)\n        )\n        .setContext(Collections.singletonMap(GroupByQueryConfig.CTX_KEY_VECTORIZE, doVectorize))\n        .build();\n\n    \r\n    ObjectMapper jsonMapper = groupByQueryTestHelper.getObjectMapper();\n    query = (GroupByQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence<ResultRow> seq = groupByQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    Row result = Iterables.getOnlyElement(seq.toList()).toMapBasedRow(query);\n\n    Assert.assertEquals(6.2d, result.getMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":121,"status":"M"},{"authorDate":"2020-06-17 19:52:02","commitOrder":3,"curCode":"  public void testAggretatorUsingTimeseriesQuery(boolean doVectorize) throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .context(ImmutableMap.of(QueryContexts.VECTORIZE_KEY, doVectorize))\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","date":"2020-06-17 19:52:02","endLine":175,"groupId":"106924","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testAggretatorUsingTimeseriesQuery","params":"(booleandoVectorize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/0d57b09cdd1b0bf4e2aad24a46c86372971859.src","preCode":"  public void testAggretatorUsingTimeseriesQuery(boolean doVectorize) throws Exception\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(\"1970/2050\")\n                                  .aggregators(\n                                      new DoubleMeanAggregatorFactory(\"meanOnDouble\", SimpleTestIndex.DOUBLE_COL),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnString\",\n                                          SimpleTestIndex.SINGLE_VALUE_DOUBLE_AS_STRING_DIM\n                                      ),\n                                      new DoubleMeanAggregatorFactory(\n                                          \"meanOnMultiValue\",\n                                          SimpleTestIndex.MULTI_VALUE_DOUBLE_AS_STRING_DIM\n                                      )\n                                  )\n                                  .context(ImmutableMap.of(QueryContexts.VECTORIZE_KEY, doVectorize))\n                                  .build();\n\n    \r\n    ObjectMapper jsonMapper = timeseriesQueryTestHelper.getObjectMapper();\n    query = (TimeseriesQuery) jsonMapper.readValue(jsonMapper.writeValueAsString(query), Query.class);\n\n    Sequence seq = timeseriesQueryTestHelper.runQueryOnSegmentsObjs(segments, query);\n    TimeseriesResultValue result = ((Result<TimeseriesResultValue>) Iterables.getOnlyElement(seq.toList())).getValue();\n\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnDouble\").doubleValue(), 0.0001d);\n    Assert.assertEquals(6.2d, result.getDoubleMetric(\"meanOnString\").doubleValue(), 0.0001d);\n    Assert.assertEquals(4.1333d, result.getDoubleMetric(\"meanOnMultiValue\").doubleValue(), 0.0001d);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/aggregation/mean/DoubleMeanAggregationTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"N"}],"commitId":"1d6cb624f4a455f45f41ef4b773cf21859a09ef4","commitMessage":"@@@add vectorizeVirtualColumns query context parameter (#10432)\n\n* add vectorizeVirtualColumns query context parameter\n\n* oops\n\n* spelling\n\n* default to false.  more docs\n\n* fix test\n\n* fix spelling","date":"2020-09-29 09:48:34","modifiedFileCount":"18","status":"M","submitter":"Clint Wylie"}]
