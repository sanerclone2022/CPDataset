[{"authorTime":"2019-12-10 15:05:49","codes":[{"authorDate":"2019-08-16 08:43:35","commitOrder":2,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n    }\n    return TaskStatus.fromCode(getId(), state);\n  }\n","date":"2019-08-16 08:43:35","endLine":453,"groupId":"2879","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2f/a30e34270cbf73e77f8b0d52fcc889b0794b21.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n    }\n    return TaskStatus.fromCode(getId(), state);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":440,"status":"NB"},{"authorDate":"2019-12-10 15:05:49","commitOrder":2,"curCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n          + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(toolbox, tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions));\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n    }\n\n    return TaskStatus.fromCode(getId(), mergeState);\n  }\n","date":"2019-12-10 15:05:49","endLine":648,"groupId":"2879","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/db/31af67d91a21a5ff6b201661d6f091cda50de1.src","preCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n          + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(toolbox, tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions));\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n    }\n\n    return TaskStatus.fromCode(getId(), mergeState);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":599,"status":"B"}],"commitId":"bab78fc80e8ee2929d6d2c277d3999695c8402a4","commitMessage":"@@@Parallel indexing single dim partitions (#8925)\n\n* Parallel indexing single dim partitions\n\nImplements single dimension range partitioning for native parallel batch\nindexing as described in #8769. This initial version requires the\ndruid-datasketches extension to be loaded.\n\nThe algorithm has 5 phases that are orchestrated by the supervisor in\n`ParallelIndexSupervisorTask#runRangePartitionMultiPhaseParallel()`.\nThese phases and the main classes involved are described below:\n\n1) In parallel.  determine the distribution of dimension values for each\n   input source split.\n\n   `PartialDimensionDistributionTask` uses `StringSketch` to generate\n   the approximate distribution of dimension values for each input\n   source split. If the rows are ungrouped. \n   `PartialDimensionDistributionTask.UngroupedRowDimensionValueFilter`\n   uses a Bloom filter to skip rows that would be grouped. The final\n   distribution is sent back to the supervisor via\n   `DimensionDistributionReport`.\n\n2) The range partitions are determined.\n\n   In `ParallelIndexSupervisorTask#determineAllRangePartitions()`.  the\n   supervisor uses `StringSketchMerger` to merge the individual\n   `StringSketch`es created in the preceding phase. The merged sketch is\n   then used to create the range partitions.\n\n3) In parallel.  generate partial range-partitioned segments.\n\n   `PartialRangeSegmentGenerateTask` uses the range partitions\n   determined in the preceding phase and\n   `RangePartitionCachingLocalSegmentAllocator` to generate\n   `SingleDimensionShardSpec`s.  The partition information is sent back\n   to the supervisor via `GeneratedGenericPartitionsReport`.\n\n4) The partial range segments are grouped.\n\n   In `ParallelIndexSupervisorTask#groupGenericPartitionLocationsPerPartition()`. \n   the supervisor creates the `PartialGenericSegmentMergeIOConfig`s\n   necessary for the next phase.\n\n5) In parallel.  merge partial range-partitioned segments.\n\n   `PartialGenericSegmentMergeTask` uses `GenericPartitionLocation` to\n   retrieve the partial range-partitioned segments generated earlier and\n   then merges and publishes them.\n\n* Fix dependencies & forbidden apis\n\n* Fixes for integration test\n\n* Address review comments\n\n* Fix docs.  strict compile.  sketch check.  rollup check\n\n* Fix first shard spec.  partition serde.  single subtask\n\n* Fix first partition check in test\n\n* Misc rewording/refactoring to address code review\n\n* Fix doc link\n\n* Split batch index integration test\n\n* Do not run parallel-batch-index twice\n\n* Adjust last partition\n\n* Split ITParallelIndexTest to reduce runtime\n\n* Rename test class\n\n* Allow null values in range partitions\n\n* Indicate which phase failed\n\n* Improve asserts in tests\n","date":"2019-12-10 15:05:49","modifiedFileCount":"18","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2020-11-26 06:50:22","codes":[{"authorDate":"2019-08-16 08:43:35","commitOrder":3,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n    }\n    return TaskStatus.fromCode(getId(), state);\n  }\n","date":"2019-08-16 08:43:35","endLine":453,"groupId":"2879","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2f/a30e34270cbf73e77f8b0d52fcc889b0794b21.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n    }\n    return TaskStatus.fromCode(getId(), state);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":440,"status":"N"},{"authorDate":"2020-11-26 06:50:22","commitOrder":3,"curCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n    }\n\n    return TaskStatus.fromCode(getId(), mergeState);\n  }\n","date":"2020-11-26 06:50:22","endLine":712,"groupId":"2879","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3d/272b43813c4d222e918d7c69cdad0ae3e419df.src","preCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n          + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(toolbox, tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions));\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n    }\n\n    return TaskStatus.fromCode(getId(), mergeState);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":652,"status":"M"}],"commitId":"7462b0b953e87890a683a0bee7b7480465450342","commitMessage":"@@@Allow missing intervals for Parallel task with hash/range partitioning (#10592)\n\n* Allow missing intervals for Parallel task\n\n* fix row filter\n\n* fix tests\n\n* fix log","date":"2020-11-26 06:50:22","modifiedFileCount":"22","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-04-09 12:03:00","codes":[{"authorDate":"2021-04-09 12:03:00","commitOrder":4,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n    }\n    TaskStatus taskStatus = TaskStatus.fromCode(getId(), state);\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-04-09 12:03:00","endLine":547,"groupId":"2879","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/984e8a9dbb447af7d2cec5781c4c746fcb2eff.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n    }\n    return TaskStatus.fromCode(getId(), state);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":526,"status":"M"},{"authorDate":"2021-04-09 12:03:00","commitOrder":4,"curCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n    }\n\n    TaskStatus taskStatus = TaskStatus.fromCode(getId(), mergeState);\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-04-09 12:03:00","endLine":764,"groupId":"2879","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/984e8a9dbb447af7d2cec5781c4c746fcb2eff.src","preCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n    }\n\n    return TaskStatus.fromCode(getId(), mergeState);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":696,"status":"M"}],"commitId":"8264203cee688607091232897749e959e7706010","commitMessage":"@@@Allow client to configure batch ingestion task to wait to complete until segments are confirmed to be available by other (#10676)\n\n* Add ability to wait for segment availability for batch jobs\n\n* IT updates\n\n* fix queries in legacy hadoop IT\n\n* Fix broken indexing integration tests\n\n* address an lgtm flag\n\n* spell checker still flagging for hadoop doc. adding under that file header too\n\n* fix compaction IT\n\n* Updates to wait for availability method\n\n* improve unit testing for patch\n\n* fix bad indentation\n\n* refactor waitForSegmentAvailability\n\n* Fixes based off of review comments\n\n* cleanup to get compile after merging with master\n\n* fix failing test after previous logic update\n\n* add back code that must have gotten deleted during conflict resolution\n\n* update some logging code\n\n* fixes to get compilation working after merge with master\n\n* reset interrupt flag in catch block after code review pointed it out\n\n* small changes following self-review\n\n* fixup some issues brought on by merge with master\n\n* small changes after review\n\n* cleanup a little bit after merge with master\n\n* Fix potential resource leak in AbstractBatchIndexTask\n\n* syntax fix\n\n* Add a Compcation TuningConfig type\n\n* add docs stipulating the lack of support by Compaction tasks for the new config\n\n* Fixup compilation errors after merge with master\n\n* Remove erreneous newline","date":"2021-04-09 12:03:00","modifiedFileCount":"106","status":"M","submitter":"Lucas Capistrant"},{"authorTime":"2021-08-03 03:11:28","codes":[{"authorDate":"2021-08-03 03:11:28","commitOrder":5,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    TaskStatus taskStatus;\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(state.isFailure(), \"Unrecognized state after task is complete[%s]\", state);\n      final String errorMessage = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          runner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errorMessage);\n    }\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-08-03 03:11:28","endLine":584,"groupId":"10656","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d2/a3ca7819df3dc7fa78aaaf3e72308e8fdbff1d.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n    }\n    TaskStatus taskStatus = TaskStatus.fromCode(getId(), state);\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":554,"status":"M"},{"authorDate":"2021-08-03 03:11:28","commitOrder":5,"curCode":"  TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      String errMsg = StringUtils.format(TASK_PHASE_FAILURE_MSG, distributionRunner.getName());\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          indexingRunner.getName()\n      );\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    TaskStatus taskStatus;\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(mergeState.isFailure(), \"Unrecognized state after task is complete[%s]\", mergeState);\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          mergeRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errMsg);\n    }\n\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-08-03 03:11:28","endLine":834,"groupId":"10658","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d2/a3ca7819df3dc7fa78aaaf3e72308e8fdbff1d.src","preCode":"  private TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialDimensionDistributionTask.TYPE + \" failed\");\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      return TaskStatus.failure(getId(), PartialRangeSegmentGenerateTask.TYPE + \" failed\");\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n    }\n\n    TaskStatus taskStatus = TaskStatus.fromCode(getId(), mergeState);\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":752,"status":"M"}],"commitId":"a2da407b704db8eed85b97cd7c1d22541f2b1102","commitMessage":"@@@Add error msg to parallel task's TaskStatus (#11486)\n\n* Add error msg to parallel task's TaskStatus\n\n* Consolidate failure block\n\n* Add failure test\n\n* Make it fail\n\n* Add fail while stopped\n\n* Simplify hash task test using a runner that fails after so many runs (parameter)\n\n* Remove unthrown exception\n\n* Use runner names to identify phase\n\n* Added range partition kill test & fixed a timing bug with the custom runner\n\n* Forbidden api\n\n* Style\n\n* Unit test code cleanup\n\n* Added message to invalid state exception and improved readability  of the phase error messages for the parallel task failure unit tests","date":"2021-08-03 03:11:28","modifiedFileCount":"19","status":"M","submitter":"Agustin Gonzalez"},{"authorTime":"2021-08-14 04:40:25","codes":[{"authorDate":"2021-08-03 03:11:28","commitOrder":6,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    TaskStatus taskStatus;\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(state.isFailure(), \"Unrecognized state after task is complete[%s]\", state);\n      final String errorMessage = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          runner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errorMessage);\n    }\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-08-03 03:11:28","endLine":584,"groupId":"10656","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d2/a3ca7819df3dc7fa78aaaf3e72308e8fdbff1d.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    TaskStatus taskStatus;\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(state.isFailure(), \"Unrecognized state after task is complete[%s]\", state);\n      final String errorMessage = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          runner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errorMessage);\n    }\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":554,"status":"N"},{"authorDate":"2021-08-14 04:40:25","commitOrder":6,"curCode":"  TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      String errMsg = StringUtils.format(TASK_PHASE_FAILURE_MSG, distributionRunner.getName());\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          indexingRunner.getName()\n      );\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<PartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    TaskStatus taskStatus;\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(mergeState.isFailure(), \"Unrecognized state after task is complete[%s]\", mergeState);\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          mergeRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errMsg);\n    }\n\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-08-14 04:40:25","endLine":834,"groupId":"10658","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/6f49f7a6c8a7b15f150b69f2416af8f16759e2.src","preCode":"  TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      String errMsg = StringUtils.format(TASK_PHASE_FAILURE_MSG, distributionRunner.getName());\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport<GenericPartitionStat>> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          indexingRunner.getName()\n      );\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<GenericPartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialGenericSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    TaskStatus taskStatus;\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(mergeState.isFailure(), \"Unrecognized state after task is complete[%s]\", mergeState);\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          mergeRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errMsg);\n    }\n\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":752,"status":"M"}],"commitId":"c7b46671b311e841f7ddc3596dc4e9b4cf96b24d","commitMessage":"@@@option to use deep storage for storing shuffle data (#11507)\n\nFixes #11297.\nDescription\n\nDescription and design in the proposal #11297\nKey changed/added classes in this PR\n\n    *DataSegmentPusher\n    *ShuffleClient\n    *PartitionStat\n    *PartitionLocation\n    *IntermediaryDataManager\n","date":"2021-08-14 04:40:25","modifiedFileCount":"47","status":"M","submitter":"Parag Jain"},{"authorTime":"2021-08-14 04:40:25","codes":[{"authorDate":"2021-09-17 02:58:11","commitOrder":7,"curCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ingestionState = IngestionState.BUILD_SEGMENTS;\n    ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> parallelSinglePhaseRunner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(parallelSinglePhaseRunner);\n    TaskStatus taskStatus;\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, parallelSinglePhaseRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(parallelSinglePhaseRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(state.isFailure(), \"Unrecognized state after task is complete[%s]\", state);\n      final String errorMessage = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          parallelSinglePhaseRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errorMessage);\n    }\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-09-17 02:58:11","endLine":593,"groupId":"104781","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"runSinglePhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/19/b965c2e57ae115d3ecb994fd967a8fe88fbf38.src","preCode":"  private TaskStatus runSinglePhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    final ParallelIndexTaskRunner<SinglePhaseSubTask, PushedSegmentsReport> runner = createRunner(\n        toolbox,\n        this::createSinglePhaseTaskRunner\n    );\n\n    final TaskState state = runNextPhase(runner);\n    TaskStatus taskStatus;\n    if (state.isSuccess()) {\n      \r\n      publishSegments(toolbox, runner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(runner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(state.isFailure(), \"Unrecognized state after task is complete[%s]\", state);\n      final String errorMessage = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          runner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errorMessage);\n    }\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":562,"status":"M"},{"authorDate":"2021-08-14 04:40:25","commitOrder":7,"curCode":"  TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      String errMsg = StringUtils.format(TASK_PHASE_FAILURE_MSG, distributionRunner.getName());\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          indexingRunner.getName()\n      );\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<PartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    TaskStatus taskStatus;\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(mergeState.isFailure(), \"Unrecognized state after task is complete[%s]\", mergeState);\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          mergeRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errMsg);\n    }\n\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","date":"2021-08-14 04:40:25","endLine":834,"groupId":"104781","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"runRangePartitionMultiPhaseParallel","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/6f49f7a6c8a7b15f150b69f2416af8f16759e2.src","preCode":"  TaskStatus runRangePartitionMultiPhaseParallel(TaskToolbox toolbox) throws Exception\n  {\n    ParallelIndexIngestionSpec ingestionSchemaToUse = ingestionSchema;\n    ParallelIndexTaskRunner<PartialDimensionDistributionTask, DimensionDistributionReport> distributionRunner =\n        createRunner(\n            toolbox,\n            this::createPartialDimensionDistributionRunner\n        );\n\n    TaskState distributionState = runNextPhase(distributionRunner);\n    if (distributionState.isFailure()) {\n      String errMsg = StringUtils.format(TASK_PHASE_FAILURE_MSG, distributionRunner.getName());\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    Map<Interval, PartitionBoundaries> intervalToPartitions =\n        determineAllRangePartitions(distributionRunner.getReports().values());\n\n    if (intervalToPartitions.isEmpty()) {\n      String msg = \"No valid rows for single dimension partitioning.\"\n                   + \" All rows may have invalid timestamps or multiple dimension values.\";\n      LOG.warn(msg);\n      return TaskStatus.success(getId(), msg);\n    }\n\n    ingestionSchemaToUse = rewriteIngestionSpecWithIntervalsIfMissing(\n        ingestionSchemaToUse,\n        intervalToPartitions.keySet()\n    );\n\n    final ParallelIndexIngestionSpec segmentCreateIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialRangeSegmentGenerateTask, GeneratedPartitionsReport> indexingRunner =\n        createRunner(\n            toolbox,\n            tb -> createPartialRangeSegmentGenerateRunner(tb, intervalToPartitions, segmentCreateIngestionSpec)\n        );\n\n    TaskState indexingState = runNextPhase(indexingRunner);\n    if (indexingState.isFailure()) {\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          indexingRunner.getName()\n      );\n      return TaskStatus.failure(getId(), errMsg);\n    }\n\n    \r\n    Map<Pair<Interval, Integer>, List<PartitionLocation>> partitionToLocations =\n        groupGenericPartitionLocationsPerPartition(indexingRunner.getReports());\n    final List<PartialSegmentMergeIOConfig> ioConfigs = createGenericMergeIOConfigs(\n        ingestionSchema.getTuningConfig().getTotalNumMergeTasks(),\n        partitionToLocations\n    );\n\n    final ParallelIndexIngestionSpec segmentMergeIngestionSpec = ingestionSchemaToUse;\n    ParallelIndexTaskRunner<PartialGenericSegmentMergeTask, PushedSegmentsReport> mergeRunner = createRunner(\n        toolbox,\n        tb -> createPartialGenericSegmentMergeRunner(tb, ioConfigs, segmentMergeIngestionSpec)\n    );\n    TaskState mergeState = runNextPhase(mergeRunner);\n    TaskStatus taskStatus;\n    if (mergeState.isSuccess()) {\n      publishSegments(toolbox, mergeRunner.getReports());\n      if (awaitSegmentAvailabilityTimeoutMillis > 0) {\n        waitForSegmentAvailability(mergeRunner.getReports());\n      }\n      taskStatus = TaskStatus.success(getId());\n    } else {\n      \r\n      Preconditions.checkState(mergeState.isFailure(), \"Unrecognized state after task is complete[%s]\", mergeState);\n      String errMsg = StringUtils.format(\n          TASK_PHASE_FAILURE_MSG,\n          mergeRunner.getName()\n      );\n      taskStatus = TaskStatus.failure(getId(), errMsg);\n    }\n\n    toolbox.getTaskReportFileWriter().write(\n        getId(),\n        getTaskCompletionReports(taskStatus, segmentAvailabilityConfirmationCompleted)\n    );\n    return taskStatus;\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":752,"status":"N"}],"commitId":"22b41ddbbfe2b07b085e295ba171bcdc07e04900","commitMessage":"@@@Task reports for parallel task: single phase and sequential mode (#11688)\n\n* Task reports for parallel task: single phase and sequential mode\n\n* Address comments\n\n* Add null check for currentSubTaskHolder","date":"2021-09-17 02:58:11","modifiedFileCount":"13","status":"M","submitter":"Jonathan Wei"}]
