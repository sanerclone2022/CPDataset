[{"authorTime":"2021-03-03 03:23:52","codes":[{"authorDate":"2021-03-03 03:23:52","commitOrder":6,"curCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-03-03 03:23:52","endLine":155,"groupId":"4584","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e6/3fbb0110d0b0eeec258fd69a5ed781e0e0b9b4.src","preCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"B"},{"authorDate":"2021-03-03 03:23:52","commitOrder":6,"curCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-03-03 03:23:52","endLine":198,"groupId":"7337","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"loadDataAndCompact","params":"(StringindexTask@StringqueriesResource@StringcompactionResource@GranularityTypenewSegmentGranularity)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e6/3fbb0110d0b0eeec258fd69a5ed781e0e0b9b4.src","preCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"MB"}],"commitId":"b7b0ee83627dd7887392e8f9d6fb5cb29465c28c","commitMessage":"@@@Add query granularity to compaction task (#10900)\n\n* add query granularity to compaction task\n\n* fix checkstyle\n\n* fix checkstyle\n\n* fix test\n\n* fix test\n\n* add tests\n\n* fix test\n\n* fix test\n\n* cleanup\n\n* rename class\n\n* fix test\n\n* fix test\n\n* add test\n\n* fix test","date":"2021-03-03 03:23:52","modifiedFileCount":"15","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2021-03-19 08:04:28","codes":[{"authorDate":"2021-03-19 08:04:28","commitOrder":7,"curCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-03-19 08:04:28","endLine":169,"groupId":"4584","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/8332270bd81a9c9508a29d55aa34eeaa14a486.src","preCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":140,"status":"M"},{"authorDate":"2021-03-19 08:04:28","commitOrder":7,"curCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-03-19 08:04:28","endLine":212,"groupId":"7337","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"loadDataAndCompact","params":"(StringindexTask@StringqueriesResource@StringcompactionResource@GranularityTypenewSegmentGranularity)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/8332270bd81a9c9508a29d55aa34eeaa14a486.src","preCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":177,"status":"M"}],"commitId":"f19c2e9ce40b711b5cf1ac1ad1cef9d50167c371","commitMessage":"@@@If ingested data has sparse columns.  the ingested data with forceGuaranteedRollup=true can result in imperfect rollup and final dimension ordering can be different from dimensionSpec ordering in the ingestionSpec (#10948)\n\n* add IT\n\n* add IT\n\n* add the fix\n\n* fix checkstyle\n\n* fix compile\n\n* fix compile\n\n* fix test\n\n* fix test\n\n* address comments","date":"2021-03-19 08:04:28","modifiedFileCount":"9","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2021-04-09 12:03:00","codes":[{"authorDate":"2021-03-19 08:04:28","commitOrder":8,"curCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-03-19 08:04:28","endLine":169,"groupId":"103685","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/8332270bd81a9c9508a29d55aa34eeaa14a486.src","preCode":"  public void testCompactionWithSegmentGranularityAndQueryGranularityInGranularitySpec() throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(INDEX_TASK, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(COMPACTION_TASK_WITH_GRANULARITY_SPEC, GranularityType.YEAR, GranularityType.YEAR);\n\n      \r\n      checkNumberOfSegments(1);\n      queryResponseTemplate = getQueryResponseTemplate(INDEX_QUERIES_YEAR_RESOURCE);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.YEAR.name(), 1);\n\n      List<String> newIntervals = new ArrayList<>();\n      for (String interval : expectedIntervalAfterCompaction) {\n        for (Interval newinterval : GranularityType.YEAR.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n          newIntervals.add(newinterval.toString());\n        }\n      }\n      expectedIntervalAfterCompaction = newIntervals;\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":140,"status":"N"},{"authorDate":"2021-04-09 12:03:00","commitOrder":8,"curCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n\n      queryResponseTemplate = StringUtils.replace(\n          queryResponseTemplate,\n          \"%%SEGMENT_AVAIL_TIMEOUT_MILLIS%%\",\n          jsonMapper.writeValueAsString(\"0\")\n      );\n\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","date":"2021-04-09 12:03:00","endLine":219,"groupId":"103685","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"loadDataAndCompact","params":"(StringindexTask@StringqueriesResource@StringcompactionResource@GranularityTypenewSegmentGranularity)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/95/7c8a5522c4c99375e092c80cb235a6d183213c.src","preCode":"  private void loadDataAndCompact(\n      String indexTask,\n      String queriesResource,\n      String compactionResource,\n      GranularityType newSegmentGranularity\n  ) throws Exception\n  {\n    try (final Closeable ignored = unloader(fullDatasourceName)) {\n      loadData(indexTask, fullDatasourceName);\n      \r\n      checkNumberOfSegments(4);\n      List<String> expectedIntervalAfterCompaction = coordinator.getSegmentIntervals(fullDatasourceName);\n      expectedIntervalAfterCompaction.sort(null);\n\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 4);\n      String queryResponseTemplate = getQueryResponseTemplate(queriesResource);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      compactData(compactionResource, newSegmentGranularity, null);\n\n      \r\n      checkNumberOfSegments(2);\n      queryHelper.testQueriesFromString(queryResponseTemplate);\n      checkQueryGranularity(SEGMENT_METADATA_QUERY_RESOURCE, GranularityType.SECOND.name(), 2);\n\n      if (newSegmentGranularity != null) {\n        List<String> newIntervals = new ArrayList<>();\n        for (String interval : expectedIntervalAfterCompaction) {\n          for (Interval newinterval : newSegmentGranularity.getDefaultGranularity().getIterable(new Interval(interval, ISOChronology.getInstanceUTC()))) {\n            newIntervals.add(newinterval.toString());\n          }\n        }\n        expectedIntervalAfterCompaction = newIntervals;\n      }\n      checkCompactionIntervals(expectedIntervalAfterCompaction);\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITCompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":177,"status":"M"}],"commitId":"8264203cee688607091232897749e959e7706010","commitMessage":"@@@Allow client to configure batch ingestion task to wait to complete until segments are confirmed to be available by other (#10676)\n\n* Add ability to wait for segment availability for batch jobs\n\n* IT updates\n\n* fix queries in legacy hadoop IT\n\n* Fix broken indexing integration tests\n\n* address an lgtm flag\n\n* spell checker still flagging for hadoop doc. adding under that file header too\n\n* fix compaction IT\n\n* Updates to wait for availability method\n\n* improve unit testing for patch\n\n* fix bad indentation\n\n* refactor waitForSegmentAvailability\n\n* Fixes based off of review comments\n\n* cleanup to get compile after merging with master\n\n* fix failing test after previous logic update\n\n* add back code that must have gotten deleted during conflict resolution\n\n* update some logging code\n\n* fixes to get compilation working after merge with master\n\n* reset interrupt flag in catch block after code review pointed it out\n\n* small changes following self-review\n\n* fixup some issues brought on by merge with master\n\n* small changes after review\n\n* cleanup a little bit after merge with master\n\n* Fix potential resource leak in AbstractBatchIndexTask\n\n* syntax fix\n\n* Add a Compcation TuningConfig type\n\n* add docs stipulating the lack of support by Compaction tasks for the new config\n\n* Fixup compilation errors after merge with master\n\n* Remove erreneous newline","date":"2021-04-09 12:03:00","modifiedFileCount":"106","status":"M","submitter":"Lucas Capistrant"}]
