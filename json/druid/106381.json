[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators, Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","date":"2018-08-31 00:56:26","endLine":4278,"groupId":"2002","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d8/05065b1a763d6958ac6c554b91a76be76340a5.src","preCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators, Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4221,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","date":"2018-08-31 00:56:26","endLine":4352,"groupId":"2002","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d8/05065b1a763d6958ac6c554b91a76be76340a5.src","preCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4299,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-10-29 20:02:43","codes":[{"authorDate":"2018-10-29 20:02:43","commitOrder":2,"curCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","date":"2018-10-29 20:02:43","endLine":4278,"groupId":"2002","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/98/fa0135f2c77a8eb7deaef9bde2f0cb7ef290be.src","preCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4220,"status":"M"},{"authorDate":"2018-10-29 20:02:43","commitOrder":2,"curCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","date":"2018-10-29 20:02:43","endLine":4352,"groupId":"2002","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/98/fa0135f2c77a8eb7deaef9bde2f0cb7ef290be.src","preCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = Maps.newHashMap();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4299,"status":"M"}],"commitId":"676f5e6d7f184101b8763e4249b18b237bbe0ec7","commitMessage":"@@@Prohibit some guava collection APIs and use JDK collection APIs directly (#6511)\n\n* Prohibit some guava collection APIs and use JDK APIs directly\n\n* reset files that changed by accident\n\n* sort codestyle/druid-forbidden-apis.txt alphabetically\n","date":"2018-10-29 20:02:43","modifiedFileCount":"427","status":"M","submitter":"QiuMM"},{"authorTime":"2019-01-22 03:11:10","codes":[{"authorDate":"2019-01-22 03:11:10","commitOrder":3,"curCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","date":"2019-01-22 03:11:10","endLine":4273,"groupId":"2002","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/da/23ca673a73841a537a373894cd2e3a58281cc4.src","preCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4215,"status":"M"},{"authorDate":"2019-01-22 03:11:10","commitOrder":3,"curCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","date":"2019-01-22 03:11:10","endLine":4347,"groupId":"2002","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/da/23ca673a73841a537a373894cd2e3a58281cc4.src","preCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnInterval)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4294,"status":"M"}],"commitId":"8eae26fd4e7572060d112864dd3d5f6a865b9c89","commitMessage":"@@@Introduce SegmentId class (#6370)\n\n* Introduce SegmentId class\n\n* tmp\n\n* Fix SelectQueryRunnerTest\n\n* Fix indentation\n\n* Fixes\n\n* Remove Comparators.inverse() tests\n\n* Refinements\n\n* Fix tests\n\n* Fix more tests\n\n* Remove duplicate DataSegmentTest.  fixes #6064\n\n* SegmentDescriptor doc\n\n* Fix SQLMetadataStorageUpdaterJobHandler\n\n* Fix DataSegment deserialization for ignoring id\n\n* Add comments\n\n* More comments\n\n* Address more comments\n\n* Fix compilation\n\n* Restore segment2 in SystemSchemaTest according to a comment\n\n* Fix style\n\n* fix testServerSegmentsTable\n\n* Fix compilation\n\n* Add comments about why SegmentId and SegmentIdWithShardSpec are separate classes\n\n* Fix SystemSchemaTest\n\n* Fix style\n\n* Compare SegmentDescriptor with SegmentId in Javadoc and comments rather than with DataSegment\n\n* Remove a link.  see https://youtrack.jetbrains.com/issue/IDEA-205164\n\n* Fix compilation\n","date":"2019-01-22 03:11:10","modifiedFileCount":"308","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-07-19 04:16:28","codes":[{"authorDate":"2019-07-19 04:16:28","commitOrder":4,"curCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.addRowsIndexConstant);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","date":"2019-07-19 04:16:28","endLine":4291,"groupId":"2002","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/4b/9fb51afb036dca9148a4c39b6dbecbf810868c.src","preCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4233,"status":"M"},{"authorDate":"2019-07-19 04:16:28","commitOrder":4,"curCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.addRowsIndexConstant);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","date":"2019-07-19 04:16:28","endLine":4374,"groupId":"2002","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/4b/9fb51afb036dca9148a4c39b6dbecbf810868c.src","preCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(Lists.newArrayList(Iterables.concat(commonAggregators, Lists.newArrayList(\n            new FilteredAggregatorFactory(new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                                          extractionFilter),\n            \r\n            new DoubleMinAggregatorFactory(\"minIndex\", \"index\")))))\n        .postAggregators(Collections.singletonList(QueryRunnerTestHelper.addRowsIndexConstant));\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4312,"status":"M"}],"commitId":"03e55d30ebcac9ec97edb1a638a5a99886c41374","commitMessage":"@@@add CachingClusteredClient benchmark.  refactor some stuff (#8089)\n\n* add CachingClusteredClient benchmark.  refactor some stuff\n\n* revert WeightedServerSelectorStrategy to ConnectionCountServerSelectorStrategy and remove getWeight since felt artificial.  default mergeResults in toolchest implementation for topn.  search.  select\n\n* adjust javadoc\n\n* adjustments\n\n* oops\n\n* use it\n\n* use BinaryOperator.  remove CombiningFunction.  use Comparator instead of Ordering.  other review adjustments\n\n* rename createComparator to createResultComparator.  fix typo.  firstNonNull nullable parameters\n","date":"2019-07-19 04:16:28","modifiedFileCount":"50","status":"M","submitter":"Clint Wylie"},{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2019-08-23 18:13:54","commitOrder":5,"curCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.DATA_SOURCE)\n        .granularity(QueryRunnerTestHelper.ALL_GRAN)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.INDEX_METRIC)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.ADD_ROWS_INDEX_CONSTANT);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","date":"2019-08-23 18:13:54","endLine":4288,"groupId":"106381","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c6/f894ad5ddd5fccc9520230d8961edd721a636c.src","preCode":"  public void testTopNWithExtractionFilterAndFilteredAggregatorCaseNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, false);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, false);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.addRowsIndexConstant);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4230,"status":"M"},{"authorDate":"2019-08-23 18:13:54","commitOrder":5,"curCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.DATA_SOURCE)\n        .granularity(QueryRunnerTestHelper.ALL_GRAN)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.INDEX_METRIC)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.ADD_ROWS_INDEX_CONSTANT);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","date":"2019-08-23 18:13:54","endLine":4371,"groupId":"106381","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testTopNWithExtractionFilterNoExistingValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c6/f894ad5ddd5fccc9520230d8961edd721a636c.src","preCode":"  public void testTopNWithExtractionFilterNoExistingValue()\n  {\n    Map<String, String> extractionMap = new HashMap<>();\n\n    MapLookupExtractor mapLookupExtractor = new MapLookupExtractor(extractionMap, false);\n    LookupExtractionFn lookupExtractionFn;\n    if (NullHandling.replaceWithDefault()) {\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, null, true, true);\n      extractionMap.put(\"\", \"NULL\");\n    } else {\n      extractionMap.put(\"\", \"NOT_USED\");\n      lookupExtractionFn = new LookupExtractionFn(mapLookupExtractor, false, \"NULL\", true, true);\n    }\n    DimFilter extractionFilter = new ExtractionDimFilter(\"null_column\", \"NULL\", lookupExtractionFn, null);\n    TopNQueryBuilder topNQueryBuilder = new TopNQueryBuilder()\n        .dataSource(QueryRunnerTestHelper.dataSource)\n        .granularity(QueryRunnerTestHelper.allGran)\n        .dimension(\"null_column\")\n        .metric(QueryRunnerTestHelper.indexMetric)\n        .threshold(4)\n        .intervals(QueryRunnerTestHelper.fullOnIntervalSpec)\n        .aggregators(\n            Lists.newArrayList(\n                Iterables.concat(\n                    commonAggregators,\n                    Lists.newArrayList(\n                        new FilteredAggregatorFactory(\n                            new DoubleMaxAggregatorFactory(\"maxIndex\", \"index\"),\n                            extractionFilter\n                        ),\n                        new DoubleMinAggregatorFactory(\"minIndex\", \"index\")\n                    )\n                )\n            )\n        )\n        .postAggregators(QueryRunnerTestHelper.addRowsIndexConstant);\n    TopNQuery topNQueryWithNULLValueExtraction = topNQueryBuilder\n        .filters(extractionFilter)\n        .build();\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"null_column\", null);\n    map.put(\"rows\", 1209L);\n    map.put(\"index\", 503332.5071372986D);\n    map.put(\"addRowsIndexConstant\", 504542.5071372986D);\n    map.put(\"uniques\", QueryRunnerTestHelper.UNIQUES_9);\n    map.put(\"maxIndex\", 1870.061029D);\n    map.put(\"minIndex\", 59.02102279663086D);\n    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2011-01-12T00:00:00.000Z\"),\n            new TopNResultValue(\n                Collections.singletonList(\n                    map\n                )\n            )\n        )\n    );\n    assertExpectedResults(expectedResults, topNQueryWithNULLValueExtraction);\n    \r\n    final Sequence<Result<TopNResultValue>> retval = runWithPreMergeAndMerge(topNQueryWithNULLValueExtraction);\n    TestHelper.assertExpectedResults(expectedResults, retval);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/query/topn/TopNQueryRunnerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":4309,"status":"M"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"}]
