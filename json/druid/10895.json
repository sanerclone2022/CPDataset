[{"authorTime":"2019-04-19 04:31:29","codes":[{"authorDate":"2019-04-19 04:31:29","commitOrder":2,"curCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(\"ETag\"));\n  }\n","date":"2019-04-19 04:31:29","endLine":3133,"groupId":"20361","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testIfNoneMatch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/3a309e687e2aa34be12fba038d11594edea2c9.src","preCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(\"ETag\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3098,"status":"MB"},{"authorDate":"2019-04-19 04:31:29","commitOrder":2,"curCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                     .dataSource(DATA_SOURCE)\n                                     .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                     .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                     .build();\n\n\n    final Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(\"ETag\");\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(\"ETag\");\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","date":"2019-04-19 04:31:29","endLine":3182,"groupId":"20361","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testEtagforDifferentQueryInterval","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/3a309e687e2aa34be12fba038d11594edea2c9.src","preCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                     .dataSource(DATA_SOURCE)\n                                     .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                     .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                     .build();\n\n\n    final Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(\"ETag\");\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(\"ETag\");\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3136,"status":"B"}],"commitId":"c2a42e05bb08aefa31f1d1ed09d568cdaa726b8a","commitMessage":"@@@Fix result-level cache for queries (#7325)\n\n* Add SegmentDescriptor interval in the hash while calculating Etag\n\n* Add computeResultLevelCacheKey to CacheStrategy\n\nMake HavingSpec cacheable and implement getCacheKey for subclasses\nAdd unit tests for computeResultLevelCacheKey\n\n* Add more tests\n\n* Use CacheKeyBuilder for HavingSpec's getCacheKey\n\n* Initialize aggregators map to avoid NPE\n\n* adjust cachekey builder for HavingSpec to ignore aggregators\n\n* unused import\n\n* PR comments\n","date":"2019-04-19 04:31:29","modifiedFileCount":"26","status":"M","submitter":"Surekha"},{"authorTime":"2019-07-24 23:29:03","codes":[{"authorDate":"2019-07-24 23:29:03","commitOrder":3,"curCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(ResponseContext.CTX_ETAG));\n  }\n","date":"2019-07-24 23:29:03","endLine":3116,"groupId":"20361","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testIfNoneMatch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/38/9b49f4678c068e8f186b7e52c88926a999f50a.src","preCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(\"ETag\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3081,"status":"M"},{"authorDate":"2019-07-24 23:29:03","commitOrder":3,"curCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                     .dataSource(DATA_SOURCE)\n                                     .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                     .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                     .build();\n\n\n    final ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(\"ETag\");\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(\"ETag\");\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","date":"2019-07-24 23:29:03","endLine":3165,"groupId":"20361","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testEtagforDifferentQueryInterval","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/38/9b49f4678c068e8f186b7e52c88926a999f50a.src","preCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                     .dataSource(DATA_SOURCE)\n                                     .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                     .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                     .build();\n\n\n    final Map<String, Object> responseContext = new HashMap<>();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(\"ETag\");\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(\"ETag\");\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3119,"status":"M"}],"commitId":"799d20249fe6333ea86b020f6d09c91fa4d3f998","commitMessage":"@@@Response context refactoring (#8110)\n\n* Response context refactoring\n\n* Serialization/Deserialization of ResponseContext\n\n* Added java doc comments\n\n* Renamed vars related to ResponseContext\n\n* Renamed empty() methods to createEmpty()\n\n* Fixed ResponseContext usage\n\n* Renamed multiple ResponseContext static fields\n\n* Added PublicApi annotations\n\n* Renamed QueryResponseContext class to ResourceIOReaderWriter\n\n* Moved the protected method below public static constants\n\n* Added createEmpty method to ResponseContext with DefaultResponseContext creation\n\n* Fixed inspection error\n\n* Added comments to the ResponseContext length limit and ResponseContext\nhttp header name\n\n* Added a comment of possible future refactoring\n\n* Removed .gitignore file of indexing-service\n\n* Removed a never-used method\n\n* VisibleForTesting method reducing boilerplate\n\nCo-Authored-By: Clint Wylie <cjwylie@gmail.com>\n\n* Reduced boilerplate\n\n* Renamed the method serialize to serializeWith\n\n* Removed unused import\n\n* Fixed incorrectly refactored test method\n\n* Added comments for ResponseContext keys\n\n* Fixed incorrectly refactored test method\n\n* Fixed IntervalChunkingQueryRunnerTest mocks\n","date":"2019-07-24 23:29:03","modifiedFileCount":"142","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2019-08-03 17:05:21","codes":[{"authorDate":"2019-08-03 17:05:21","commitOrder":4,"curCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(ResponseContext.Key.ETAG));\n  }\n","date":"2019-08-03 17:05:21","endLine":3198,"groupId":"20361","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testIfNoneMatch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2b/8e2f52b811aba26f6c7d3e1e6a9c464cd32932.src","preCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(ResponseContext.CTX_ETAG));\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3163,"status":"M"},{"authorDate":"2019-08-03 17:05:21","commitOrder":4,"curCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                          .dataSource(DATA_SOURCE)\n                                          .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                          .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                          .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                           .dataSource(DATA_SOURCE)\n                                           .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                           .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                           .build();\n\n\n    final ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(ResponseContext.Key.ETAG);\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(ResponseContext.Key.ETAG);\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","date":"2019-08-03 17:05:21","endLine":3247,"groupId":"20361","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testEtagforDifferentQueryInterval","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2b/8e2f52b811aba26f6c7d3e1e6a9c464cd32932.src","preCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                          .dataSource(DATA_SOURCE)\n                                          .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                          .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                          .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                           .dataSource(DATA_SOURCE)\n                                           .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                           .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                           .build();\n\n\n    final ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(\"ETag\");\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(\"ETag\");\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3201,"status":"M"}],"commitId":"3f3162b85e269749bf0aa848f435409b3a1db8fe","commitMessage":"@@@Enum of ResponseContext keys (#8157)\n\n* Refactored ResponseContext and aggregated its keys into Enum\n\n* Added unit tests for ResponseContext and refactored the serialization\n\n* Removed unused methods\n\n* Fixed code style\n\n* Fixed code style\n\n* Fixed code style\n\n* Made SerializationResult static\n\n* Updated according to the PR discussion:\n\nRenamed an argument\n\nUpdated comparator\n\nReplaced Pair usage with Map.Entry\n\nAdded a comment about quadratic complexity\n\nRemoved boolean field with an expression\n\nRenamed SerializationResult field\n\nRenamed the method merge to add and renamed several context keys\n\nRenamed field and method related to scanRowsLimit\n\nUpdated a comment\n\nSimplified a block of code\n\nRenamed a variable\n\n* Added JsonProperty annotation to renamed ScanQuery field\n\n* Extension-friendly context key implementation\n\n* Refactored ResponseContext: updated delegate type.  comments and exceptions\n\nReducing serialized context length by removing some of its'\ncollection elements\n\n* Fixed tests\n\n* Simplified response context truncation during serialization\n\n* Extracted a method of removing elements from a response context and\nadded some comments\n\n* Fixed typos and updated comments\n","date":"2019-08-03 17:05:21","modifiedFileCount":"28","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2020-07-02 05:02:21","codes":[{"authorDate":"2020-07-02 05:02:21","commitOrder":5,"curCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .randomQueryId()\n                                    .build();\n\n\n    final ResponseContext responseContext = initializeResponseContext();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(ResponseContext.Key.ETAG));\n  }\n","date":"2020-07-02 05:02:21","endLine":2949,"groupId":"10895","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testIfNoneMatch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/45/2dd8cadd6b4c232ab41fc0990812d7c3f25a27.src","preCode":"  public void testIfNoneMatch()\n  {\n    Interval interval = Intervals.of(\"2016/2017\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                    .dataSource(DATA_SOURCE)\n                                    .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(interval)))\n                                    .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                    .build();\n\n\n    ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    Assert.assertEquals(\"MDs2yIUvYLVzaG6zmwTH1plqaYE=\", responseContext.get(ResponseContext.Key.ETAG));\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":2913,"status":"M"},{"authorDate":"2020-07-02 05:02:21","commitOrder":5,"curCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                          .dataSource(DATA_SOURCE)\n                                          .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                          .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                          .randomQueryId()\n                                          .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                           .dataSource(DATA_SOURCE)\n                                           .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                           .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                           .randomQueryId()\n                                           .build();\n\n\n    final ResponseContext responseContext = initializeResponseContext();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(ResponseContext.Key.ETAG);\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(ResponseContext.Key.ETAG);\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","date":"2020-07-02 05:02:21","endLine":3000,"groupId":"10895","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testEtagforDifferentQueryInterval","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/45/2dd8cadd6b4c232ab41fc0990812d7c3f25a27.src","preCode":"  public void testEtagforDifferentQueryInterval()\n  {\n    final Interval interval = Intervals.of(\"2016-01-01/2016-01-02\");\n    final Interval queryInterval = Intervals.of(\"2016-01-01T14:00:00/2016-01-02T14:00:00\");\n    final Interval queryInterval2 = Intervals.of(\"2016-01-01T18:00:00/2016-01-02T18:00:00\");\n    final DataSegment dataSegment = new DataSegment(\n        \"dataSource\",\n        interval,\n        \"ver\",\n        ImmutableMap.of(\n            \"type\", \"hdfs\",\n            \"path\", \"/tmp\"\n        ),\n        ImmutableList.of(\"product\"),\n        ImmutableList.of(\"visited_sum\"),\n        NoneShardSpec.instance(),\n        9,\n        12334\n    );\n    final ServerSelector selector = new ServerSelector(\n        dataSegment,\n        new HighestPriorityTierSelectorStrategy(new RandomServerSelectorStrategy())\n    );\n    selector.addServerAndUpdateSegment(new QueryableDruidServer(servers[0], null), dataSegment);\n    timeline.add(interval, \"ver\", new SingleElementPartitionChunk<>(selector));\n\n    final TimeBoundaryQuery query = Druids.newTimeBoundaryQueryBuilder()\n                                          .dataSource(DATA_SOURCE)\n                                          .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval)))\n                                          .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                          .build();\n\n    final TimeBoundaryQuery query2 = Druids.newTimeBoundaryQueryBuilder()\n                                           .dataSource(DATA_SOURCE)\n                                           .intervals(new MultipleIntervalSegmentSpec(ImmutableList.of(queryInterval2)))\n                                           .context(ImmutableMap.of(\"If-None-Match\", \"aVJV29CJY93rszVW/QBy0arWZo0=\"))\n                                           .build();\n\n\n    final ResponseContext responseContext = ResponseContext.createEmpty();\n\n    getDefaultQueryRunner().run(QueryPlus.wrap(query), responseContext);\n    final Object etag1 = responseContext.get(ResponseContext.Key.ETAG);\n    getDefaultQueryRunner().run(QueryPlus.wrap(query2), responseContext);\n    final Object etag2 = responseContext.get(ResponseContext.Key.ETAG);\n    Assert.assertNotEquals(etag1, etag2);\n  }\n","realPath":"server/src/test/java/org/apache/druid/client/CachingClusteredClientTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":2952,"status":"M"}],"commitId":"657f8ee80fa86779cf26a01072814b1530277aa7","commitMessage":"@@@Fix RetryQueryRunner to actually do the job (#10082)\n\n* Fix RetryQueryRunner to actually do the job\n\n* more javadoc\n\n* fix test and checkstyle\n\n* don't combine for testing\n\n* address comments\n\n* fix unit tests\n\n* always initialize response context in cachingClusteredClient\n\n* fix subquery\n\n* address comments\n\n* fix test\n\n* query id for builders\n\n* make queryId optional in the builders and ClusterQueryResult\n\n* fix test\n\n* suppress tests and unused methods\n\n* exclude groupBy builder\n\n* fix jacoco exclusion\n\n* add tests for builders\n\n* address comments\n\n* don't truncate","date":"2020-07-02 05:02:21","modifiedFileCount":"33","status":"M","submitter":"Jihoon Son"}]
