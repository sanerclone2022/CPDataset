[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":798,"groupId":"20292","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":747,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-10-07 07:45:07","commitOrder":2,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-10-07 07:45:07","endLine":802,"groupId":"15139","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/af/814d9f8497924ba6a3bac7c9b37ec1f3b7fa97.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":750,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"45aa51a00c642a501834e2dfe54d68cbab8e0464","commitMessage":"@@@Add support hash partitioning by a subset of dimensions to indexTask (#6326)\n\n* Add support hash partitioning by a subset of dimensions to indexTask\n\n* add doc\n\n* fix style\n\n* fix test\n\n* fix doc\n\n* fix build\n","date":"2018-10-07 07:45:07","modifiedFileCount":"9","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2019-01-11 01:50:14","commitOrder":3,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-01-11 01:50:14","endLine":805,"groupId":"4025","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/66/f0ec9d0c2e9ac9adeaccd6fccea8a95c9fa97f.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":752,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":3,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"c35a39d70bf705aa49c3a3c97bab87959bb80a4e","commitMessage":"@@@Add support maxRowsPerSegment for auto compaction (#6780)\n\n* Add support maxRowsPerSegment for auto compaction\n\n* fix build\n\n* fix build\n\n* fix teamcity\n\n* add test\n\n* fix test\n\n* address comment\n","date":"2019-01-11 01:50:14","modifiedFileCount":"33","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2019-03-16 14:29:25","commitOrder":4,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-03-16 14:29:25","endLine":797,"groupId":"3444","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/6f/2b99218a2649eb187fb0f28f22de2071f0c516.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":745,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":4,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"892d1d35d6cc00487d583f05f1cc138782180ef9","commitMessage":"@@@Deprecate NoneShardSpec and drop support for automatic segment merge (#6883)\n\n* Deprecate noneShardSpec\n\n* clean up noneShardSpec constructor\n\n* revert unnecessary change\n\n* Deprecate mergeTask\n\n* add more doc\n\n* remove convert from indexMerger\n\n* Remove mergeTask\n\n* remove HadoopDruidConverterConfig\n\n* fix build\n\n* fix build\n\n* fix teamcity\n\n* fix teamcity\n\n* fix ServerModule\n\n* fix compilation\n\n* fix compilation\n","date":"2019-03-16 14:29:25","modifiedFileCount":"40","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2019-07-11 03:22:24","commitOrder":5,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-07-11 03:22:24","endLine":799,"groupId":"10685","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d8/c0af320a9e289662a7bca7b017f48d54db856c.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":746,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":5,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"14aec7fceca90dfaf9b2ce4dae68186d04ffcc47","commitMessage":"@@@add config to optionally disable all compression  in intermediate segment persists while ingestion (#7919)\n\n* disable all compression in intermediate segment persists while ingestion\n\n* more changes and build fix\n\n* by default retain existing indexingSpec for intermediate persisted segments\n\n* document indexSpecForIntermediatePersists index tuning config\n\n* fix build issues\n\n* update serde tests\n","date":"2019-07-11 03:22:24","modifiedFileCount":"56","status":"M","submitter":"Himanshu"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2019-07-30 08:06:33","commitOrder":6,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-07-30 08:06:33","endLine":809,"groupId":"0","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/cb/320e8bcfb6ec45c7fa15f70b09b359ec8b92f9.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":755,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":6,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"640b7afc1cee911a27de7bf938dda24a85ba1510","commitMessage":"@@@Add CliIndexer process type and initial task runner implementation (#8107)\n\n* Add CliIndexer process type and initial task runner implementation\n\n* Fix HttpRemoteTaskRunnerTest\n\n* Remove batch sanity check on PeonAppenderatorsManager\n\n* Fix paralle index tests\n\n* PR comments\n\n* Adjust Jersey resource logging\n\n* Additional cleanup\n\n* Fix SystemSchemaTest\n\n* Add comment to LocalDataSegmentPusherTest absolute path test\n\n* More PR comments\n\n* Use Server annotated with RemoteChatHandler\n\n* More PR comments\n\n* Checkstyle\n\n* PR comments\n\n* Add task shutdown to stopGracefully\n\n* Small cleanup\n\n* Compile fix\n\n* Address PR comments\n\n* Adjust TaskReportFileWriter and fix nits\n\n* Remove unnecessary closer\n\n* More PR comments\n\n* Minor adjustments\n\n* PR comments\n\n* ThreadingTaskRunner: cancel  task run future not shutdownFuture and remove thread from workitem\n","date":"2019-07-30 08:06:33","modifiedFileCount":"64","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2019-07-31 08:24:39","commitOrder":7,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-07-31 08:24:39","endLine":809,"groupId":"14200","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8d/b01cbab5f776813e3581be3ed2cf1751999b87.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                true,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":755,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":7,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2018-08-31 00:56:26","endLine":1027,"groupId":"14600","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/e8debf718ced71c74552e50d9d420f45cdfee4.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":996,"status":"N"}],"commitId":"385f492a555add279a8c6dd368954fde18c41dcb","commitMessage":"@@@Use PartitionsSpec for all task types (#8141)\n\n* Use partitionsSpec for all task types\n\n* fix doc\n\n* fix typos and revert to use isPushRequired\n\n* address comments\n\n* move partitionsSpec to core\n\n* remove hadoopPartitionsSpec\n","date":"2019-07-31 08:24:39","modifiedFileCount":"29","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-13 08:42:06","codes":[{"authorDate":"2019-07-31 08:24:39","commitOrder":8,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-07-31 08:24:39","endLine":809,"groupId":"14200","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8d/b01cbab5f776813e3581be3ed2cf1751999b87.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":755,"status":"N"},{"authorDate":"2019-08-13 08:42:06","commitOrder":8,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-08-13 08:42:06","endLine":1063,"groupId":"14600","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/47/5b8ef6f68fddee2711cf7578da052f644ef8c5.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1027,"status":"M"}],"commitId":"312cdc245239aa1411665e91eaeeadfd13301d25","commitMessage":"@@@Add TaskResourceCleaner; fix a couple of concurrency bugs in batch tasks (#8236)\n\n* Add TaskResourceCleaner; fix a couple of concurrency bugs in batch tasks\n\n* kill runner when it's ready\n\n* add comment\n\n* kill run thread\n\n* fix test\n\n* Take closeable out of Appenderator\n\n* add javadoc\n\n* fix test\n\n* fix test\n\n* update javadoc\n\n* add javadoc about killed task\n\n* address comment\n\n* handling missing exceptions\n\n* more clear javadoc for stopGracefully\n\n* update javadoc\n\n* Add missing statement in javadoc\n\n* typo\n","date":"2019-08-13 08:42:06","modifiedFileCount":"20","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-16 05:57:02","codes":[{"authorDate":"2019-08-16 05:57:02","commitOrder":9,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-08-16 05:57:02","endLine":821,"groupId":"14200","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1a/e89f7a0a35e2067543a7012d74e3a171e672e6.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":766,"status":"M"},{"authorDate":"2019-08-16 05:57:02","commitOrder":9,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-08-16 05:57:02","endLine":1077,"groupId":"14600","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1a/e89f7a0a35e2067543a7012d74e3a171e672e6.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1040,"status":"M"}],"commitId":"ef7b9606f2137a7a724e65c52c28375ce0dff427","commitMessage":"@@@Keep track of task location for completed tasks (#8286)\n\n* Keep track of task location for completed tasks\n\n* Add TaskLifecycleTest location checks\n","date":"2019-08-16 05:57:02","modifiedFileCount":"8","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2019-08-16 05:57:02","commitOrder":10,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-08-16 05:57:02","endLine":821,"groupId":"14200","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1a/e89f7a0a35e2067543a7012d74e3a171e672e6.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":766,"status":"N"},{"authorDate":"2019-11-07 03:07:04","commitOrder":10,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment.builder()\n                                               .dataSource(\"ds\")\n                                               .interval(Intervals.of(\"2012-01-01/P1D\"))\n                                               .version(myLock.getVersion() + \"1!!!1!!\")\n                                               .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"M"}],"commitId":"5c0fc0a13ab4d259b430bf50b322f631504c4529","commitMessage":"@@@Fix ambiguity about IndexerSQLMetadataStorageCoordinator.getUsedSegmentsForInterval() returning only non-overshadowed or all used segments (#8564)\n\n* IndexerSQLMetadataStorageCoordinator.getTimelineForIntervalsWithHandle() don't fetch abutting intervals; simplify getUsedSegmentsForIntervals()\n\n* Add VersionedIntervalTimeline.findNonOvershadowedObjectsInInterval() method; Propagate the decision about whether only visible segmetns or visible and overshadowed segments should be returned from IndexerMetadataStorageCoordinator's methods to the user logic; Rename SegmentListUsedAction to RetrieveUsedSegmentsAction.  SegmetnListUnusedAction to RetrieveUnusedSegmentsAction.  and UsedSegmentLister to UsedSegmentsRetriever\n\n* Fix tests\n\n* More fixes\n\n* Add javadoc notes about returning Collection instead of Set. Add JacksonUtils.readValue() to reduce boilerplate code\n\n* Fix KinesisIndexTaskTest.  factor out common parts from KinesisIndexTaskTest and KafkaIndexTaskTest into SeekableStreamIndexTaskTestBase\n\n* More test fixes\n\n* More test fixes\n\n* Add a comment to VersionedIntervalTimelineTestBase\n\n* Fix tests\n\n* Set DataSegment.size(0) in more tests\n\n* Specify DataSegment.size(0) in more places in tests\n\n* Fix more tests\n\n* Fix DruidSchemaTest\n\n* Set DataSegment's size in more tests and benchmarks\n\n* Fix HdfsDataSegmentPusherTest\n\n* Doc changes addressing comments\n\n* Extended doc for visibility\n\n* Typo\n\n* Typo 2\n\n* Address comment\n","date":"2019-11-07 03:07:04","modifiedFileCount":"88","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2019-11-16 01:22:09","commitOrder":11,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-16 01:22:09","endLine":860,"groupId":"20292","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/38/d25dd2b1dada3146b84dddcaed36090f8dbf1c.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(new MockExceptionalFirehoseFactory(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":805,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":11,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"1611792855ad9def8b6f5b1375862d05d1acca0a","commitMessage":"@@@Add InputSource and InputFormat interfaces (#8823)\n\n* Add InputSource and InputFormat interfaces\n\n* revert orc dependency\n\n* fix dimension exclusions and failing unit tests\n\n* fix tests\n\n* fix test\n\n* fix test\n\n* fix firehose and inputSource for parallel indexing task\n\n* fix tc\n\n* fix tc: remove unused method\n\n* Formattable\n\n* add needsFormat(); renamed to ObjectSource; pass metricsName for reader\n\n* address comments\n\n* fix closing resource\n\n* fix checkstyle\n\n* fix tests\n\n* remove verify from csv\n\n* Revert \"remove verify from csv\"\n\nThis reverts commit 1ea7758489cc8c9d708bd691fd48e62085fd9455.\n\n* address comments\n\n* fix import order and javadoc\n\n* flatMap\n\n* sampleLine\n\n* Add IntermediateRowParsingReader\n\n* Address comments\n\n* move csv reader test\n\n* remove test for verify\n\n* adjust comments\n\n* Fix InputEntityIteratingReader\n\n* rename source -> entity\n\n* address comments\n","date":"2019-11-16 01:22:09","modifiedFileCount":"72","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2020-08-27 08:08:12","commitOrder":12,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2020-08-27 08:08:12","endLine":858,"groupId":"20292","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/99/ab9a480e9e22e0ff66f204d5b99f7fa005fd6d.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        null,\n        ROW_INGESTION_METERS_FACTORY,\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":807,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":12,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"f82fd22fa7de175200b7127c34c2eb2900bf7317","commitMessage":"@@@Move tools for indexing to TaskToolbox instead of injecting them in constructor (#10308)\n\n* Move tools for indexing to TaskToolbox instead of injecting them in constructor\n\n* oops.  other changes\n\n* fix test\n\n* unnecessary new file\n\n* fix test\n\n* fix build","date":"2020-08-27 08:08:12","modifiedFileCount":"67","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2020-10-24 09:34:26","commitOrder":13,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2020-10-24 09:34:26","endLine":860,"groupId":"20292","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/48/f75d7a82c32a4206662d6bdb878c3089b73bb3.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":808,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":13,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"f3a2903218573f5d336b082b1c9b8a60a19e8c54","commitMessage":"@@@Configurable Index Type (#10335)\n\n* Introduce a Configurable Index Type\n\n* Change to @UnstableApi\n\n* Add AppendableIndexSpecTest\n\n* Update doc\n\n* Add spelling exception\n\n* Add tests coverage\n\n* Revert some of the changes to reduce diff\n\n* Minor fixes\n\n* Update getMaxBytesInMemoryOrDefault() comment\n\n* Fix typo.  remove redundant interface\n\n* Remove off-heap spec (postponed to a later PR)\n\n* Add javadocs to AppendableIndexSpec\n\n* Describe testCreateTask()\n\n* Add tests for AppendableIndexSpec within TuningConfig\n\n* Modify hashCode() to conform with equals()\n\n* Add comment where building incremental-index\n\n* Add \"EqualsVerifier\" tests\n\n* Revert some of the API back to AppenderatorConfig\n\n* Don't use multi-line comments\n\n* Remove knob documentation (deferred)","date":"2020-10-24 09:34:26","modifiedFileCount":"72","status":"M","submitter":"Liran Funaro"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2021-01-06 14:19:09","commitOrder":14,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2021-01-06 14:19:09","endLine":862,"groupId":"20292","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d4/8520ad3bb8fe7e4f786a3c46982530b004adcb.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":809,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":14,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"68bb038b314c26bcc57aa96e1078c22d2f24fd35","commitMessage":"@@@Multiphase segment merge for IndexMergerV9 (#10689)\n\n* Multiphase merge for IndexMergerV9\n\n* JSON fix\n\n* Cleanup temp files\n\n* Docs\n\n* Address logging and add IT\n\n* Fix spelling and test unloader datasource name","date":"2021-01-06 14:19:09","modifiedFileCount":"40","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2021-01-27 16:34:56","commitOrder":15,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2021-01-27 16:34:56","endLine":864,"groupId":"20292","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/b8e3ef6274c2f6211a805c23cf31ce2e38f8bc.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":810,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":15,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"a46d561bd7e2b045a08a2e475847d4a7505a1c93","commitMessage":"@@@Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead (#10740)\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* fix checkstyle\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* fix test\n\n* fix test\n\n* add log\n\n* Fix byte calculation for maxBytesInMemory to take into account of Sink/Hydrant Object overhead\n\n* address comments\n\n* fix checkstyle\n\n* fix checkstyle\n\n* add config to skip overhead memory calculation\n\n* add test for the skipBytesInMemoryOverheadCheck config\n\n* add docs\n\n* fix checkstyle\n\n* fix checkstyle\n\n* fix spelling\n\n* address comments\n\n* fix travis\n\n* address comments","date":"2021-01-27 16:34:56","modifiedFileCount":"50","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2021-04-02 03:29:36","commitOrder":16,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false, false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2021-04-02 03:29:36","endLine":864,"groupId":"20292","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8f/220870c47400a785d224037a706510fad9493d.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":810,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":16,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"6262","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"d7f529336463dad273a742808b49d524bdc4ae11","commitMessage":"@@@Add an option for ingestion task to drop (mark unused) all existing segments that are contained by interval in the ingestionSpec (#11025)\n\n* Auto-Compaction can run indefinitely when segmentGranularity is changed from coarser to finer.\n\n* Add option to drop segments after ingestion\n\n* fix checkstyle\n\n* add tests\n\n* add tests\n\n* add tests\n\n* fix test\n\n* add tests\n\n* fix checkstyle\n\n* fix checkstyle\n\n* add docs\n\n* fix docs\n\n* address comments\n\n* address comments\n\n* fix spelling","date":"2021-04-02 03:29:36","modifiedFileCount":"44","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2019-11-07 03:07:04","codes":[{"authorDate":"2021-04-09 12:03:00","commitOrder":17,"curCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false, false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2021-04-09 12:03:00","endLine":866,"groupId":"104149","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexTaskFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e3/ba195fce1ad2a303473425f3b232e42be82210.src","preCode":"  public void testIndexTaskFailure() throws Exception\n  {\n    final Task indexTask = new IndexTask(\n        null,\n        null,\n        new IndexIngestionSpec(\n            new DataSchema(\n                \"foo\",\n                null,\n                new AggregatorFactory[]{new DoubleSumAggregatorFactory(\"met\", \"met\")},\n                new UniformGranularitySpec(\n                    Granularities.DAY,\n                    null,\n                    ImmutableList.of(Intervals.of(\"2010-01-01/P1D\"))\n                ),\n                null,\n                mapper\n            ),\n            new IndexIOConfig(null, new MockExceptionInputSource(), new NoopInputFormat(), false, false),\n            new IndexTuningConfig(\n                null,\n                10000,\n                null,\n                10,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                indexSpec,\n                null,\n                3,\n                false,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null,\n                null\n            )\n        ),\n        null\n    );\n\n    final TaskStatus status = runTask(indexTask);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"num segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"num segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":811,"status":"M"},{"authorDate":"2019-11-07 03:07:04","commitOrder":17,"curCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","date":"2019-11-07 03:07:04","endLine":1063,"groupId":"104149","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"testBadVersion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/4099eac7b05b146653677d2a76084b314afe7e.src","preCode":"  public void testBadVersion() throws Exception\n  {\n    final Task task = new AbstractFixedIntervalTask(\"id1\", \"id1\", \"ds\", Intervals.of(\"2012-01-01/P1D\"), null)\n    {\n      @Override\n      public String getType()\n      {\n        return \"test\";\n      }\n\n      @Override\n      public void stopGracefully(TaskConfig taskConfig)\n      {\n      }\n\n      @Override\n      public TaskStatus run(TaskToolbox toolbox) throws Exception\n      {\n        final TaskLock myLock = Iterables.getOnlyElement(toolbox.getTaskActionClient().submit(new LockListAction()));\n\n        final DataSegment segment = DataSegment\n            .builder()\n            .dataSource(\"ds\")\n            .interval(Intervals.of(\"2012-01-01/P1D\"))\n            .version(myLock.getVersion() + \"1!!!1!!\")\n            .size(0)\n            .build();\n\n        toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.of(segment)));\n        return TaskStatus.success(getId());\n      }\n    };\n\n    final TaskStatus status = runTask(task);\n\n    Assert.assertEquals(\"statusCode\", TaskState.FAILED, status.getStatusCode());\n    Assert.assertEquals(taskLocation, status.getLocation());\n    Assert.assertEquals(\"segments published\", 0, mdc.getPublished().size());\n    Assert.assertEquals(\"segments nuked\", 0, mdc.getNuked().size());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLifecycleTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1024,"status":"N"}],"commitId":"8264203cee688607091232897749e959e7706010","commitMessage":"@@@Allow client to configure batch ingestion task to wait to complete until segments are confirmed to be available by other (#10676)\n\n* Add ability to wait for segment availability for batch jobs\n\n* IT updates\n\n* fix queries in legacy hadoop IT\n\n* Fix broken indexing integration tests\n\n* address an lgtm flag\n\n* spell checker still flagging for hadoop doc. adding under that file header too\n\n* fix compaction IT\n\n* Updates to wait for availability method\n\n* improve unit testing for patch\n\n* fix bad indentation\n\n* refactor waitForSegmentAvailability\n\n* Fixes based off of review comments\n\n* cleanup to get compile after merging with master\n\n* fix failing test after previous logic update\n\n* add back code that must have gotten deleted during conflict resolution\n\n* update some logging code\n\n* fixes to get compilation working after merge with master\n\n* reset interrupt flag in catch block after code review pointed it out\n\n* small changes following self-review\n\n* fixup some issues brought on by merge with master\n\n* small changes after review\n\n* cleanup a little bit after merge with master\n\n* Fix potential resource leak in AbstractBatchIndexTask\n\n* syntax fix\n\n* Add a Compcation TuningConfig type\n\n* add docs stipulating the lack of support by Compaction tasks for the new config\n\n* Fixup compilation errors after merge with master\n\n* Remove erreneous newline","date":"2021-04-09 12:03:00","modifiedFileCount":"106","status":"M","submitter":"Lucas Capistrant"}]
