[{"authorTime":"2018-10-15 11:37:37","codes":[{"authorDate":"2018-10-11 08:17:29","commitOrder":5,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n\n    Pair<JavaType, JavaType> types = typesMap.get(query.getClass());\n    if (types == null) {\n      final TypeFactory typeFactory = objectMapper.getTypeFactory();\n      JavaType baseType = typeFactory.constructType(toolChest.getResultTypeReference());\n      JavaType bySegmentType = typeFactory.constructParametricType(\n          Result.class, typeFactory.constructParametricType(BySegmentResultValueClass.class, baseType)\n      );\n      types = Pair.of(baseType, bySegmentType);\n      typesMap.put(query.getClass(), types);\n    }\n\n    final JavaType typeRef;\n    if (isBySegment) {\n      typeRef = types.rhs;\n    } else {\n      typeRef = types.lhs;\n    }\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext, JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future, new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(typeRef, future, url, query, host, objectMapper);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2018-10-11 08:17:29","endLine":567,"groupId":"18978","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalMap<String@Object>context)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/da/2fb03b819c4699b96e452b663e706489733658.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n\n    Pair<JavaType, JavaType> types = typesMap.get(query.getClass());\n    if (types == null) {\n      final TypeFactory typeFactory = objectMapper.getTypeFactory();\n      JavaType baseType = typeFactory.constructType(toolChest.getResultTypeReference());\n      JavaType bySegmentType = typeFactory.constructParametricType(\n          Result.class, typeFactory.constructParametricType(BySegmentResultValueClass.class, baseType)\n      );\n      types = Pair.of(baseType, bySegmentType);\n      typesMap.put(query.getClass(), types);\n    }\n\n    final JavaType typeRef;\n    if (isBySegment) {\n      typeRef = types.rhs;\n    } else {\n      typeRef = types.lhs;\n    }\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext, JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future, new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(typeRef, future, url, query, host, objectMapper);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"NB"},{"authorDate":"2018-10-15 11:37:37","commitOrder":5,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2018-10-15 11:37:37","endLine":98,"groupId":"8913","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/cd/6a0ceea70cd15b0e55ebf88020288d7fa445e9.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"B"}],"commitId":"84598fba3b283cbfd6a5addd2602c7b12ba8c00c","commitMessage":"@@@combine druid-api.  druid-common.  java-util into druid-core (#6443)\n\n* combine druid-api.  druid-common.  java-util\n\n* spacing\n","date":"2018-10-15 11:37:37","modifiedFileCount":"0","status":"M","submitter":"Clint Wylie"},{"authorTime":"2018-10-15 11:37:37","codes":[{"authorDate":"2018-11-07 05:09:51","commitOrder":6,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n\n    Pair<JavaType, JavaType> types = typesMap.get(query.getClass());\n    if (types == null) {\n      final TypeFactory typeFactory = objectMapper.getTypeFactory();\n      JavaType baseType = typeFactory.constructType(toolChest.getResultTypeReference());\n      JavaType bySegmentType = typeFactory.constructParametricType(\n          Result.class,\n          typeFactory.constructParametricType(BySegmentResultValueClass.class, baseType)\n      );\n      types = Pair.of(baseType, bySegmentType);\n      typesMap.put(query.getClass(), types);\n    }\n\n    final JavaType typeRef;\n    if (isBySegment) {\n      typeRef = types.rhs;\n    } else {\n      typeRef = types.lhs;\n    }\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(typeRef, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2018-11-07 05:09:51","endLine":570,"groupId":"18978","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalMap<String@Object>context)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3f/86efd18c677def6306073755333bf0ca1392d2.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n\n    Pair<JavaType, JavaType> types = typesMap.get(query.getClass());\n    if (types == null) {\n      final TypeFactory typeFactory = objectMapper.getTypeFactory();\n      JavaType baseType = typeFactory.constructType(toolChest.getResultTypeReference());\n      JavaType bySegmentType = typeFactory.constructParametricType(\n          Result.class,\n          typeFactory.constructParametricType(BySegmentResultValueClass.class, baseType)\n      );\n      types = Pair.of(baseType, bySegmentType);\n      typesMap.put(query.getClass(), types);\n    }\n\n    final JavaType typeRef;\n    if (isBySegment) {\n      typeRef = types.rhs;\n    } else {\n      typeRef = types.lhs;\n    }\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(typeRef, future, url, query, host, objectMapper);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"M"},{"authorDate":"2018-10-15 11:37:37","commitOrder":6,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2018-10-15 11:37:37","endLine":98,"groupId":"8913","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/cd/6a0ceea70cd15b0e55ebf88020288d7fa445e9.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"bcb754d066cc8a140d4c67ae7d51a31ec8cc7554","commitMessage":"@@@Use current coordinator leader instead of cached one (#6551) (#6552)\n\n* Use current coordinator leader instead of cached one (#6551)\n\nCheck the response status and throw exception if not OK\n\n* Modify tests\n\n* PR comment\n\n* Add the correct check for status of BytesAccumulatingResponseHandler\n\n* Move the status check into JsonParserIterator so sql query outputs meaningful message on failure\n\n* Fix tests\n","date":"2018-11-07 05:09:51","modifiedFileCount":"5","status":"M","submitter":"Surekha"},{"authorTime":"2018-10-15 11:37:37","codes":[{"authorDate":"2019-02-05 01:18:12","commitOrder":7,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-02-05 01:18:12","endLine":544,"groupId":"18978","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalMap<String@Object>context)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/7f/73abf97c8f5808f207ea2fcbc5707a622bd928.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n\n    Pair<JavaType, JavaType> types = typesMap.get(query.getClass());\n    if (types == null) {\n      final TypeFactory typeFactory = objectMapper.getTypeFactory();\n      JavaType baseType = typeFactory.constructType(toolChest.getResultTypeReference());\n      JavaType bySegmentType = typeFactory.constructParametricType(\n          Result.class,\n          typeFactory.constructParametricType(BySegmentResultValueClass.class, baseType)\n      );\n      types = Pair.of(baseType, bySegmentType);\n      typesMap.put(query.getClass(), types);\n    }\n\n    final JavaType typeRef;\n    if (isBySegment) {\n      typeRef = types.rhs;\n    } else {\n      typeRef = types.lhs;\n    }\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(typeRef, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":146,"status":"M"},{"authorDate":"2018-10-15 11:37:37","commitOrder":7,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2018-10-15 11:37:37","endLine":98,"groupId":"8913","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/cd/6a0ceea70cd15b0e55ebf88020288d7fa445e9.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"0e926e865276f892ddc5b62685d331b822104022","commitMessage":"@@@Prohibit assigning concurrent maps into Map-typed variables and fields and fix a race condition in CoordinatorRuleManager (#6898)\n\n* Prohibit assigning concurrent maps into Map-types variables and fields; Fix a race condition in CoordinatorRuleManager; improve logic in DirectDruidClient and ResourcePool\n\n* Enforce that if compute().  computeIfAbsent().  computeIfPresent() or merge() is called on a ConcurrentHashMap.  it's stored in a ConcurrentHashMap-typed variable.  not ConcurrentMap; add comments explaining get()-before-computeIfAbsent() optimization; refactor Counters; fix a race condition in Intialization.java\n\n* Remove unnecessary comment\n\n* Checkstyle\n\n* Fix getFromExtensions()\n\n* Add a reference to the comment about guarded computeIfAbsent() optimization; IdentityHashMap optimization\n\n* Fix UriCacheGeneratorTest\n\n* Workaround issue with MaterializedViewQueryQueryToolChest\n\n* Strengthen Appenderator's contract regarding concurrency\n","date":"2019-02-05 01:18:12","modifiedFileCount":"101","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-03-15 05:28:33","commitOrder":8,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-03-15 05:28:33","endLine":543,"groupId":"8070","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalMap<String@Object>context)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d8/57a9ccc01e4d12a9626b6476c95569558ec25c.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw Throwables.propagate(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw Throwables.propagate(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw Throwables.propagate(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  Throwables.propagate(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":8,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw Throwables.propagate(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw Throwables.propagate(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"}],"commitId":"7ada1c49f9735a37808f3ed7656d93ae88b8b925","commitMessage":"@@@Prohibit Throwables.propagate() (#7121)\n\n* Throw caught exception.\n\n* Throw caught exceptions.\n\n* Related checkstyle rule is added to prevent further bugs.\n\n* RuntimeException() is used instead of Throwables.propagate().\n\n* Missing import is added.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* * Checkstyle definition is improved.\n* Throwables.propagate() usages are removed.\n\n* Checkstyle pattern is changed for only scanning \"Throwables.propagate(\" instead of checking lookbehind.\n\n* Throwable is kept before firing a Runtime Exception.\n\n* Fix unused assignments.\n","date":"2019-03-15 05:28:33","modifiedFileCount":"228","status":"M","submitter":"Furkan KAMACI"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-07-08 16:03:00","commitOrder":9,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-07-08 16:03:00","endLine":542,"groupId":"8070","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalMap<String@Object>context)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0d/b333533ad1330f1ff6bf85db6df9b0e79065c7.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      new StatusResponseHandler(StandardCharsets.UTF_8),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":144,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":9,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"N"}],"commitId":"6701dc08fe96e32edf49645a8f07cb17ee6038a3","commitMessage":"@@@Making StatusResponseHandler singleton and fixing all its instantiation invocations (#7969)\n\n* Making StatusResponseHandler singleton and fixing all its instantiation invocations\n\n* Using StatusResponseHandler.getInstance() where applicable\n","date":"2019-07-08 16:03:00","modifiedFileCount":"18","status":"M","submitter":"Sashidhar Thallam"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-07-24 23:29:03","commitOrder":10,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.CTX_QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.putAll(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-07-24 23:29:03","endLine":535,"groupId":"17242","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/98/802402ec8a2880fccea143a49912a4631b4021.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final Map<String, Object> context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(\"X-Druid-Response-Context\");\n            \r\n            if (responseContext != null) {\n              context.putAll(\n                  objectMapper.<Map<String, Object>>readValue(\n                      responseContext,\n                      JacksonUtils.TYPE_REFERENCE_MAP_STRING_OBJECT\n                  )\n              );\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":10,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"N"}],"commitId":"799d20249fe6333ea86b020f6d09c91fa4d3f998","commitMessage":"@@@Response context refactoring (#8110)\n\n* Response context refactoring\n\n* Serialization/Deserialization of ResponseContext\n\n* Added java doc comments\n\n* Renamed vars related to ResponseContext\n\n* Renamed empty() methods to createEmpty()\n\n* Fixed ResponseContext usage\n\n* Renamed multiple ResponseContext static fields\n\n* Added PublicApi annotations\n\n* Renamed QueryResponseContext class to ResourceIOReaderWriter\n\n* Moved the protected method below public static constants\n\n* Added createEmpty method to ResponseContext with DefaultResponseContext creation\n\n* Fixed inspection error\n\n* Added comments to the ResponseContext length limit and ResponseContext\nhttp header name\n\n* Added a comment of possible future refactoring\n\n* Removed .gitignore file of indexing-service\n\n* Removed a never-used method\n\n* VisibleForTesting method reducing boilerplate\n\nCo-Authored-By: Clint Wylie <cjwylie@gmail.com>\n\n* Reduced boilerplate\n\n* Renamed the method serialize to serializeWith\n\n* Removed unused import\n\n* Fixed incorrectly refactored test method\n\n* Added comments for ResponseContext keys\n\n* Fixed incorrectly refactored test method\n\n* Fixed IntervalChunkingQueryRunnerTest mocks\n","date":"2019-07-24 23:29:03","modifiedFileCount":"142","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-08-01 07:15:12","commitOrder":11,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.CTX_QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.putAll(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-08-01 07:15:12","endLine":543,"groupId":"17242","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ab/06f54126a80bad3b27a5ff46a9582ccb2fa654.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.CTX_QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.putAll(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(queryResultType, future, url, query, host, objectMapper, null);\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":11,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"N"}],"commitId":"77297f4e6f2e9d617c96cd46852bb5a772961e85","commitMessage":"@@@GroupBy array-based result rows. (#8196)\n\n* GroupBy array-based result rows.\n\nFixes #8118; see that proposal for details.\n\nOther than the GroupBy changes.  the main other \"interesting\" classes are:\n\n- ResultRow: The array-based result type.\n- BaseQuery: T is no longer required to be Comparable.\n- QueryToolChest: Adds \"decorateObjectMapper\" to enable query-aware serialization\n  and deserialization of result rows (necessary due to their positional nature).\n- QueryResource: Uses the new decoration functionality.\n- DirectDruidClient: Also uses the new decoration functionality.\n- QueryMaker (in Druid SQL): Modifications to read ResultRows.\n\nThese classes weren't changed.  but got some new javadocs:\n\n- BySegmentQueryRunner\n- FinalizeResultsQueryRunner\n- Query\n\n* Adjustments for TC stuff.\n","date":"2019-08-01 07:15:12","modifiedFileCount":"111","status":"M","submitter":"Gian Merlino"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-08-03 17:05:21","commitOrder":12,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-08-03 17:05:21","endLine":543,"groupId":"2790","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/4c/5017435e69fe4e50df8c3e127b3ca79e79db96.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.CTX_QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.putAll(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":12,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"N"}],"commitId":"3f3162b85e269749bf0aa848f435409b3a1db8fe","commitMessage":"@@@Enum of ResponseContext keys (#8157)\n\n* Refactored ResponseContext and aggregated its keys into Enum\n\n* Added unit tests for ResponseContext and refactored the serialization\n\n* Removed unused methods\n\n* Fixed code style\n\n* Fixed code style\n\n* Fixed code style\n\n* Made SerializationResult static\n\n* Updated according to the PR discussion:\n\nRenamed an argument\n\nUpdated comparator\n\nReplaced Pair usage with Map.Entry\n\nAdded a comment about quadratic complexity\n\nRemoved boolean field with an expression\n\nRenamed SerializationResult field\n\nRenamed the method merge to add and renamed several context keys\n\nRenamed field and method related to scanRowsLimit\n\nUpdated a comment\n\nSimplified a block of code\n\nRenamed a variable\n\n* Added JsonProperty annotation to renamed ScanQuery field\n\n* Extension-friendly context key implementation\n\n* Refactored ResponseContext: updated delegate type.  comments and exceptions\n\nReducing serialized context length by removing some of its'\ncollection elements\n\n* Fixed tests\n\n* Simplified response context truncation during serialization\n\n* Extracted a method of removing elements from a response context and\nadded some comments\n\n* Fixed typos and updated comments\n","date":"2019-08-03 17:05:21","modifiedFileCount":"28","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-08-19 16:19:44","commitOrder":13,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        query,\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-08-19 16:19:44","endLine":544,"groupId":"2790","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/bdde4094d0fa232bea21d7a971bf0fe470fb25.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":13,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-03-15 05:28:33","endLine":97,"groupId":"0","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/3a0d2aed6718261f8d26b7780db8ad4e48950f.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"N"}],"commitId":"566dc8c719489283f9190cefd6346bbb3f12955f","commitMessage":"@@@Fix missing format argument (#8331)\n\n","date":"2019-08-19 16:19:44","modifiedFileCount":"2","status":"M","submitter":"Benedict Jin"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2019-08-19 16:19:44","commitOrder":14,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        query,\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-08-19 16:19:44","endLine":544,"groupId":"2790","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/bdde4094d0fa232bea21d7a971bf0fe470fb25.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        query,\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"N"},{"authorDate":"2019-08-20 17:55:41","commitOrder":14,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    try {\n      queue.put(new ChannelBufferInputStream(response.getContent()));\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"781873ba53a43db50e99e6f21180f748b3c65919","commitMessage":"@@@Fix resource leak (#8337)\n\n* Fix resource leak\n\n* Patch comments\n","date":"2019-08-20 17:55:41","modifiedFileCount":"8","status":"M","submitter":"Benedict Jin"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2019-11-08 02:12:18","commitOrder":15,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2019-11-08 02:12:18","endLine":522,"groupId":"2790","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/06/976c1a5b4149f985280db78b2795205e076496.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                \r\n                try {\n                  StatusResponseHolder res = httpClient.go(\n                      new Request(\n                          HttpMethod.DELETE,\n                          new URL(cancelUrl)\n                      ).setContent(objectMapper.writeValueAsBytes(query))\n                       .setHeader(\n                           HttpHeaders.Names.CONTENT_TYPE,\n                           isSmile\n                           ? SmileMediaTypes.APPLICATION_JACKSON_SMILE\n                           : MediaType.APPLICATION_JSON\n                       ),\n                      StatusResponseHandler.getInstance(),\n                      Duration.standardSeconds(1)\n                  ).get(1, TimeUnit.SECONDS);\n\n                  if (res.getStatus().getCode() >= 500) {\n                    throw new RE(\n                        \"Error cancelling query[%s]: queriable node returned status[%d] [%s].\",\n                        query,\n                        res.getStatus().getCode(),\n                        res.getStatus().getReasonPhrase()\n                    );\n                  }\n                }\n                catch (IOException | ExecutionException | InterruptedException | TimeoutException e) {\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n          }\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":146,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":15,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"a9aa416c3d52f5a4e2786bd6f1dada100e0bfda5","commitMessage":"@@@In DirectDruidClient.  don't run Future cancellation listener in? (#8700)\n\n* In DirectDruidClient.  don't run Future cancellation listener in HTTP library executor\n\n* extract cancelQuery as a method of DirectDruidClient\n\n* Fix testCancel\n\n* Add exception as the first argument to log.error\n","date":"2019-11-08 02:12:18","modifiedFileCount":"2","status":"M","submitter":"Zhenxiao Luo"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2020-03-10 17:57:16","commitOrder":16,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2020-03-10 17:57:16","endLine":522,"groupId":"2790","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/02/0446d69f84757686747d4183cb5282ab3b9280.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQuery(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":146,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":16,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"8b9fe6f58461f1fc3f453c14f1634f9e779aeb71","commitMessage":"@@@query laning and load shedding (#9407)\n\n* prototype\n\n* merge QueryScheduler and QueryManager\n\n* everything in its right place\n\n* adjustments\n\n* docs\n\n* fixes\n\n* doc fixes\n\n* use resilience4j instead of semaphore\n\n* more tests\n\n* simplify\n\n* checkstyle\n\n* spelling\n\n* oops heh\n\n* remove unused\n\n* simplify\n\n* concurrency tests\n\n* add SqlResource tests.  refactor error response\n\n* add json config tests\n\n* use LongAdder instead of AtomicLong\n\n* remove test only stuffs from scheduler\n\n* javadocs.  etc\n\n* style\n\n* partial review stuffs\n\n* adjust\n\n* review stuffs\n\n* more javadoc\n\n* error response documentation\n\n* spelling\n\n* preserve user specified lane for NoSchedulingStrategy\n\n* more test.  why not\n\n* doc adjustment\n\n* style\n\n* missed review for make a thing a constant\n\n* fixes and tests\n\n* fix test\n\n* Update docs/configuration/index.md\n\nCo-Authored-By: sthetland <steve.hetland@imply.io>\n\n* doc update\n\nCo-authored-by: sthetland <steve.hetland@imply.io>","date":"2020-03-10 17:57:16","modifiedFileCount":"26","status":"M","submitter":"Clint Wylie"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2020-07-02 05:02:21","commitOrder":17,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      \r\n      \r\n      final Query<T> queryToSend = QueryContexts.setFailOnTruncatedResponseContext(\n          QueryContexts.withTimeout(query, timeLeft)\n      );\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(queryToSend))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2020-07-02 05:02:21","endLine":544,"groupId":"12308","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e9/dd1cad5ac36b888a9b9e2b8c24a2b2a1640dc9.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":17,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"657f8ee80fa86779cf26a01072814b1530277aa7","commitMessage":"@@@Fix RetryQueryRunner to actually do the job (#10082)\n\n* Fix RetryQueryRunner to actually do the job\n\n* more javadoc\n\n* fix test and checkstyle\n\n* don't combine for testing\n\n* address comments\n\n* fix unit tests\n\n* always initialize response context in cachingClusteredClient\n\n* fix subquery\n\n* address comments\n\n* fix test\n\n* query id for builders\n\n* make queryId optional in the builders and ClusterQueryResult\n\n* fix test\n\n* suppress tests and unused methods\n\n* exclude groupBy builder\n\n* fix jacoco exclusion\n\n* add tests for builders\n\n* address comments\n\n* don't truncate","date":"2020-07-02 05:02:21","modifiedFileCount":"33","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2020-07-09 04:28:11","commitOrder":18,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2020-07-09 04:28:11","endLine":538,"groupId":"12308","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/65/1ae635049244cac22e0ad18cf63861b2d5d5be.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      \r\n      \r\n      final Query<T> queryToSend = QueryContexts.setFailOnTruncatedResponseContext(\n          QueryContexts.withTimeout(query, timeLeft)\n      );\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(queryToSend))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":18,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"53a25505719f05b7041c35b2cb783dcb1466c7cd","commitMessage":"@@@Follow-up for RetryQueryRunner fix (#10144)\n\n* address comments; use guice instead of query context\n\n* typo\n\n* QueryResource tests\n\n* address comments\n\n* catch queryException\n\n* fix spell check","date":"2020-07-09 04:28:11","modifiedFileCount":"12","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2020-08-15 01:51:18","commitOrder":19,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2020-08-15 01:51:18","endLine":537,"groupId":"12308","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/fa/6c45e9af3f3c07c741183d16cc02f875b857c9.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query),\n                null\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":19,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"12ae84165e8da0d775f5e5e1c5c042d903f260f4","commitMessage":"@@@remove DruidLeaderClient.goAsync(..) that does not follow redirect. Replace its usage by DruidLeaderClient.go(..) with InputStreamFullResponseHandler (#9717)\n\n* remove DruidLeaderClient.goAsync(..) that does not follow redirect.\nReplace its usage by DruidLeaadereClient.go(..) with\nInputStreamFullResponseHandler\n\n* remove ByteArrayResponseHolder dependency from JsonParserIterator\n\n* add UT to cover lines in InputStreamFullResponseHandler\n\n* refactor SystemSchema to reduce branches\n\n* further reduce branches\n\n* Revert \"add UT to cover lines in InputStreamFullResponseHandler\"\n\nThis reverts commit 330aba3dd98ce15a13cd6ca607824bc07036ee81.\n\n* UTs for InputStreamFullResponseHandler\n\n* remove unused imports","date":"2020-08-15 01:51:18","modifiedFileCount":"10","status":"M","submitter":"Himanshu"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2020-11-03 23:00:33","commitOrder":20,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new QueryTimeoutException(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2020-11-03 23:00:33","endLine":538,"groupId":"5091","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/c5d78f4c8a7101c8e123ecfa35c3f565df702a.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new RE(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":20,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"6ccddedb7a1752dc130d939066b04da16eb6b1bd","commitMessage":"@@@Improved exception handling in case of query timeouts (#10464)\n\n* Separate timeout exceptions\n\n* Add more tests\n\nCo-authored-by: Atul Mohan <atulmohan@yahoo-inc.com>","date":"2020-11-03 23:00:33","modifiedFileCount":"25","status":"M","submitter":"Atul Mohan"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2021-01-14 09:20:00","commitOrder":21,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new QueryTimeoutException(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new ResourceLimitExceededException(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2021-01-14 09:20:00","endLine":539,"groupId":"5091","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/23/b9f046d12873ddaeb4b8a88803d91e024d7f80.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new QueryTimeoutException(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new RE(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":21,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"9157","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"149306c9db2daf65d9e10fc632aa1240b4f7d208","commitMessage":"@@@Tidy up HTTP status codes for query errors (#10746)\n\n* Tidy up query error codes\n\n* fix tests\n\n* Restore query exception type in JsonParserIterator\n\n* address review comments; add a comment explaining the ugly switch\n\n* fix test","date":"2021-01-14 09:20:00","modifiedFileCount":"24","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-20 17:55:41","codes":[{"authorDate":"2021-03-17 13:06:26","commitOrder":22,"curCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = scheme + \"://\" + host + \"/druid/v2/\";\n    final String cancelUrl = url + query.getId();\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new QueryTimeoutException(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new ResourceLimitExceededException(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","date":"2021-03-17 13:06:26","endLine":539,"groupId":"101240","id":35,"instanceNumber":1,"isCurCommit":1,"methodName":"run","params":"(finalQueryPlus<T>queryPlus@finalResponseContextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/75/a2a4507e417c26f1df815e67991fab728ce260.src","preCode":"  public Sequence<T> run(final QueryPlus<T> queryPlus, final ResponseContext context)\n  {\n    final Query<T> query = queryPlus.getQuery();\n    QueryToolChest<T, Query<T>> toolChest = warehouse.getToolChest(query);\n    boolean isBySegment = QueryContexts.isBySegment(query);\n    final JavaType queryResultType = isBySegment ? toolChest.getBySegmentResultType() : toolChest.getBaseResultType();\n\n    final ListenableFuture<InputStream> future;\n    final String url = StringUtils.format(\"%s://%s/druid/v2/\", scheme, host);\n    final String cancelUrl = StringUtils.format(\"%s://%s/druid/v2/%s\", scheme, host, query.getId());\n\n    try {\n      log.debug(\"Querying queryId[%s] url[%s]\", query.getId(), url);\n\n      final long requestStartTimeNs = System.nanoTime();\n      final long timeoutAt = query.getContextValue(QUERY_FAIL_TIME);\n      final long maxScatterGatherBytes = QueryContexts.getMaxScatterGatherBytes(query);\n      final AtomicLong totalBytesGathered = (AtomicLong) context.get(ResponseContext.Key.QUERY_TOTAL_BYTES_GATHERED);\n      final long maxQueuedBytes = QueryContexts.getMaxQueuedBytes(query, 0);\n      final boolean usingBackpressure = maxQueuedBytes > 0;\n\n      final HttpResponseHandler<InputStream, InputStream> responseHandler = new HttpResponseHandler<InputStream, InputStream>()\n      {\n        private final AtomicLong totalByteCount = new AtomicLong(0);\n        private final AtomicLong queuedByteCount = new AtomicLong(0);\n        private final AtomicLong channelSuspendedTime = new AtomicLong(0);\n        private final BlockingQueue<InputStreamHolder> queue = new LinkedBlockingQueue<>();\n        private final AtomicBoolean done = new AtomicBoolean(false);\n        private final AtomicReference<String> fail = new AtomicReference<>();\n        private final AtomicReference<TrafficCop> trafficCopRef = new AtomicReference<>();\n\n        private QueryMetrics<? super Query<T>> queryMetrics;\n        private long responseStartTimeNs;\n\n        private QueryMetrics<? super Query<T>> acquireResponseMetrics()\n        {\n          if (queryMetrics == null) {\n            queryMetrics = toolChest.makeMetrics(query);\n            queryMetrics.server(host);\n          }\n          return queryMetrics;\n        }\n\n        \r\n\n        private boolean enqueue(ChannelBuffer buffer, long chunkNum) throws InterruptedException\n        {\n          \r\n          \r\n          final InputStreamHolder holder = InputStreamHolder.fromChannelBuffer(buffer, chunkNum);\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(holder.getLength());\n          queue.put(holder);\n\n          \r\n          return !usingBackpressure || currentQueuedByteCount < maxQueuedBytes;\n        }\n\n        private InputStream dequeue() throws InterruptedException\n        {\n          final InputStreamHolder holder = queue.poll(checkQueryTimeout(), TimeUnit.MILLISECONDS);\n          if (holder == null) {\n            throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n          }\n\n          final long currentQueuedByteCount = queuedByteCount.addAndGet(-holder.getLength());\n          if (usingBackpressure && currentQueuedByteCount < maxQueuedBytes) {\n            long backPressureTime = Preconditions.checkNotNull(trafficCopRef.get(), \"No TrafficCop, how can this be?\")\n                                                 .resume(holder.getChunkNum());\n            channelSuspendedTime.addAndGet(backPressureTime);\n          }\n\n          return holder.getStream();\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n        {\n          trafficCopRef.set(trafficCop);\n          checkQueryTimeout();\n          checkTotalBytesLimit(response.getContent().readableBytes());\n\n          log.debug(\"Initial response from url[%s] for queryId[%s]\", url, query.getId());\n          responseStartTimeNs = System.nanoTime();\n          acquireResponseMetrics().reportNodeTimeToFirstByte(responseStartTimeNs - requestStartTimeNs).emit(emitter);\n\n          final boolean continueReading;\n          try {\n            log.trace(\n                \"Got a response from [%s] for query ID[%s], subquery ID[%s]\",\n                url,\n                query.getId(),\n                query.getSubQueryId()\n            );\n            final String responseContext = response.headers().get(QueryResource.HEADER_RESPONSE_CONTEXT);\n            context.add(\n                ResponseContext.Key.REMAINING_RESPONSES_FROM_QUERY_SERVERS,\n                new NonnullPair<>(query.getMostSpecificId(), VAL_TO_REDUCE_REMAINING_RESPONSES)\n            );\n            \r\n            if (responseContext != null) {\n              context.merge(ResponseContext.deserialize(responseContext, objectMapper));\n            }\n            continueReading = enqueue(response.getContent(), 0L);\n          }\n          catch (final IOException e) {\n            log.error(e, \"Error parsing response context from url [%s]\", url);\n            return ClientResponse.finished(\n                new InputStream()\n                {\n                  @Override\n                  public int read() throws IOException\n                  {\n                    throw e;\n                  }\n                }\n            );\n          }\n          catch (InterruptedException e) {\n            log.error(e, \"Queue appending interrupted\");\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n          }\n          totalByteCount.addAndGet(response.getContent().readableBytes());\n          return ClientResponse.finished(\n              new SequenceInputStream(\n                  new Enumeration<InputStream>()\n                  {\n                    @Override\n                    public boolean hasMoreElements()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n                      checkQueryTimeout();\n\n                      \r\n                      \r\n                      synchronized (done) {\n                        return !done.get() || !queue.isEmpty();\n                      }\n                    }\n\n                    @Override\n                    public InputStream nextElement()\n                    {\n                      if (fail.get() != null) {\n                        throw new RE(fail.get());\n                      }\n\n                      try {\n                        return dequeue();\n                      }\n                      catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                        throw new RuntimeException(e);\n                      }\n                    }\n                  }\n              ),\n              continueReading\n          );\n        }\n\n        @Override\n        public ClientResponse<InputStream> handleChunk(\n            ClientResponse<InputStream> clientResponse,\n            HttpChunk chunk,\n            long chunkNum\n        )\n        {\n          checkQueryTimeout();\n\n          final ChannelBuffer channelBuffer = chunk.getContent();\n          final int bytes = channelBuffer.readableBytes();\n\n          checkTotalBytesLimit(bytes);\n\n          boolean continueReading = true;\n          if (bytes > 0) {\n            try {\n              continueReading = enqueue(channelBuffer, chunkNum);\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            totalByteCount.addAndGet(bytes);\n          }\n\n          return ClientResponse.finished(clientResponse.getObj(), continueReading);\n        }\n\n        @Override\n        public ClientResponse<InputStream> done(ClientResponse<InputStream> clientResponse)\n        {\n          long stopTimeNs = System.nanoTime();\n          long nodeTimeNs = stopTimeNs - requestStartTimeNs;\n          final long nodeTimeMs = TimeUnit.NANOSECONDS.toMillis(nodeTimeNs);\n          log.debug(\n              \"Completed queryId[%s] request to url[%s] with %,d bytes returned in %,d millis [%,f b/s].\",\n              query.getId(),\n              url,\n              totalByteCount.get(),\n              nodeTimeMs,\n              \r\n              totalByteCount.get() / (0.001 * nodeTimeMs)\n          );\n          QueryMetrics<? super Query<T>> responseMetrics = acquireResponseMetrics();\n          responseMetrics.reportNodeTime(nodeTimeNs);\n          responseMetrics.reportNodeBytes(totalByteCount.get());\n\n          if (usingBackpressure) {\n            responseMetrics.reportBackPressureTime(channelSuspendedTime.get());\n          }\n\n          responseMetrics.emit(emitter);\n          synchronized (done) {\n            try {\n              \r\n              \r\n              queue.put(InputStreamHolder.fromChannelBuffer(ChannelBuffers.EMPTY_BUFFER, Long.MAX_VALUE));\n            }\n            catch (InterruptedException e) {\n              log.error(e, \"Unable to put finalizing input stream into Sequence queue for url [%s]\", url);\n              Thread.currentThread().interrupt();\n              throw new RuntimeException(e);\n            }\n            finally {\n              done.set(true);\n            }\n          }\n          return ClientResponse.finished(clientResponse.getObj());\n        }\n\n        @Override\n        public void exceptionCaught(final ClientResponse<InputStream> clientResponse, final Throwable e)\n        {\n          String msg = StringUtils.format(\n              \"Query[%s] url[%s] failed with exception msg [%s]\",\n              query.getId(),\n              url,\n              e.getMessage()\n          );\n          setupResponseReadFailure(msg, e);\n        }\n\n        private void setupResponseReadFailure(String msg, Throwable th)\n        {\n          fail.set(msg);\n          queue.clear();\n          queue.offer(\n              InputStreamHolder.fromStream(\n                  new InputStream()\n                  {\n                    @Override\n                    public int read() throws IOException\n                    {\n                      if (th != null) {\n                        throw new IOException(msg, th);\n                      } else {\n                        throw new IOException(msg);\n                      }\n                    }\n                  },\n                  -1,\n                  0\n              )\n          );\n        }\n\n        \r\n        private long checkQueryTimeout()\n        {\n          long timeLeft = timeoutAt - System.currentTimeMillis();\n          if (timeLeft <= 0) {\n            String msg = StringUtils.format(\"Query[%s] url[%s] timed out.\", query.getId(), url);\n            setupResponseReadFailure(msg, null);\n            throw new QueryTimeoutException(msg);\n          } else {\n            return timeLeft;\n          }\n        }\n\n        private void checkTotalBytesLimit(long bytes)\n        {\n          if (maxScatterGatherBytes < Long.MAX_VALUE && totalBytesGathered.addAndGet(bytes) > maxScatterGatherBytes) {\n            String msg = StringUtils.format(\n                \"Query[%s] url[%s] max scatter-gather bytes limit reached.\",\n                query.getId(),\n                url\n            );\n            setupResponseReadFailure(msg, null);\n            throw new ResourceLimitExceededException(msg);\n          }\n        }\n      };\n\n      long timeLeft = timeoutAt - System.currentTimeMillis();\n\n      if (timeLeft <= 0) {\n        throw new QueryTimeoutException(StringUtils.nonStrictFormat(\"Query[%s] url[%s] timed out.\", query.getId(), url));\n      }\n\n      future = httpClient.go(\n          new Request(\n              HttpMethod.POST,\n              new URL(url)\n          ).setContent(objectMapper.writeValueAsBytes(QueryContexts.withTimeout(query, timeLeft)))\n           .setHeader(\n               HttpHeaders.Names.CONTENT_TYPE,\n               isSmile ? SmileMediaTypes.APPLICATION_JACKSON_SMILE : MediaType.APPLICATION_JSON\n           ),\n          responseHandler,\n          Duration.millis(timeLeft)\n      );\n\n      queryWatcher.registerQueryFuture(query, future);\n\n      openConnections.getAndIncrement();\n      Futures.addCallback(\n          future,\n          new FutureCallback<InputStream>()\n          {\n            @Override\n            public void onSuccess(InputStream result)\n            {\n              openConnections.getAndDecrement();\n            }\n\n            @Override\n            public void onFailure(Throwable t)\n            {\n              openConnections.getAndDecrement();\n              if (future.isCancelled()) {\n                cancelQuery(query, cancelUrl);\n              }\n            }\n          },\n          \r\n          Execs.directExecutor()\n      );\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    Sequence<T> retVal = new BaseSequence<>(\n        new BaseSequence.IteratorMaker<T, JsonParserIterator<T>>()\n        {\n          @Override\n          public JsonParserIterator<T> make()\n          {\n            return new JsonParserIterator<T>(\n                queryResultType,\n                future,\n                url,\n                query,\n                host,\n                toolChest.decorateObjectMapper(objectMapper, query)\n            );\n          }\n\n          @Override\n          public void cleanup(JsonParserIterator<T> iterFromMake)\n          {\n            CloseQuietly.close(iterFromMake);\n          }\n        }\n    );\n\n    \r\n    \r\n    if (!isBySegment) {\n      retVal = Sequences.map(\n          retVal,\n          toolChest.makePreComputeManipulatorFn(\n              query,\n              MetricManipulatorFns.deserializing()\n          )\n      );\n    }\n\n    return retVal;\n  }\n","realPath":"server/src/main/java/org/apache/druid/client/DirectDruidClient.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"M"},{"authorDate":"2019-08-20 17:55:41","commitOrder":22,"curCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","date":"2019-08-20 17:55:41","endLine":103,"groupId":"101240","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"handleResponse","params":"(HttpResponseresponse@TrafficCoptrafficCop)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c3/247d69832bef7763d219f167be4a7744fb03a4.src","preCode":"  public ClientResponse<InputStream> handleResponse(HttpResponse response, TrafficCop trafficCop)\n  {\n    ChannelBufferInputStream channelStream = null;\n    try {\n      channelStream = new ChannelBufferInputStream(response.getContent());\n      queue.put(channelStream);\n    }\n    catch (InterruptedException e) {\n      log.error(e, \"Queue appending interrupted\");\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(e);\n    }\n    finally {\n      CloseQuietly.close(channelStream);\n    }\n    byteCount.addAndGet(response.getContent().readableBytes());\n    return ClientResponse.finished(\n        new SequenceInputStream(\n            new Enumeration<InputStream>()\n            {\n              @Override\n              public boolean hasMoreElements()\n              {\n                \r\n                \r\n                synchronized (done) {\n                  return !done.get() || !queue.isEmpty();\n                }\n              }\n\n              @Override\n              public InputStream nextElement()\n              {\n                try {\n                  return queue.take();\n                }\n                catch (InterruptedException e) {\n                  log.warn(e, \"Thread interrupted while taking from queue\");\n                  Thread.currentThread().interrupt();\n                  throw new RuntimeException(e);\n                }\n              }\n            }\n        )\n    );\n  }\n","realPath":"core/src/main/java/org/apache/druid/java/util/http/client/response/SequenceInputStreamResponseHandler.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"1061faa6ba97106aec79d48aac158e88faa965c8","commitMessage":"@@@prefer string concatenation over String.format in performance sensitive code (#10997)\n\nString.format relies on regex parsing.  which makes these calls expensive\nat higher request volumes.","date":"2021-03-17 13:06:26","modifiedFileCount":"5","status":"M","submitter":"Xavier L?aut?"}]
