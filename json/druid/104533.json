[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testBasics() throws Exception\n  {\n    expectPublishedSegments(1);\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    \r\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","date":"2018-08-31 00:56:26","endLine":402,"groupId":"12758","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testBasics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1e/fcd94da19dd9f05cce3027a3abada825548097.src","preCode":"  public void testBasics() throws Exception\n  {\n    expectPublishedSegments(1);\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    \r\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":344,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testTransformSpec() throws Exception\n  {\n    expectPublishedSegments(2);\n\n    final TransformSpec transformSpec = new TransformSpec(\n        new SelectorDimFilter(\"dim1\", \"foo\", null),\n        ImmutableList.of(\n            new ExpressionTransform(\"dim1t\", \"concat(dim1,dim1)\", ExprMacroTable.nil())\n        )\n    );\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null, transformSpec, true, 0, true, 0, 1);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.minus(new Period(\"P1D\")).getMillis(), \"dim1\", \"foo\", \"met1\", 2.0),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(1, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(2, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"foofoo\", null), \"rows\").longValue());\n    if (NullHandling.replaceWithDefault()) {\n      Assert.assertEquals(0, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\").longValue());\n    } else {\n      Assert.assertNull(sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\"));\n    }\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","date":"2018-08-31 00:56:26","endLine":603,"groupId":"6580","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testTransformSpec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1e/fcd94da19dd9f05cce3027a3abada825548097.src","preCode":"  public void testTransformSpec() throws Exception\n  {\n    expectPublishedSegments(2);\n\n    final TransformSpec transformSpec = new TransformSpec(\n        new SelectorDimFilter(\"dim1\", \"foo\", null),\n        ImmutableList.of(\n            new ExpressionTransform(\"dim1t\", \"concat(dim1,dim1)\", ExprMacroTable.nil())\n        )\n    );\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null, transformSpec, true, 0, true, 0, 1);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.minus(new Period(\"P1D\")).getMillis(), \"dim1\", \"foo\", \"met1\", 2.0),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(1, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(2, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"foofoo\", null), \"rows\").longValue());\n    if (NullHandling.replaceWithDefault()) {\n      Assert.assertEquals(0, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\").longValue());\n    } else {\n      Assert.assertNull(sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\"));\n    }\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":532,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2020-06-09 11:15:59","commitOrder":2,"curCode":"  public void testBasics() throws Exception\n  {\n    expectPublishedSegments(1);\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null);\n    Assert.assertTrue(task.supportsQueries());\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    \r\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","date":"2020-06-09 11:15:59","endLine":395,"groupId":"104533","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testBasics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/51/3a590be9fd2ef14c1f57e01ca8728e5dc257aa.src","preCode":"  public void testBasics() throws Exception\n  {\n    expectPublishedSegments(1);\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    \r\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":336,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void testTransformSpec() throws Exception\n  {\n    expectPublishedSegments(2);\n\n    final TransformSpec transformSpec = new TransformSpec(\n        new SelectorDimFilter(\"dim1\", \"foo\", null),\n        ImmutableList.of(\n            new ExpressionTransform(\"dim1t\", \"concat(dim1,dim1)\", ExprMacroTable.nil())\n        )\n    );\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null, transformSpec, true, 0, true, 0, 1);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.minus(new Period(\"P1D\")).getMillis(), \"dim1\", \"foo\", \"met1\", 2.0),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(1, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(2, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"foofoo\", null), \"rows\").longValue());\n    if (NullHandling.replaceWithDefault()) {\n      Assert.assertEquals(0, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\").longValue());\n    } else {\n      Assert.assertNull(sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\"));\n    }\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","date":"2018-08-31 00:56:26","endLine":603,"groupId":"104533","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testTransformSpec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1e/fcd94da19dd9f05cce3027a3abada825548097.src","preCode":"  public void testTransformSpec() throws Exception\n  {\n    expectPublishedSegments(2);\n\n    final TransformSpec transformSpec = new TransformSpec(\n        new SelectorDimFilter(\"dim1\", \"foo\", null),\n        ImmutableList.of(\n            new ExpressionTransform(\"dim1t\", \"concat(dim1,dim1)\", ExprMacroTable.nil())\n        )\n    );\n    final AppenderatorDriverRealtimeIndexTask task = makeRealtimeTask(null, transformSpec, true, 0, true, 0, 1);\n    final ListenableFuture<TaskStatus> statusFuture = runTask(task);\n\n    \r\n    while (task.getFirehose() == null) {\n      Thread.sleep(50);\n    }\n\n    final TestFirehose firehose = (TestFirehose) task.getFirehose();\n\n    firehose.addRows(\n        ImmutableList.of(\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim1\", \"foo\", \"met1\", \"1\"),\n            ImmutableMap.of(\"t\", now.minus(new Period(\"P1D\")).getMillis(), \"dim1\", \"foo\", \"met1\", 2.0),\n            ImmutableMap.of(\"t\", now.getMillis(), \"dim2\", \"bar\", \"met1\", 2.0)\n        )\n    );\n\n    \r\n    firehose.close();\n\n    Collection<DataSegment> publishedSegments = awaitSegments();\n\n    \r\n    Assert.assertEquals(2, task.getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(1, task.getRowIngestionMeters().getThrownAway());\n    Assert.assertEquals(0, task.getRowIngestionMeters().getUnparseable());\n\n    \r\n    Assert.assertEquals(2, sumMetric(task, null, \"rows\").longValue());\n    Assert.assertEquals(2, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"foofoo\", null), \"rows\").longValue());\n    if (NullHandling.replaceWithDefault()) {\n      Assert.assertEquals(0, sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\").longValue());\n    } else {\n      Assert.assertNull(sumMetric(task, new SelectorDimFilter(\"dim1t\", \"barbar\", null), \"metric1\"));\n    }\n    Assert.assertEquals(3, sumMetric(task, null, \"met1\").longValue());\n\n    awaitHandoffs();\n\n    for (DataSegment publishedSegment : publishedSegments) {\n      Pair<Executor, Runnable> executorRunnablePair = handOffCallbacks.get(\n          new SegmentDescriptor(\n              publishedSegment.getInterval(),\n              publishedSegment.getVersion(),\n              publishedSegment.getShardSpec().getPartitionNum()\n          )\n      );\n      Assert.assertNotNull(\n          publishedSegment + \" missing from handoff callbacks: \" + handOffCallbacks,\n          executorRunnablePair\n      );\n\n      \r\n      executorRunnablePair.lhs.execute(executorRunnablePair.rhs);\n    }\n    handOffCallbacks.clear();\n\n    \r\n    final TaskStatus taskStatus = statusFuture.get();\n    Assert.assertEquals(TaskState.SUCCESS, taskStatus.getStatusCode());\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":532,"status":"N"}],"commitId":"771870ae2d312d643e6d98f3d0af8a9618af9681","commitMessage":"@@@Load broadcast datasources on broker and tasks (#9971)\n\n* Load broadcast datasources on broker and tasks\n\n* Add javadocs\n\n* Support HTTP segment management\n\n* Fix indexer maxSize\n\n* inspection fix\n\n* Make segment cache optional on non-historicals\n\n* Fix build\n\n* Fix inspections.  some coverage.  failed tests\n\n* More tests\n\n* Add CliIndexer to MainTest\n\n* Fix inspection\n\n* Rename UnprunedDataSegment to LoadableDataSegment\n\n* Address PR comments\n\n* Fix","date":"2020-06-09 11:15:59","modifiedFileCount":"52","status":"M","submitter":"Jonathan Wei"}]
