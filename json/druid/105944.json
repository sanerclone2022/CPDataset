[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":522,"groupId":"1204","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/c4d2f8c76a74ab886b9c59bd9102f37974df19.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":473,"groupId":"22810","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/50/791c53dcebf8f47a1223a1cf59d98721187213.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-09-15 04:35:51","codes":[{"authorDate":"2018-09-15 04:35:51","commitOrder":2,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-09-15 04:35:51","endLine":523,"groupId":"1204","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/14/bbe8974cbacb26a26f403c22050bb644943a0d.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":280,"status":"M"},{"authorDate":"2018-09-15 04:35:51","commitOrder":2,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-09-15 04:35:51","endLine":474,"groupId":"9696","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/88/840a4494b750a0c7db4b7fb6bed5ffc32046b7.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = new Random();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":260,"status":"M"}],"commitId":"0c4bd2b57b19bcbd9a275fad412960aa0a39ca5f","commitMessage":"@@@Prohibit some Random usage patterns (#6226)\n\n* Prohibit Random usage patterns\n\n* Fix FlattenJSONBenchmarkUtil\n","date":"2018-09-15 04:35:51","modifiedFileCount":"44","status":"M","submitter":"Roman Leventov"},{"authorTime":"2018-10-29 20:02:43","codes":[{"authorDate":"2018-09-15 04:35:51","commitOrder":3,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-09-15 04:35:51","endLine":523,"groupId":"1204","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/14/bbe8974cbacb26a26f403c22050bb644943a0d.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":280,"status":"N"},{"authorDate":"2018-10-29 20:02:43","commitOrder":3,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-10-29 20:02:43","endLine":474,"groupId":"9696","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3f/f9fb73b5e412c2191349815c2412fbf0e220ea.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Lists.newArrayList()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":260,"status":"M"}],"commitId":"676f5e6d7f184101b8763e4249b18b237bbe0ec7","commitMessage":"@@@Prohibit some guava collection APIs and use JDK collection APIs directly (#6511)\n\n* Prohibit some guava collection APIs and use JDK APIs directly\n\n* reset files that changed by accident\n\n* sort codestyle/druid-forbidden-apis.txt alphabetically\n","date":"2018-10-29 20:02:43","modifiedFileCount":"427","status":"M","submitter":"QiuMM"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":522,"groupId":"1204","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/74/b3070ef5651c6429aa2a7e5aeb364e18ac50da.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":473,"groupId":"9696","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e1/43caa10981038b772e2285a40b4ebb4ac237f7.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"}],"commitId":"7ada1c49f9735a37808f3ed7656d93ae88b8b925","commitMessage":"@@@Prohibit Throwables.propagate() (#7121)\n\n* Throw caught exception.\n\n* Throw caught exceptions.\n\n* Related checkstyle rule is added to prevent further bugs.\n\n* RuntimeException() is used instead of Throwables.propagate().\n\n* Missing import is added.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* * Checkstyle definition is improved.\n* Throwables.propagate() usages are removed.\n\n* Checkstyle pattern is changed for only scanning \"Throwables.propagate(\" instead of checking lookbehind.\n\n* Throwable is kept before firing a Runtime Exception.\n\n* Fix unused assignments.\n","date":"2019-03-15 05:28:33","modifiedFileCount":"228","status":"M","submitter":"Furkan KAMACI"},{"authorTime":"2020-09-12 07:31:10","codes":[{"authorDate":"2020-09-12 07:31:10","commitOrder":5,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-09-12 07:31:10","endLine":519,"groupId":"1204","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/74/4b25d812f374e4e61b407ab01d4250e9e15d36.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2020-09-12 07:31:10","commitOrder":5,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-09-12 07:31:10","endLine":468,"groupId":"9696","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a6/207aa09e52590968087d91c50644044261a2ff.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setReportParseExceptions(false)\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":257,"status":"M"}],"commitId":"8f14ac814e1fdf11878a5ba9bdba58fb745b4c8f","commitMessage":"@@@More structured way to handle parse exceptions (#10336)\n\n* More structured way to handle parse exceptions\n\n* checkstyle; add more tests\n\n* forbidden api; test\n\n* address comment; new test\n\n* address review comments\n\n* javadoc for parseException; remove redundant parseException in streaming ingestion\n\n* fix tests\n\n* unnecessary catch\n\n* unused imports\n\n* appenderator test\n\n* unused import","date":"2020-09-12 07:31:10","modifiedFileCount":"116","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-01-06 14:19:09","codes":[{"authorDate":"2021-01-06 14:19:09","commitOrder":6,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2021-01-06 14:19:09","endLine":520,"groupId":"1204","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8b/961b6de54fffb8bb31319d2a69567a8055c9ff.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2021-01-06 14:19:09","commitOrder":6,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2021-01-06 14:19:09","endLine":469,"groupId":"9696","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5c/c81909dc3f89afce64a1337a9f9792d2248de5.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":257,"status":"M"}],"commitId":"68bb038b314c26bcc57aa96e1078c22d2f24fd35","commitMessage":"@@@Multiphase segment merge for IndexMergerV9 (#10689)\n\n* Multiphase merge for IndexMergerV9\n\n* JSON fix\n\n* Cleanup temp files\n\n* Docs\n\n* Address logging and add IT\n\n* Fix spelling and test unloader datasource name","date":"2021-01-06 14:19:09","modifiedFileCount":"40","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2021-01-08 14:18:47","codes":[{"authorDate":"2021-01-08 14:18:47","commitOrder":7,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .build();\n\n      IncrementalIndex second = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .build();\n\n      IncrementalIndex third = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .build();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2021-01-08 14:18:47","endLine":521,"groupId":"105944","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"makeMergedQueryableIndex","params":"(IndexSpecindexSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/47/835bf273ea2c0ab1279d186643bc59c48aaf0e.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(IndexSpec indexSpec)\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(1000)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Arrays.asList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  Arrays.asList(\"lat\", \"long\")\n                              ),\n                              new SpatialDimensionSchema(\n                                  \"spatialIsRad\",\n                                  Arrays.asList(\"lat2\", \"long2\")\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 0.0f,\n                  \"long\", 0.0f,\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 1.0f,\n                  \"long\", 3.0f,\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 4.0f,\n                  \"long\", 2.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", \"_mmx.unknown\",\n                  \"long\", \"_mmx.unknown\",\n                  \"val\", 101L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 7.0f,\n                  \"long\", 3.0f,\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"lat\", 8.0f,\n                  \"long\", 6.0f,\n                  \"val\", 47L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"lat2\", 0.0f,\n                  \"long2\", 0.0f,\n                  \"val\", 13L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 8; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"lat\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"long\", (float) (rand.nextFloat() * 10 + 10.0),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      INDEX_MERGER.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      INDEX_MERGER.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      INDEX_MERGER.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = INDEX_IO.loadIndex(\n          INDEX_MERGER.mergeQueryableIndex(\n              Arrays.asList(INDEX_IO.loadIndex(firstFile), INDEX_IO.loadIndex(secondFile), INDEX_IO.loadIndex(thirdFile)),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":280,"status":"M"},{"authorDate":"2021-01-08 14:18:47","commitOrder":7,"curCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .build();\n\n      IncrementalIndex second = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .build();\n\n      IncrementalIndex third = new OnheapIncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .build();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2021-01-08 14:18:47","endLine":470,"groupId":"105944","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"makeMergedQueryableIndex","params":"(finalIndexSpecindexSpec@finalIndexMergerindexMerger@finalIndexIOindexIO)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/94/e413c3b7987bebe04887b5c825a4f16fa665e7.src","preCode":"  private static QueryableIndex makeMergedQueryableIndex(\n      final IndexSpec indexSpec,\n      final IndexMerger indexMerger,\n      final IndexIO indexIO\n  )\n  {\n    try {\n      IncrementalIndex first = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex second = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      IncrementalIndex third = new IncrementalIndex.Builder()\n          .setIndexSchema(\n              new IncrementalIndexSchema.Builder()\n                  .withMinTimestamp(DATA_INTERVAL.getStartMillis())\n                  .withQueryGranularity(Granularities.DAY)\n                  .withMetrics(METRIC_AGGS)\n                  .withDimensionsSpec(\n                      new DimensionsSpec(\n                          null,\n                          null,\n                          Collections.singletonList(\n                              new SpatialDimensionSchema(\n                                  \"dim.geo\",\n                                  new ArrayList<>()\n                              )\n                          )\n                      )\n\n                  ).build()\n          )\n          .setMaxRowCount(NUM_POINTS)\n          .buildOnheap();\n\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-01\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"0.0,0.0\",\n                  \"val\", 17L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-02\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-02\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"1.0,3.0\",\n                  \"val\", 29L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-03\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-03\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"4.0,2.0\",\n                  \"val\", 13L\n              )\n          )\n      );\n      first.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"_mmx.unknown\",\n                  \"val\", 501L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-04\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-04\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"7.0,3.0\",\n                  \"val\", 91L\n              )\n          )\n      );\n      second.add(\n          new MapBasedInputRow(\n              DateTimes.of(\"2013-01-05\").getMillis(),\n              DIMS,\n              ImmutableMap.of(\n                  \"timestamp\", DateTimes.of(\"2013-01-05\").toString(),\n                  \"dim\", \"foo\",\n                  \"dim.geo\", \"8.0,6.0\",\n                  \"val\", 47L\n              )\n          )\n      );\n\n      \r\n      Random rand = ThreadLocalRandom.current();\n      for (int i = 6; i < NUM_POINTS; i++) {\n        third.add(\n            new MapBasedInputRow(\n                DateTimes.of(\"2013-01-01\").getMillis(),\n                DIMS,\n                ImmutableMap.of(\n                    \"timestamp\", DateTimes.of(\"2013-01-01\").toString(),\n                    \"dim\", \"boo\",\n                    \"dim.geo\", StringUtils.format(\n                        \"%s,%s\",\n                        (float) (rand.nextFloat() * 10 + 10.0),\n                        (float) (rand.nextFloat() * 10 + 10.0)\n                    ),\n                    \"val\", i\n                )\n            )\n        );\n      }\n\n\n      File tmpFile = File.createTempFile(\"yay\", \"who\");\n      tmpFile.delete();\n\n      File firstFile = new File(tmpFile, \"first\");\n      File secondFile = new File(tmpFile, \"second\");\n      File thirdFile = new File(tmpFile, \"third\");\n      File mergedFile = new File(tmpFile, \"merged\");\n\n      firstFile.mkdirs();\n      firstFile.deleteOnExit();\n      secondFile.mkdirs();\n      secondFile.deleteOnExit();\n      thirdFile.mkdirs();\n      thirdFile.deleteOnExit();\n      mergedFile.mkdirs();\n      mergedFile.deleteOnExit();\n\n      indexMerger.persist(first, DATA_INTERVAL, firstFile, indexSpec, null);\n      indexMerger.persist(second, DATA_INTERVAL, secondFile, indexSpec, null);\n      indexMerger.persist(third, DATA_INTERVAL, thirdFile, indexSpec, null);\n\n      QueryableIndex mergedRealtime = indexIO.loadIndex(\n          indexMerger.mergeQueryableIndex(\n              Arrays.asList(\n                  indexIO.loadIndex(firstFile),\n                  indexIO.loadIndex(secondFile),\n                  indexIO.loadIndex(thirdFile)\n              ),\n              true,\n              METRIC_AGGS,\n              mergedFile,\n              indexSpec,\n              null,\n              -1\n          )\n      );\n\n      return mergedRealtime;\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"}],"commitId":"08ab82f55ca856d60dfe1088c1c0393428b0bb6d","commitMessage":"@@@IncrementalIndex Tests and Benchmarks Parametrization (#10593)\n\n* Remove redundant IncrementalIndex.Builder\n\n* Parametrize incremental index tests and benchmarks\n\n- Reveal and fix a bug in OffheapIncrementalIndex\n\n* Fix forbiddenapis error: Forbidden method invocation: java.lang.String#format(java.lang.String. java.lang.Object[]) [Uses default locale]\n\n* Fix Intellij errors: declared exception is never thrown\n\n* Add documentation and validate before closing objects on tearDown.\n\n* Add documentation to OffheapIncrementalIndexTestSpec\n\n* Doc corrections and minor changes.\n\n* Add logging for generated rows.\n\n* Refactor new tests/benchmarks.\n\n* Improve IncrementalIndexCreator documentation\n\n* Add required tests for DataGenerator\n\n* Revert \"rollupOpportunity\" to be a string","date":"2021-01-08 14:18:47","modifiedFileCount":"62","status":"M","submitter":"Liran Funaro"}]
