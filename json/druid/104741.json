[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw Throwables.propagate(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2018-08-31 00:56:26","endLine":479,"groupId":"18240","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/05/770b41be69ef8205c159d513e7b1e858c5ccdd.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw Throwables.propagate(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":201,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-08-31 00:56:26","endLine":687,"groupId":"20059","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/49/a9333567eec4d6ece0f23fa7d58550ac0de79a.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":674,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2018-10-15 11:49:38","commitOrder":2,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw Throwables.propagate(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2018-10-15 11:49:38","endLine":488,"groupId":"19145","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/83/130e6c6abd8213156ea15fd2a9902de77103cc.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw Throwables.propagate(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":2,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        DruidNodeDiscoveryProvider.NODE_TYPE_PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"M"}],"commitId":"aa121da25f019ad3345c747ce56261fbb7e77885","commitMessage":"@@@Use NodeType enum instead of Strings (#6377)\n\n* Use NodeType enum instead of Strings\n\n* Make NodeType constants uppercase\n\n* Fix CommonCacheNotifier and NodeType/ServerType comments\n\n* Reconsidering comment\n\n* Fix import\n\n* Add a comment to CommonCacheNotifier.NODE_TYPES\n","date":"2018-10-15 11:49:38","modifiedFileCount":"30","status":"M","submitter":"Roman Leventov"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2019-03-15 05:28:33","commitOrder":3,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-03-15 05:28:33","endLine":487,"groupId":"8196","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/27/86805b9f4c35d382081b22c51a277bf91343b0.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw Throwables.propagate(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":3,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"N"}],"commitId":"7ada1c49f9735a37808f3ed7656d93ae88b8b925","commitMessage":"@@@Prohibit Throwables.propagate() (#7121)\n\n* Throw caught exception.\n\n* Throw caught exceptions.\n\n* Related checkstyle rule is added to prevent further bugs.\n\n* RuntimeException() is used instead of Throwables.propagate().\n\n* Missing import is added.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* * Checkstyle definition is improved.\n* Throwables.propagate() usages are removed.\n\n* Checkstyle pattern is changed for only scanning \"Throwables.propagate(\" instead of checking lookbehind.\n\n* Throwable is kept before firing a Runtime Exception.\n\n* Fix unused assignments.\n","date":"2019-03-15 05:28:33","modifiedFileCount":"228","status":"M","submitter":"Furkan KAMACI"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2019-07-25 08:35:46","commitOrder":4,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-07-25 08:35:46","endLine":487,"groupId":"8196","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ce/2b1c6cb65aadb1b6618aa35322fc1c696d1b46.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new LockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final LockAcquireAction action = new LockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":4,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"N"}],"commitId":"db149462073d59e7563f0d3834e69d44a2bb4011","commitMessage":"@@@Add support minor compaction with segment locking (#7547)\n\n* Segment locking\n\n* Allow both timeChunk and segment lock in the same gruop\n\n* fix it test\n\n* Fix adding same chunk to atomicUpdateGroup\n\n* resolving todos\n\n* Fix segments to lock\n\n* fix segments to lock\n\n* fix kill task\n\n* resolving todos\n\n* resolving todos\n\n* fix teamcity\n\n* remove unused class\n\n* fix single map\n\n* resolving todos\n\n* fix build\n\n* fix SQLMetadataSegmentManager\n\n* fix findInputSegments\n\n* adding more tests\n\n* fixing task lock checks\n\n* add SegmentTransactionalOverwriteAction\n\n* changing publisher\n\n* fixing something\n\n* fix for perfect rollup\n\n* fix test\n\n* adjust package-lock.json\n\n* fix test\n\n* fix style\n\n* adding javadocs\n\n* remove unused classes\n\n* add more javadocs\n\n* unused import\n\n* fix test\n\n* fix test\n\n* Support forceTimeChunk context and force timeChunk lock for parallel index task if intervals are missing\n\n* fix travis\n\n* fix travis\n\n* unused import\n\n* spotbug\n\n* revert getMaxVersion\n\n* address comments\n\n* fix tc\n\n* add missing error handling\n\n* fix backward compatibility\n\n* unused import\n\n* Fix perf of versionedIntervalTimeline\n\n* fix timeline\n\n* fix tc\n\n* remove remaining todos\n\n* add comment for parallel index\n\n* fix javadoc and typos\n\n* typo\n\n* address comments\n","date":"2019-07-25 08:35:46","modifiedFileCount":"130","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2019-10-24 07:52:02","commitOrder":5,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-10-24 07:52:02","endLine":482,"groupId":"0","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5b/8731edf5815fa718c77b00853cb8d8b38d8444.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    Supplier<Committer> committerSupplier = null;\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n          committerSupplier = Committers.supplierFromFirehose(firehose);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":206,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":5,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"N"}],"commitId":"094936ca039f5a204d525416f22e746095056acc","commitMessage":"@@@Remove commit() method Firehose (#8688)\n\n* Remove commit() method Firehose\n\n* fix javadoc\n","date":"2019-10-24 07:52:02","modifiedFileCount":"23","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2019-11-16 01:22:09","commitOrder":6,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-11-16 01:22:09","endLine":485,"groupId":"12096","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/dc/07d2b22b187adcf1fdfc33335fccaad270b18f.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getFirehoseTemporaryDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(spec.getDataSchema().getParser(), firehoseTempDir);\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":206,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":6,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"N"}],"commitId":"1611792855ad9def8b6f5b1375862d05d1acca0a","commitMessage":"@@@Add InputSource and InputFormat interfaces (#8823)\n\n* Add InputSource and InputFormat interfaces\n\n* revert orc dependency\n\n* fix dimension exclusions and failing unit tests\n\n* fix tests\n\n* fix test\n\n* fix test\n\n* fix firehose and inputSource for parallel indexing task\n\n* fix tc\n\n* fix tc: remove unused method\n\n* Formattable\n\n* add needsFormat(); renamed to ObjectSource; pass metricsName for reader\n\n* address comments\n\n* fix closing resource\n\n* fix checkstyle\n\n* fix tests\n\n* remove verify from csv\n\n* Revert \"remove verify from csv\"\n\nThis reverts commit 1ea7758489cc8c9d708bd691fd48e62085fd9455.\n\n* address comments\n\n* fix import order and javadoc\n\n* flatMap\n\n* sampleLine\n\n* Add IntermediateRowParsingReader\n\n* Address comments\n\n* move csv reader test\n\n* remove test for verify\n\n* adjust comments\n\n* Fix InputEntityIteratingReader\n\n* rename source -> entity\n\n* address comments\n","date":"2019-11-16 01:22:09","modifiedFileCount":"72","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-10-15 11:49:38","codes":[{"authorDate":"2019-11-20 05:57:58","commitOrder":7,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-11-20 05:57:58","endLine":485,"groupId":"12096","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c8/5d4683310b1e50551b896ec8ab6959b4f8032e.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getObjectMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":206,"status":"M"},{"authorDate":"2018-10-15 11:49:38","commitOrder":7,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2018-10-15 11:49:38","endLine":681,"groupId":"20970","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/ab3a0ff77abb80465c8ddd8f193300a3d039c3.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":668,"status":"N"}],"commitId":"c44452f0c1b051b03343d8bb479828f01461d68f","commitMessage":"@@@Tidy up lifecycle.  query.  and ingestion logging. (#8889)\n\n* Tidy up lifecycle.  query.  and ingestion logging.\n\nThe goal of this patch is to improve the clarity and usefulness of\nDruid's logging for cluster operators. For more information.  see\nhttps://twitter.com/cowtowncoder/status/1195469299814555648.\n\nConcretely.  this patch does the following:\n\n- Changes a lot of INFO logs to DEBUG.  and DEBUG to TRACE.  with the\n  goal of reducing redundancy and improving clarity by avoiding\n  showing rarely-useful log messages. This includes most \"starting\"\n  and \"stopping\" messages.  and most messages related to individual\n  columns.\n- Adds new log4j2 templates that show operators how to enabled DEBUG\n  logging for certain important packages.\n- Eliminate stack traces for query errors.  unless log level is DEBUG\n  or more. This is useful because query errors often indicate user\n  error rather than system error.  but dumping stack trace often gave\n  operators the impression that there was a system failure.\n- Adds task id to Appenderator.  AppenderatorDriver thread names. In\n  the default log4j2 configuration.  this will put them in log lines\n  as well. It's very useful if a user is using the Indexer.  where\n  multiple tasks run in the same JVM.\n- More consistent terminology when it comes to \"sequences\" (sets of\n  segments that are handed-off together by Kafka ingestion) and\n  \"offsets\" (cursors in partitions). These terms had been confused in\n  some log messages due to the fact that Kinesis calls offsets\n  \"sequence numbers\".\n- Replaces some ugly toString calls with either the JSONification or\n  something more operator-accessible (like a URL or segment identifier. \n  instead of JSON object representing the same).\n\n* Adjustments.\n\n* Adjust integration test.\n","date":"2019-11-20 05:57:58","modifiedFileCount":"101","status":"M","submitter":"Gian Merlino"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2019-12-08 23:47:58","commitOrder":8,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2019-12-08 23:47:58","endLine":485,"groupId":"0","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/c5799f3eb3ae9a14181b69f01269e509cacbd8.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":206,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":8,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"7439","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeType.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"M"}],"commitId":"1c62987783e85867856f567b04aad807a26bb2e3","commitMessage":"@@@Add SelfDiscoveryResource; rename org.apache.druid.discovery.No? (#6702)\n\n* Add SelfDiscoveryResource\n\n* Rename org.apache.druid.discovery.NodeType to NodeRole. Refactor CuratorDruidNodeDiscoveryProvider. Make SelfDiscoveryResource to listen to updates only about a single node (itself).\n\n* Extended docs\n\n* Fix brace\n\n* Remove redundant throws in Lifecycle.Handler.stop()\n\n* Import order\n\n* Remove unresolvable link\n\n* Address comments\n\n* tmp\n\n* tmp\n\n* Rollback docker changes\n\n* Remove extra .sh files\n\n* Move filter\n\n* Fix SecurityResourceFilterTest\n","date":"2019-12-08 23:47:58","modifiedFileCount":"54","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2020-01-25 05:10:01","commitOrder":9,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2020-01-25 05:10:01","endLine":486,"groupId":"23532","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ed/2ddd2c604ef9bd4e7501f3f6f57bff36f7061f.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":206,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":9,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"7439","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"N"}],"commitId":"19b427e8f371bed0b0100272ac890b3775471654","commitMessage":"@@@Add JoinableFactory interface and use it in the query stack. (#9247)\n\n* Add JoinableFactory interface and use it in the query stack.\n\nAlso includes InlineJoinableFactory.  which enables joining against\ninline datasources. This is the first patch where a basic join query\nactually works. It includes integration tests.\n\n* Fix test issues.\n\n* Adjustments from code review.\n","date":"2020-01-25 05:10:01","modifiedFileCount":"51","status":"M","submitter":"Gian Merlino"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2020-06-26 05:41:22","commitOrder":10,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2020-06-26 05:41:22","endLine":486,"groupId":"0","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/98/d3164ac843b0980abe099d80e75cbbd61287b8.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n    final File firehoseTempDir = toolbox.getIndexingTmpDir();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      FileUtils.forceMkdir(firehoseTempDir);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              firehoseTempDir\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":10,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"7439","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"N"}],"commitId":"f6594fff608d4b2e071c7bdd6d86d7f87398ce4f","commitMessage":"@@@Fix missing temp dir for native single_dim (#10046)\n\n* Fix missing temp dir for native single_dim\n\nNative single dim indexing throws a file not found exception from\nInputEntityIteratingReader.java:81.  This MR creates the required\ntemporary directory when setting up the\nPartialDimensionDistributionTask.  The change was tested on a Druid\ncluster.  After installing the change native single_dim indexing\ncompletes successfully.\n\n* Fix indentation\n\n* Use SinglePhaseSubTask as example for creating the temp dir\n\n* Move temporary indexing dir creation in to TaskToolbox\n\n* Remove unused dependency\n\nCo-authored-by: Morri Feldman <morri@appsflyer.com>","date":"2020-06-26 05:41:22","modifiedFileCount":"6","status":"M","submitter":"morrifeldman"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2020-06-30 12:03:07","commitOrder":11,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2020-06-30 12:03:07","endLine":486,"groupId":"6974","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/aa3967bc0ee815cae68249a77c6693b40ad54e.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.getMonitorScheduler().removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":11,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"7439","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"N"}],"commitId":"363d0d86be9e83a5d24d5cf002cac57d99a43baa","commitMessage":"@@@QueryCountStatsMonitor can be injected in the Peon (#10092)\n\n* QueryCountStatsMonitor can be injected in the Peon\n\nThis change fixes a dependency injection bug where there is a circular\ndependency on getting the MonitorScheduler when a user configures the\nQueryCountStatsMonitor to be used.\n\n* fix tests\n\n* Actually fix the tests this time","date":"2020-06-30 12:03:07","modifiedFileCount":"13","status":"M","submitter":"Suneet Saldanha"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2020-08-29 02:38:50","commitOrder":12,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"Plumber must be null\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2020-08-29 02:38:50","endLine":486,"groupId":"6974","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b4/c75206058d676ef90ca9aef1c59eb3103c3176.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"WTF?!? run with non-null plumber??!\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":12,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"7439","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"N"}],"commitId":"8ab19793043c65bd79315de6fb26683f561a8a58","commitMessage":"@@@Remove implied profanity from error messages. (#10270)\n\ni.e. WTF.  WTH.","date":"2020-08-29 02:38:50","modifiedFileCount":"76","status":"M","submitter":"Gian Merlino"},{"authorTime":"2019-12-08 23:47:58","codes":[{"authorDate":"2021-07-01 18:33:08","commitOrder":13,"curCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"Plumber must be null\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryProcessingPool(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","date":"2021-07-01 18:33:08","endLine":486,"groupId":"104741","id":25,"instanceNumber":1,"isCurCommit":1,"methodName":"run","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/6a/5fc698daf3bcabf3dd965f007bda70416bf406.src","preCode":"  public TaskStatus run(final TaskToolbox toolbox) throws Exception\n  {\n    runThread = Thread.currentThread();\n\n    if (this.plumber != null) {\n      throw new IllegalStateException(\"Plumber must be null\");\n    }\n\n    setupTimeoutAlert();\n\n    boolean normalExit = true;\n\n    \r\n    \r\n\n    final SegmentPublisher segmentPublisher = new TaskActionSegmentPublisher(toolbox);\n\n    \r\n    \r\n    \r\n\n    \r\n    final long lockTimeoutMs = getContextValue(Tasks.LOCK_TIMEOUT_KEY, Tasks.DEFAULT_LOCK_TIMEOUT_MILLIS);\n    \r\n    \r\n    final DataSegmentAnnouncer lockingSegmentAnnouncer = new DataSegmentAnnouncer()\n    {\n      @Override\n      public void announceSegment(final DataSegment segment) throws IOException\n      {\n        \r\n        Preconditions.checkNotNull(\n            toolbox.getTaskActionClient().submit(\n                new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n            ),\n            \"Cannot acquire a lock for interval[%s]\",\n            segment.getInterval()\n        );\n        toolbox.getSegmentAnnouncer().announceSegment(segment);\n      }\n\n      @Override\n      public void unannounceSegment(final DataSegment segment) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegment(segment);\n        }\n        finally {\n          toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n        }\n      }\n\n      @Override\n      public void announceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        \r\n        for (DataSegment segment : segments) {\n          Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(\n                  new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, segment.getInterval(), lockTimeoutMs)\n              ),\n              \"Cannot acquire a lock for interval[%s]\",\n              segment.getInterval()\n          );\n        }\n        toolbox.getSegmentAnnouncer().announceSegments(segments);\n      }\n\n      @Override\n      public void unannounceSegments(Iterable<DataSegment> segments) throws IOException\n      {\n        try {\n          toolbox.getSegmentAnnouncer().unannounceSegments(segments);\n        }\n        finally {\n          for (DataSegment segment : segments) {\n            toolbox.getTaskActionClient().submit(new LockReleaseAction(segment.getInterval()));\n          }\n        }\n      }\n    };\n\n    \r\n    \r\n\n    \r\n    \r\n    \r\n    final VersioningPolicy versioningPolicy = new VersioningPolicy()\n    {\n      @Override\n      public String getVersion(final Interval interval)\n      {\n        try {\n          \r\n          final TimeChunkLockAcquireAction action = new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE, interval, lockTimeoutMs);\n          final TaskLock lock = Preconditions.checkNotNull(\n              toolbox.getTaskActionClient().submit(action),\n              \"Cannot acquire a lock for interval[%s]\",\n              interval\n          );\n\n          return lock.getVersion();\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    DataSchema dataSchema = spec.getDataSchema();\n    RealtimeIOConfig realtimeIOConfig = spec.getIOConfig();\n    RealtimeTuningConfig tuningConfig = spec.getTuningConfig()\n                                            .withBasePersistDirectory(toolbox.getPersistDir())\n                                            .withVersioningPolicy(versioningPolicy);\n\n    final FireDepartment fireDepartment = new FireDepartment(\n        dataSchema,\n        realtimeIOConfig,\n        tuningConfig\n    );\n    this.metrics = fireDepartment.getMetrics();\n    final RealtimeMetricsMonitor metricsMonitor = TaskRealtimeMetricsMonitorBuilder.build(this, fireDepartment);\n\n    this.queryRunnerFactoryConglomerate = toolbox.getQueryRunnerFactoryConglomerate();\n\n    \r\n    \r\n    \r\n    \r\n    final PlumberSchool plumberSchool = new RealtimePlumberSchool(\n        toolbox.getEmitter(),\n        toolbox.getQueryRunnerFactoryConglomerate(),\n        toolbox.getSegmentPusher(),\n        lockingSegmentAnnouncer,\n        segmentPublisher,\n        toolbox.getSegmentHandoffNotifierFactory(),\n        toolbox.getQueryExecutorService(),\n        toolbox.getJoinableFactory(),\n        toolbox.getIndexMergerV9(),\n        toolbox.getIndexIO(),\n        toolbox.getCache(),\n        toolbox.getCacheConfig(),\n        toolbox.getCachePopulatorStats(),\n        toolbox.getJsonMapper()\n    );\n\n    this.plumber = plumberSchool.findPlumber(dataSchema, tuningConfig, metrics);\n\n    final Supplier<Committer> committerSupplier = Committers.nilSupplier();\n\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService((String) getContextValue(CTX_KEY_LOOKUP_TIER));\n    DiscoveryDruidNode discoveryDruidNode = new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n\n    try {\n      toolbox.getDataSegmentServerAnnouncer().announce();\n      toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);\n\n\n      plumber.startJob();\n\n      \r\n      toolbox.addMonitor(metricsMonitor);\n\n      \r\n      final FirehoseFactory firehoseFactory = spec.getIOConfig().getFirehoseFactory();\n      final boolean firehoseDrainableByClosing = isFirehoseDrainableByClosing(firehoseFactory);\n\n      \r\n      synchronized (this) {\n        if (!gracefullyStopped) {\n          firehose = firehoseFactory.connect(\n              Preconditions.checkNotNull(spec.getDataSchema().getParser(), \"inputRowParser\"),\n              toolbox.getIndexingTmpDir()\n          );\n        }\n      }\n\n      \r\n      while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {\n        Plumbers.addNextRow(\n            committerSupplier,\n            firehose,\n            plumber,\n            tuningConfig.isReportParseExceptions(),\n            metrics\n        );\n      }\n    }\n    catch (Throwable e) {\n      normalExit = false;\n      log.makeAlert(e, \"Exception aborted realtime processing[%s]\", dataSchema.getDataSource())\n         .emit();\n      throw e;\n    }\n    finally {\n      if (normalExit) {\n        try {\n          \r\n          if (firehose != null) {\n            log.info(\"Persisting remaining data.\");\n\n            final Committer committer = committerSupplier.get();\n            final CountDownLatch persistLatch = new CountDownLatch(1);\n            plumber.persist(\n                new Committer()\n                {\n                  @Override\n                  public Object getMetadata()\n                  {\n                    return committer.getMetadata();\n                  }\n\n                  @Override\n                  public void run()\n                  {\n                    try {\n                      committer.run();\n                    }\n                    finally {\n                      persistLatch.countDown();\n                    }\n                  }\n                }\n            );\n            persistLatch.await();\n          }\n\n          if (gracefullyStopped) {\n            log.info(\"Gracefully stopping.\");\n          } else {\n            log.info(\"Finishing the job.\");\n            synchronized (this) {\n              if (gracefullyStopped) {\n                \r\n                log.info(\"Gracefully stopping.\");\n              } else {\n                finishingJob = true;\n              }\n            }\n\n            if (finishingJob) {\n              plumber.finishJob();\n            }\n          }\n        }\n        catch (InterruptedException e) {\n          log.debug(e, \"Interrupted while finishing the job\");\n        }\n        catch (Exception e) {\n          log.makeAlert(e, \"Failed to finish realtime task\").emit();\n          throw e;\n        }\n        finally {\n          if (firehose != null) {\n            CloseQuietly.close(firehose);\n          }\n          toolbox.removeMonitor(metricsMonitor);\n        }\n      }\n\n      toolbox.getDataSegmentServerAnnouncer().unannounce();\n      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);\n    }\n\n    log.info(\"Job done!\");\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"},{"authorDate":"2019-12-08 23:47:58","commitOrder":13,"curCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","date":"2019-12-08 23:47:58","endLine":753,"groupId":"104741","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"createDiscoveryDruidNode","params":"(TaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/db37a5bf6ee089ca92daf8741cc480c88469ec.src","preCode":"  private DiscoveryDruidNode createDiscoveryDruidNode(TaskToolbox toolbox)\n  {\n    LookupNodeService lookupNodeService = getContextValue(CTX_KEY_LOOKUP_TIER) == null ?\n                                          toolbox.getLookupNodeService() :\n                                          new LookupNodeService(getContextValue(CTX_KEY_LOOKUP_TIER));\n    return new DiscoveryDruidNode(\n        toolbox.getDruidNode(),\n        NodeRole.PEON,\n        ImmutableMap.of(\n            toolbox.getDataNodeService().getName(), toolbox.getDataNodeService(),\n            lookupNodeService.getName(), lookupNodeService\n        )\n    );\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":740,"status":"N"}],"commitId":"03a6a6d6e1f7024c2691e6fef0685bd137d223e7","commitMessage":"@@@Replace Processing ExecutorService with QueryProcessingPool (#11382)\n\nThis PR refactors the code for QueryRunnerFactory#mergeRunners to accept a new interface called QueryProcessingPool instead of ExecutorService for concurrent execution of query runners. This interface will let custom extensions inject their own implementation for deciding which query-runner to prioritize first. The default implementation is the same as today that takes the priority of query into account. QueryProcessingPool can also be used as a regular executor service. It has a dedicated method for accepting query execution work so implementations can differentiate between regular async tasks and query execution tasks. This dedicated method also passes the QueryRunner object as part of the task information. This hook will let custom extensions carry any state from QuerySegmentWalker to QueryProcessingPool#mergeRunners which is not possible currently.","date":"2021-07-01 18:33:08","modifiedFileCount":"52","status":"M","submitter":"Abhishek Agarwal"}]
