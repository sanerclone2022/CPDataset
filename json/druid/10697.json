[{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2018-08-31 00:56:26","endLine":178,"groupId":"22251","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/07539e6f6c5d64f76d5b8978eaaf386f2b5cab.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"NB"},{"authorDate":"2019-08-23 18:13:54","commitOrder":2,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2019-08-23 18:13:54","endLine":88,"groupId":"17872","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/7e9c7f3aca346de3d4620173aee2953c4a922f.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"B"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"},{"authorTime":"2019-12-04 01:47:01","codes":[{"authorDate":"2019-12-04 01:47:01","commitOrder":3,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2019-12-04 01:47:01","endLine":177,"groupId":"22251","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/24/828e2bbaac28cc1d0604b685d88904e60e0faf.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"M"},{"authorDate":"2019-12-04 01:47:01","commitOrder":3,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2019-12-04 01:47:01","endLine":88,"groupId":"17872","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/c9c1671fc33539e493287f8ff5d425aaa2d504.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"187cf0dd3f6079077c07a6c8ef10621c26383d17","commitMessage":"@@@[Improvement] historical fast restart by lazy load columns metadata(20X faster) (#6988)\n\n* historical fast restart by lazy load columns metadata\n\n* delete repeated code\n\n* add documentation for druid.segmentCache.lazyLoadOnStart\n\n* fix unit test fail\n\n* fix spellcheck\n\n* update docs\n\n* update docs mentioning a catch\n","date":"2019-12-04 01:47:01","modifiedFileCount":"15","status":"M","submitter":"Fangyuan Deng"},{"authorTime":"2019-12-04 01:47:01","codes":[{"authorDate":"2020-01-25 05:10:01","commitOrder":4,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2020-01-25 05:10:01","endLine":179,"groupId":"17872","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/35/6302cee228754f38cfa5e15f54389a83e000a9.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"M"},{"authorDate":"2019-12-04 01:47:01","commitOrder":4,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2019-12-04 01:47:01","endLine":88,"groupId":"17872","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/c9c1671fc33539e493287f8ff5d425aaa2d504.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"N"}],"commitId":"19b427e8f371bed0b0100272ac890b3775471654","commitMessage":"@@@Add JoinableFactory interface and use it in the query stack. (#9247)\n\n* Add JoinableFactory interface and use it in the query stack.\n\nAlso includes InlineJoinableFactory.  which enables joining against\ninline datasources. This is the first patch where a basic join query\nactually works. It includes integration tests.\n\n* Fix test issues.\n\n* Adjustments from code review.\n","date":"2020-01-25 05:10:01","modifiedFileCount":"51","status":"M","submitter":"Gian Merlino"},{"authorTime":"2019-12-04 01:47:01","codes":[{"authorDate":"2020-07-21 12:02:52","commitOrder":5,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2020-07-21 12:02:52","endLine":204,"groupId":"13607","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/bf/74ba66d7e8af4ac26a2252831eecd4bb5a2d39.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            return (QueryRunnerFactory) factory;\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":127,"status":"M"},{"authorDate":"2019-12-04 01:47:01","commitOrder":5,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2019-12-04 01:47:01","endLine":88,"groupId":"17872","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/c9c1671fc33539e493287f8ff5d425aaa2d504.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"N"}],"commitId":"41982116f4ff7a05dbf292db71b1bcab2cbe7c66","commitMessage":"@@@Report missing segments when there is no segment for the query datasource in historicals (#10199)\n\n* Report missing segments when there is no segment for the query\ndatasource in historicals\n\n* test\n\n* missing part for test\n\n* another test","date":"2020-07-21 12:02:52","modifiedFileCount":"4","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-01-17 11:53:30","codes":[{"authorDate":"2021-01-17 11:53:30","commitOrder":6,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2021-01-17 11:53:30","endLine":213,"groupId":"13607","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/6f/8d5a63e9dbfcf150c8c5ebb2b1ba623a5ba860.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":136,"status":"M"},{"authorDate":"2021-01-17 11:53:30","commitOrder":6,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2021-01-17 11:53:30","endLine":92,"groupId":"17872","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/2339f7f1f85f9b78fd56c4361f3b8af9f14eb5.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"2590ad4f67fab99760eb4562d84b34e8aa55f6c1","commitMessage":"@@@Historical unloads damaged segments automatically when lazy on start. (#10688)\n\n* ready to test\n\n* tested on dev cluster\n\n* tested\n\n* code review\n\n* add UTs\n\n* add UTs\n\n* ut passed\n\n* ut passed\n\n* opti imports\n\n* done\n\n* done\n\n* fix checkstyle\n\n* modify uts\n\n* modify logs\n\n* changing the package of SegmentLazyLoadFailCallback.java to org.apache.druid.segment\n\n* merge from master\n\n* modify import orders\n\n* merge from master\n\n* merge from master\n\n* modify logs\n\n* modify docs\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\n* modify logs to rerun ci\n\nCo-authored-by: yuezhang <yuezhang@freewheel.tv>","date":"2021-01-17 11:53:30","modifiedFileCount":"20","status":"M","submitter":"zhangyue19921010"},{"authorTime":"2021-01-17 11:53:30","codes":[{"authorDate":"2021-07-01 18:33:08","commitOrder":7,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        new ForwardingQueryProcessingPool(serverManagerExec),\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2021-07-01 18:33:08","endLine":216,"groupId":"17872","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/90/2acd8d02af769a999474d7bc333143d223206f.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        serverManagerExec,\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"M"},{"authorDate":"2021-01-17 11:53:30","commitOrder":7,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2021-01-17 11:53:30","endLine":92,"groupId":"17872","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/2339f7f1f85f9b78fd56c4361f3b8af9f14eb5.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"N"}],"commitId":"03a6a6d6e1f7024c2691e6fef0685bd137d223e7","commitMessage":"@@@Replace Processing ExecutorService with QueryProcessingPool (#11382)\n\nThis PR refactors the code for QueryRunnerFactory#mergeRunners to accept a new interface called QueryProcessingPool instead of ExecutorService for concurrent execution of query runners. This interface will let custom extensions inject their own implementation for deciding which query-runner to prioritize first. The default implementation is the same as today that takes the priority of query into account. QueryProcessingPool can also be used as a regular executor service. It has a dedicated method for accepting query execution work so implementations can differentiate between regular async tasks and query execution tasks. This dedicated method also passes the QueryRunner object as part of the task information. This hook will let custom extensions carry any state from QuerySegmentWalker to QueryProcessingPool#mergeRunners which is not possible currently.","date":"2021-07-01 18:33:08","modifiedFileCount":"52","status":"M","submitter":"Abhishek Agarwal"},{"authorTime":"2021-07-21 02:44:19","codes":[{"authorDate":"2021-07-21 02:44:19","commitOrder":8,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        new ForwardingQueryProcessingPool(serverManagerExec),\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2021-07-21 02:44:19","endLine":203,"groupId":"17872","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/16/832b3dfcb380200fa2440c0a55855cbd89fb6e.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public boolean isSegmentLoaded(DataSegment segment)\n          {\n            return false;\n          }\n\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public File getSegmentFiles(DataSegment segment)\n          {\n            throw new UnsupportedOperationException();\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        new ForwardingQueryProcessingPool(serverManagerExec),\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"M"},{"authorDate":"2021-07-21 02:44:19","commitOrder":8,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2021-07-21 02:44:19","endLine":80,"groupId":"17872","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/86/98146c9d5330d0c7276f018883558ba2ab9477.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public boolean isSegmentLoaded(DataSegment segment)\n    {\n      return false;\n    }\n\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public File getSegmentFiles(DataSegment segment)\n    {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"94c1671eaf7b050972602fdedcb1971cdbde692d","commitMessage":"@@@Split SegmentLoader into SegmentLoader and SegmentCacheManager (#11466)\n\nThis PR splits current SegmentLoader into SegmentLoader and SegmentCacheManager.\n\nSegmentLoader - this class is responsible for building the segment object but does not expose any methods for downloading.  cache space management.  etc. Default implementation delegates the download operations to SegmentCacheManager and only contains the logic for building segments once downloaded. . This class will be used in SegmentManager to construct Segment objects.\n\nSegmentCacheManager - this class manages the segment cache on the local disk. It fetches the segment files to the local disk.  can clean up the cache.  and in the future.  support reserve and release on cache space. [See https://github.com/Make SegmentLoader extensible and customizable #11398]. This class will be used in ingestion tasks such as compaction.  re-indexing where segment files need to be downloaded locally.","date":"2021-07-21 02:44:19","modifiedFileCount":"41","status":"M","submitter":"Abhishek Agarwal"},{"authorTime":"2021-07-22 20:30:49","codes":[{"authorDate":"2021-07-22 20:30:49","commitOrder":9,"curCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public ReferenceCountingSegment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return ReferenceCountingSegment.wrapSegment(new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            ), segment.getShardSpec());\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        new ForwardingQueryProcessingPool(serverManagerExec),\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","date":"2021-07-22 20:30:49","endLine":203,"groupId":"10697","id":15,"instanceNumber":1,"isCurCommit":1,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a7/6cc5b25bec6b86a9db29d4351e64d5e63ce54d.src","preCode":"  public void setUp()\n  {\n    EmittingLogger.registerEmitter(new NoopServiceEmitter());\n\n    queryWaitLatch = new CountDownLatch(1);\n    queryWaitYieldLatch = new CountDownLatch(1);\n    queryNotifyLatch = new CountDownLatch(1);\n    factory = new MyQueryRunnerFactory(queryWaitLatch, queryWaitYieldLatch, queryNotifyLatch);\n    serverManagerExec = Executors.newFixedThreadPool(2);\n    segmentManager = new SegmentManager(\n        new SegmentLoader()\n        {\n          @Override\n          public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback SegmentLazyLoadFailCallback)\n          {\n            return new SegmentForTesting(\n                MapUtils.getString(segment.getLoadSpec(), \"version\"),\n                (Interval) segment.getLoadSpec().get(\"interval\")\n            );\n          }\n\n          @Override\n          public void cleanup(DataSegment segment)\n          {\n\n          }\n        }\n    );\n    serverManager = new ServerManager(\n        new QueryRunnerFactoryConglomerate()\n        {\n          @Override\n          public <T, QueryType extends Query<T>> QueryRunnerFactory<T, QueryType> findFactory(QueryType query)\n          {\n            if (query instanceof SearchQuery) {\n              return (QueryRunnerFactory) factory;\n            } else {\n              return null;\n            }\n          }\n        },\n        new NoopServiceEmitter(),\n        new ForwardingQueryProcessingPool(serverManagerExec),\n        new ForegroundCachePopulator(new DefaultObjectMapper(), new CachePopulatorStats(), -1),\n        new DefaultObjectMapper(),\n        new LocalCacheProvider().get(),\n        new CacheConfig(),\n        segmentManager,\n        NoopJoinableFactory.INSTANCE,\n        new ServerConfig()\n    );\n\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"P1d/2011-04-02\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-03\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-04\"));\n    loadQueryable(\"test\", \"1\", Intervals.of(\"P1d/2011-04-05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T01\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T02\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T03\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T05\"));\n    loadQueryable(\"test\", \"2\", Intervals.of(\"PT1h/2011-04-04T06\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-01\"));\n    loadQueryable(\"test2\", \"1\", Intervals.of(\"P1d/2011-04-02\"));\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordination/ServerManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"M"},{"authorDate":"2021-07-22 20:30:49","commitOrder":9,"curCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public ReferenceCountingSegment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return ReferenceCountingSegment.wrapSegment(new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      ), segment.getShardSpec());\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","date":"2021-07-22 20:30:49","endLine":80,"groupId":"10697","id":16,"instanceNumber":2,"isCurCommit":1,"methodName":"SEGMENT_LOADER","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/83/f0a8ff1e081232f36cdb94d5b11beb46f81e30.src","preCode":"  private static final SegmentLoader SEGMENT_LOADER = new SegmentLoader()\n  {\n    @Override\n    public Segment getSegment(final DataSegment segment, boolean lazy, SegmentLazyLoadFailCallback loadFailed)\n    {\n      return new SegmentForTesting(\n          MapUtils.getString(segment.getLoadSpec(), \"version\"),\n          (Interval) segment.getLoadSpec().get(\"interval\")\n      );\n    }\n\n    @Override\n    public void cleanup(DataSegment segment)\n    {\n\n    }\n  };\n","realPath":"server/src/test/java/org/apache/druid/server/SegmentManagerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"ce1faa56352766522610e3ae306c15b55df19fb0","commitMessage":"@@@Make SegmentLoader extensible and customizable (#11398)\n\nThis PR refactors the code related to segment loading specifically SegmentLoader and SegmentLoaderLocalCacheManager. SegmentLoader is marked UnstableAPI which means.  it can be extended outside core druid in custom extensions. Here is a summary of changes\n\nSegmentLoader returns an instance of ReferenceCountingSegment instead of Segment. Earlier.  SegmentManager was wrapping Segment objects inside ReferenceCountingSegment. That is now moved to SegmentLoader. With this.  a custom implementation can track the references of segments. It also allows them to create custom ReferenceCountingSegment implementations. For this reason.  the constructor visibility in ReferenceCountingSegment is changed from private to protected.\nSegmentCacheManager has two additional methods called - reserve(DataSegment) and release(DataSegment). These methods let the caller reserve or release space without calling SegmentLoader#getSegment. We already had similar methods in StorageLocation and now they are available in SegmentCacheManager too which wraps multiple locations.\nRefactoring to simplify the code in SegmentCacheManager wherever possible. There is no change in the functionality.","date":"2021-07-22 20:30:49","modifiedFileCount":"14","status":"M","submitter":"Abhishek Agarwal"}]
