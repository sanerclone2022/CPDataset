[{"authorTime":"2020-04-25 01:22:51","codes":[{"authorDate":"2020-04-25 01:22:51","commitOrder":1,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap());\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2020-04-25 01:22:51","endLine":92,"groupId":"10109","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/a02db31385208f3475a4b33f186b2ea76e9102.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap());\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"B"},{"authorDate":"2020-04-25 01:22:51","commitOrder":1,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new NotConvertibleToInputFormatParseSpec(),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","date":"2020-04-25 01:22:51","endLine":128,"groupId":"15529","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/a02db31385208f3475a4b33f186b2ea76e9102.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new NotConvertibleToInputFormatParseSpec(),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"B"}],"commitId":"7fa72fbf15f627d25e860eb249922bea9331d623","commitMessage":"@@@Initialize SettableByteEntityReader only when inputFormat is not null (#9734)\n\n* Lazy initialization of SettableByteEntityReader to avoid NPE\n\n* toInputFormat for tsv\n\n* address comments\n\n* common code","date":"2020-04-25 01:22:51","modifiedFileCount":"4","status":"B","submitter":"Jihoon Son"},{"authorTime":"2020-05-06 02:17:57","codes":[{"authorDate":"2020-04-25 01:22:51","commitOrder":2,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap());\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2020-04-25 01:22:51","endLine":92,"groupId":"10109","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/a02db31385208f3475a4b33f186b2ea76e9102.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap());\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"N"},{"authorDate":"2020-05-06 02:17:57","commitOrder":2,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap()\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","date":"2020-05-06 02:17:57","endLine":137,"groupId":"15529","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c1/814d6695faa52b8a92ce5a67455b2b9c114079.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new NotConvertibleToInputFormatParseSpec(),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"}],"commitId":"964a1fc9df69520e54e10edd33e0404ed6e8330d","commitMessage":"@@@Remove ParseSpec.toInputFormat() (#9815)\n\n* Remove toInputFormat() from ParseSpec\n\n* fix test","date":"2020-05-06 02:17:57","modifiedFileCount":"24","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-05-09 12:53:39","codes":[{"authorDate":"2020-05-09 12:53:39","commitOrder":3,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2020-05-09 12:53:39","endLine":97,"groupId":"10109","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/10/732921eb8d610f6cf02444edffb6383a53cca5.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap());\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":86,"status":"M"},{"authorDate":"2020-05-09 12:53:39","commitOrder":3,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","date":"2020-05-09 12:53:39","endLine":139,"groupId":"15529","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/10/732921eb8d610f6cf02444edffb6383a53cca5.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap()\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"M"}],"commitId":"28be107a1c18ef1fd9fd268c8b04e232efb63695","commitMessage":"@@@add flag to flattenSpec to keep null columns (#9814)\n\n* add flag to flattenSpec to keep null columns\n\n* remove changes to inputFormat interface\n\n* add comment\n\n* change comment message\n\n* update web console e2e test\n\n* move keepNullColmns to JSONParseSpec\n\n* fix merge conflicts\n\n* fix tests\n\n* set keepNullColumns to false by default\n\n* fix lgtm\n\n* change Boolean to boolean.  add keepNullColumns to hash.  add tests for keepKeepNullColumns false + true with no nuulul columns\n\n* Add equals verifier tests","date":"2020-05-09 12:53:39","modifiedFileCount":"41","status":"M","submitter":"mcbrewster"},{"authorTime":"2020-09-12 07:31:10","codes":[{"authorDate":"2020-09-12 07:31:10","commitOrder":4,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2020-09-12 07:31:10","endLine":114,"groupId":"10109","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/52/6430db7b1715d1875f84f274965194b0492cf2.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2020-09-12 07:31:10","commitOrder":4,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","date":"2020-09-12 07:31:10","endLine":162,"groupId":"15529","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/52/6430db7b1715d1875f84f274965194b0492cf2.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder()\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"}],"commitId":"8f14ac814e1fdf11878a5ba9bdba58fb745b4c8f","commitMessage":"@@@More structured way to handle parse exceptions (#10336)\n\n* More structured way to handle parse exceptions\n\n* checkstyle; add more tests\n\n* forbidden api; test\n\n* address comment; new test\n\n* address review comments\n\n* javadoc for parseException; remove redundant parseException in streaming ingestion\n\n* fix tests\n\n* unnecessary catch\n\n* unused imports\n\n* appenderator test\n\n* unused import","date":"2020-09-12 07:31:10","modifiedFileCount":"116","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-11-14 05:59:23","codes":[{"authorDate":"2020-09-12 07:31:10","commitOrder":5,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2020-09-12 07:31:10","endLine":114,"groupId":"10109","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/52/6430db7b1715d1875f84f274965194b0492cf2.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"N"},{"authorDate":"2020-11-14 05:59:23","commitOrder":5,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.props.used);\n  }\n","date":"2020-11-14 05:59:23","endLine":163,"groupId":"15529","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/4619a08937701bcec071387ba60cece6a5f17e.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"}],"commitId":"e83d5cb59e07d605f6198dfade87d2d71eb31c01","commitMessage":"@@@Fix ingestion failure of pretty-formatted JSON message (#10383)\n\n* support multi-line text\n\n* add test cases\n\n* split json text into lines case by case\n\n* improve exception handle\n\n* fix CI\n\n* use IntermediateRowParsingReader as base of JsonReader\n\n* update doc\n\n* ignore the non-immutable field in test case\n\n* add more test cases\n\n* mark `lineSplittable` as final\n\n* fix testcases\n\n* fix doc\n\n* add a test case for SqlReader\n\n* return all raw columns when exception occurs\n\n* fix CI\n\n* fix test cases\n\n* resolve review comments\n\n* handle ParseException returned by index.add\n\n* apply Iterables.getOnlyElement\n\n* fix CI\n\n* fix test cases\n\n* improve code in more graceful way\n\n* fix test cases\n\n* fix test cases\n\n* add a test case to check multiple json string in one text block\n\n* fix inspection check","date":"2020-11-14 05:59:23","modifiedFileCount":"28","status":"M","submitter":"frank chen"},{"authorTime":"2021-01-09 08:04:37","codes":[{"authorDate":"2021-01-09 08:04:37","commitOrder":6,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2021-01-09 08:04:37","endLine":115,"groupId":"12090","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/7e/0ece635dc181c8b9ad806c5ff83afeff4cbcef.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"M"},{"authorDate":"2021-01-09 08:04:37","commitOrder":6,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.props.used);\n  }\n","date":"2021-01-09 08:04:37","endLine":164,"groupId":"12089","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/7e/0ece635dc181c8b9ad806c5ff83afeff4cbcef.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser chunkParser = new StreamChunkParser(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.props.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":135,"status":"M"}],"commitId":"118b50195e5c2989e04e0f5290aa72cae114db39","commitMessage":"@@@Introduce KafkaRecordEntity to support Kafka headers in InputFormats (#10730)\n\nToday Kafka message support in streaming indexing tasks is limited to\nmessage values.  and does not provide a way to expose Kafka headers. \ntimestamps.  or keys.  which may be of interest to more specialized\nDruid input formats. For instance.  Kafka headers may be used to indicate\npayload format/encoding or additional metadata.  and timestamps are often\nomitted from values in Kafka streams applications.  since they are\nincluded in the record.\n\nThis change proposes to introduce KafkaRecordEntity as InputEntity. \nwhich would give input formats full access to the underlying Kafka record. \nincluding headers.  key.  timestamps. It would also open access to low-level\ninformation such as topic.  partition.  offset if needed.\n\nKafkaEntity is a subclass of ByteEntity for backwards compatibility with\nexisting input formats.  and to avoid introducing unnecessary complexity\nfor Kinesis indexing tasks.","date":"2021-01-09 08:04:37","modifiedFileCount":"30","status":"M","submitter":"Xavier L?aut?"},{"authorTime":"2021-03-26 01:32:21","codes":[{"authorDate":"2021-03-26 01:32:21","commitOrder":7,"curCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, ColumnsFilter.all()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","date":"2021-03-26 01:32:21","endLine":121,"groupId":"104135","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"testWithNullParserAndInputformatParseProperly","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1c/ab704a2effeae8be86596b362e3208085f6b8f.src","preCode":"  public void testWithNullParserAndInputformatParseProperly() throws IOException\n  {\n    final JsonInputFormat inputFormat = new JsonInputFormat(JSONPathSpec.DEFAULT, Collections.emptyMap(), null);\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        null,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"},{"authorDate":"2021-03-26 01:32:21","commitOrder":7,"curCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, ColumnsFilter.all()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.props.used);\n  }\n","date":"2021-03-26 01:32:21","endLine":170,"groupId":"104135","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"testBothParserAndInputFormatParseProperlyUsingInputFormat","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1c/ab704a2effeae8be86596b362e3208085f6b8f.src","preCode":"  public void testBothParserAndInputFormatParseProperlyUsingInputFormat() throws IOException\n  {\n    final InputRowParser<ByteBuffer> parser = new StringInputRowParser(\n        new JSONParseSpec(\n            TIMESTAMP_SPEC,\n            DimensionsSpec.EMPTY,\n            JSONPathSpec.DEFAULT,\n            Collections.emptyMap(),\n            false\n        ),\n        StringUtils.UTF8_STRING\n    );\n\n    final TrackingJsonInputFormat inputFormat = new TrackingJsonInputFormat(\n        JSONPathSpec.DEFAULT,\n        Collections.emptyMap()\n    );\n    final StreamChunkParser<ByteEntity> chunkParser = new StreamChunkParser<>(\n        parser,\n        inputFormat,\n        new InputRowSchema(TIMESTAMP_SPEC, DimensionsSpec.EMPTY, Collections.emptyList()),\n        TransformSpec.NONE,\n        temporaryFolder.newFolder(),\n        row -> true,\n        rowIngestionMeters,\n        parseExceptionHandler\n    );\n    parseAndAssertResult(chunkParser);\n    Assert.assertTrue(inputFormat.props.used);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/StreamChunkParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":141,"status":"M"}],"commitId":"bf20f9e9798417c9293a195690b6adcb48f44d3f","commitMessage":"@@@DruidInputSource: Fix issues in column projection.  timestamp handling. (#10267)\n\n* DruidInputSource: Fix issues in column projection.  timestamp handling.\n\nDruidInputSource.  DruidSegmentReader changes:\n\n1) Remove \"dimensions\" and \"metrics\". They are not necessary.  because we\n   can compute which columns we need to read based on what is going to\n   be used by the timestamp.  transform.  dimensions.  and metrics.\n2) Start using ColumnsFilter (see below) to decide which columns we need\n   to read.\n3) Actually respect the \"timestampSpec\". Previously.  it was ignored.  and\n   the timestamp of the returned InputRows was set to the `__time` column\n   of the input datasource.\n\n(1) and (2) together fix a bug in which the DruidInputSource would not\nproperly read columns that are used as inputs to a transformSpec.\n\n(3) fixes a bug where the timestampSpec would be ignored if you attempted\nto set the column to something other than `__time`.\n\n(1) and (3) are breaking changes.\n\nWeb console changes:\n\n1) Remove \"Dimensions\" and \"Metrics\" from the Druid input source.\n2) Set timestampSpec to `{\"column\": \"__time\".  \"format\": \"millis\"}` for\n   compatibility with the new behavior.\n\nOther changes:\n\n1) Add ColumnsFilter.  a new class that allows input readers to determine\n   which columns they need to read. Currently.  it's only used by the\n   DruidInputSource.  but it could be used by other columnar input sources\n   in the future.\n2) Add a ColumnsFilter to InputRowSchema.\n3) Remove the metric names from InputRowSchema (they were unused).\n4) Add InputRowSchemas.fromDataSchema method that computes the proper\n   ColumnsFilter for given timestamp.  dimensions.  transform.  and metrics.\n5) Add \"getRequiredColumns\" method to TransformSpec to support the above.\n\n* Various fixups.\n\n* Uncomment incorrectly commented lines.\n\n* Move TransformSpecTest to the proper module.\n\n* Add druid.indexer.task.ignoreTimestampSpecForDruidInputSource setting.\n\n* Fix.\n\n* Fix build.\n\n* Checkstyle.\n\n* Misc fixes.\n\n* Fix test.\n\n* Move config.\n\n* Fix imports.\n\n* Fixup.\n\n* Fix ShuffleResourceTest.\n\n* Add import.\n\n* Smarter exclusions.\n\n* Fixes based on tests.\n\nAlso.  add TIME_COLUMN constant in the web console.\n\n* Adjustments for tests.\n\n* Reorder test data.\n\n* Update docs.\n\n* Update docs to say Druid 0.22.0 instead of 0.21.0.\n\n* Fix test.\n\n* Fix ITAutoCompactionTest.\n\n* Changes from review & from merging.","date":"2021-03-26 01:32:21","modifiedFileCount":"60","status":"M","submitter":"Gian Merlino"}]
