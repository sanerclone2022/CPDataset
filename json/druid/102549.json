[{"authorTime":"2019-02-19 03:50:08","codes":[{"authorDate":"2019-07-31 07:25:32","commitOrder":3,"curCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n    \n    \r\n    insertData();\n    \n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n  \n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n  \n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        objectMapper\n    );\n    \n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n    \n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n    \n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n    \n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n    \n    recordSupplier.close();\n  }\n","date":"2019-07-31 07:25:32","endLine":277,"groupId":"16376","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPollCustomDeserializer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/47/6a1939c4be6d88179897fad80408a47f6075e0.src","preCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n    \n    \r\n    insertData();\n    \n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n  \n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n  \n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        objectMapper\n    );\n    \n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n    \n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n    \n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n    \n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n    \n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"B"},{"authorDate":"2019-02-19 03:50:08","commitOrder":3,"curCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), objectMapper);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","date":"2019-02-19 03:50:08","endLine":220,"groupId":"16376","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testPoll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f9/44bf04610b33cb5d4e910b174cc1d9d834f984.src","preCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), objectMapper);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":190,"status":"NB"}],"commitId":"aba65bb675e0c34216c8d1d0efbe93f17842c1f4","commitMessage":"@@@removed hard-coded Kafka key and value deserializer (#8112)\n\n* removed hard-coded Kafka key and value deserializer.  leaving default deserializer as org.apache.kafka.common.serialization.ByteArrayDeserializer.  Also added checks to ensure that any provided deserializer class extends org.apache.kafka.serialization.Deserializer and outputs a byte array.\n\n* Addressed all comments from original pull request and also added a\nunit test.\n\n* Added additional test that uses \"poll\" to ensure that custom deserializer\nworks properly.\n","date":"2019-07-31 07:25:32","modifiedFileCount":"4","status":"M","submitter":"Aaron Bossert"},{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2019-08-23 18:13:54","commitOrder":4,"curCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        OBJECT_MAPPER\n    );\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","date":"2019-08-23 18:13:54","endLine":277,"groupId":"16376","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPollCustomDeserializer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c4/739abc4deada30f0fd7e54706b1b200f2a2135.src","preCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n    \n    \r\n    insertData();\n    \n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n  \n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n  \n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        objectMapper\n    );\n    \n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n    \n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n    \n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n    \n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n    \n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"},{"authorDate":"2019-08-23 18:13:54","commitOrder":4,"curCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), OBJECT_MAPPER);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","date":"2019-08-23 18:13:54","endLine":310,"groupId":"16376","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testPoll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c4/739abc4deada30f0fd7e54706b1b200f2a2135.src","preCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), objectMapper);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":280,"status":"M"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"},{"authorTime":"2021-01-09 08:04:37","codes":[{"authorDate":"2021-01-09 08:04:37","commitOrder":5,"curCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        OBJECT_MAPPER\n    );\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long, KafkaRecordEntity>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long, KafkaRecordEntity>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","date":"2021-01-09 08:04:37","endLine":285,"groupId":"102549","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testPollCustomDeserializer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/a3ac09044cbda1a7c927011350ba2556a751ad.src","preCode":"  public void testPollCustomDeserializer() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    Map<String, Object> properties = kafkaServer.consumerProperties();\n    properties.put(\"key.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n    properties.put(\"value.deserializer\", KafkaRecordSupplierTest.TestKafkaDeserializer.class.getName());\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        properties,\n        OBJECT_MAPPER\n    );\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":249,"status":"M"},{"authorDate":"2021-01-09 08:04:37","commitOrder":5,"curCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), OBJECT_MAPPER);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long, KafkaRecordEntity>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long, KafkaRecordEntity>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","date":"2021-01-09 08:04:37","endLine":318,"groupId":"102549","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"testPoll","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/a3ac09044cbda1a7c927011350ba2556a751ad.src","preCode":"  public void testPoll() throws InterruptedException, ExecutionException\n  {\n\n    \r\n    insertData();\n\n    Set<StreamPartition<Integer>> partitions = ImmutableSet.of(\n        StreamPartition.of(topic, 0),\n        StreamPartition.of(topic, 1)\n    );\n\n    KafkaRecordSupplier recordSupplier = new KafkaRecordSupplier(\n        kafkaServer.consumerProperties(), OBJECT_MAPPER);\n\n    recordSupplier.assign(partitions);\n    recordSupplier.seekToEarliest(partitions);\n\n    List<OrderedPartitionableRecord<Integer, Long>> initialRecords = new ArrayList<>(createOrderedPartitionableRecords());\n\n    List<OrderedPartitionableRecord<Integer, Long>> polledRecords = recordSupplier.poll(poll_timeout_millis);\n    for (int i = 0; polledRecords.size() != initialRecords.size() && i < pollRetry; i++) {\n      polledRecords.addAll(recordSupplier.poll(poll_timeout_millis));\n      Thread.sleep(200);\n    }\n\n    Assert.assertEquals(partitions, recordSupplier.getAssignment());\n    Assert.assertEquals(initialRecords.size(), polledRecords.size());\n    Assert.assertTrue(initialRecords.containsAll(polledRecords));\n\n    recordSupplier.close();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaRecordSupplierTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":288,"status":"M"}],"commitId":"118b50195e5c2989e04e0f5290aa72cae114db39","commitMessage":"@@@Introduce KafkaRecordEntity to support Kafka headers in InputFormats (#10730)\n\nToday Kafka message support in streaming indexing tasks is limited to\nmessage values.  and does not provide a way to expose Kafka headers. \ntimestamps.  or keys.  which may be of interest to more specialized\nDruid input formats. For instance.  Kafka headers may be used to indicate\npayload format/encoding or additional metadata.  and timestamps are often\nomitted from values in Kafka streams applications.  since they are\nincluded in the record.\n\nThis change proposes to introduce KafkaRecordEntity as InputEntity. \nwhich would give input formats full access to the underlying Kafka record. \nincluding headers.  key.  timestamps. It would also open access to low-level\ninformation such as topic.  partition.  offset if needed.\n\nKafkaEntity is a subclass of ByteEntity for backwards compatibility with\nexisting input formats.  and to avoid introducing unnecessary complexity\nfor Kinesis indexing tasks.","date":"2021-01-09 08:04:37","modifiedFileCount":"30","status":"M","submitter":"Xavier L?aut?"}]
