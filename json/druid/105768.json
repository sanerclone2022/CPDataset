[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testObjectColumnSelectorOnVaryingColumnSchema() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T00:00:00\"),\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T01:00:00\"),\n            Lists.newArrayList(\"billy\", \"sally\"),\n            ImmutableMap.of(\n                \"billy\", \"hip\",\n                \"sally\", \"hop\"\n            )\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(\n                          new LongSumAggregatorFactory(\"cnt\", \"cnt\")\n                      )\n                      .addAggregator(\n                          new JavaScriptAggregatorFactory(\n                              \"fieldLength\",\n                              Arrays.asList(\"sally\", \"billy\"),\n                              \"function(current, s, b) { return current + (s == null ? 0 : s.length) + (b == null ? 0 : b.length); }\",\n                              \"function() { return 0; }\",\n                              \"function(a,b) { return a + b; }\",\n                              JavaScriptConfig.getEnabledInstance()\n                          )\n                      )\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(2, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L, \"fieldLength\", 2.0), row.getEvent());\n\n      row = (MapBasedRow) results.get(1);\n      Assert.assertEquals(\n          ImmutableMap.of(\"billy\", \"hip\", \"sally\", \"hop\", \"cnt\", 1L, \"fieldLength\", 6.0),\n          row.getEvent()\n      );\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":253,"groupId":"21209","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testObjectColumnSelectorOnVaryingColumnSchema","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/00/e718435f7be78583a1a10a9313ba648b4e7879.src","preCode":"  public void testObjectColumnSelectorOnVaryingColumnSchema() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T00:00:00\"),\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T01:00:00\"),\n            Lists.newArrayList(\"billy\", \"sally\"),\n            ImmutableMap.of(\n                \"billy\", \"hip\",\n                \"sally\", \"hop\"\n            )\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(\n                          new LongSumAggregatorFactory(\"cnt\", \"cnt\")\n                      )\n                      .addAggregator(\n                          new JavaScriptAggregatorFactory(\n                              \"fieldLength\",\n                              Arrays.asList(\"sally\", \"billy\"),\n                              \"function(current, s, b) { return current + (s == null ? 0 : s.length) + (b == null ? 0 : b.length); }\",\n                              \"function() { return 0; }\",\n                              \"function(a,b) { return a + b; }\",\n                              JavaScriptConfig.getEnabledInstance()\n                          )\n                      )\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(2, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L, \"fieldLength\", 2.0), row.getEvent());\n\n      row = (MapBasedRow) results.get(1);\n      Assert.assertEquals(\n          ImmutableMap.of(\"billy\", \"hip\", \"sally\", \"hop\", \"cnt\", 1L, \"fieldLength\", 6.0),\n          row.getEvent()\n      );\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/incremental/IncrementalIndexStorageAdapterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":175,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testFilterByNull() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"sally\"),\n            ImmutableMap.of(\"sally\", \"bo\")\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(new LongSumAggregatorFactory(\"cnt\", \"cnt\"))\n                      .setDimFilter(DimFilters.dimEquals(\"sally\", (String) null))\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(1, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L), row.getEvent());\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":417,"groupId":"16249","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFilterByNull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/00/e718435f7be78583a1a10a9313ba648b4e7879.src","preCode":"  public void testFilterByNull() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"sally\"),\n            ImmutableMap.of(\"sally\", \"bo\")\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(new LongSumAggregatorFactory(\"cnt\", \"cnt\"))\n                      .setDimFilter(DimFilters.dimEquals(\"sally\", (String) null))\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(1, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L), row.getEvent());\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/incremental/IncrementalIndexStorageAdapterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":359,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2021-01-08 14:18:47","codes":[{"authorDate":"2021-01-08 14:18:47","commitOrder":2,"curCode":"  public void testObjectColumnSelectorOnVaryingColumnSchema() throws Exception\n  {\n    IncrementalIndex<?> index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T00:00:00\"),\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T01:00:00\"),\n            Lists.newArrayList(\"billy\", \"sally\"),\n            ImmutableMap.of(\n                \"billy\", \"hip\",\n                \"sally\", \"hop\"\n            )\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(\n                          new LongSumAggregatorFactory(\"cnt\", \"cnt\")\n                      )\n                      .addAggregator(\n                          new JavaScriptAggregatorFactory(\n                              \"fieldLength\",\n                              Arrays.asList(\"sally\", \"billy\"),\n                              \"function(current, s, b) { return current + (s == null ? 0 : s.length) + (b == null ? 0 : b.length); }\",\n                              \"function() { return 0; }\",\n                              \"function(a,b) { return a + b; }\",\n                              JavaScriptConfig.getEnabledInstance()\n                          )\n                      )\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(2, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L, \"fieldLength\", 2.0), row.getEvent());\n\n      row = (MapBasedRow) results.get(1);\n      Assert.assertEquals(\n          ImmutableMap.of(\"billy\", \"hip\", \"sally\", \"hop\", \"cnt\", 1L, \"fieldLength\", 6.0),\n          row.getEvent()\n      );\n    }\n  }\n","date":"2021-01-08 14:18:47","endLine":255,"groupId":"105768","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testObjectColumnSelectorOnVaryingColumnSchema","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/61/68719a5da29c7500ab083cfa2af123e730053c.src","preCode":"  public void testObjectColumnSelectorOnVaryingColumnSchema() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T00:00:00\"),\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            DateTimes.of(\"2014-09-01T01:00:00\"),\n            Lists.newArrayList(\"billy\", \"sally\"),\n            ImmutableMap.of(\n                \"billy\", \"hip\",\n                \"sally\", \"hop\"\n            )\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(\n                          new LongSumAggregatorFactory(\"cnt\", \"cnt\")\n                      )\n                      .addAggregator(\n                          new JavaScriptAggregatorFactory(\n                              \"fieldLength\",\n                              Arrays.asList(\"sally\", \"billy\"),\n                              \"function(current, s, b) { return current + (s == null ? 0 : s.length) + (b == null ? 0 : b.length); }\",\n                              \"function() { return 0; }\",\n                              \"function(a,b) { return a + b; }\",\n                              JavaScriptConfig.getEnabledInstance()\n                          )\n                      )\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(2, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L, \"fieldLength\", 2.0), row.getEvent());\n\n      row = (MapBasedRow) results.get(1);\n      Assert.assertEquals(\n          ImmutableMap.of(\"billy\", \"hip\", \"sally\", \"hop\", \"cnt\", 1L, \"fieldLength\", 6.0),\n          row.getEvent()\n      );\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/incremental/IncrementalIndexStorageAdapterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":177,"status":"M"},{"authorDate":"2021-01-08 14:18:47","commitOrder":2,"curCode":"  public void testFilterByNull() throws Exception\n  {\n    IncrementalIndex<?> index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"sally\"),\n            ImmutableMap.of(\"sally\", \"bo\")\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(new LongSumAggregatorFactory(\"cnt\", \"cnt\"))\n                      .setDimFilter(DimFilters.dimEquals(\"sally\", (String) null))\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(1, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L), row.getEvent());\n    }\n  }\n","date":"2021-01-08 14:18:47","endLine":419,"groupId":"105768","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testFilterByNull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/61/68719a5da29c7500ab083cfa2af123e730053c.src","preCode":"  public void testFilterByNull() throws Exception\n  {\n    IncrementalIndex index = indexCreator.createIndex();\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"billy\"),\n            ImmutableMap.of(\"billy\", \"hi\")\n        )\n    );\n    index.add(\n        new MapBasedInputRow(\n            System.currentTimeMillis() - 1,\n            Collections.singletonList(\"sally\"),\n            ImmutableMap.of(\"sally\", \"bo\")\n        )\n    );\n\n    try (\n        CloseableStupidPool<ByteBuffer> pool = new CloseableStupidPool<>(\n            \"GroupByQueryEngine-bufferPool\",\n            () -> ByteBuffer.allocate(50000)\n        )\n    ) {\n      final GroupByQueryEngine engine = new GroupByQueryEngine(\n          Suppliers.ofInstance(\n              new GroupByQueryConfig()\n              {\n                @Override\n                public int getMaxIntermediateRows()\n                {\n                  return 5;\n                }\n              }\n          ),\n          pool\n      );\n\n      final Sequence<Row> rows = engine.process(\n          GroupByQuery.builder()\n                      .setDataSource(\"test\")\n                      .setGranularity(Granularities.ALL)\n                      .setInterval(new Interval(DateTimes.EPOCH, DateTimes.nowUtc()))\n                      .addDimension(\"billy\")\n                      .addDimension(\"sally\")\n                      .addAggregator(new LongSumAggregatorFactory(\"cnt\", \"cnt\"))\n                      .setDimFilter(DimFilters.dimEquals(\"sally\", (String) null))\n                      .build(),\n          new IncrementalIndexStorageAdapter(index)\n      );\n\n      final List<Row> results = rows.toList();\n\n      Assert.assertEquals(1, results.size());\n\n      MapBasedRow row = (MapBasedRow) results.get(0);\n      Assert.assertEquals(ImmutableMap.of(\"billy\", \"hi\", \"cnt\", 1L), row.getEvent());\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/incremental/IncrementalIndexStorageAdapterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":361,"status":"M"}],"commitId":"08ab82f55ca856d60dfe1088c1c0393428b0bb6d","commitMessage":"@@@IncrementalIndex Tests and Benchmarks Parametrization (#10593)\n\n* Remove redundant IncrementalIndex.Builder\n\n* Parametrize incremental index tests and benchmarks\n\n- Reveal and fix a bug in OffheapIncrementalIndex\n\n* Fix forbiddenapis error: Forbidden method invocation: java.lang.String#format(java.lang.String. java.lang.Object[]) [Uses default locale]\n\n* Fix Intellij errors: declared exception is never thrown\n\n* Add documentation and validate before closing objects on tearDown.\n\n* Add documentation to OffheapIncrementalIndexTestSpec\n\n* Doc corrections and minor changes.\n\n* Add logging for generated rows.\n\n* Refactor new tests/benchmarks.\n\n* Improve IncrementalIndexCreator documentation\n\n* Add required tests for DataGenerator\n\n* Revert \"rollupOpportunity\" to be a string","date":"2021-01-08 14:18:47","modifiedFileCount":"62","status":"M","submitter":"Liran Funaro"}]
