[{"authorTime":"2020-01-28 03:24:29","codes":[{"authorDate":"2021-03-06 17:06:52","commitOrder":10,"curCode":"  public void testNoInitialStateWithAutoscaler() throws Exception\n  {\n    KafkaIndexTaskClientFactory taskClientFactory = new KafkaIndexTaskClientFactory(\n            null,\n            null\n    )\n    {\n      @Override\n      public KafkaIndexTaskClient build(\n              TaskInfoProvider taskInfoProvider,\n              String dataSource,\n              int numThreads,\n              Duration httpTimeout,\n              long numRetries\n      )\n      {\n        Assert.assertEquals(TEST_CHAT_THREADS, numThreads);\n        Assert.assertEquals(TEST_HTTP_TIMEOUT.toStandardDuration(), httpTimeout);\n        Assert.assertEquals(TEST_CHAT_RETRIES, numRetries);\n        return taskClient;\n      }\n    };\n\n    HashMap<String, Object> autoScalerConfig = new HashMap<>();\n    autoScalerConfig.put(\"enableTaskAutoScaler\", true);\n    autoScalerConfig.put(\"lagCollectionIntervalMillis\", 500);\n    autoScalerConfig.put(\"lagCollectionRangeMillis\", 500);\n    autoScalerConfig.put(\"scaleOutThreshold\", 0);\n    autoScalerConfig.put(\"triggerScaleOutFractionThreshold\", 0.0);\n    autoScalerConfig.put(\"scaleInThreshold\", 1000000);\n    autoScalerConfig.put(\"triggerScaleInFractionThreshold\", 0.8);\n    autoScalerConfig.put(\"scaleActionStartDelayMillis\", 0);\n    autoScalerConfig.put(\"scaleActionPeriodMillis\", 100);\n    autoScalerConfig.put(\"taskCountMax\", 2);\n    autoScalerConfig.put(\"taskCountMin\", 1);\n    autoScalerConfig.put(\"scaleInStep\", 1);\n    autoScalerConfig.put(\"scaleOutStep\", 2);\n    autoScalerConfig.put(\"minTriggerScaleActionFrequencyMillis\", 1200000);\n\n    final Map<String, Object> consumerProperties = KafkaConsumerConfigs.getConsumerProperties();\n    consumerProperties.put(\"myCustomKey\", \"myCustomValue\");\n    consumerProperties.put(\"bootstrap.servers\", kafkaHost);\n\n    KafkaSupervisorIOConfig kafkaSupervisorIOConfig = new KafkaSupervisorIOConfig(\n            topic,\n            INPUT_FORMAT,\n            1,\n            1,\n            new Period(\"PT1H\"),\n            consumerProperties,\n            OBJECT_MAPPER.convertValue(autoScalerConfig, LagBasedAutoScalerConfig.class),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            new Period(\"P1D\"),\n            new Period(\"PT30S\"),\n            true,\n            new Period(\"PT30M\"),\n            null,\n            null,\n            null\n    );\n\n    final KafkaSupervisorTuningConfig tuningConfigOri = new KafkaSupervisorTuningConfig(\n            null,\n            1000,\n            null,\n            null,\n            50000,\n            null,\n            new Period(\"P1Y\"),\n            new File(\"/test\"),\n            null,\n            null,\n            null,\n            true,\n            false,\n            null,\n            false,\n            null,\n            numThreads,\n            TEST_CHAT_THREADS,\n            TEST_CHAT_RETRIES,\n            TEST_HTTP_TIMEOUT,\n            TEST_SHUTDOWN_TIMEOUT,\n            null,\n            null,\n            null,\n            null,\n            null\n    );\n\n    EasyMock.expect(ingestionSchema.getIOConfig()).andReturn(kafkaSupervisorIOConfig).anyTimes();\n    EasyMock.expect(ingestionSchema.getDataSchema()).andReturn(dataSchema).anyTimes();\n    EasyMock.expect(ingestionSchema.getTuningConfig()).andReturn(tuningConfigOri).anyTimes();\n    EasyMock.replay(ingestionSchema);\n\n    SeekableStreamSupervisorSpec testableSupervisorSpec = new KafkaSupervisorSpec(\n            ingestionSchema,\n            dataSchema,\n            tuningConfigOri,\n            kafkaSupervisorIOConfig,\n            null,\n            false,\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            new NoopServiceEmitter(),\n            new DruidMonitorSchedulerConfig(),\n            rowIngestionMetersFactory,\n            new SupervisorStateManagerConfig()\n    );\n\n    supervisor = new TestableKafkaSupervisor(\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            (KafkaSupervisorSpec) testableSupervisorSpec,\n            rowIngestionMetersFactory\n    );\n\n    SupervisorTaskAutoScaler autoscaler = testableSupervisorSpec.createAutoscaler(supervisor);\n\n\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskMaster.getSupervisorManager()).andReturn(Optional.absent()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n            new KafkaDataSourceMetadata(\n                    null\n            )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    supervisor.start();\n    int taskCountBeforeScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(1, taskCountBeforeScale);\n    autoscaler.start();\n    supervisor.runInternal();\n    Thread.sleep(1 * 1000);\n    verifyAll();\n\n    int taskCountAfterScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(2, taskCountAfterScale);\n\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(KafkaSupervisorTest.dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2));\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2)\n    );\n\n    autoscaler.reset();\n    autoscaler.stop();\n  }\n","date":"2021-03-06 17:06:52","endLine":429,"groupId":"15736","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoInitialStateWithAutoscaler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ac/6b6e50590f06e42808368c88192fade7284e26.src","preCode":"  public void testNoInitialStateWithAutoscaler() throws Exception\n  {\n    KafkaIndexTaskClientFactory taskClientFactory = new KafkaIndexTaskClientFactory(\n            null,\n            null\n    )\n    {\n      @Override\n      public KafkaIndexTaskClient build(\n              TaskInfoProvider taskInfoProvider,\n              String dataSource,\n              int numThreads,\n              Duration httpTimeout,\n              long numRetries\n      )\n      {\n        Assert.assertEquals(TEST_CHAT_THREADS, numThreads);\n        Assert.assertEquals(TEST_HTTP_TIMEOUT.toStandardDuration(), httpTimeout);\n        Assert.assertEquals(TEST_CHAT_RETRIES, numRetries);\n        return taskClient;\n      }\n    };\n\n    HashMap<String, Object> autoScalerConfig = new HashMap<>();\n    autoScalerConfig.put(\"enableTaskAutoScaler\", true);\n    autoScalerConfig.put(\"lagCollectionIntervalMillis\", 500);\n    autoScalerConfig.put(\"lagCollectionRangeMillis\", 500);\n    autoScalerConfig.put(\"scaleOutThreshold\", 0);\n    autoScalerConfig.put(\"triggerScaleOutFractionThreshold\", 0.0);\n    autoScalerConfig.put(\"scaleInThreshold\", 1000000);\n    autoScalerConfig.put(\"triggerScaleInFractionThreshold\", 0.8);\n    autoScalerConfig.put(\"scaleActionStartDelayMillis\", 0);\n    autoScalerConfig.put(\"scaleActionPeriodMillis\", 100);\n    autoScalerConfig.put(\"taskCountMax\", 2);\n    autoScalerConfig.put(\"taskCountMin\", 1);\n    autoScalerConfig.put(\"scaleInStep\", 1);\n    autoScalerConfig.put(\"scaleOutStep\", 2);\n    autoScalerConfig.put(\"minTriggerScaleActionFrequencyMillis\", 1200000);\n\n    final Map<String, Object> consumerProperties = KafkaConsumerConfigs.getConsumerProperties();\n    consumerProperties.put(\"myCustomKey\", \"myCustomValue\");\n    consumerProperties.put(\"bootstrap.servers\", kafkaHost);\n\n    KafkaSupervisorIOConfig kafkaSupervisorIOConfig = new KafkaSupervisorIOConfig(\n            topic,\n            INPUT_FORMAT,\n            1,\n            1,\n            new Period(\"PT1H\"),\n            consumerProperties,\n            OBJECT_MAPPER.convertValue(autoScalerConfig, LagBasedAutoScalerConfig.class),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            new Period(\"P1D\"),\n            new Period(\"PT30S\"),\n            true,\n            new Period(\"PT30M\"),\n            null,\n            null,\n            null\n    );\n\n    final KafkaSupervisorTuningConfig tuningConfigOri = new KafkaSupervisorTuningConfig(\n            null,\n            1000,\n            null,\n            null,\n            50000,\n            null,\n            new Period(\"P1Y\"),\n            new File(\"/test\"),\n            null,\n            null,\n            null,\n            true,\n            false,\n            null,\n            false,\n            null,\n            numThreads,\n            TEST_CHAT_THREADS,\n            TEST_CHAT_RETRIES,\n            TEST_HTTP_TIMEOUT,\n            TEST_SHUTDOWN_TIMEOUT,\n            null,\n            null,\n            null,\n            null,\n            null\n    );\n\n    EasyMock.expect(ingestionSchema.getIOConfig()).andReturn(kafkaSupervisorIOConfig).anyTimes();\n    EasyMock.expect(ingestionSchema.getDataSchema()).andReturn(dataSchema).anyTimes();\n    EasyMock.expect(ingestionSchema.getTuningConfig()).andReturn(tuningConfigOri).anyTimes();\n    EasyMock.replay(ingestionSchema);\n\n    SeekableStreamSupervisorSpec testableSupervisorSpec = new KafkaSupervisorSpec(\n            ingestionSchema,\n            dataSchema,\n            tuningConfigOri,\n            kafkaSupervisorIOConfig,\n            null,\n            false,\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            new NoopServiceEmitter(),\n            new DruidMonitorSchedulerConfig(),\n            rowIngestionMetersFactory,\n            new SupervisorStateManagerConfig()\n    );\n\n    supervisor = new TestableKafkaSupervisor(\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            (KafkaSupervisorSpec) testableSupervisorSpec,\n            rowIngestionMetersFactory\n    );\n\n    SupervisorTaskAutoScaler autoscaler = testableSupervisorSpec.createAutoscaler(supervisor);\n\n\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskMaster.getSupervisorManager()).andReturn(Optional.absent()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n            new KafkaDataSourceMetadata(\n                    null\n            )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    supervisor.start();\n    int taskCountBeforeScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(1, taskCountBeforeScale);\n    autoscaler.start();\n    supervisor.runInternal();\n    Thread.sleep(1 * 1000);\n    verifyAll();\n\n    int taskCountAfterScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(2, taskCountAfterScale);\n\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(KafkaSupervisorTest.dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2));\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2)\n    );\n\n    autoscaler.reset();\n    autoscaler.stop();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"B"},{"authorDate":"2020-01-28 03:24:29","commitOrder":10,"curCode":"  public void testFailedInitializationAndRecovery() throws Exception\n  {\n    \r\n    supervisor = getTestableSupervisor(\n        1,\n        1,\n        true,\n        \"PT1H\",\n        null,\n        null,\n        false,\n        StringUtils.format(\"badhostname:%d\", kafkaServer.getPort())\n    );\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n\n    replayAll();\n\n    supervisor.start();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertFalse(supervisor.isStarted());\n\n    verifyAll();\n\n    while (supervisor.getInitRetryCounter() < 3) {\n      Thread.sleep(1000);\n    }\n\n    \r\n    resetAll();\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    \r\n    \r\n    \r\n    supervisor.getIoConfig().getConsumerProperties().put(\"bootstrap.servers\", kafkaHost);\n    supervisor.tryInit();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertTrue(supervisor.isStarted());\n\n    supervisor.runInternal();\n    verifyAll();\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n  }\n","date":"2020-01-28 03:24:29","endLine":2885,"groupId":"4225","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFailedInitializationAndRecovery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0b/29b65a628bb6f0503d980831a84ce2d009150d.src","preCode":"  public void testFailedInitializationAndRecovery() throws Exception\n  {\n    \r\n    supervisor = getTestableSupervisor(\n        1,\n        1,\n        true,\n        \"PT1H\",\n        null,\n        null,\n        false,\n        StringUtils.format(\"badhostname:%d\", kafkaServer.getPort())\n    );\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n\n    replayAll();\n\n    supervisor.start();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertFalse(supervisor.isStarted());\n\n    verifyAll();\n\n    while (supervisor.getInitRetryCounter() < 3) {\n      Thread.sleep(1000);\n    }\n\n    \r\n    resetAll();\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    \r\n    \r\n    \r\n    supervisor.getIoConfig().getConsumerProperties().put(\"bootstrap.servers\", kafkaHost);\n    supervisor.tryInit();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertTrue(supervisor.isStarted());\n\n    supervisor.runInternal();\n    verifyAll();\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":2780,"status":"NB"}],"commitId":"bddacbb1c3abccf6ad035a4756a6960761fd43a2","commitMessage":"@@@Dynamic auto scale Kafka-Stream ingest tasks (#10524)\n\n* druid task auto scale based on kafka lag\n\n* fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig\n\n* druid task auto scale based on kafka lag\n\n* fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig\n\n* test dynamic auto scale done\n\n* auto scale tasks tested on prd cluster\n\n* auto scale tasks tested on prd cluster\n\n* modify code style to solve 29055.10 29055.9 29055.17 29055.18 29055.19 29055.20\n\n* rename test fiel function\n\n* change codes and add docs based on capistrant reviewed\n\n* midify test docs\n\n* modify docs\n\n* modify docs\n\n* modify docs\n\n* merge from master\n\n* Extract the autoScale logic out of SeekableStreamSupervisor to minimize putting more stuff inside there &&  Make autoscaling algorithm configurable and scalable.\n\n* fix ci failed\n\n* revert msic.xml\n\n* add uts to test autoscaler create && scale out/in and kafka ingest with scale enable\n\n* add more uts\n\n* fix inner class check\n\n* add IT for kafka ingestion with autoscaler\n\n* add new IT in groups=kafka-index named testKafkaIndexDataWithWithAutoscaler\n\n* review change\n\n* code review\n\n* remove unused imports\n\n* fix NLP\n\n* fix docs and UTs\n\n* revert misc.xml\n\n* use jackson to build autoScaleConfig with default values\n\n* add uts\n\n* use jackson to init AutoScalerConfig in IOConfig instead of Map<>\n\n* autoscalerConfig interface and provide a defaultAutoScalerConfig\n\n* modify uts\n\n* modify docs\n\n* fix checkstyle\n\n* revert misc.xml\n\n* modify uts\n\n* reviewed code change\n\n* reviewed code change\n\n* code reviewed\n\n* code review\n\n* log changed\n\n* do StringUtils.encodeForFormat when create allocationExec\n\n* code review && limit taskCountMax to partitionNumbers\n\n* modify docs\n\n* code review\n\nCo-authored-by: yuezhang <yuezhang@freewheel.tv>","date":"2021-03-06 17:06:52","modifiedFileCount":"24","status":"M","submitter":"zhangyue19921010"},{"authorTime":"2020-01-28 03:24:29","codes":[{"authorDate":"2021-06-24 07:36:46","commitOrder":11,"curCode":"  public void testNoInitialStateWithAutoscaler() throws Exception\n  {\n    KafkaIndexTaskClientFactory taskClientFactory = new KafkaIndexTaskClientFactory(\n            null,\n            null\n    )\n    {\n      @Override\n      public KafkaIndexTaskClient build(\n              TaskInfoProvider taskInfoProvider,\n              String dataSource,\n              int numThreads,\n              Duration httpTimeout,\n              long numRetries\n      )\n      {\n        Assert.assertEquals(TEST_CHAT_THREADS, numThreads);\n        Assert.assertEquals(TEST_HTTP_TIMEOUT.toStandardDuration(), httpTimeout);\n        Assert.assertEquals(TEST_CHAT_RETRIES, numRetries);\n        return taskClient;\n      }\n    };\n\n    HashMap<String, Object> autoScalerConfig = new HashMap<>();\n    autoScalerConfig.put(\"enableTaskAutoScaler\", true);\n    autoScalerConfig.put(\"lagCollectionIntervalMillis\", 500);\n    autoScalerConfig.put(\"lagCollectionRangeMillis\", 500);\n    autoScalerConfig.put(\"scaleOutThreshold\", 0);\n    autoScalerConfig.put(\"triggerScaleOutFractionThreshold\", 0.0);\n    autoScalerConfig.put(\"scaleInThreshold\", 1000000);\n    autoScalerConfig.put(\"triggerScaleInFractionThreshold\", 0.8);\n    autoScalerConfig.put(\"scaleActionStartDelayMillis\", 0);\n    autoScalerConfig.put(\"scaleActionPeriodMillis\", 100);\n    autoScalerConfig.put(\"taskCountMax\", 2);\n    autoScalerConfig.put(\"taskCountMin\", 1);\n    autoScalerConfig.put(\"scaleInStep\", 1);\n    autoScalerConfig.put(\"scaleOutStep\", 2);\n    autoScalerConfig.put(\"minTriggerScaleActionFrequencyMillis\", 1200000);\n\n    final Map<String, Object> consumerProperties = KafkaConsumerConfigs.getConsumerProperties();\n    consumerProperties.put(\"myCustomKey\", \"myCustomValue\");\n    consumerProperties.put(\"bootstrap.servers\", kafkaHost);\n\n    KafkaSupervisorIOConfig kafkaSupervisorIOConfig = new KafkaSupervisorIOConfig(\n            topic,\n            INPUT_FORMAT,\n            1,\n            1,\n            new Period(\"PT1H\"),\n            consumerProperties,\n            OBJECT_MAPPER.convertValue(autoScalerConfig, LagBasedAutoScalerConfig.class),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            new Period(\"P1D\"),\n            new Period(\"PT30S\"),\n            true,\n            new Period(\"PT30M\"),\n            null,\n            null,\n            null\n    );\n\n    final KafkaSupervisorTuningConfig tuningConfigOri = new KafkaSupervisorTuningConfig(\n            null,\n            1000,\n            null,\n            null,\n            50000,\n            null,\n            new Period(\"P1Y\"),\n            new File(\"/test\"),\n            null,\n            null,\n            null,\n            false,\n            null,\n            false,\n            null,\n            numThreads,\n            TEST_CHAT_THREADS,\n            TEST_CHAT_RETRIES,\n            TEST_HTTP_TIMEOUT,\n            TEST_SHUTDOWN_TIMEOUT,\n            null,\n            null,\n            null,\n            null,\n            null\n    );\n\n    EasyMock.expect(ingestionSchema.getIOConfig()).andReturn(kafkaSupervisorIOConfig).anyTimes();\n    EasyMock.expect(ingestionSchema.getDataSchema()).andReturn(dataSchema).anyTimes();\n    EasyMock.expect(ingestionSchema.getTuningConfig()).andReturn(tuningConfigOri).anyTimes();\n    EasyMock.replay(ingestionSchema);\n\n    SeekableStreamSupervisorSpec testableSupervisorSpec = new KafkaSupervisorSpec(\n            ingestionSchema,\n            dataSchema,\n            tuningConfigOri,\n            kafkaSupervisorIOConfig,\n            null,\n            false,\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            new NoopServiceEmitter(),\n            new DruidMonitorSchedulerConfig(),\n            rowIngestionMetersFactory,\n            new SupervisorStateManagerConfig()\n    );\n\n    supervisor = new TestableKafkaSupervisor(\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            (KafkaSupervisorSpec) testableSupervisorSpec,\n            rowIngestionMetersFactory\n    );\n\n    SupervisorTaskAutoScaler autoscaler = testableSupervisorSpec.createAutoscaler(supervisor);\n\n\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskMaster.getSupervisorManager()).andReturn(Optional.absent()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n            new KafkaDataSourceMetadata(\n                    null\n            )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    supervisor.start();\n    int taskCountBeforeScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(1, taskCountBeforeScale);\n    autoscaler.start();\n    supervisor.runInternal();\n    Thread.sleep(1 * 1000);\n    verifyAll();\n\n    int taskCountAfterScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(2, taskCountAfterScale);\n\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(KafkaSupervisorTest.dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2));\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2)\n    );\n\n    autoscaler.reset();\n    autoscaler.stop();\n  }\n","date":"2021-06-24 07:36:46","endLine":428,"groupId":"102457","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoInitialStateWithAutoscaler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/48a110a853ae1a13832d1b96d67fe79c0a2cf9.src","preCode":"  public void testNoInitialStateWithAutoscaler() throws Exception\n  {\n    KafkaIndexTaskClientFactory taskClientFactory = new KafkaIndexTaskClientFactory(\n            null,\n            null\n    )\n    {\n      @Override\n      public KafkaIndexTaskClient build(\n              TaskInfoProvider taskInfoProvider,\n              String dataSource,\n              int numThreads,\n              Duration httpTimeout,\n              long numRetries\n      )\n      {\n        Assert.assertEquals(TEST_CHAT_THREADS, numThreads);\n        Assert.assertEquals(TEST_HTTP_TIMEOUT.toStandardDuration(), httpTimeout);\n        Assert.assertEquals(TEST_CHAT_RETRIES, numRetries);\n        return taskClient;\n      }\n    };\n\n    HashMap<String, Object> autoScalerConfig = new HashMap<>();\n    autoScalerConfig.put(\"enableTaskAutoScaler\", true);\n    autoScalerConfig.put(\"lagCollectionIntervalMillis\", 500);\n    autoScalerConfig.put(\"lagCollectionRangeMillis\", 500);\n    autoScalerConfig.put(\"scaleOutThreshold\", 0);\n    autoScalerConfig.put(\"triggerScaleOutFractionThreshold\", 0.0);\n    autoScalerConfig.put(\"scaleInThreshold\", 1000000);\n    autoScalerConfig.put(\"triggerScaleInFractionThreshold\", 0.8);\n    autoScalerConfig.put(\"scaleActionStartDelayMillis\", 0);\n    autoScalerConfig.put(\"scaleActionPeriodMillis\", 100);\n    autoScalerConfig.put(\"taskCountMax\", 2);\n    autoScalerConfig.put(\"taskCountMin\", 1);\n    autoScalerConfig.put(\"scaleInStep\", 1);\n    autoScalerConfig.put(\"scaleOutStep\", 2);\n    autoScalerConfig.put(\"minTriggerScaleActionFrequencyMillis\", 1200000);\n\n    final Map<String, Object> consumerProperties = KafkaConsumerConfigs.getConsumerProperties();\n    consumerProperties.put(\"myCustomKey\", \"myCustomValue\");\n    consumerProperties.put(\"bootstrap.servers\", kafkaHost);\n\n    KafkaSupervisorIOConfig kafkaSupervisorIOConfig = new KafkaSupervisorIOConfig(\n            topic,\n            INPUT_FORMAT,\n            1,\n            1,\n            new Period(\"PT1H\"),\n            consumerProperties,\n            OBJECT_MAPPER.convertValue(autoScalerConfig, LagBasedAutoScalerConfig.class),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            new Period(\"P1D\"),\n            new Period(\"PT30S\"),\n            true,\n            new Period(\"PT30M\"),\n            null,\n            null,\n            null\n    );\n\n    final KafkaSupervisorTuningConfig tuningConfigOri = new KafkaSupervisorTuningConfig(\n            null,\n            1000,\n            null,\n            null,\n            50000,\n            null,\n            new Period(\"P1Y\"),\n            new File(\"/test\"),\n            null,\n            null,\n            null,\n            true,\n            false,\n            null,\n            false,\n            null,\n            numThreads,\n            TEST_CHAT_THREADS,\n            TEST_CHAT_RETRIES,\n            TEST_HTTP_TIMEOUT,\n            TEST_SHUTDOWN_TIMEOUT,\n            null,\n            null,\n            null,\n            null,\n            null\n    );\n\n    EasyMock.expect(ingestionSchema.getIOConfig()).andReturn(kafkaSupervisorIOConfig).anyTimes();\n    EasyMock.expect(ingestionSchema.getDataSchema()).andReturn(dataSchema).anyTimes();\n    EasyMock.expect(ingestionSchema.getTuningConfig()).andReturn(tuningConfigOri).anyTimes();\n    EasyMock.replay(ingestionSchema);\n\n    SeekableStreamSupervisorSpec testableSupervisorSpec = new KafkaSupervisorSpec(\n            ingestionSchema,\n            dataSchema,\n            tuningConfigOri,\n            kafkaSupervisorIOConfig,\n            null,\n            false,\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            new NoopServiceEmitter(),\n            new DruidMonitorSchedulerConfig(),\n            rowIngestionMetersFactory,\n            new SupervisorStateManagerConfig()\n    );\n\n    supervisor = new TestableKafkaSupervisor(\n            taskStorage,\n            taskMaster,\n            indexerMetadataStorageCoordinator,\n            taskClientFactory,\n            OBJECT_MAPPER,\n            (KafkaSupervisorSpec) testableSupervisorSpec,\n            rowIngestionMetersFactory\n    );\n\n    SupervisorTaskAutoScaler autoscaler = testableSupervisorSpec.createAutoscaler(supervisor);\n\n\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskMaster.getSupervisorManager()).andReturn(Optional.absent()).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n            new KafkaDataSourceMetadata(\n                    null\n            )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    supervisor.start();\n    int taskCountBeforeScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(1, taskCountBeforeScale);\n    autoscaler.start();\n    supervisor.runInternal();\n    Thread.sleep(1 * 1000);\n    verifyAll();\n\n    int taskCountAfterScale = supervisor.getIoConfig().getTaskCount();\n    Assert.assertEquals(2, taskCountAfterScale);\n\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(KafkaSupervisorTest.dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1));\n    Assert.assertEquals(0L, (long) taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2));\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1)\n    );\n    Assert.assertEquals(\n            Long.MAX_VALUE,\n            (long) taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2)\n    );\n\n    autoscaler.reset();\n    autoscaler.stop();\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"},{"authorDate":"2020-01-28 03:24:29","commitOrder":11,"curCode":"  public void testFailedInitializationAndRecovery() throws Exception\n  {\n    \r\n    supervisor = getTestableSupervisor(\n        1,\n        1,\n        true,\n        \"PT1H\",\n        null,\n        null,\n        false,\n        StringUtils.format(\"badhostname:%d\", kafkaServer.getPort())\n    );\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n\n    replayAll();\n\n    supervisor.start();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertFalse(supervisor.isStarted());\n\n    verifyAll();\n\n    while (supervisor.getInitRetryCounter() < 3) {\n      Thread.sleep(1000);\n    }\n\n    \r\n    resetAll();\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    \r\n    \r\n    \r\n    supervisor.getIoConfig().getConsumerProperties().put(\"bootstrap.servers\", kafkaHost);\n    supervisor.tryInit();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertTrue(supervisor.isStarted());\n\n    supervisor.runInternal();\n    verifyAll();\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n  }\n","date":"2020-01-28 03:24:29","endLine":2885,"groupId":"102457","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testFailedInitializationAndRecovery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0b/29b65a628bb6f0503d980831a84ce2d009150d.src","preCode":"  public void testFailedInitializationAndRecovery() throws Exception\n  {\n    \r\n    supervisor = getTestableSupervisor(\n        1,\n        1,\n        true,\n        \"PT1H\",\n        null,\n        null,\n        false,\n        StringUtils.format(\"badhostname:%d\", kafkaServer.getPort())\n    );\n    final KafkaSupervisorTuningConfig tuningConfig = supervisor.getTuningConfig();\n    addSomeEvents(1);\n\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n\n    replayAll();\n\n    supervisor.start();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertFalse(supervisor.isStarted());\n\n    verifyAll();\n\n    while (supervisor.getInitRetryCounter() < 3) {\n      Thread.sleep(1000);\n    }\n\n    \r\n    resetAll();\n\n    Capture<KafkaIndexTask> captured = Capture.newInstance();\n    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();\n    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();\n    EasyMock.expect(taskStorage.getActiveTasksByDatasource(DATASOURCE)).andReturn(ImmutableList.of()).anyTimes();\n    EasyMock.expect(indexerMetadataStorageCoordinator.retrieveDataSourceMetadata(DATASOURCE)).andReturn(\n        new KafkaDataSourceMetadata(\n            null\n        )\n    ).anyTimes();\n    EasyMock.expect(taskQueue.add(EasyMock.capture(captured))).andReturn(true);\n    taskRunner.registerListener(EasyMock.anyObject(TaskRunnerListener.class), EasyMock.anyObject(Executor.class));\n    replayAll();\n\n    \r\n    \r\n    \r\n    supervisor.getIoConfig().getConsumerProperties().put(\"bootstrap.servers\", kafkaHost);\n    supervisor.tryInit();\n\n    Assert.assertTrue(supervisor.isLifecycleStarted());\n    Assert.assertTrue(supervisor.isStarted());\n\n    supervisor.runInternal();\n    verifyAll();\n\n    KafkaIndexTask task = captured.getValue();\n    Assert.assertEquals(dataSchema, task.getDataSchema());\n    Assert.assertEquals(tuningConfig.convertToTaskTuningConfig(), task.getTuningConfig());\n\n    KafkaIndexTaskIOConfig taskConfig = task.getIOConfig();\n    Assert.assertEquals(kafkaHost, taskConfig.getConsumerProperties().get(\"bootstrap.servers\"));\n    Assert.assertEquals(\"myCustomValue\", taskConfig.getConsumerProperties().get(\"myCustomKey\"));\n    Assert.assertEquals(\"sequenceName-0\", taskConfig.getBaseSequenceName());\n    Assert.assertTrue(\"isUseTransaction\", taskConfig.isUseTransaction());\n    Assert.assertFalse(\"minimumMessageTime\", taskConfig.getMinimumMessageTime().isPresent());\n    Assert.assertFalse(\"maximumMessageTime\", taskConfig.getMaximumMessageTime().isPresent());\n\n    Assert.assertEquals(topic, taskConfig.getStartSequenceNumbers().getStream());\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        0L,\n        taskConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n\n    Assert.assertEquals(topic, taskConfig.getEndSequenceNumbers().getStream());\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(0).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(1).longValue()\n    );\n    Assert.assertEquals(\n        Long.MAX_VALUE,\n        taskConfig.getEndSequenceNumbers().getPartitionSequenceNumberMap().get(2).longValue()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":2780,"status":"N"}],"commitId":"de8daf8139dcb8a497f1191587dcd5e7ea992092","commitMessage":"@@@Delete buildV9Directly in Kafka and Kinesis Indexing Service (#11351)\n\n* delete_buildV9Directly_in_kafka_and_kinesis_indexing_service\n\n* delete\n\n* delete them from server\n\n* delete buildV9Directly from hadoop indexing\n\n* bug fixed\n\nCo-authored-by: yuanyi <yuanyi@freewheel.tv>","date":"2021-06-24 07:36:46","modifiedFileCount":"38","status":"M","submitter":"Yi Yuan"}]
