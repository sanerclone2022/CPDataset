[{"authorTime":"2019-06-01 08:16:01","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","date":"2018-08-31 00:56:26","endLine":2416,"groupId":"18530","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getDataSchema","params":"(StringdataSource)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5d/773db661d0c8e87703ae229b128551316998e5.src","preCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":2383,"status":"NB"},{"authorDate":"2019-06-01 08:16:01","commitOrder":2,"curCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","date":"2019-06-01 08:16:01","endLine":583,"groupId":"18530","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getDataSchema","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/10/58eb01e073d33c89742689aac409cfc5652abf.src","preCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":550,"status":"B"}],"commitId":"8032c4add8f78d0c15044d0847201c618e27dc25","commitMessage":"@@@Add errors and state to stream supervisor status API endpoint (#7428)\n\n* Add state and error tracking for seekable stream supervisors\n\n* Fixed nits in docs\n\n* Made inner class static and updated spec test with jackson inject\n\n* Review changes\n\n* Remove redundant config param in supervisor\n\n* Style\n\n* Applied some of Jon's recommendations\n\n* Add transience field\n\n* write test\n\n* implement code review changes except for reconsidering logic of markRunFinishedAndEvaluateHealth()\n\n* remove transience reporting and fix SeekableStreamSupervisorStateManager impl\n\n* move call to stateManager.markRunFinished() from RunNotice to runInternal() for tests\n\n* remove stateHistory because it wasn't adding much value.  some fixes.  and add more tests\n\n* fix tests\n\n* code review changes and add HTTP health check status\n\n* fix test failure\n\n* refactor to split into a generic SupervisorStateManager and a specific SeekableStreamSupervisorStateManager\n\n* fixup after merge\n\n* code review changes - add additional docs\n\n* cleanup KafkaIndexTaskTest\n\n* add additional documentation for Kinesis indexing\n\n* remove unused throws class\n","date":"2019-06-01 08:16:01","modifiedFileCount":"32","status":"M","submitter":"Justin Borromeo"},{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2019-08-23 18:13:54","commitOrder":3,"curCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        OBJECT_MAPPER.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        OBJECT_MAPPER\n    );\n  }\n","date":"2019-08-23 18:13:54","endLine":3641,"groupId":"18530","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getDataSchema","params":"(StringdataSource)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/4d/fa47227192d656c1fe4c9dce5d9f5723fe6865.src","preCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3608,"status":"M"},{"authorDate":"2019-08-23 18:13:54","commitOrder":3,"curCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        OBJECT_MAPPER.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        OBJECT_MAPPER\n    );\n  }\n","date":"2019-08-23 18:13:54","endLine":589,"groupId":"18530","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getDataSchema","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/9d/4676087478374a907c38f39fc418b26bf7c116.src","preCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        objectMapper.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        objectMapper\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":556,"status":"M"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"},{"authorTime":"2019-11-21 06:51:25","codes":[{"authorDate":"2019-11-21 06:51:25","commitOrder":4,"curCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        new TimestampSpec(\"timestamp\", \"iso\", null),\n        new DimensionsSpec(\n            dimensions,\n            null,\n            null\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null\n    );\n  }\n","date":"2019-11-21 06:51:25","endLine":3700,"groupId":"102317","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getDataSchema","params":"(StringdataSource)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/47/b2d11cc7cf8846f79b5794f16229d5d583aad9.src","preCode":"  private static DataSchema getDataSchema(String dataSource)\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        dataSource,\n        OBJECT_MAPPER.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        OBJECT_MAPPER\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":3678,"status":"M"},{"authorDate":"2019-11-21 06:51:25","commitOrder":4,"curCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        new TimestampSpec(\"timestamp\", \"iso\", null),\n        new DimensionsSpec(\n            dimensions,\n            null,\n            null\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null\n    );\n  }\n","date":"2019-11-21 06:51:25","endLine":576,"groupId":"102317","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getDataSchema","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3d/cd6d9f9a0364317a14d03ab3e2b30188a030a6.src","preCode":"  private static DataSchema getDataSchema()\n  {\n    List<DimensionSchema> dimensions = new ArrayList<>();\n    dimensions.add(StringDimensionSchema.create(\"dim1\"));\n    dimensions.add(StringDimensionSchema.create(\"dim2\"));\n\n    return new DataSchema(\n        DATASOURCE,\n        OBJECT_MAPPER.convertValue(\n            new StringInputRowParser(\n                new JSONParseSpec(\n                    new TimestampSpec(\"timestamp\", \"iso\", null),\n                    new DimensionsSpec(\n                        dimensions,\n                        null,\n                        null\n                    ),\n                    new JSONPathSpec(true, ImmutableList.of()),\n                    ImmutableMap.of()\n                ),\n                StandardCharsets.UTF_8.name()\n            ),\n            Map.class\n        ),\n        new AggregatorFactory[]{new CountAggregatorFactory(\"rows\")},\n        new UniformGranularitySpec(\n            Granularities.HOUR,\n            Granularities.NONE,\n            ImmutableList.of()\n        ),\n        null,\n        OBJECT_MAPPER\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":554,"status":"M"}],"commitId":"ac6d703814ccb5b258c586b63e0bc33d669e0f57","commitMessage":"@@@Support inputFormat and inputSource for sampler (#8901)\n\n* Support inputFormat and inputSource for sampler\n\n* Cleanup javadocs and names\n\n* fix style\n\n* fix timed shutoff input source reader\n\n* fix timed shutoff input source reader again\n\n* tidy up timed shutoff reader\n\n* unused imports\n\n* fix tc\n","date":"2019-11-21 06:51:25","modifiedFileCount":"66","status":"M","submitter":"Jihoon Son"}]
