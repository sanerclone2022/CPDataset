[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2018-08-31 00:56:26","endLine":156,"groupId":"5260","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"checkSerializedSizeAndData","params":"(intchunkSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/9ae961bb60f7a0df9a1206a445b010f2ced558.src","preCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        segmentWriteOutMedium, \"test\", chunkFactor, byteOrder, compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2018-08-31 00:56:26","endLine":153,"groupId":"7960","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"checkSerializedSizeAndData","params":"(intchunkFactor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/99/20907abcddd6fb4d5a7b89dd5d18cb62efc97c.src","preCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        segmentWriteOutMedium, \"test\", chunkFactor, byteOrder, compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":117,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2019-07-07 00:33:12","codes":[{"authorDate":"2019-07-07 00:33:12","commitOrder":2,"curCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2019-07-07 00:33:12","endLine":149,"groupId":"5260","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"checkSerializedSizeAndData","params":"(intchunkSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/15/0dd0d8955f47fc0f42fc28ddaccdef80128b15.src","preCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":108,"status":"M"},{"authorDate":"2019-07-07 00:33:12","commitOrder":2,"curCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        chunkFactor,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    Assert.assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2019-07-07 00:33:12","endLine":150,"groupId":"7960","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"checkSerializedSizeAndData","params":"(intchunkFactor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/fe/fd2a7685d11bac25cc930062692021342a4d2f.src","preCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        chunkFactor,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"}],"commitId":"1166bbcb75d432817715fdd429737f86730b5591","commitMessage":"@@@Remove static imports from tests (#8036)\n\nMake static imports forbidden in tests and remove all occurrences to be\nconsistent with the non-test code.\n\nAlso.  various changes to files affected by above:\n- Reformat to adhere to druid style guide\n- Fix various IntelliJ warnings\n- Fix various SonarLint warnings (e.g..  the expected/actual args to\n  Assert.assertEquals() were flipped)","date":"2019-07-07 00:33:12","modifiedFileCount":"98","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2020-03-27 07:54:48","codes":[{"authorDate":"2020-03-27 07:54:48","commitOrder":3,"curCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n    final String columnName = \"test\";\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        columnName,\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2020-03-27 07:54:48","endLine":158,"groupId":"105575","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"checkSerializedSizeAndData","params":"(intchunkSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5b/a842013bbab798b8b70f61e28d1266594f09bc.src","preCode":"  private void checkSerializedSizeAndData(int chunkSize) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedVSizeColumnarIntsSerializer writer = new CompressedVSizeColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedVSizeColumnarIntsSupplier supplierFromList = CompressedVSizeColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        vals.length > 0 ? Ints.max(vals) : 0,\n        chunkSize,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedVSizeColumnarIntsSupplier supplierFromByteBuffer = CompressedVSizeColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":116,"status":"M"},{"authorDate":"2020-03-27 07:54:48","commitOrder":3,"curCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        \"test\",\n        segmentWriteOutMedium,\n        \"test\",\n        chunkFactor,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    Assert.assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","date":"2020-03-27 07:54:48","endLine":230,"groupId":"105575","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"checkSerializedSizeAndData","params":"(intchunkFactor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/43/ea5eb08637d9f98a886caeb15fb4f9c8880cdc.src","preCode":"  private void checkSerializedSizeAndData(int chunkFactor) throws Exception\n  {\n    FileSmoosher smoosher = new FileSmoosher(temporaryFolder.newFolder());\n\n    CompressedColumnarIntsSerializer writer = new CompressedColumnarIntsSerializer(\n        segmentWriteOutMedium,\n        \"test\",\n        chunkFactor,\n        byteOrder,\n        compressionStrategy\n    );\n    CompressedColumnarIntsSupplier supplierFromList = CompressedColumnarIntsSupplier.fromList(\n        IntArrayList.wrap(vals),\n        chunkFactor,\n        byteOrder,\n        compressionStrategy,\n        segmentWriteOutMedium.getCloser()\n    );\n    writer.open();\n    for (int val : vals) {\n      writer.addValue(val);\n    }\n    long writtenLength = writer.getSerializedSize();\n    final WriteOutBytes writeOutBytes = segmentWriteOutMedium.makeWriteOutBytes();\n    writer.writeTo(writeOutBytes, smoosher);\n    smoosher.close();\n\n    Assert.assertEquals(writtenLength, supplierFromList.getSerializedSize());\n\n    \r\n    CompressedColumnarIntsSupplier supplierFromByteBuffer = CompressedColumnarIntsSupplier.fromByteBuffer(\n        ByteBuffer.wrap(IOUtils.toByteArray(writeOutBytes.asInputStream())),\n        byteOrder\n    );\n    ColumnarInts columnarInts = supplierFromByteBuffer.get();\n    Assert.assertEquals(vals.length, columnarInts.size());\n    for (int i = 0; i < vals.length; ++i) {\n      Assert.assertEquals(vals[i], columnarInts.get(i));\n    }\n    CloseQuietly.close(columnarInts);\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/data/CompressedColumnarIntsSerializerTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":189,"status":"M"}],"commitId":"2c49f6d89acdf1e15f6bc339321f0e78066e2e42","commitMessage":"@@@error on value counter overflow instead of writing sad segments (#9559)\n\n","date":"2020-03-27 07:54:48","modifiedFileCount":"32","status":"M","submitter":"Clint Wylie"}]
