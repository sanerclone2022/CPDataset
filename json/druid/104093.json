[{"authorTime":"2019-05-07 14:39:40","codes":[{"authorDate":"2019-05-07 14:39:40","commitOrder":1,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-05-07 14:39:40","endLine":287,"groupId":"4738","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/27/f5509570e47f609bf6d41ad9d77ff2ceb02e25.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"B"},{"authorDate":"2019-05-07 14:39:40","commitOrder":1,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-05-07 14:39:40","endLine":318,"groupId":"4738","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/27/f5509570e47f609bf6d41ad9d77ff2ceb02e25.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"B"}],"commitId":"dadf6a2f11c00a1864c32f5e91e175543f83b5e5","commitMessage":"@@@Add tool for migrating from local deep storage/Derby metadata (#7598)\n\n* Add tool for migrating from local deep storage/Derby metadata\n\n* Split deep storage and metadata migration docs\n\n* Support import into Derby\n\n* Fix create tables cmd\n\n* Fix create tables cmd\n\n* Fix commands\n\n* PR comment\n\n* Add -p\n","date":"2019-05-07 14:39:40","modifiedFileCount":"4","status":"B","submitter":"Jonathan Wei"},{"authorTime":"2019-07-27 01:49:03","codes":[{"authorDate":"2019-07-27 01:49:03","commitOrder":2,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-07-27 01:49:03","endLine":287,"groupId":"4738","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/97/d77ef4562a56f80c33d9eb6a718abd1fdcc3a4.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-07-27 01:49:03","commitOrder":2,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-07-27 01:49:03","endLine":318,"groupId":"4738","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/97/d77ef4562a56f80c33d9eb6a718abd1fdcc3a4.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"}],"commitId":"5dd0d8e873c51c06d18a8018bd1abe050a6a0ad3","commitMessage":"@@@Fix dependency analyze warnings (#8128)\n\n* Fix dependency analyze warnings\n\nUpdate the maven dependency plugin to the latest version and fix all\nwarnings for unused declared and used undeclared dependencies in the\ncompile scope. Added new travis job to add the check to CI. Also fixed\nsome source code files to use the correct packages for their imports.\n\n* Fix licenses and dependencies\n\n* Fix licenses and dependencies again\n\n* Fix integration test dependency\n\n* Address review comments\n\n* Fix unit test dependencies\n\n* Fix integration test dependency\n\n* Fix integration test dependency again\n\n* Fix integration test dependency third time\n\n* Fix integration test dependency fourth time\n\n* Fix compile error\n\n* Fix assert package\n","date":"2019-07-27 01:49:03","modifiedFileCount":"5","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2019-07-30 02:42:16","codes":[{"authorDate":"2019-07-30 02:42:16","commitOrder":3,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-07-30 02:42:16","endLine":287,"groupId":"4738","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/27/f5509570e47f609bf6d41ad9d77ff2ceb02e25.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-07-30 02:42:16","commitOrder":3,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-07-30 02:42:16","endLine":318,"groupId":"4738","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/27/f5509570e47f609bf6d41ad9d77ff2ceb02e25.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"}],"commitId":"ab71a2e1e4a3c106ba9f9d58554d09f66aec7839","commitMessage":"@@@Revert \"Fix dependency analyze warnings (#8128)\" (#8189)\n\nThis reverts commit 5dd0d8e873c51c06d18a8018bd1abe050a6a0ad3.","date":"2019-07-30 02:42:16","modifiedFileCount":"5","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2019-08-23 18:13:54","commitOrder":4,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-08-23 18:13:54","endLine":287,"groupId":"4738","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/30/906860e172f255fa954165b9eb660f4cdf5416.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-08-23 18:13:54","commitOrder":4,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-08-23 18:13:54","endLine":318,"groupId":"4738","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/30/906860e172f255fa954165b9eb660f4cdf5416.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = parser.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"},{"authorTime":"2019-09-10 05:37:21","codes":[{"authorDate":"2019-09-10 05:37:21","commitOrder":5,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-09-10 05:37:21","endLine":287,"groupId":"4738","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/56/457c300fa8ab498f373756d38bfd16e037e9f7.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-09-10 05:37:21","commitOrder":5,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2019-09-10 05:37:21","endLine":318,"groupId":"4738","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/56/457c300fa8ab498f373756d38bfd16e037e9f7.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), Charsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), Charsets.UTF_8);\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"}],"commitId":"5f61374cb3d161c8ac09ec6f59147bf9d7adf664","commitMessage":"@@@Fix dependency analyze warnings (#8230)\n\n* Fix dependency analyze warnings\n\nUpdate the maven dependency plugin to the latest version and fix all\nwarnings for unused declared and used undeclared dependencies in the\ncompile scope. Added new travis job to add the check to CI. Also fixed\nsome source code files to use the correct packages for their imports and\nupdated druid-forbidden-apis to prevent regressions.\n\n* Address review comments\n\n* Adjust scope for org.glassfish.jaxb:jaxb-runtime\n\n* Fix dependencies for hdfs-storage\n\n* Consolidate netty4 versions\n","date":"2019-09-10 05:37:21","modifiedFileCount":"3","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2020-04-11 01:04:40","codes":[{"authorDate":"2020-04-11 01:04:40","commitOrder":6,"curCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        String newLine = parsed[0] + \",\" \r\n                         + parsed[1] + \",\" \r\n                         + rewriteHexPayloadAsEscapedJson(parsed[2]) + \",\" \r\n                         + parsed[3] \r\n                         + \"\\n\";\n        writer.write(newLine);\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2020-04-11 01:04:40","endLine":287,"groupId":"104093","id":11,"instanceNumber":1,"isCurCommit":1,"methodName":"rewriteDatasourceExport","params":"(StringdatasourceTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/6fcf94a877bd0216cf01c16ae09388dd2bc2a3.src","preCode":"  private void rewriteDatasourceExport(\n      String datasourceTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, datasourceTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, datasourceTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[2])).append(\",\"); \r\n        newLineBuilder.append(parsed[3]); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"},{"authorDate":"2020-04-11 01:04:40","commitOrder":6,"curCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        String newLine = parsed[0] + \",\" \r\n                         + parsed[1] + \",\" \r\n                         + parsed[2] + \",\" \r\n                         + rewriteHexPayloadAsEscapedJson(parsed[3]) \r\n                         + \"\\n\";\n        writer.write(newLine);\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","date":"2020-04-11 01:04:40","endLine":317,"groupId":"104093","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"rewriteRulesExport","params":"(StringrulesTableName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b6/6fcf94a877bd0216cf01c16ae09388dd2bc2a3.src","preCode":"  private void rewriteRulesExport(\n      String rulesTableName\n  )\n  {\n    String inFile = StringUtils.format((\"%s/%s_raw.csv\"), outputPath, rulesTableName);\n    String outFile = StringUtils.format(\"%s/%s.csv\", outputPath, rulesTableName);\n    try (\n        BufferedReader reader = new BufferedReader(\n            new InputStreamReader(new FileInputStream(inFile), StandardCharsets.UTF_8)\n        );\n        OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(outFile), StandardCharsets.UTF_8)\n    ) {\n      String line;\n      while ((line = reader.readLine()) != null) {\n        String[] parsed = PARSER.parseLine(line);\n\n        StringBuilder newLineBuilder = new StringBuilder();\n        newLineBuilder.append(parsed[0]).append(\",\"); \r\n        newLineBuilder.append(parsed[1]).append(\",\"); \r\n        newLineBuilder.append(parsed[2]).append(\",\"); \r\n        newLineBuilder.append(rewriteHexPayloadAsEscapedJson(parsed[3])); \r\n        newLineBuilder.append(\"\\n\");\n        writer.write(newLineBuilder.toString());\n\n      }\n    }\n    catch (IOException ioex) {\n      throw new RuntimeException(ioex);\n    }\n  }\n","realPath":"services/src/main/java/org/apache/druid/cli/ExportMetadata.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"}],"commitId":"1ced3b33fb1642ee71e542940e4e2a4840e7a48c","commitMessage":"@@@IntelliJ inspections cleanup (#9339)\n\n* IntelliJ inspections cleanup\n\n* Standard Charset object can be used\n* Redundant Collection.addAll() call\n* String literal concatenation missing whitespace\n* Statement with empty body\n* Redundant Collection operation\n* StringBuilder can be replaced with String\n* Type parameter hides visible type\n\n* fix warnings in test code\n\n* more test fixes\n\n* remove string concatenation inspection error\n\n* fix extra curly brace\n\n* cleanup AzureTestUtils\n\n* fix charsets for RangerAdminClient\n\n* review comments","date":"2020-04-11 01:04:40","modifiedFileCount":"33","status":"M","submitter":"Suneet Saldanha"}]
