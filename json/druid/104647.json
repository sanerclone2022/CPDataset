[{"authorTime":"2018-12-22 03:49:24","codes":[{"authorDate":"2018-12-22 03:49:24","commitOrder":1,"curCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with RandomIdUtils [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","date":"2018-12-22 03:49:24","endLine":974,"groupId":"5524","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"addTaskGroupToActivelyReadingTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/dd/d854d3bdad3c52a817a39ba53df90700e68f50.src","preCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with RandomIdUtils [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":951,"status":"B"},{"authorDate":"2018-12-22 03:49:24","commitOrder":1,"curCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","date":"2018-12-22 03:49:24","endLine":996,"groupId":"5524","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"addTaskGroupToPendingCompletionTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/dd/d854d3bdad3c52a817a39ba53df90700e68f50.src","preCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":977,"status":"B"}],"commitId":"7c7997e8a1183a7bffad731ca94e8b4c381e8665","commitMessage":"@@@Add Kinesis Indexing Service to core Druid (#6431)\n\n* created seekablestream classes\n\n* created seekablestreamsupervisor class\n\n* first attempt to integrate kafa indexing service to use SeekableStream\n\n* seekablestream bug fixes\n\n* kafkarecordsupplier\n\n* integrated kafka indexing service with seekablestream\n\n* implemented resume/suspend and refactored some package names\n\n* moved kinesis indexing service into core druid extensions\n\n* merged some changes from kafka supervisor race condition\n\n* integrated kinesis-indexing-service with seekablestream\n\n* unite tests for kinesis-indexing-service\n\n* various bug fixes for kinesis-indexing-service\n\n* refactored kinesisindexingtask\n\n* finished up more kinesis unit tests\n\n* more bug fixes for kinesis-indexing-service\n\n* finsihed refactoring kinesis unit tests\n\n* removed KinesisParititons and KafkaPartitions to use SeekableStreamPartitions\n\n* kinesis-indexing-service code cleanup and docs\n\n* merge #6291\n\nmerge #6337\n\nmerge #6383\n\n* added more docs and reordered methods\n\n* fixd kinesis tests after merging master and added docs in seekablestream\n\n* fix various things from pr comment\n\n* improve recordsupplier and add unit tests\n\n* migrated to aws-java-sdk-kinesis\n\n* merge changes from master\n\n* fix pom files and forbiddenapi checks\n\n* checkpoint JavaType bug fix\n\n* fix pom and stuff\n\n* disable checkpointing in kinesis\n\n* fix kinesis sequence number null in closed shard\n\n* merge changes from master\n\n* fixes for kinesis tasks\n\n* capitalized <partitionType.  sequenceType>\n\n* removed abstract class loggers\n\n* conform to guava api restrictions\n\n* add docker for travis other modules test\n\n* address comments\n\n* improve RecordSupplier to supply records in batch\n\n* fix strict compile issue\n\n* add test scope for localstack dependency\n\n* kinesis indexing task refactoring\n\n* comments\n\n* github comments\n\n* minor fix\n\n* removed unneeded readme\n\n* fix deserialization bug\n\n* fix various bugs\n\n* KinesisRecordSupplier unable to catch up to earliest position in stream bug fix\n\n* minor changes to kinesis\n\n* implement deaggregate for kinesis\n\n* Merge remote-tracking branch 'upstream/master' into seekablestream\n\n* fix kinesis offset discrepancy with kafka\n\n* kinesis record supplier disable getPosition\n\n* pr comments\n\n* mock for kinesis tests and remove docker dependency for unit tests\n\n* PR comments\n\n* avg lag in kafkasupervisor #6587\n\n* refacotred SequenceMetadata in taskRunners\n\n* small fix\n\n* more small fix\n\n* recordsupplier resource leak\n\n* revert .travis.yml formatting\n\n* fix style\n\n* kinesis docs\n\n* doc part2\n\n* more docs\n\n* comments\n\n* comments*2\n\n* revert string replace changes\n\n* comments\n\n* teamcity\n\n* comments part 1\n\n* comments part 2\n\n* comments part 3\n\n* merge #6754\n\n* fix injection binding\n\n* comments\n\n* KinesisRegion refactor\n\n* comments part idk lol\n\n* can't think of a commit msg anymore\n\n* remove possiblyResetDataSourceMetadata() for IncrementalPublishingTaskRunner\n\n* commmmmmmmmmments\n\n* extra error handling in KinesisRecordSupplier getRecords\n\n* comments\n\n* quickfix\n\n* typo\n\n* oof\n","date":"2018-12-22 03:49:24","modifiedFileCount":"22","status":"B","submitter":"Joshua Sun"},{"authorTime":"2019-10-10 15:16:44","codes":[{"authorDate":"2019-10-10 15:16:44","commitOrder":2,"curCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with RandomIdUtils [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","date":"2019-10-10 15:16:44","endLine":1027,"groupId":"5524","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"addTaskGroupToActivelyReadingTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/5807f6c0225a38c1691787af3c6a8099819161.src","preCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with RandomIdUtils [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1003,"status":"M"},{"authorDate":"2019-10-10 15:16:44","commitOrder":2,"curCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","date":"2019-10-10 15:16:44","endLine":1050,"groupId":"5524","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"addTaskGroupToPendingCompletionTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/5807f6c0225a38c1691787af3c6a8099819161.src","preCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1030,"status":"M"}],"commitId":"0c387c1d47a56b04c60b642958d7de9b625556c5","commitMessage":"@@@Fix Kinesis resharding issues (#8644)\n\n* Fix Kinesis resharding issues\n\n* PR comments\n\n* Adjust metadata error message\n\n* Remove unused method\n\n* Use sha1 for shard id hashing\n\n* Add metadata sanity check.  add comment\n\n* Only use shard ID hashing for group mapping\n\n* Style fix\n\n* Fix unused import\n\n* update comment\n\n* Fix teamcity inspection\n","date":"2019-10-10 15:16:44","modifiedFileCount":"5","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2019-10-10 15:16:44","codes":[{"authorDate":"2020-04-08 00:47:18","commitOrder":3,"curCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with id [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","date":"2020-04-08 00:47:18","endLine":1005,"groupId":"104647","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"addTaskGroupToActivelyReadingTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/68/2a560e8eef9a734785d3c29a083f6448046105.src","preCode":"  public void addTaskGroupToActivelyReadingTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    if (activelyReadingTaskGroups.putIfAbsent(taskGroupId, group) != null) {\n      throw new ISE(\n          \"trying to add taskGroup with RandomIdUtils [%s] to actively reading task groups, but group already exists.\",\n          taskGroupId\n      );\n    }\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":981,"status":"M"},{"authorDate":"2019-10-10 15:16:44","commitOrder":3,"curCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","date":"2019-10-10 15:16:44","endLine":1050,"groupId":"104647","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"addTaskGroupToPendingCompletionTaskGroup","params":"(inttaskGroupId@ImmutableMap<PartitionIdType@SequenceOffsetType>partitionOffsets@Optional<DateTime>minMsgTime@Optional<DateTime>maxMsgTime@Set<String>tasks@Set<PartitionIdType>exclusiveStartingSequencePartitions)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/5807f6c0225a38c1691787af3c6a8099819161.src","preCode":"  public void addTaskGroupToPendingCompletionTaskGroup(\n      int taskGroupId,\n      ImmutableMap<PartitionIdType, SequenceOffsetType> partitionOffsets,\n      Optional<DateTime> minMsgTime,\n      Optional<DateTime> maxMsgTime,\n      Set<String> tasks,\n      Set<PartitionIdType> exclusiveStartingSequencePartitions\n  )\n  {\n    TaskGroup group = new TaskGroup(\n        taskGroupId,\n        partitionOffsets,\n        null,\n        minMsgTime,\n        maxMsgTime,\n        exclusiveStartingSequencePartitions\n    );\n    group.tasks.putAll(tasks.stream().collect(Collectors.toMap(x -> x, x -> new TaskData())));\n    pendingCompletionTaskGroups.computeIfAbsent(taskGroupId, x -> new CopyOnWriteArrayList<>())\n                               .add(group);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1030,"status":"N"}],"commitId":"d267b1c414b9b55b129729692755273d2a35e304","commitMessage":"@@@check paths used for shuffle intermediary data manager get and delete (#9630)\n\n* check paths used for shuffle intermediary data manager get and delete\n\n* add test\n\n* newline\n\n* meh","date":"2020-04-08 00:47:18","modifiedFileCount":"10","status":"M","submitter":"Clint Wylie"}]
