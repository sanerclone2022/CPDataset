[{"authorTime":"2020-06-04 07:46:28","codes":[{"authorDate":"2020-06-04 07:46:28","commitOrder":1,"curCode":"  public void testJoinOnTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (TIME_FLOOR(__time, 'PT1H'), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT TIME_FLOOR(__time, 'PT1H') AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    Druids.newTimeseriesQueryBuilder()\n                                          .dataSource(CalciteTests.DATASOURCE1)\n                                          .intervals(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                          .filters(selector(\"dim3\", \"b\", null))\n                                          .granularity(new PeriodGranularity(Period.hours(1), null, DateTimeZone.UTC))\n                                          .aggregators(aggregators(\n                                              new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                          ))\n                                          .context(getTimeseriesContextWithFloorTime(TIMESERIES_CONTEXT_DEFAULT, \"d0\"))\n                                          .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","date":"2020-06-04 07:46:28","endLine":439,"groupId":"22635","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testJoinOnTimeseriesWithFloorOnTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/80/68a0d9e38b7f8629d5cf759c2492a4d2cb8fd4.src","preCode":"  public void testJoinOnTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (TIME_FLOOR(__time, 'PT1H'), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT TIME_FLOOR(__time, 'PT1H') AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    Druids.newTimeseriesQueryBuilder()\n                                          .dataSource(CalciteTests.DATASOURCE1)\n                                          .intervals(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                          .filters(selector(\"dim3\", \"b\", null))\n                                          .granularity(new PeriodGranularity(Period.hours(1), null, DateTimeZone.UTC))\n                                          .aggregators(aggregators(\n                                              new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                          ))\n                                          .context(getTimeseriesContextWithFloorTime(TIMESERIES_CONTEXT_DEFAULT, \"d0\"))\n                                          .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","realPath":"sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":388,"status":"B"},{"authorDate":"2020-06-04 07:46:28","commitOrder":1,"curCode":"  public void testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT) + 0 AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    GroupByQuery.builder()\n                                                .setDataSource(CalciteTests.DATASOURCE1)\n                                                .setInterval(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                                .setVirtualColumns(\n                                                    expressionVirtualColumn(\n                                                        \"v0\",\n                                                        \"(timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') + 0)\",\n                                                        ValueType.LONG\n                                                    )\n                                                )\n                                                .setDimFilter(selector(\"dim3\", \"b\", null))\n                                                .setGranularity(Granularities.ALL)\n                                                .setDimensions(dimensions(new DefaultDimensionSpec(\"v0\", \"d0\", ValueType.LONG)))\n                                                .setAggregatorSpecs(aggregators(\n                                                    new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                                ))\n                                                .setContext(QUERY_CONTEXT_DEFAULT)\n                                                .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","date":"2020-06-04 07:46:28","endLine":501,"groupId":"7384","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/80/68a0d9e38b7f8629d5cf759c2492a4d2cb8fd4.src","preCode":"  public void testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT) + 0 AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    GroupByQuery.builder()\n                                                .setDataSource(CalciteTests.DATASOURCE1)\n                                                .setInterval(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                                .setVirtualColumns(\n                                                    expressionVirtualColumn(\n                                                        \"v0\",\n                                                        \"(timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') + 0)\",\n                                                        ValueType.LONG\n                                                    )\n                                                )\n                                                .setDimFilter(selector(\"dim3\", \"b\", null))\n                                                .setGranularity(Granularities.ALL)\n                                                .setDimensions(dimensions(new DefaultDimensionSpec(\"v0\", \"d0\", ValueType.LONG)))\n                                                .setAggregatorSpecs(aggregators(\n                                                    new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                                ))\n                                                .setContext(QUERY_CONTEXT_DEFAULT)\n                                                .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","realPath":"sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"B"}],"commitId":"790e9482ea18d87d59eeeeab4ceec14e4b1e192d","commitMessage":"@@@Fix Subquery could not be converted to groupBy query (#9959)\n\n* Fix join\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* Fix Subquery could not be converted to groupBy query\n\n* add tests\n\n* address comments\n\n* fix failing tests","date":"2020-06-04 07:46:28","modifiedFileCount":"12","status":"B","submitter":"Maytas Monsereenusorn"},{"authorTime":"2020-06-04 07:46:28","codes":[{"authorDate":"2021-05-11 01:13:37","commitOrder":2,"curCode":"  public void testJoinOnTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (TIME_FLOOR(__time, 'PT1H'), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT TIME_FLOOR(__time, 'PT1H') AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    Druids.newTimeseriesQueryBuilder()\n                                          .dataSource(CalciteTests.DATASOURCE1)\n                                          .intervals(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                          .filters(selector(\"dim3\", \"b\", null))\n                                          .granularity(new PeriodGranularity(Period.hours(1), null, DateTimeZone.UTC))\n                                          .aggregators(aggregators(\n                                              new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                          ))\n                                          .context(getTimeseriesContextWithFloorTime(TIMESERIES_CONTEXT_BY_GRAN, \"d0\"))\n                                          .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","date":"2021-05-11 01:13:37","endLine":642,"groupId":"101567","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testJoinOnTimeseriesWithFloorOnTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1e/fd99b05ebe6da94fffaa752ce8de0e97ef485f.src","preCode":"  public void testJoinOnTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (TIME_FLOOR(__time, 'PT1H'), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT TIME_FLOOR(__time, 'PT1H') AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    Druids.newTimeseriesQueryBuilder()\n                                          .dataSource(CalciteTests.DATASOURCE1)\n                                          .intervals(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                          .filters(selector(\"dim3\", \"b\", null))\n                                          .granularity(new PeriodGranularity(Period.hours(1), null, DateTimeZone.UTC))\n                                          .aggregators(aggregators(\n                                              new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                          ))\n                                          .context(getTimeseriesContextWithFloorTime(TIMESERIES_CONTEXT_DEFAULT, \"d0\"))\n                                          .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","realPath":"sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":591,"status":"M"},{"authorDate":"2020-06-04 07:46:28","commitOrder":2,"curCode":"  public void testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT) + 0 AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    GroupByQuery.builder()\n                                                .setDataSource(CalciteTests.DATASOURCE1)\n                                                .setInterval(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                                .setVirtualColumns(\n                                                    expressionVirtualColumn(\n                                                        \"v0\",\n                                                        \"(timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') + 0)\",\n                                                        ValueType.LONG\n                                                    )\n                                                )\n                                                .setDimFilter(selector(\"dim3\", \"b\", null))\n                                                .setGranularity(Granularities.ALL)\n                                                .setDimensions(dimensions(new DefaultDimensionSpec(\"v0\", \"d0\", ValueType.LONG)))\n                                                .setAggregatorSpecs(aggregators(\n                                                    new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                                ))\n                                                .setContext(QUERY_CONTEXT_DEFAULT)\n                                                .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","date":"2020-06-04 07:46:28","endLine":501,"groupId":"101567","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/80/68a0d9e38b7f8629d5cf759c2492a4d2cb8fd4.src","preCode":"  public void testJoinOnGroupByInsteadOfTimeseriesWithFloorOnTime() throws Exception\n  {\n    \r\n    cannotVectorize();\n\n    testQuery(\n        \"SELECT CAST(__time AS BIGINT), m1, ANY_VALUE(dim3, 100) FROM foo WHERE (CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT), m1) IN\\n\"\n        + \"   (\\n\"\n        + \"     SELECT CAST(TIME_FLOOR(__time, 'PT1H') AS BIGINT) + 0 AS t1, MIN(m1) AS t2 FROM foo WHERE dim3 = 'b'\\n\"\n        + \"         AND __time BETWEEN '1994-04-29 00:00:00' AND '2020-01-11 00:00:00' GROUP BY 1\\n\"\n        + \"    )\\n\"\n        + \"GROUP BY 1, 2\\n\",\n        ImmutableList.of(\n            GroupByQuery.builder()\n                        .setDataSource(\n                            join(\n                                new TableDataSource(CalciteTests.DATASOURCE1),\n                                new QueryDataSource(\n                                    GroupByQuery.builder()\n                                                .setDataSource(CalciteTests.DATASOURCE1)\n                                                .setInterval(querySegmentSpec(Intervals.of(\"1994-04-29/2020-01-11T00:00:00.001Z\")))\n                                                .setVirtualColumns(\n                                                    expressionVirtualColumn(\n                                                        \"v0\",\n                                                        \"(timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') + 0)\",\n                                                        ValueType.LONG\n                                                    )\n                                                )\n                                                .setDimFilter(selector(\"dim3\", \"b\", null))\n                                                .setGranularity(Granularities.ALL)\n                                                .setDimensions(dimensions(new DefaultDimensionSpec(\"v0\", \"d0\", ValueType.LONG)))\n                                                .setAggregatorSpecs(aggregators(\n                                                    new FloatMinAggregatorFactory(\"a0\", \"m1\")\n                                                ))\n                                                .setContext(QUERY_CONTEXT_DEFAULT)\n                                                .build()),\n                                \"j0.\",\n                                \"((timestamp_floor(\\\"__time\\\",'PT1H',null,'UTC') == \\\"j0.d0\\\") && (\\\"m1\\\" == \\\"j0.a0\\\"))\",\n                                JoinType.INNER\n                            )\n                        )\n                        .setInterval(querySegmentSpec(Filtration.eternity()))\n                        .setDimensions(\n                            new DefaultDimensionSpec(\"__time\", \"d0\", ValueType.LONG),\n                            new DefaultDimensionSpec(\"m1\", \"d1\", ValueType.FLOAT)\n\n                        )\n                        .setGranularity(Granularities.ALL)\n                        .setAggregatorSpecs(aggregators(\n                            new StringAnyAggregatorFactory(\"a0\", \"dim3\", 100)\n                        ))\n                        .setContext(QUERY_CONTEXT_DEFAULT)\n                        .build()\n        ),\n        ImmutableList.of(\n            new Object[]{946684800000L, 1.0f, \"[a, b]\"},\n            new Object[]{946771200000L, 2.0f, \"[b, c]\"}\n        )\n    );\n  }\n","realPath":"sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"N"}],"commitId":"691d7a1d548909951468005348a603380f4d6d74","commitMessage":"@@@SQL timeseries no longer skip empty buckets with all granularity (#11188)\n\n* SQL timeseries no longer skip empty buckets with all granularity\n\n* add comment.  fix tests\n\n* the ol switcheroo\n\n* revert unintended change\n\n* docs and more tests\n\n* style\n\n* make checkstyle happy\n\n* docs fixes and more tests\n\n* add docs.  tests for array_agg\n\n* fixes\n\n* oops\n\n* doc stuffs\n\n* fix compile.  match doc style","date":"2021-05-11 01:13:37","modifiedFileCount":"16","status":"M","submitter":"Clint Wylie"}]
