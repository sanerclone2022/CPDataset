[{"authorTime":"2018-12-22 03:49:24","codes":[{"authorDate":"2018-12-22 03:49:24","commitOrder":1,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(new TypeReference<TreeMap<Integer, Map<String, String>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","date":"2018-12-22 03:49:24","endLine":180,"groupId":"15081","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f5/3bdf2ad12970fca7c4f4134ea66a25cd1f1ad2.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(new TypeReference<TreeMap<Integer, Map<String, String>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"B"},{"authorDate":"2018-12-22 03:49:24","commitOrder":1,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerWithType(new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","date":"2018-12-22 03:49:24","endLine":262,"groupId":"1054","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/6f/4434ea3e957879b81e01236e6d6820a4e1a378.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerWithType(new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":220,"status":"B"}],"commitId":"7c7997e8a1183a7bffad731ca94e8b4c381e8665","commitMessage":"@@@Add Kinesis Indexing Service to core Druid (#6431)\n\n* created seekablestream classes\n\n* created seekablestreamsupervisor class\n\n* first attempt to integrate kafa indexing service to use SeekableStream\n\n* seekablestream bug fixes\n\n* kafkarecordsupplier\n\n* integrated kafka indexing service with seekablestream\n\n* implemented resume/suspend and refactored some package names\n\n* moved kinesis indexing service into core druid extensions\n\n* merged some changes from kafka supervisor race condition\n\n* integrated kinesis-indexing-service with seekablestream\n\n* unite tests for kinesis-indexing-service\n\n* various bug fixes for kinesis-indexing-service\n\n* refactored kinesisindexingtask\n\n* finished up more kinesis unit tests\n\n* more bug fixes for kinesis-indexing-service\n\n* finsihed refactoring kinesis unit tests\n\n* removed KinesisParititons and KafkaPartitions to use SeekableStreamPartitions\n\n* kinesis-indexing-service code cleanup and docs\n\n* merge #6291\n\nmerge #6337\n\nmerge #6383\n\n* added more docs and reordered methods\n\n* fixd kinesis tests after merging master and added docs in seekablestream\n\n* fix various things from pr comment\n\n* improve recordsupplier and add unit tests\n\n* migrated to aws-java-sdk-kinesis\n\n* merge changes from master\n\n* fix pom files and forbiddenapi checks\n\n* checkpoint JavaType bug fix\n\n* fix pom and stuff\n\n* disable checkpointing in kinesis\n\n* fix kinesis sequence number null in closed shard\n\n* merge changes from master\n\n* fixes for kinesis tasks\n\n* capitalized <partitionType.  sequenceType>\n\n* removed abstract class loggers\n\n* conform to guava api restrictions\n\n* add docker for travis other modules test\n\n* address comments\n\n* improve RecordSupplier to supply records in batch\n\n* fix strict compile issue\n\n* add test scope for localstack dependency\n\n* kinesis indexing task refactoring\n\n* comments\n\n* github comments\n\n* minor fix\n\n* removed unneeded readme\n\n* fix deserialization bug\n\n* fix various bugs\n\n* KinesisRecordSupplier unable to catch up to earliest position in stream bug fix\n\n* minor changes to kinesis\n\n* implement deaggregate for kinesis\n\n* Merge remote-tracking branch 'upstream/master' into seekablestream\n\n* fix kinesis offset discrepancy with kafka\n\n* kinesis record supplier disable getPosition\n\n* pr comments\n\n* mock for kinesis tests and remove docker dependency for unit tests\n\n* PR comments\n\n* avg lag in kafkasupervisor #6587\n\n* refacotred SequenceMetadata in taskRunners\n\n* small fix\n\n* more small fix\n\n* recordsupplier resource leak\n\n* revert .travis.yml formatting\n\n* fix style\n\n* kinesis docs\n\n* doc part2\n\n* more docs\n\n* comments\n\n* comments*2\n\n* revert string replace changes\n\n* comments\n\n* teamcity\n\n* comments part 1\n\n* comments part 2\n\n* comments part 3\n\n* merge #6754\n\n* fix injection binding\n\n* comments\n\n* KinesisRegion refactor\n\n* comments part idk lol\n\n* can't think of a commit msg anymore\n\n* remove possiblyResetDataSourceMetadata() for IncrementalPublishingTaskRunner\n\n* commmmmmmmmmments\n\n* extra error handling in KinesisRecordSupplier getRecords\n\n* comments\n\n* quickfix\n\n* typo\n\n* oof\n","date":"2018-12-22 03:49:24","modifiedFileCount":"22","status":"B","submitter":"Joshua Sun"},{"authorTime":"2019-03-27 05:39:07","codes":[{"authorDate":"2019-03-27 05:39:07","commitOrder":2,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-03-27 05:39:07","endLine":180,"groupId":"15081","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/87/0d7ecb7d388a88271b8c3cbc15309f66f9aad3.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(new TypeReference<TreeMap<Integer, Map<String, String>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"M"},{"authorDate":"2019-03-27 05:39:07","commitOrder":2,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-03-27 05:39:07","endLine":257,"groupId":"1054","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b2/924ea2fdff5d4abef643c60618dad1f10ede36.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerWithType(new TypeReference<TreeMap<Integer, Map<Integer, Long>>>()\n    {\n    }).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = spec.getContext() == null\n                                        ? ImmutableMap.of(\n        \"checkpoints\",\n        checkpoints,\n        IS_INCREMENTAL_HANDOFF_SUPPORTED,\n        true\n    ) : ImmutableMap.<String, Object>builder()\n                                            .put(\"checkpoints\", checkpoints)\n                                            .put(IS_INCREMENTAL_HANDOFF_SUPPORTED, true)\n                                            .putAll(spec.getContext())\n                                            .build();\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":226,"status":"M"}],"commitId":"5294277cb4a382ae77baec2111d9383f0b34bed3","commitMessage":"@@@Fix exclusive start partitions for sequenceMetadata (#7339)\n\n* Fix exclusvie start partitions for sequenceMetadata\n\n* add empty check\n","date":"2019-03-27 05:39:07","modifiedFileCount":"10","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-07-10 23:29:37","codes":[{"authorDate":"2019-03-27 05:39:07","commitOrder":3,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-03-27 05:39:07","endLine":180,"groupId":"15081","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/87/0d7ecb7d388a88271b8c3cbc15309f66f9aad3.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"N"},{"authorDate":"2019-07-10 23:29:37","commitOrder":3,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-07-10 23:29:37","endLine":265,"groupId":"1054","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c7/696173ad58cdbd031603ee23e54547c183ba94.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"}],"commitId":"fcf56f23300a32f14a0e34ed2c330c490f95b867","commitMessage":"@@@Add IS_INCREMENTAL_HANDOFF_SUPPORTED for KIS backward compatibility (#8050)\n\n* Add IS_INCREMENTAL_HANDOFF_SUPPORTED for KIS backward compatibility\n\n* do it for kafka only\n\n* fix test\n","date":"2019-07-10 23:29:37","modifiedFileCount":"4","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-07-30 08:06:33","codes":[{"authorDate":"2019-07-30 08:06:33","commitOrder":4,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-07-30 08:06:33","endLine":181,"groupId":"15081","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0e/919b3c7ad5bfb2ac54dd5b8abb727388fba7c6.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"M"},{"authorDate":"2019-07-30 08:06:33","commitOrder":4,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2019-07-30 08:06:33","endLine":266,"groupId":"1054","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d6/fb3c781ed887c8dbd1e304956a8ff874bb053c.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"}],"commitId":"640b7afc1cee911a27de7bf938dda24a85ba1510","commitMessage":"@@@Add CliIndexer process type and initial task runner implementation (#8107)\n\n* Add CliIndexer process type and initial task runner implementation\n\n* Fix HttpRemoteTaskRunnerTest\n\n* Remove batch sanity check on PeonAppenderatorsManager\n\n* Fix paralle index tests\n\n* PR comments\n\n* Adjust Jersey resource logging\n\n* Additional cleanup\n\n* Fix SystemSchemaTest\n\n* Add comment to LocalDataSegmentPusherTest absolute path test\n\n* More PR comments\n\n* Use Server annotated with RemoteChatHandler\n\n* More PR comments\n\n* Checkstyle\n\n* PR comments\n\n* Add task shutdown to stopGracefully\n\n* Small cleanup\n\n* Compile fix\n\n* Address PR comments\n\n* Adjust TaskReportFileWriter and fix nits\n\n* Remove unnecessary closer\n\n* More PR comments\n\n* Minor adjustments\n\n* PR comments\n\n* ThreadingTaskRunner: cancel  task run future not shutdownFuture and remove thread from workitem\n","date":"2019-07-30 08:06:33","modifiedFileCount":"64","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2020-04-08 00:47:18","codes":[{"authorDate":"2020-04-08 00:47:18","commitOrder":5,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, TaskIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-04-08 00:47:18","endLine":188,"groupId":"15081","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c7/89fc7f3ac73162223838489f41f5ce2854814f.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":156,"status":"M"},{"authorDate":"2020-04-08 00:47:18","commitOrder":5,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, TaskIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-04-08 00:47:18","endLine":240,"groupId":"1054","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ba/12128ab1e181159cc763696e5499ae5d35e66a.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, RandomIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":204,"status":"M"}],"commitId":"d267b1c414b9b55b129729692755273d2a35e304","commitMessage":"@@@check paths used for shuffle intermediary data manager get and delete (#9630)\n\n* check paths used for shuffle intermediary data manager get and delete\n\n* add test\n\n* newline\n\n* meh","date":"2020-04-08 00:47:18","modifiedFileCount":"10","status":"M","submitter":"Clint Wylie"},{"authorTime":"2020-05-17 05:09:39","codes":[{"authorDate":"2020-05-17 05:09:39","commitOrder":6,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = TaskIdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-05-17 05:09:39","endLine":185,"groupId":"18409","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/49/4e901dad7eb7e1b5b7a7d7171fe4c42d2a3826.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, TaskIdUtils.getRandomId());\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"M"},{"authorDate":"2020-05-17 05:09:39","commitOrder":6,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = TaskIdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-05-17 05:09:39","endLine":238,"groupId":"1850","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b2/352fe40c496195b6244b09056b64ba656b40e6.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = Joiner.on(\"_\").join(baseSequenceName, TaskIdUtils.getRandomId());\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":202,"status":"M"}],"commitId":"2e9548d93d5a27e824cc93293e1de55af63d158f","commitMessage":"@@@refactor SeekableStreamSupervisor usage of RecordSupplier (#9819)\n\n* refactor SeekableStreamSupervisor usage of RecordSupplier to reduce contention between background threads and main thread.  refactor KinesisRecordSupplier.  refactor Kinesis lag metric collection and emitting\n\n* fix style and test\n\n* cleanup.  refactor.  javadocs.  test\n\n* fixes\n\n* keep collecting current offsets and lag if unhealthy in background reporting thread\n\n* review stuffs\n\n* add comment","date":"2020-05-17 05:09:39","modifiedFileCount":"13","status":"M","submitter":"Clint Wylie"},{"authorTime":"2020-07-14 12:15:54","codes":[{"authorDate":"2020-07-14 12:15:54","commitOrder":7,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-07-14 12:15:54","endLine":185,"groupId":"18409","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/81/28796eb57d9a0b7fac76c0f251929c2e1e96ae.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = TaskIdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"M"},{"authorDate":"2020-07-14 12:15:54","commitOrder":7,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-07-14 12:15:54","endLine":238,"groupId":"1850","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0e/b90f99012f7a22411f7d9b0c1c86c7d6a0d7b8.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = TaskIdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":202,"status":"M"}],"commitId":"e6c9142129f1462feabefb4b13aa8a037fbe793f","commitMessage":"@@@Add validation for authenticator and authorizer name (#10106)\n\n* Add validation for authorizer name\n\n* fix deps\n\n* add javadocs\n\n* Do not use resource filters\n\n* Fix BasicAuthenticatorResource as well\n\n* Add integration tests\n\n* fix test\n\n* fix","date":"2020-07-14 12:15:54","modifiedFileCount":"16","status":"M","submitter":"Suneet Saldanha"},{"authorTime":"2020-08-27 08:08:12","codes":[{"authorDate":"2020-08-27 08:08:12","commitOrder":8,"curCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-08-27 08:08:12","endLine":181,"groupId":"18409","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d2/1e2fbc2dc2121abb0207e1722797b733289bc9.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          awsCredentialsConfig,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"M"},{"authorDate":"2020-08-27 08:08:12","commitOrder":8,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","date":"2020-08-27 08:08:12","endLine":234,"groupId":"1850","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1a/72ef47950bd18b683084b8f15f3f85a1cd7f37.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          null,\n          null,\n          rowIngestionMetersFactory,\n          sortingMapper,\n          null\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":202,"status":"M"}],"commitId":"f82fd22fa7de175200b7127c34c2eb2900bf7317","commitMessage":"@@@Move tools for indexing to TaskToolbox instead of injecting them in constructor (#10308)\n\n* Move tools for indexing to TaskToolbox instead of injecting them in constructor\n\n* oops.  other changes\n\n* fix test\n\n* unnecessary new file\n\n* fix test\n\n* fix build","date":"2020-08-27 08:08:12","modifiedFileCount":"67","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-01-09 08:04:37","codes":[{"authorDate":"2021-01-09 08:04:37","commitOrder":9,"curCode":"  protected List<SeekableStreamIndexTask<String, String, ByteEntity>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String, ByteEntity>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","date":"2021-01-09 08:04:37","endLine":182,"groupId":"102402","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<String@String>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a7/bc5997d655b81d59f470ed747b9d3043ad3fbb.src","preCode":"  protected List<SeekableStreamIndexTask<String, String>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<String, String>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n\n    List<SeekableStreamIndexTask<String, String>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KinesisIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KinesisIndexTaskTuningConfig) taskTuningConfig,\n          (KinesisIndexTaskIOConfig) taskIoConfig,\n          context,\n          awsCredentialsConfig\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"M"},{"authorDate":"2021-01-09 08:04:37","commitOrder":9,"curCode":"  protected List<SeekableStreamIndexTask<Integer, Long, KafkaRecordEntity>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long, KafkaRecordEntity>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","date":"2021-01-09 08:04:37","endLine":235,"groupId":"102402","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"createIndexTasks","params":"(intreplicas@StringbaseSequenceName@ObjectMappersortingMapper@TreeMap<Integer@Map<Integer@Long>>sequenceOffsets@SeekableStreamIndexTaskIOConfigtaskIoConfig@SeekableStreamIndexTaskTuningConfigtaskTuningConfig@RowIngestionMetersFactoryrowIngestionMetersFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d5/92f789953f02b84ad4b97ba4662e4042cc329a.src","preCode":"  protected List<SeekableStreamIndexTask<Integer, Long>> createIndexTasks(\n      int replicas,\n      String baseSequenceName,\n      ObjectMapper sortingMapper,\n      TreeMap<Integer, Map<Integer, Long>> sequenceOffsets,\n      SeekableStreamIndexTaskIOConfig taskIoConfig,\n      SeekableStreamIndexTaskTuningConfig taskTuningConfig,\n      RowIngestionMetersFactory rowIngestionMetersFactory\n  ) throws JsonProcessingException\n  {\n    final String checkpoints = sortingMapper.writerFor(CHECKPOINTS_TYPE_REF).writeValueAsString(sequenceOffsets);\n    final Map<String, Object> context = createBaseTaskContexts();\n    context.put(CHECKPOINTS_CTX_KEY, checkpoints);\n    \r\n    \r\n    \r\n    context.put(\"IS_INCREMENTAL_HANDOFF_SUPPORTED\", true);\n\n    List<SeekableStreamIndexTask<Integer, Long>> taskList = new ArrayList<>();\n    for (int i = 0; i < replicas; i++) {\n      String taskId = IdUtils.getRandomIdWithPrefix(baseSequenceName);\n      taskList.add(new KafkaIndexTask(\n          taskId,\n          new TaskResource(baseSequenceName, 1),\n          spec.getDataSchema(),\n          (KafkaIndexTaskTuningConfig) taskTuningConfig,\n          (KafkaIndexTaskIOConfig) taskIoConfig,\n          context,\n          sortingMapper\n      ));\n    }\n    return taskList;\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisor.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"M"}],"commitId":"118b50195e5c2989e04e0f5290aa72cae114db39","commitMessage":"@@@Introduce KafkaRecordEntity to support Kafka headers in InputFormats (#10730)\n\nToday Kafka message support in streaming indexing tasks is limited to\nmessage values.  and does not provide a way to expose Kafka headers. \ntimestamps.  or keys.  which may be of interest to more specialized\nDruid input formats. For instance.  Kafka headers may be used to indicate\npayload format/encoding or additional metadata.  and timestamps are often\nomitted from values in Kafka streams applications.  since they are\nincluded in the record.\n\nThis change proposes to introduce KafkaRecordEntity as InputEntity. \nwhich would give input formats full access to the underlying Kafka record. \nincluding headers.  key.  timestamps. It would also open access to low-level\ninformation such as topic.  partition.  offset if needed.\n\nKafkaEntity is a subclass of ByteEntity for backwards compatibility with\nexisting input formats.  and to avoid introducing unnecessary complexity\nfor Kinesis indexing tasks.","date":"2021-01-09 08:04:37","modifiedFileCount":"30","status":"M","submitter":"Xavier L?aut?"}]
