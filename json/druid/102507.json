[{"authorTime":"2019-11-21 06:51:25","codes":[{"authorDate":"2019-11-21 06:51:25","commitOrder":9,"curCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","date":"2019-11-21 06:51:25","endLine":371,"groupId":"7020","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testRunAfterDataInserted","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e8/bde11469c6f5c09cd43b1c5d562e5b78e0f593.src","preCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":328,"status":"MB"},{"authorDate":"2019-11-21 06:51:25","commitOrder":9,"curCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","date":"2019-11-21 06:51:25","endLine":418,"groupId":"12456","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRunAfterDataInsertedWithLegacyParser","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e8/bde11469c6f5c09cd43b1c5d562e5b78e0f593.src","preCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":374,"status":"B"}],"commitId":"ac6d703814ccb5b258c586b63e0bc33d669e0f57","commitMessage":"@@@Support inputFormat and inputSource for sampler (#8901)\n\n* Support inputFormat and inputSource for sampler\n\n* Cleanup javadocs and names\n\n* fix style\n\n* fix timed shutoff input source reader\n\n* fix timed shutoff input source reader again\n\n* tidy up timed shutoff reader\n\n* unused imports\n\n* fix tc\n","date":"2019-11-21 06:51:25","modifiedFileCount":"66","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-01-28 03:24:29","codes":[{"authorDate":"2020-01-28 03:24:29","commitOrder":10,"curCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2020-01-28 03:24:29","endLine":369,"groupId":"7020","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testRunAfterDataInserted","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d4/468bd39e032386fe654402d0006ecea542747e.src","preCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":326,"status":"M"},{"authorDate":"2020-01-28 03:24:29","commitOrder":10,"curCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2020-01-28 03:24:29","endLine":416,"groupId":"12456","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRunAfterDataInsertedWithLegacyParser","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d4/468bd39e032386fe654402d0006ecea542747e.src","preCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        metadataStorageCoordinator.getDataSourceMetadata(NEW_DATA_SCHEMA.getDataSource())\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":372,"status":"M"}],"commitId":"b9186f8f9ff2ff52aceda42bc5f24ffd47a7d17e","commitMessage":"@@@Reconcile terminology and method naming to 'used/unused segments'; Rename MetadataSegmentManager to MetadataSegmentsManager (#7306)\n\n* Reconcile terminology and method naming to 'used/unused segments'; Don't use terms 'enable/disable data source'; Rename MetadataSegmentManager to MetadataSegments; Make REST API methods which mark segments as used/unused to return server error instead of an empty response in case of error\n\n* Fix brace\n\n* Import order\n\n* Rename withKillDataSourceWhitelist to withSpecificDataSourcesToKill\n\n* Fix tests\n\n* Fix tests by adding proper methods without interval parameters to IndexerMetadataStorageCoordinator instead of hacking with Intervals.ETERNITY\n\n* More aligned names of DruidCoordinatorHelpers.  rename several CoordinatorDynamicConfig parameters\n\n* Rename ClientCompactTaskQuery to ClientCompactionTaskQuery for consistency with CompactionTask; ClientCompactQueryTuningConfig to ClientCompactionTaskQueryTuningConfig\n\n* More variable and method renames\n\n* Rename MetadataSegments to SegmentsMetadata\n\n* Javadoc update\n\n* Simplify SegmentsMetadata.getUnusedSegmentIntervals().  more javadocs\n\n* Update Javadoc of VersionedIntervalTimeline.iterateAllObjects()\n\n* Reorder imports\n\n* Rename SegmentsMetadata.tryMark... methods to mark... and make them to return boolean and the numbers of segments changed and relay exceptions to callers\n\n* Complete merge\n\n* Add CollectionUtils.newTreeSet(); Refactor DruidCoordinatorRuntimeParams creation in tests\n\n* Remove MetadataSegmentManager\n\n* Rename millisLagSinceCoordinatorBecomesLeaderBeforeCanMarkAsUnusedOvershadowedSegments to leadingTimeMillisBeforeCanMarkAsUnusedOvershadowedSegments\n\n* Fix tests.  refactor DruidCluster creation in tests into DruidClusterBuilder\n\n* Fix inspections\n\n* Fix SQLMetadataSegmentManagerEmptyTest and rename it to SqlSegmentsMetadataEmptyTest\n\n* Rename SegmentsAndMetadata to SegmentsAndCommitMetadata to reduce the similarity with SegmentsMetadata; Rename some methods\n\n* Rename DruidCoordinatorHelper to CoordinatorDuty.  refactor DruidCoordinator\n\n* Unused import\n\n* Optimize imports\n\n* Rename IndexerSQLMetadataStorageCoordinator.getDataSourceMetadata() to retrieveDataSourceMetadata()\n\n* Unused import\n\n* Update terminology in datasource-view.tsx\n\n* Fix label in datasource-view.spec.tsx.snap\n\n* Fix lint errors in datasource-view.tsx\n\n* Doc improvements\n\n* Another attempt to please TSLint\n\n* Another attempt to please TSLint\n\n* Style fixes\n\n* Fix IndexerSQLMetadataStorageCoordinator.createUsedSegmentsSqlQueryForIntervals() (wrong merge)\n\n* Try to fix docs build issue\n\n* Javadoc and spelling fixes\n\n* Rename SegmentsMetadata to SegmentsMetadataManager.  address other comments\n\n* Address more comments\n","date":"2020-01-28 03:24:29","modifiedFileCount":"127","status":"M","submitter":"Roman Leventov"},{"authorTime":"2020-01-28 03:24:29","codes":[{"authorDate":"2020-06-09 11:15:59","commitOrder":11,"curCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n    Assert.assertTrue(task.supportsQueries());\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2020-06-09 11:15:59","endLine":372,"groupId":"16514","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testRunAfterDataInserted","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/eb/41749c33ad86986b4f4220c8b3e51396c10262.src","preCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":328,"status":"M"},{"authorDate":"2020-01-28 03:24:29","commitOrder":11,"curCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2020-01-28 03:24:29","endLine":416,"groupId":"12456","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRunAfterDataInsertedWithLegacyParser","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d4/468bd39e032386fe654402d0006ecea542747e.src","preCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":372,"status":"N"}],"commitId":"771870ae2d312d643e6d98f3d0af8a9618af9681","commitMessage":"@@@Load broadcast datasources on broker and tasks (#9971)\n\n* Load broadcast datasources on broker and tasks\n\n* Add javadocs\n\n* Support HTTP segment management\n\n* Fix indexer maxSize\n\n* inspection fix\n\n* Make segment cache optional on non-historicals\n\n* Fix build\n\n* Fix inspections.  some coverage.  failed tests\n\n* More tests\n\n* Add CliIndexer to MainTest\n\n* Fix inspection\n\n* Rename UnprunedDataSegment to LoadableDataSegment\n\n* Address PR comments\n\n* Fix","date":"2020-06-09 11:15:59","modifiedFileCount":"52","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2021-02-05 18:49:58","codes":[{"authorDate":"2021-02-05 18:49:58","commitOrder":12,"curCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n    Assert.assertTrue(task.supportsQueries());\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n    Assert.assertNotEquals(-1, task.getRunner().getFireDepartmentMetrics().processingCompletionTime());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2021-02-05 18:49:58","endLine":423,"groupId":"102507","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testRunAfterDataInserted","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/f6ea8fd6f5932be04d7c480d8682e116420929.src","preCode":"  public void testRunAfterDataInserted() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            INPUT_FORMAT\n        )\n    );\n    Assert.assertTrue(task.supportsQueries());\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":378,"status":"M"},{"authorDate":"2021-02-05 18:49:58","commitOrder":12,"curCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n    Assert.assertNotEquals(-1, task.getRunner().getFireDepartmentMetrics().processingCompletionTime());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","date":"2021-02-05 18:49:58","endLine":471,"groupId":"102507","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testRunAfterDataInsertedWithLegacyParser","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/f6ea8fd6f5932be04d7c480d8682e116420929.src","preCode":"  public void testRunAfterDataInsertedWithLegacyParser() throws Exception\n  {\n    \r\n    insertData();\n\n    final KafkaIndexTask task = createTask(\n        null,\n        OLD_DATA_SCHEMA,\n        new KafkaIndexTaskIOConfig(\n            0,\n            \"sequence0\",\n            new SeekableStreamStartSequenceNumbers<>(topic, ImmutableMap.of(0, 2L), ImmutableSet.of()),\n            new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L)),\n            kafkaServer.consumerProperties(),\n            KafkaSupervisorIOConfig.DEFAULT_POLL_TIMEOUT_MILLIS,\n            true,\n            null,\n            null,\n            null\n        )\n    );\n\n    final ListenableFuture<TaskStatus> future = runTask(task);\n\n    \r\n    Assert.assertEquals(TaskState.SUCCESS, future.get().getStatusCode());\n\n    \r\n    Assert.assertEquals(3, task.getRunner().getRowIngestionMeters().getProcessed());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getUnparseable());\n    Assert.assertEquals(0, task.getRunner().getRowIngestionMeters().getThrownAway());\n\n    \r\n    assertEqualsExceptVersion(\n        ImmutableList.of(\n            sdd(\"2010/P1D\", 0, ImmutableList.of(\"c\")),\n            sdd(\"2011/P1D\", 0, ImmutableList.of(\"d\", \"e\"))\n        ),\n        publishedDescriptors()\n    );\n    Assert.assertEquals(\n        new KafkaDataSourceMetadata(new SeekableStreamEndSequenceNumbers<>(topic, ImmutableMap.of(0, 5L))),\n        newDataSchemaMetadata()\n    );\n  }\n","realPath":"extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":426,"status":"M"}],"commitId":"96d26e53380aea78337ff098f239df29b7076382","commitMessage":"@@@Fix kinesis ingestion bugs (#10761)\n\n* add offsetFetchPeriod to kinesis ingestion doc\n\n* Remove jackson dependencies from extensions\n\n* Use fixed delay for lag collection\n\n* Metrics reset after finishing processing\n\n* comments\n\n* Broaden the list of exceptions to retry for\n\n* Unit tests\n\n* Add more tests\n\n* Refactoring\n\n* re-order metrics\n\n* Doc suggestions\n\nCo-authored-by: Charles Smith <38529548+techdocsmith@users.noreply.github.com>\n\n* Add tests\n\nCo-authored-by: Charles Smith <38529548+techdocsmith@users.noreply.github.com>","date":"2021-02-05 18:49:58","modifiedFileCount":"9","status":"M","submitter":"Abhishek Agarwal"}]
