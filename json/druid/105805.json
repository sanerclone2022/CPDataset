[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":592,"groupId":"11749","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/35/09eec506a0b927f41a07e2d407045b394b6816.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":542,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":525,"groupId":"8067","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/50/791c53dcebf8f47a1223a1cf59d98721187213.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":476,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-10-29 20:02:43","commitOrder":2,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-10-29 20:02:43","endLine":593,"groupId":"11749","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/80/6e76006110b883864e18269c080aa0dec655f9.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":543,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":525,"groupId":"8067","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/50/791c53dcebf8f47a1223a1cf59d98721187213.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":476,"status":"N"}],"commitId":"676f5e6d7f184101b8763e4249b18b237bbe0ec7","commitMessage":"@@@Prohibit some guava collection APIs and use JDK collection APIs directly (#6511)\n\n* Prohibit some guava collection APIs and use JDK APIs directly\n\n* reset files that changed by accident\n\n* sort codestyle/druid-forbidden-apis.txt alphabetically\n","date":"2018-10-29 20:02:43","modifiedFileCount":"427","status":"M","submitter":"QiuMM"},{"authorTime":"2019-02-05 01:18:12","codes":[{"authorDate":"2019-02-05 01:18:12","commitOrder":3,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2019-02-05 01:18:12","endLine":593,"groupId":"11749","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e2/064e0d89e79354180aa395f0742d0cabd34435.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":543,"status":"M"},{"authorDate":"2019-02-05 01:18:12","commitOrder":3,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2019-02-05 01:18:12","endLine":526,"groupId":"8067","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/69/857f5c5ecc95a70b49ad506972034c1550de29.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":477,"status":"M"}],"commitId":"0e926e865276f892ddc5b62685d331b822104022","commitMessage":"@@@Prohibit assigning concurrent maps into Map-typed variables and fields and fix a race condition in CoordinatorRuleManager (#6898)\n\n* Prohibit assigning concurrent maps into Map-types variables and fields; Fix a race condition in CoordinatorRuleManager; improve logic in DirectDruidClient and ResourcePool\n\n* Enforce that if compute().  computeIfAbsent().  computeIfPresent() or merge() is called on a ConcurrentHashMap.  it's stored in a ConcurrentHashMap-typed variable.  not ConcurrentMap; add comments explaining get()-before-computeIfAbsent() optimization; refactor Counters; fix a race condition in Intialization.java\n\n* Remove unnecessary comment\n\n* Checkstyle\n\n* Fix getFromExtensions()\n\n* Add a reference to the comment about guarded computeIfAbsent() optimization; IdentityHashMap optimization\n\n* Fix UriCacheGeneratorTest\n\n* Workaround issue with MaterializedViewQueryQueryToolChest\n\n* Strengthen Appenderator's contract regarding concurrency\n","date":"2019-02-05 01:18:12","modifiedFileCount":"101","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":592,"groupId":"11749","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f8/819abde4d4d648490e171fed346662ec42ee5d.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":542,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":525,"groupId":"8067","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e1/43caa10981038b772e2285a40b4ebb4ac237f7.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":476,"status":"M"}],"commitId":"7ada1c49f9735a37808f3ed7656d93ae88b8b925","commitMessage":"@@@Prohibit Throwables.propagate() (#7121)\n\n* Throw caught exception.\n\n* Throw caught exceptions.\n\n* Related checkstyle rule is added to prevent further bugs.\n\n* RuntimeException() is used instead of Throwables.propagate().\n\n* Missing import is added.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* * Checkstyle definition is improved.\n* Throwables.propagate() usages are removed.\n\n* Checkstyle pattern is changed for only scanning \"Throwables.propagate(\" instead of checking lookbehind.\n\n* Throwable is kept before firing a Runtime Exception.\n\n* Fix unused assignments.\n","date":"2019-03-15 05:28:33","modifiedFileCount":"228","status":"M","submitter":"Furkan KAMACI"},{"authorTime":"2019-07-24 23:29:03","codes":[{"authorDate":"2019-07-24 23:29:03","commitOrder":5,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-07-24 23:29:03","endLine":591,"groupId":"11749","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/72/b639ee08dbe0a16ac9c1744c5682cb25f4c060.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":541,"status":"M"},{"authorDate":"2019-07-24 23:29:03","commitOrder":5,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-07-24 23:29:03","endLine":523,"groupId":"8067","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/bf/29d87b0418deb5d61f12982661f1bc6853a9b0.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":475,"status":"M"}],"commitId":"799d20249fe6333ea86b020f6d09c91fa4d3f998","commitMessage":"@@@Response context refactoring (#8110)\n\n* Response context refactoring\n\n* Serialization/Deserialization of ResponseContext\n\n* Added java doc comments\n\n* Renamed vars related to ResponseContext\n\n* Renamed empty() methods to createEmpty()\n\n* Fixed ResponseContext usage\n\n* Renamed multiple ResponseContext static fields\n\n* Added PublicApi annotations\n\n* Renamed QueryResponseContext class to ResourceIOReaderWriter\n\n* Moved the protected method below public static constants\n\n* Added createEmpty method to ResponseContext with DefaultResponseContext creation\n\n* Fixed inspection error\n\n* Added comments to the ResponseContext length limit and ResponseContext\nhttp header name\n\n* Added a comment of possible future refactoring\n\n* Removed .gitignore file of indexing-service\n\n* Removed a never-used method\n\n* VisibleForTesting method reducing boilerplate\n\nCo-Authored-By: Clint Wylie <cjwylie@gmail.com>\n\n* Reduced boilerplate\n\n* Renamed the method serialize to serializeWith\n\n* Removed unused import\n\n* Fixed incorrectly refactored test method\n\n* Added comments for ResponseContext keys\n\n* Fixed incorrectly refactored test method\n\n* Fixed IntervalChunkingQueryRunnerTest mocks\n","date":"2019-07-24 23:29:03","modifiedFileCount":"142","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2020-01-20 09:14:23","codes":[{"authorDate":"2020-01-20 09:14:23","commitOrder":6,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-01-20 09:14:23","endLine":589,"groupId":"105805","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1c/68a21568d333ee590c46decad1aa80bf52c32d.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()\n          ),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/IndexMergerV9WithSpatialIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":541,"status":"M"},{"authorDate":"2020-01-20 09:14:23","commitOrder":6,"curCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-01-20 09:14:23","endLine":522,"groupId":"105805","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQuery","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/93/28904fc7bf75fd97bfcc78c6268dbc99701e7f.src","preCode":"  public void testSpatialQuery()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.ALL)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RadiusBound(new float[]{0.0f, 0.0f}, 5)\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 3L)\n                    .put(\"val\", 59L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":475,"status":"M"}],"commitId":"d21054f7c5f72f9db1ecfb72b46ee866876f1e4b","commitMessage":"@@@Remove the deprecated interval-chunking stuff. (#9216)\n\n* Remove the deprecated interval-chunking stuff.\n\nSee https://github.com/apache/druid/pull/6591.  https://github.com/apache/druid/pull/4004#issuecomment-284171911 for details.\n\n* Remove unused import.\n\n* Remove chunkInterval too.\n","date":"2020-01-20 09:14:23","modifiedFileCount":"65","status":"M","submitter":"Gian Merlino"}]
