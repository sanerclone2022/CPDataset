[{"authorTime":"2020-01-28 03:24:29","codes":[{"authorDate":"2020-01-28 03:24:29","commitOrder":1,"curCode":"  public void testDropTooManyInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockPeon.dropSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    server1.addDataSegment(usedSegments.get(0));\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertEquals(1L, stats.getTieredStat(\"droppedCount\", \"normal\"));\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","date":"2020-01-28 03:24:29","endLine":611,"groupId":"18879","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDropTooManyInDifferentTiers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f5/582550d8ea7432d58e89e77890410371bc9623.src","preCode":"  public void testDropTooManyInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockPeon.dropSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    server1.addDataSegment(usedSegments.get(0));\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertEquals(1L, stats.getTieredStat(\"droppedCount\", \"normal\"));\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":559,"status":"B"},{"authorDate":"2020-01-28 03:24:29","commitOrder":1,"curCode":"  public void testDontDropInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertTrue(stats.getTiers(\"droppedCount\").isEmpty());\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","date":"2020-01-28 03:24:29","endLine":663,"groupId":"21240","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testDontDropInDifferentTiers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f5/582550d8ea7432d58e89e77890410371bc9623.src","preCode":"  public void testDontDropInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertTrue(stats.getTiers(\"droppedCount\").isEmpty());\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":614,"status":"B"}],"commitId":"b9186f8f9ff2ff52aceda42bc5f24ffd47a7d17e","commitMessage":"@@@Reconcile terminology and method naming to 'used/unused segments'; Rename MetadataSegmentManager to MetadataSegmentsManager (#7306)\n\n* Reconcile terminology and method naming to 'used/unused segments'; Don't use terms 'enable/disable data source'; Rename MetadataSegmentManager to MetadataSegments; Make REST API methods which mark segments as used/unused to return server error instead of an empty response in case of error\n\n* Fix brace\n\n* Import order\n\n* Rename withKillDataSourceWhitelist to withSpecificDataSourcesToKill\n\n* Fix tests\n\n* Fix tests by adding proper methods without interval parameters to IndexerMetadataStorageCoordinator instead of hacking with Intervals.ETERNITY\n\n* More aligned names of DruidCoordinatorHelpers.  rename several CoordinatorDynamicConfig parameters\n\n* Rename ClientCompactTaskQuery to ClientCompactionTaskQuery for consistency with CompactionTask; ClientCompactQueryTuningConfig to ClientCompactionTaskQueryTuningConfig\n\n* More variable and method renames\n\n* Rename MetadataSegments to SegmentsMetadata\n\n* Javadoc update\n\n* Simplify SegmentsMetadata.getUnusedSegmentIntervals().  more javadocs\n\n* Update Javadoc of VersionedIntervalTimeline.iterateAllObjects()\n\n* Reorder imports\n\n* Rename SegmentsMetadata.tryMark... methods to mark... and make them to return boolean and the numbers of segments changed and relay exceptions to callers\n\n* Complete merge\n\n* Add CollectionUtils.newTreeSet(); Refactor DruidCoordinatorRuntimeParams creation in tests\n\n* Remove MetadataSegmentManager\n\n* Rename millisLagSinceCoordinatorBecomesLeaderBeforeCanMarkAsUnusedOvershadowedSegments to leadingTimeMillisBeforeCanMarkAsUnusedOvershadowedSegments\n\n* Fix tests.  refactor DruidCluster creation in tests into DruidClusterBuilder\n\n* Fix inspections\n\n* Fix SQLMetadataSegmentManagerEmptyTest and rename it to SqlSegmentsMetadataEmptyTest\n\n* Rename SegmentsAndMetadata to SegmentsAndCommitMetadata to reduce the similarity with SegmentsMetadata; Rename some methods\n\n* Rename DruidCoordinatorHelper to CoordinatorDuty.  refactor DruidCoordinator\n\n* Unused import\n\n* Optimize imports\n\n* Rename IndexerSQLMetadataStorageCoordinator.getDataSourceMetadata() to retrieveDataSourceMetadata()\n\n* Unused import\n\n* Update terminology in datasource-view.tsx\n\n* Fix label in datasource-view.spec.tsx.snap\n\n* Fix lint errors in datasource-view.tsx\n\n* Doc improvements\n\n* Another attempt to please TSLint\n\n* Another attempt to please TSLint\n\n* Style fixes\n\n* Fix IndexerSQLMetadataStorageCoordinator.createUsedSegmentsSqlQueryForIntervals() (wrong merge)\n\n* Try to fix docs build issue\n\n* Javadoc and spelling fixes\n\n* Rename SegmentsMetadata to SegmentsMetadataManager.  address other comments\n\n* Address more comments\n","date":"2020-01-28 03:24:29","modifiedFileCount":"127","status":"B","submitter":"Roman Leventov"},{"authorTime":"2021-03-18 02:34:05","codes":[{"authorDate":"2021-03-18 02:34:05","commitOrder":2,"curCode":"  public void testDropTooManyInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockPeon.dropSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    server1.addDataSegment(usedSegments.get(0));\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster, false);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertEquals(1L, stats.getTieredStat(\"droppedCount\", \"normal\"));\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","date":"2021-03-18 02:34:05","endLine":626,"groupId":"10317","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDropTooManyInDifferentTiers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/34/4fec40fe6a135cf9914d8d4c254183c6c36b72.src","preCode":"  public void testDropTooManyInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockPeon.dropSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    server1.addDataSegment(usedSegments.get(0));\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertEquals(1L, stats.getTieredStat(\"droppedCount\", \"normal\"));\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":574,"status":"M"},{"authorDate":"2021-03-18 02:34:05","commitOrder":2,"curCode":"  public void testDontDropInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster, false);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertTrue(stats.getTiers(\"droppedCount\").isEmpty());\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","date":"2021-03-18 02:34:05","endLine":678,"groupId":"10317","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testDontDropInDifferentTiers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/34/4fec40fe6a135cf9914d8d4c254183c6c36b72.src","preCode":"  public void testDontDropInDifferentTiers()\n  {\n    mockCoordinator();\n    mockPeon.loadSegment(EasyMock.anyObject(), EasyMock.anyObject());\n    EasyMock.expectLastCall().atLeastOnce();\n    mockEmptyPeon();\n\n    EasyMock.expect(databaseRuleManager.getRulesWithDefault(EasyMock.anyObject())).andReturn(\n        Lists.newArrayList(\n            new IntervalLoadRule(\n                Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-01T12:00:00.000Z\"),\n                ImmutableMap.of(\"hot\", 1)\n            ),\n            new IntervalDropRule(Intervals.of(\"2012-01-01T00:00:00.000Z/2012-01-02T00:00:00.000Z\"))\n        )\n    ).atLeastOnce();\n    EasyMock.replay(databaseRuleManager);\n\n    DruidServer server1 = new DruidServer(\"server1\", \"host1\", null, 1000, ServerType.HISTORICAL, \"hot\", 0);\n    DruidServer server2 = new DruidServer(\"serverNorm2\", \"hostNorm2\", null, 1000, ServerType.HISTORICAL, \"normal\", 0);\n    for (DataSegment segment : usedSegments) {\n      server2.addDataSegment(segment);\n    }\n\n    DruidCluster druidCluster = DruidClusterBuilder\n        .newBuilder()\n        .addTier(\"hot\", new ServerHolder(server1.toImmutableDruidServer(), mockPeon))\n        .addTier(\"normal\", new ServerHolder(server2.toImmutableDruidServer(), mockPeon))\n        .build();\n\n    SegmentReplicantLookup segmentReplicantLookup = SegmentReplicantLookup.make(druidCluster);\n\n    ListeningExecutorService exec = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(1));\n    BalancerStrategy balancerStrategy = new CostBalancerStrategyFactory().createBalancerStrategy(exec);\n\n    DruidCoordinatorRuntimeParams params = createCoordinatorRuntimeParams(druidCluster)\n        .withDynamicConfigs(COORDINATOR_CONFIG_WITH_ZERO_LEADING_TIME_BEFORE_CAN_MARK_AS_UNUSED_OVERSHADOWED_SEGMENTS)\n        .withSegmentReplicantLookup(segmentReplicantLookup)\n        .withBalancerStrategy(balancerStrategy)\n        .build();\n\n    DruidCoordinatorRuntimeParams afterParams = ruleRunner.run(params);\n    CoordinatorStats stats = afterParams.getCoordinatorStats();\n\n    Assert.assertTrue(stats.getTiers(\"droppedCount\").isEmpty());\n    Assert.assertEquals(12L, stats.getGlobalStat(\"deletedCount\"));\n\n    exec.shutdown();\n    EasyMock.verify(mockPeon);\n  }\n","realPath":"server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":629,"status":"M"}],"commitId":"3d7e7c2c836d73cb77dbd412d6eb2d61f6912a69","commitMessage":"@@@Avoid deletion of load/drop entry from CuratorLoadQueuePeon in case of load timeout (#10213)\n\n* Skip queue removal on timeout\n\n* Clarify error\n\n* Add new config to control replication\n\nCo-authored-by: Atul Mohan <atulmohan@yahoo-inc.com>","date":"2021-03-18 02:34:05","modifiedFileCount":"12","status":"M","submitter":"Atul Mohan"}]
