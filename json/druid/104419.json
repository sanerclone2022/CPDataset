[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2018-08-31 00:56:26","endLine":1094,"groupId":"2979","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/88/a5a43ac6348dcc06d166c7ecd82fe32df01520.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":963,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            handoffLatch.countDown();\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2018-08-31 00:56:26","endLine":1512,"groupId":"7094","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1e/fcd94da19dd9f05cce3027a3abada825548097.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            handoffLatch.countDown();\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1344,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-09-08 04:17:49","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2018-08-31 00:56:26","endLine":1094,"groupId":"2979","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/88/a5a43ac6348dcc06d166c7ecd82fe32df01520.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":963,"status":"N"},{"authorDate":"2018-09-08 04:17:49","commitOrder":2,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2018-09-08 04:17:49","endLine":1622,"groupId":"7094","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/da/6cd0b429362a471d42ba5a941466696623de28.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            handoffLatch.countDown();\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1466,"status":"M"}],"commitId":"e6e068ce60a073700701dd2a7b2b59218d59a2c3","commitMessage":"@@@Add support for 'maxTotalRows' to incremental publishing kafka indexing task and appenderator based realtime task (#6129)\n\n* resolves #5898 by adding maxTotalRows to incremental publishing kafka index task and appenderator based realtime indexing task.  as available in IndexTask\n\n* address review comments\n\n* changes due to review\n\n* merge fail\n","date":"2018-09-08 04:17:49","modifiedFileCount":"16","status":"M","submitter":"Clint Wylie"},{"authorTime":"2018-09-27 07:28:02","codes":[{"authorDate":"2018-09-27 07:28:02","commitOrder":3,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2018-09-27 07:28:02","endLine":1098,"groupId":"2979","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a0/a39a3df50aaa2341dd4f6f9a63738316600582.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":966,"status":"M"},{"authorDate":"2018-09-27 07:28:02","commitOrder":3,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2018-09-27 07:28:02","endLine":1625,"groupId":"1245","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8e/169f97c4da50dd5c221349779040c4010206af.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments, DataSourceMetadata startMetadata, DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(\n          QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest\n      )\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor, Executor exec, Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1468,"status":"M"}],"commitId":"6fb503c07360bec4a09cef88ae7ccb4cb87aaed0","commitMessage":"@@@Deprecate task audit logging (#6368)\n\n* Deprecate task audit logging\n\n* fix test\n\n* fix it test\n","date":"2018-09-27 07:28:02","modifiedFileCount":"15","status":"M","submitter":"Jihoon Son"},{"authorTime":"2018-10-29 20:02:43","codes":[{"authorDate":"2018-10-29 20:02:43","commitOrder":4,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2018-10-29 20:02:43","endLine":1098,"groupId":"2979","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/73/b5a2ce707935183e77afcdc4ad9ee4e4997818.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":966,"status":"M"},{"authorDate":"2018-10-29 20:02:43","commitOrder":4,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2018-10-29 20:02:43","endLine":1627,"groupId":"1245","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5c/2824210608e43112c007916eb4dd5c02f2548a.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return Lists.newArrayList();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1468,"status":"M"}],"commitId":"676f5e6d7f184101b8763e4249b18b237bbe0ec7","commitMessage":"@@@Prohibit some guava collection APIs and use JDK collection APIs directly (#6511)\n\n* Prohibit some guava collection APIs and use JDK APIs directly\n\n* reset files that changed by accident\n\n* sort codestyle/druid-forbidden-apis.txt alphabetically\n","date":"2018-10-29 20:02:43","modifiedFileCount":"427","status":"M","submitter":"QiuMM"},{"authorTime":"2019-01-12 02:42:19","codes":[{"authorDate":"2019-01-12 02:42:19","commitOrder":5,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-01-12 02:42:19","endLine":1098,"groupId":"2979","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/53/17b66e4a464447b0fd92011c58b8554874dc68.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":966,"status":"M"},{"authorDate":"2019-01-12 02:42:19","commitOrder":5,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-01-12 02:42:19","endLine":1627,"groupId":"1245","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/59/899feb815188892629b4527726555c08c7a1da.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        MoreExecutors.sameThreadExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1468,"status":"M"}],"commitId":"5d2947cd5229d683494b904a4146249f5dfac05f","commitMessage":"@@@Use Guava Compatible immediate executor service (#6815)\n\n* Use multi-guava version friendly direct executor implementation\n\n* Don't use a singleton\n\n* Fix strict compliation complaints\n\n* Copy Guava's DirectExecutor\n\n* Fix javadoc\n\n* Imports are the devil\n","date":"2019-01-12 02:42:19","modifiedFileCount":"41","status":"M","submitter":"Charles Allen"},{"authorTime":"2019-01-26 07:43:06","codes":[{"authorDate":"2019-01-26 07:43:06","commitOrder":6,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-01-26 07:43:06","endLine":1098,"groupId":"2979","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/9a/6a8e98e6e2d6b9d0607f383c1d2c481109ac4c.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":966,"status":"M"},{"authorDate":"2019-01-26 07:43:06","commitOrder":6,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-01-26 07:43:06","endLine":1627,"groupId":"0","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0a/dd56bd6b5b12100372c250cd925182fdf3c67c.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, false, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1468,"status":"M"}],"commitId":"8492d94f599da1f7851add2a0e7500515abd881d","commitMessage":"@@@Kill Hadoop MR task on kill of Hadoop ingestion task  (#6828)\n\n* KillTask from overlord UI now makes sure that it terminates the underlying MR job.  thus saving unnecessary compute\n\nRun in jobby is now split into 2\n 1. submitAndGetHadoopJobId followed by 2. run\n  submitAndGetHadoopJobId is responsible for submitting the job and returning the jobId as a string.  run monitors this job for completion\n\nJobHelper writes this jobId in the path provided by HadoopIndexTask which in turn is provided by the ForkingTaskRunner\n\nHadoopIndexTask reads this path when kill task is clicked to get hte jobId and fire the kill command via the yarn api. This is taken care in the stopGracefully method which is called in SingleTaskBackgroundRunner. Have enabled `canRestore` method to return `true` for HadoopIndexTask in order for the stopGracefully method to be called\n\nHadoop*Job files have been changed to incorporate the changes to jobby\n\n* Addressing PR comments\n\n* Addressing PR comments - Fix taskDir\n\n* Addressing PR comments - For changing the contract of Task.stopGracefully()\n`SingleTaskBackgroundRunner` calls stopGracefully in stop() and then checks for canRestore condition to return the status of the task\n\n* Addressing PR comments\n 1. Formatting\n 2. Removing `submitAndGetHadoopJobId` from `Jobby` and calling writeJobIdToFile in the job itself\n\n* Addressing PR comments\n 1. POM change. Moving hadoop dependency to indexing-hadoop\n\n* Addressing PR comments\n 1. stopGracefully now accepts TaskConfig as a param\n     Handling isRestoreOnRestart in stopGracefully for `AppenderatorDriverRealtimeIndexTask.  RealtimeIndexTask.  SeekableStreamIndexTask`\n     Changing tests to make TaskConfig param isRestoreOnRestart to true\n","date":"2019-01-26 07:43:06","modifiedFileCount":"20","status":"M","submitter":"Ankit Kothari"},{"authorTime":"2019-02-05 01:18:12","codes":[{"authorDate":"2019-02-05 01:18:12","commitOrder":7,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-02-05 01:18:12","endLine":1096,"groupId":"2979","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2c/3d3c3d873010d7c035b90d68772dc8cbc6541c.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":965,"status":"M"},{"authorDate":"2019-02-05 01:18:12","commitOrder":7,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-02-05 01:18:12","endLine":1625,"groupId":"22916","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b5/7397ab8cd65d4996e48a4dc6c2c0bdd7f37039.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class),\n        new Counters()\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1467,"status":"M"}],"commitId":"0e926e865276f892ddc5b62685d331b822104022","commitMessage":"@@@Prohibit assigning concurrent maps into Map-typed variables and fields and fix a race condition in CoordinatorRuleManager (#6898)\n\n* Prohibit assigning concurrent maps into Map-types variables and fields; Fix a race condition in CoordinatorRuleManager; improve logic in DirectDruidClient and ResourcePool\n\n* Enforce that if compute().  computeIfAbsent().  computeIfPresent() or merge() is called on a ConcurrentHashMap.  it's stored in a ConcurrentHashMap-typed variable.  not ConcurrentMap; add comments explaining get()-before-computeIfAbsent() optimization; refactor Counters; fix a race condition in Intialization.java\n\n* Remove unnecessary comment\n\n* Checkstyle\n\n* Fix getFromExtensions()\n\n* Add a reference to the comment about guarded computeIfAbsent() optimization; IdentityHashMap optimization\n\n* Fix UriCacheGeneratorTest\n\n* Workaround issue with MaterializedViewQueryQueryToolChest\n\n* Strengthen Appenderator's contract regarding concurrency\n","date":"2019-02-05 01:18:12","modifiedFileCount":"101","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-02-24 09:02:56","codes":[{"authorDate":"2019-02-24 09:02:56","commitOrder":8,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-02-24 09:02:56","endLine":1093,"groupId":"2979","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2d/b92726b4cfca8d47cca865cc956350525c1360.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":964,"status":"M"},{"authorDate":"2019-02-24 09:02:56","commitOrder":8,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-02-24 09:02:56","endLine":1622,"groupId":"22916","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/09e7a5ee85c10edfae37ebbb37ab679fc017cb.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(\n            new SegmentLoaderLocalCacheManager(null, segmentLoaderConfig, testUtils.getTestObjectMapper())\n        ),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1466,"status":"M"}],"commitId":"1c2753ab9033ff0c785d6e80f5f7c07dc34c3889","commitMessage":"@@@ParallelIndexSubTask: support ingestSegment in delegating factories (#7089)\n\nIndexTask had special-cased code to properly send a TaskToolbox to a\nIngestSegmentFirehoseFactory that's nested inside a CombiningFirehoseFactory. \nbut ParallelIndexSubTask didn't.\n\nThis change refactors IngestSegmentFirehoseFactory so that it doesn't need a\nTaskToolbox; it instead gets a CoordinatorClient and a SegmentLoaderFactory\ndirectly injected into it.\n\nThis also refactors SegmentLoaderFactory so it doesn't depend on\nan injectable SegmentLoaderConfig.  since its only method always\nreplaces the preconfigured SegmentLoaderConfig anyway.\nThis makes it possible to use SegmentLoaderFactory without setting\ndruid.segmentCaches.locations to some dummy value.\n\nAnother goal of this PR is to make it possible for IngestSegmentFirehoseFactory\nto list data segments outside of connect() --- specifically.  to make it a\nFiniteFirehoseFactory which can query the coordinator in order to calculate its\nsplits. See #7048.\n\nThis also adds missing datasource name URL-encoding to an API used by\nCoordinatorBasedSegmentHandoffNotifier.","date":"2019-02-24 09:02:56","modifiedFileCount":"21","status":"M","submitter":"David Glasser"},{"authorTime":"2019-07-19 05:46:47","codes":[{"authorDate":"2019-07-19 05:46:47","commitOrder":9,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-07-19 05:46:47","endLine":1006,"groupId":"2979","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/31/6327b7fb7d385f162a571023d9d8d33c8cb00f.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-07-19 05:46:47","commitOrder":9,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-07-19 05:46:47","endLine":1626,"groupId":"15561","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/76/28dea75362a28dad618effccff6c3d860555b9.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1470,"status":"M"}],"commitId":"c7eb7cd01837c48914ba284d08b6096b47c957b0","commitMessage":"@@@Add intermediary data server for shuffle (#8088)\n\n* Add intermediary data server for shuffle\n\n* javadoc\n\n* adjust timeout\n\n* resolved todo\n\n* fix test\n\n* style\n\n* address comments\n\n* rename to shuffleDataLocations\n\n* Address comments\n\n* bit adjustment StorageLocation\n\n* fix test\n\n* address comment & fix test\n\n* handle interrupted exception\n","date":"2019-07-19 05:46:47","modifiedFileCount":"29","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-07-25 08:35:46","codes":[{"authorDate":"2019-07-25 08:35:46","commitOrder":10,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-07-25 08:35:46","endLine":1006,"groupId":"2979","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a5/009058834d62acb32ed5b242934e67645f0704.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-07-25 08:35:46","commitOrder":10,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-07-25 08:35:46","endLine":1625,"groupId":"5364","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2f/568d8067fcddf7fd1847195771dc53b7ec693b.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    taskLockbox = new TaskLockbox(taskStorage);\n\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1469,"status":"M"}],"commitId":"db149462073d59e7563f0d3834e69d44a2bb4011","commitMessage":"@@@Add support minor compaction with segment locking (#7547)\n\n* Segment locking\n\n* Allow both timeChunk and segment lock in the same gruop\n\n* fix it test\n\n* Fix adding same chunk to atomicUpdateGroup\n\n* resolving todos\n\n* Fix segments to lock\n\n* fix segments to lock\n\n* fix kill task\n\n* resolving todos\n\n* resolving todos\n\n* fix teamcity\n\n* remove unused class\n\n* fix single map\n\n* resolving todos\n\n* fix build\n\n* fix SQLMetadataSegmentManager\n\n* fix findInputSegments\n\n* adding more tests\n\n* fixing task lock checks\n\n* add SegmentTransactionalOverwriteAction\n\n* changing publisher\n\n* fixing something\n\n* fix for perfect rollup\n\n* fix test\n\n* adjust package-lock.json\n\n* fix test\n\n* fix style\n\n* adding javadocs\n\n* remove unused classes\n\n* add more javadocs\n\n* unused import\n\n* fix test\n\n* fix test\n\n* Support forceTimeChunk context and force timeChunk lock for parallel index task if intervals are missing\n\n* fix travis\n\n* fix travis\n\n* unused import\n\n* spotbug\n\n* revert getMaxVersion\n\n* address comments\n\n* fix tc\n\n* add missing error handling\n\n* fix backward compatibility\n\n* unused import\n\n* Fix perf of versionedIntervalTimeline\n\n* fix timeline\n\n* fix tc\n\n* remove remaining todos\n\n* add comment for parallel index\n\n* fix javadoc and typos\n\n* typo\n\n* address comments\n","date":"2019-07-25 08:35:46","modifiedFileCount":"130","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-07-30 08:06:33","codes":[{"authorDate":"2019-07-30 08:06:33","commitOrder":11,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-07-30 08:06:33","endLine":1006,"groupId":"2979","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/a7391b5a1d32ee51324ded512e3e28e4a253d6.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-07-30 08:06:33","commitOrder":11,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-07-30 08:06:33","endLine":1630,"groupId":"5364","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/48/2ef769eafe5f40ca7e4ec8821877266cda4def.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new TaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1474,"status":"M"}],"commitId":"640b7afc1cee911a27de7bf938dda24a85ba1510","commitMessage":"@@@Add CliIndexer process type and initial task runner implementation (#8107)\n\n* Add CliIndexer process type and initial task runner implementation\n\n* Fix HttpRemoteTaskRunnerTest\n\n* Remove batch sanity check on PeonAppenderatorsManager\n\n* Fix paralle index tests\n\n* PR comments\n\n* Adjust Jersey resource logging\n\n* Additional cleanup\n\n* Fix SystemSchemaTest\n\n* Add comment to LocalDataSegmentPusherTest absolute path test\n\n* More PR comments\n\n* Use Server annotated with RemoteChatHandler\n\n* More PR comments\n\n* Checkstyle\n\n* PR comments\n\n* Add task shutdown to stopGracefully\n\n* Small cleanup\n\n* Compile fix\n\n* Address PR comments\n\n* Adjust TaskReportFileWriter and fix nits\n\n* Remove unnecessary closer\n\n* More PR comments\n\n* Minor adjustments\n\n* PR comments\n\n* ThreadingTaskRunner: cancel  task run future not shutdownFuture and remove thread from workitem\n","date":"2019-07-30 08:06:33","modifiedFileCount":"64","status":"M","submitter":"Jonathan Wei"},{"authorTime":"2019-08-03 06:34:44","codes":[{"authorDate":"2019-08-03 06:34:44","commitOrder":12,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-08-03 06:34:44","endLine":1007,"groupId":"17651","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/fb/fa7a9072806753b74c6f645e4397a02b914fd7.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-08-03 06:34:44","commitOrder":12,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile)\n    );\n  }\n","date":"2019-08-03 06:34:44","endLine":1631,"groupId":"5364","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/89/8411ae892b169740035121b6d64d2cb10c51be.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1474,"status":"M"}],"commitId":"8a16a8e97ff3c80907451bc11c4cd0ea8a421650","commitMessage":"@@@Teach tasks what machine they are running on (#8190)\n\n* Teach the middleManager port to tasks\n\n* parent annotation\n\n* Bind parent for indexer\n","date":"2019-08-03 06:34:44","modifiedFileCount":"19","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-16 08:43:35","codes":[{"authorDate":"2019-08-16 08:43:35","commitOrder":13,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-08-16 08:43:35","endLine":1008,"groupId":"17651","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/74/56ed446737b3b7bbdb9de223db286f6a3f9b25.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter()\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-08-16 08:43:35","commitOrder":13,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2019-08-16 08:43:35","endLine":1632,"groupId":"5364","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/69/1022e7bc9b804cac643c68b9d284d2c5f2d67b.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1474,"status":"M"}],"commitId":"5dac6375f382ba485ec000802ff0e922929df95d","commitMessage":"@@@Add support for parallel native indexing with shuffle for perfect rollup (#8257)\n\n* Add TaskResourceCleaner; fix a couple of concurrency bugs in batch tasks\n\n* kill runner when it's ready\n\n* add comment\n\n* kill run thread\n\n* fix test\n\n* Take closeable out of Appenderator\n\n* add javadoc\n\n* fix test\n\n* fix test\n\n* update javadoc\n\n* add javadoc about killed task\n\n* address comment\n\n* Add support for parallel native indexing with shuffle for perfect rollup.\n\n* Add comment about volatiles\n\n* fix test\n\n* fix test\n\n* handling missing exceptions\n\n* more clear javadoc for stopGracefully\n\n* unused import\n\n* update javadoc\n\n* Add missing statement in javadoc\n\n* address comments; fix doc\n\n* add javadoc for isGuaranteedRollup\n\n* Rename confusing variable name and fix typos\n\n* fix typos; move fetch() to a better home; fix the expiration time\n\n* add support https\n","date":"2019-08-16 08:43:35","modifiedFileCount":"49","status":"M","submitter":"Jihoon Son"},{"authorTime":"2019-08-23 18:13:54","codes":[{"authorDate":"2019-08-23 18:13:54","commitOrder":14,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2019-08-23 18:13:54","endLine":1008,"groupId":"17651","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/12/1f085aeaaa63b58648f1cead95e4720eb065c8.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"M"},{"authorDate":"2019-08-23 18:13:54","commitOrder":14,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2019-08-23 18:13:54","endLine":1632,"groupId":"5364","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c5/3828364197a81958b17f674639002fcb51a008.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        emitter,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        emitter,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1474,"status":"M"}],"commitId":"33f0753a70361e7d345a488034f76a889f7c3682","commitMessage":"@@@Add Checkstyle for constant name static final (#8060)\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* check ctyle for constant field name\n\n* merging with upstream\n\n* review-1\n\n* unknow changes\n\n* unknow changes\n\n* review-2\n\n* merging with master\n\n* review-2 1 changes\n\n* review changes-2 2\n\n* bug fix\n","date":"2019-08-23 18:13:54","modifiedFileCount":"298","status":"M","submitter":"SandishKumarHN"},{"authorTime":"2020-01-20 09:14:23","codes":[{"authorDate":"2020-01-20 09:14:23","commitOrder":15,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2020-01-20 09:14:23","endLine":993,"groupId":"17666","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e3/967e16cb1adc6530553212f4da8cecb92775f0.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":874,"status":"M"},{"authorDate":"2020-01-20 09:14:23","commitOrder":15,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2020-01-20 09:14:23","endLine":1609,"groupId":"1202","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/96/9f76953702f926cacbd76d800307bf9bed22e4.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    IntervalChunkingQueryRunnerDecorator queryRunnerDecorator = new IntervalChunkingQueryRunnerDecorator(\n        null,\n        null,\n        null\n    )\n    {\n      @Override\n      public <T> QueryRunner<T> decorate(QueryRunner<T> delegate, QueryToolChest<T, ? extends Query<T>> toolChest)\n      {\n        return delegate;\n      }\n    };\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(queryRunnerDecorator),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1463,"status":"M"}],"commitId":"d21054f7c5f72f9db1ecfb72b46ee866876f1e4b","commitMessage":"@@@Remove the deprecated interval-chunking stuff. (#9216)\n\n* Remove the deprecated interval-chunking stuff.\n\nSee https://github.com/apache/druid/pull/6591.  https://github.com/apache/druid/pull/4004#issuecomment-284171911 for details.\n\n* Remove unused import.\n\n* Remove chunkInterval too.\n","date":"2020-01-20 09:14:23","modifiedFileCount":"65","status":"M","submitter":"Gian Merlino"},{"authorTime":"2020-01-25 05:10:01","codes":[{"authorDate":"2020-01-25 05:10:01","commitOrder":16,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2020-01-25 05:10:01","endLine":995,"groupId":"17666","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/64/37488b1f1695a104a2feee9bb1926955b0bfbd.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":875,"status":"M"},{"authorDate":"2020-01-25 05:10:01","commitOrder":16,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2020-01-25 05:10:01","endLine":1611,"groupId":"1202","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/de/3fa29a489bccdb0960896ada9a90c11306002b.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1464,"status":"M"}],"commitId":"19b427e8f371bed0b0100272ac890b3775471654","commitMessage":"@@@Add JoinableFactory interface and use it in the query stack. (#9247)\n\n* Add JoinableFactory interface and use it in the query stack.\n\nAlso includes InlineJoinableFactory.  which enables joining against\ninline datasources. This is the first patch where a basic join query\nactually works. It includes integration tests.\n\n* Fix test issues.\n\n* Adjustments from code review.\n","date":"2020-01-25 05:10:01","modifiedFileCount":"51","status":"M","submitter":"Gian Merlino"},{"authorTime":"2020-01-25 05:10:01","codes":[{"authorDate":"2020-03-10 17:57:16","commitOrder":17,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2020-03-10 17:57:16","endLine":995,"groupId":"13432","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8c/c21d02e19a31f266499a3c5e7dae5229ce2dcc.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQuery(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":875,"status":"M"},{"authorDate":"2020-01-25 05:10:01","commitOrder":17,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2020-01-25 05:10:01","endLine":1611,"groupId":"1202","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/de/3fa29a489bccdb0960896ada9a90c11306002b.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1464,"status":"N"}],"commitId":"8b9fe6f58461f1fc3f453c14f1634f9e779aeb71","commitMessage":"@@@query laning and load shedding (#9407)\n\n* prototype\n\n* merge QueryScheduler and QueryManager\n\n* everything in its right place\n\n* adjustments\n\n* docs\n\n* fixes\n\n* doc fixes\n\n* use resilience4j instead of semaphore\n\n* more tests\n\n* simplify\n\n* checkstyle\n\n* spelling\n\n* oops heh\n\n* remove unused\n\n* simplify\n\n* concurrency tests\n\n* add SqlResource tests.  refactor error response\n\n* add json config tests\n\n* use LongAdder instead of AtomicLong\n\n* remove test only stuffs from scheduler\n\n* javadocs.  etc\n\n* style\n\n* partial review stuffs\n\n* adjust\n\n* review stuffs\n\n* more javadoc\n\n* error response documentation\n\n* spelling\n\n* preserve user specified lane for NoSchedulingStrategy\n\n* more test.  why not\n\n* doc adjustment\n\n* style\n\n* missed review for make a thing a constant\n\n* fixes and tests\n\n* fix test\n\n* Update docs/configuration/index.md\n\nCo-Authored-By: sthetland <steve.hetland@imply.io>\n\n* doc update\n\nCo-authored-by: sthetland <steve.hetland@imply.io>","date":"2020-03-10 17:57:16","modifiedFileCount":"26","status":"M","submitter":"Clint Wylie"},{"authorTime":"2020-06-30 12:03:07","codes":[{"authorDate":"2020-06-30 12:03:07","commitOrder":18,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2020-06-30 12:03:07","endLine":1001,"groupId":"13432","id":35,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/43/24576746355b3ee8ef8af52417a1493b9f9fda.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":881,"status":"M"},{"authorDate":"2020-06-30 12:03:07","commitOrder":18,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","date":"2020-06-30 12:03:07","endLine":1612,"groupId":"1202","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/57/6235ee4f38f15f39f10e676fa45586900d84f1.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1465,"status":"M"}],"commitId":"363d0d86be9e83a5d24d5cf002cac57d99a43baa","commitMessage":"@@@QueryCountStatsMonitor can be injected in the Peon (#10092)\n\n* QueryCountStatsMonitor can be injected in the Peon\n\nThis change fixes a dependency injection bug where there is a circular\ndependency on getting the MonitorScheduler when a user configures the\nQueryCountStatsMonitor to be used.\n\n* fix tests\n\n* Actually fix the tests this time","date":"2020-06-30 12:03:07","modifiedFileCount":"13","status":"M","submitter":"Suneet Saldanha"},{"authorTime":"2020-08-27 08:08:12","codes":[{"authorDate":"2020-08-27 08:08:12","commitOrder":19,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2020-08-27 08:08:12","endLine":1001,"groupId":"1055","id":37,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/86/9bfcbbd237bb3e0a057e729a2ff84618359f30.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":881,"status":"M"},{"authorDate":"2020-08-27 08:08:12","commitOrder":19,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2020-08-27 08:08:12","endLine":1599,"groupId":"12760","id":38,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/0263b643766efd520c9c8ec350bd07a536dc4b.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    rowIngestionMetersFactory = testUtils.getRowIngestionMetersFactory();\n    SegmentLoaderConfig segmentLoaderConfig = new SegmentLoaderConfig()\n    {\n      @Override\n      public List<StorageLocationConfig> getLocations()\n      {\n        return new ArrayList<>();\n      }\n    };\n\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1454,"status":"M"}],"commitId":"f82fd22fa7de175200b7127c34c2eb2900bf7317","commitMessage":"@@@Move tools for indexing to TaskToolbox instead of injecting them in constructor (#10308)\n\n* Move tools for indexing to TaskToolbox instead of injecting them in constructor\n\n* oops.  other changes\n\n* fix test\n\n* unnecessary new file\n\n* fix test\n\n* fix build","date":"2020-08-27 08:08:12","modifiedFileCount":"67","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-03-26 01:32:21","codes":[{"authorDate":"2021-03-26 01:32:21","commitOrder":20,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-03-26 01:32:21","endLine":1015,"groupId":"1055","id":39,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5d/eecafe1f598ff1bb7d2dab982e5791339446cf.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"M"},{"authorDate":"2021-03-26 01:32:21","commitOrder":20,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-03-26 01:32:21","endLine":1612,"groupId":"6044","id":40,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f6/b09cbcff84a8cff80c2d53bf44ef3c0aa5b2a2.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(directory.getPath(), null, null, 50000, null, true, null, null, null);\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1456,"status":"M"}],"commitId":"bf20f9e9798417c9293a195690b6adcb48f44d3f","commitMessage":"@@@DruidInputSource: Fix issues in column projection.  timestamp handling. (#10267)\n\n* DruidInputSource: Fix issues in column projection.  timestamp handling.\n\nDruidInputSource.  DruidSegmentReader changes:\n\n1) Remove \"dimensions\" and \"metrics\". They are not necessary.  because we\n   can compute which columns we need to read based on what is going to\n   be used by the timestamp.  transform.  dimensions.  and metrics.\n2) Start using ColumnsFilter (see below) to decide which columns we need\n   to read.\n3) Actually respect the \"timestampSpec\". Previously.  it was ignored.  and\n   the timestamp of the returned InputRows was set to the `__time` column\n   of the input datasource.\n\n(1) and (2) together fix a bug in which the DruidInputSource would not\nproperly read columns that are used as inputs to a transformSpec.\n\n(3) fixes a bug where the timestampSpec would be ignored if you attempted\nto set the column to something other than `__time`.\n\n(1) and (3) are breaking changes.\n\nWeb console changes:\n\n1) Remove \"Dimensions\" and \"Metrics\" from the Druid input source.\n2) Set timestampSpec to `{\"column\": \"__time\".  \"format\": \"millis\"}` for\n   compatibility with the new behavior.\n\nOther changes:\n\n1) Add ColumnsFilter.  a new class that allows input readers to determine\n   which columns they need to read. Currently.  it's only used by the\n   DruidInputSource.  but it could be used by other columnar input sources\n   in the future.\n2) Add a ColumnsFilter to InputRowSchema.\n3) Remove the metric names from InputRowSchema (they were unused).\n4) Add InputRowSchemas.fromDataSchema method that computes the proper\n   ColumnsFilter for given timestamp.  dimensions.  transform.  and metrics.\n5) Add \"getRequiredColumns\" method to TransformSpec to support the above.\n\n* Various fixups.\n\n* Uncomment incorrectly commented lines.\n\n* Move TransformSpecTest to the proper module.\n\n* Add druid.indexer.task.ignoreTimestampSpecForDruidInputSource setting.\n\n* Fix.\n\n* Fix build.\n\n* Checkstyle.\n\n* Misc fixes.\n\n* Fix test.\n\n* Move config.\n\n* Fix imports.\n\n* Fixup.\n\n* Fix ShuffleResourceTest.\n\n* Add import.\n\n* Smarter exclusions.\n\n* Fixes based on tests.\n\nAlso.  add TIME_COLUMN constant in the web console.\n\n* Adjustments for tests.\n\n* Reorder test data.\n\n* Update docs.\n\n* Update docs to say Druid 0.22.0 instead of 0.21.0.\n\n* Fix test.\n\n* Fix ITAutoCompactionTest.\n\n* Changes from review & from merging.","date":"2021-03-26 01:32:21","modifiedFileCount":"60","status":"M","submitter":"Gian Merlino"},{"authorTime":"2021-04-02 03:29:36","codes":[{"authorDate":"2021-03-26 01:32:21","commitOrder":21,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-03-26 01:32:21","endLine":1015,"groupId":"1055","id":41,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5d/eecafe1f598ff1bb7d2dab982e5791339446cf.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"N"},{"authorDate":"2021-04-02 03:29:36","commitOrder":21,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-04-02 03:29:36","endLine":1613,"groupId":"6044","id":42,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ab/c504b308d3f10236d238373c6fb5f2714d43f1.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1456,"status":"M"}],"commitId":"d7f529336463dad273a742808b49d524bdc4ae11","commitMessage":"@@@Add an option for ingestion task to drop (mark unused) all existing segments that are contained by interval in the ingestionSpec (#11025)\n\n* Auto-Compaction can run indefinitely when segmentGranularity is changed from coarser to finer.\n\n* Add option to drop segments after ingestion\n\n* fix checkstyle\n\n* add tests\n\n* add tests\n\n* add tests\n\n* fix test\n\n* add tests\n\n* fix checkstyle\n\n* fix checkstyle\n\n* add docs\n\n* fix docs\n\n* address comments\n\n* address comments\n\n* fix spelling","date":"2021-04-02 03:29:36","modifiedFileCount":"44","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2021-05-12 05:34:26","codes":[{"authorDate":"2021-05-12 05:34:26","commitOrder":22,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-05-12 05:34:26","endLine":1016,"groupId":"1055","id":43,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0a/2e34d7d6d7578d57b8baa09145e96d02551637.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"M"},{"authorDate":"2021-05-12 05:34:26","commitOrder":22,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-05-12 05:34:26","endLine":1614,"groupId":"16011","id":44,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/11/3d41a864af01b2a36e95b66ba4ec69d87c26ea.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1456,"status":"M"}],"commitId":"8e5048e643f95c25cc95be91317475fecbdce456","commitMessage":"@@@Avoid memory mapping hydrants after they are persisted & after they are merged for native batch ingestion (#11123)\n\n* Avoid mapping hydrants in create segments phase for native ingestion\n\n* Drop queriable indices after a given sink is fully merged\n\n* Do not drop memory mappings for realtime ingestion\n\n* Style fixes\n\n* Renamed to match use case better\n\n* Rollback memoization code and use the real time flag instead\n\n* Null ptr fix in FireHydrant toString plus adjustments to memory pressure tracking calculations\n\n* Style\n\n* Log some count stats\n\n* Make sure sinks size is obtained at the right time\n\n* BatchAppenderator unit test\n\n* Fix comment typos\n\n* Renamed methods to make them more readable\n\n* Move persisted metadata from FireHydrant class to AppenderatorImpl. Removed superfluous differences and fix comment typo. Removed custom comparator\n\n* Missing dependency\n\n* Make persisted hydrant metadata map concurrent and better reflect the fact that keys are Java references. Maintain persisted metadata when dropping/closing segments.\n\n* Replaced concurrent variables with normal ones\n\n* Added   batchMemoryMappedIndex \"fallback\" flag with default \"false\". Set this to \"true\" make code fallback to previous code path.\n\n* Style fix.\n\n* Added note to new setting in doc.  using Iterables.size (and removing a dependency).  and fixing a typo in a comment.\n\n* Forgot to commit this edited documentation message","date":"2021-05-12 05:34:26","modifiedFileCount":"33","status":"M","submitter":"Agustin Gonzalez"},{"authorTime":"2021-07-01 18:33:08","codes":[{"authorDate":"2021-07-01 18:33:08","commitOrder":23,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE,\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-07-01 18:33:08","endLine":1016,"groupId":"15629","id":45,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/f2/b1503ab40f2ba06dc1758947a5d4b8396a6555.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"M"},{"authorDate":"2021-07-01 18:33:08","commitOrder":23,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE, \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-07-01 18:33:08","endLine":1615,"groupId":"16011","id":46,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d7/c5e32260f294eb9733be27fce9c9efb45aec62.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        Execs.directExecutor(), \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1457,"status":"M"}],"commitId":"03a6a6d6e1f7024c2691e6fef0685bd137d223e7","commitMessage":"@@@Replace Processing ExecutorService with QueryProcessingPool (#11382)\n\nThis PR refactors the code for QueryRunnerFactory#mergeRunners to accept a new interface called QueryProcessingPool instead of ExecutorService for concurrent execution of query runners. This interface will let custom extensions inject their own implementation for deciding which query-runner to prioritize first. The default implementation is the same as today that takes the priority of query into account. QueryProcessingPool can also be used as a regular executor service. It has a dedicated method for accepting query execution work so implementations can differentiate between regular async tasks and query execution tasks. This dedicated method also passes the QueryRunner object as part of the task information. This hook will let custom extensions carry any state from QuerySegmentWalker to QueryProcessingPool#mergeRunners which is not possible currently.","date":"2021-07-01 18:33:08","modifiedFileCount":"52","status":"M","submitter":"Abhishek Agarwal"},{"authorTime":"2021-07-21 02:44:19","codes":[{"authorDate":"2021-07-21 02:44:19","commitOrder":24,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE,\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-07-21 02:44:19","endLine":1016,"groupId":"15629","id":47,"instanceNumber":1,"isCurCommit":0,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/94/bf84d0e329e52283e27f2c47c37459d80e711c.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE,\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"M"},{"authorDate":"2021-07-21 02:44:19","commitOrder":24,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE, \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-07-21 02:44:19","endLine":1615,"groupId":"16011","id":48,"instanceNumber":2,"isCurCommit":0,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0c/6b1c482a21326037b1f0f0463d4b863521c431.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE, \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentLoaderFactory(null, testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1457,"status":"M"}],"commitId":"94c1671eaf7b050972602fdedcb1971cdbde692d","commitMessage":"@@@Split SegmentLoader into SegmentLoader and SegmentCacheManager (#11466)\n\nThis PR splits current SegmentLoader into SegmentLoader and SegmentCacheManager.\n\nSegmentLoader - this class is responsible for building the segment object but does not expose any methods for downloading.  cache space management.  etc. Default implementation delegates the download operations to SegmentCacheManager and only contains the logic for building segments once downloaded. . This class will be used in SegmentManager to construct Segment objects.\n\nSegmentCacheManager - this class manages the segment cache on the local disk. It fetches the segment files to the local disk.  can clean up the cache.  and in the future.  support reserve and release on cache space. [See https://github.com/Make SegmentLoader extensible and customizable #11398]. This class will be used in ingestion tasks such as compaction.  re-indexing where segment files need to be downloaded locally.","date":"2021-07-21 02:44:19","modifiedFileCount":"41","status":"M","submitter":"Abhishek Agarwal"},{"authorTime":"2021-09-09 04:31:52","codes":[{"authorDate":"2021-09-09 04:31:52","commitOrder":25,"curCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false,\n        TaskConfig.BATCH_PROCESSING_MODE_DEFAULT.name()\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE,\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","date":"2021-09-09 04:31:52","endLine":1017,"groupId":"104419","id":49,"instanceNumber":1,"isCurCommit":1,"methodName":"makeToolbox","params":"(finalTasktask@finalTaskStoragetaskStorage@finalIndexerMetadataStorageCoordinatormdc@finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/bf/d96787811352ca847cbd7094219ff300f3731a.src","preCode":"  private TaskToolbox makeToolbox(\n      final Task task,\n      final TaskStorage taskStorage,\n      final IndexerMetadataStorageCoordinator mdc,\n      final File directory\n  )\n  {\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n    final TaskLockbox taskLockbox = new TaskLockbox(taskStorage, mdc);\n    try {\n      taskStorage.insert(task, TaskStatus.running(task.getId()));\n    }\n    catch (EntryExistsException e) {\n      \r\n    }\n    taskLockbox.syncFromStorage();\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                new QueryWatcher()\n                {\n                  @Override\n                  public void registerQueryFuture(Query query, ListenableFuture future)\n                  {\n                    \r\n                  }\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = new SegmentHandoffNotifierFactory()\n    {\n      @Override\n      public SegmentHandoffNotifier createSegmentHandoffNotifier(String dataSource)\n      {\n        return new SegmentHandoffNotifier()\n        {\n          @Override\n          public boolean registerSegmentHandoffCallback(\n              SegmentDescriptor descriptor,\n              Executor exec,\n              Runnable handOffRunnable\n          )\n          {\n            handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n            return true;\n          }\n\n          @Override\n          public void start()\n          {\n            \r\n          }\n\n          @Override\n          public void close()\n          {\n            \r\n          }\n\n        };\n      }\n    };\n    final TestUtils testUtils = new TestUtils();\n    final TaskToolboxFactory toolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        null, \r\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE,\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new NoopTestTaskReportFileWriter(),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n\n    return toolboxFactory.build(task);\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/RealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":884,"status":"M"},{"authorDate":"2021-09-09 04:31:52","commitOrder":25,"curCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false,\n        TaskConfig.BATCH_PROCESSING_MODE_DEFAULT.name()\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE, \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","date":"2021-09-09 04:31:52","endLine":1616,"groupId":"104419","id":50,"instanceNumber":2,"isCurCommit":1,"methodName":"makeToolboxFactory","params":"(finalFiledirectory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/48/bfab5df7534f0b83843163a078704e3fbc0180.src","preCode":"  private void makeToolboxFactory(final File directory)\n  {\n    taskStorage = new HeapMemoryTaskStorage(new TaskStorageConfig(null));\n    publishedSegments = new CopyOnWriteArrayList<>();\n\n    ObjectMapper mapper = new DefaultObjectMapper();\n    mapper.registerSubtypes(LinearShardSpec.class);\n    mapper.registerSubtypes(NumberedShardSpec.class);\n    IndexerSQLMetadataStorageCoordinator mdc = new IndexerSQLMetadataStorageCoordinator(\n        mapper,\n        derbyConnectorRule.metadataTablesConfigSupplier().get(),\n        derbyConnectorRule.getConnector()\n    )\n    {\n      @Override\n      public Set<DataSegment> announceHistoricalSegments(Set<DataSegment> segments) throws IOException\n      {\n        Set<DataSegment> result = super.announceHistoricalSegments(segments);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result);\n        segments.forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n\n      @Override\n      public SegmentPublishResult announceHistoricalSegments(\n          Set<DataSegment> segments,\n          Set<DataSegment> segmentsToDrop,\n          DataSourceMetadata startMetadata,\n          DataSourceMetadata endMetadata\n      ) throws IOException\n      {\n        SegmentPublishResult result = super.announceHistoricalSegments(segments, segmentsToDrop, startMetadata, endMetadata);\n\n        Assert.assertFalse(\n            \"Segment latch not initialized, did you forget to call expectPublishSegments?\",\n            segmentLatch == null\n        );\n\n        publishedSegments.addAll(result.getSegments());\n        result.getSegments().forEach(s -> segmentLatch.countDown());\n\n        return result;\n      }\n    };\n\n    taskLockbox = new TaskLockbox(taskStorage, mdc);\n    final TaskConfig taskConfig = new TaskConfig(\n        directory.getPath(),\n        null,\n        null,\n        50000,\n        null,\n        true,\n        null,\n        null,\n        null,\n        false,\n        false\n    );\n\n    final TaskActionToolbox taskActionToolbox = new TaskActionToolbox(\n        taskLockbox,\n        taskStorage,\n        mdc,\n        EMITTER,\n        EasyMock.createMock(SupervisorManager.class)\n    );\n    final TaskActionClientFactory taskActionClientFactory = new LocalTaskActionClientFactory(\n        taskStorage,\n        taskActionToolbox,\n        new TaskAuditLogConfig(false)\n    );\n    final QueryRunnerFactoryConglomerate conglomerate = new DefaultQueryRunnerFactoryConglomerate(\n        ImmutableMap.of(\n            TimeseriesQuery.class,\n            new TimeseriesQueryRunnerFactory(\n                new TimeseriesQueryQueryToolChest(),\n                new TimeseriesQueryEngine(),\n                (query, future) -> {\n                  \r\n                }\n            )\n        )\n    );\n    handOffCallbacks = new ConcurrentHashMap<>();\n    final SegmentHandoffNotifierFactory handoffNotifierFactory = dataSource -> new SegmentHandoffNotifier()\n    {\n      @Override\n      public boolean registerSegmentHandoffCallback(\n          SegmentDescriptor descriptor,\n          Executor exec,\n          Runnable handOffRunnable\n      )\n      {\n        handOffCallbacks.put(descriptor, new Pair<>(exec, handOffRunnable));\n        handoffLatch.countDown();\n        return true;\n      }\n\n      @Override\n      public void start()\n      {\n        \r\n      }\n\n      @Override\n      public void close()\n      {\n        \r\n      }\n\n    };\n    final TestUtils testUtils = new TestUtils();\n    taskToolboxFactory = new TaskToolboxFactory(\n        taskConfig,\n        new DruidNode(\"druid/middlemanager\", \"localhost\", false, 8091, null, true, false),\n        taskActionClientFactory,\n        EMITTER,\n        new TestDataSegmentPusher(),\n        new TestDataSegmentKiller(),\n        null, \r\n        null, \r\n        new TestDataSegmentAnnouncer(),\n        EasyMock.createNiceMock(DataSegmentServerAnnouncer.class),\n        handoffNotifierFactory,\n        () -> conglomerate,\n        DirectQueryProcessingPool.INSTANCE, \r\n        NoopJoinableFactory.INSTANCE,\n        () -> EasyMock.createMock(MonitorScheduler.class),\n        new SegmentCacheManagerFactory(testUtils.getTestObjectMapper()),\n        testUtils.getTestObjectMapper(),\n        testUtils.getTestIndexIO(),\n        MapCache.create(1024),\n        new CacheConfig(),\n        new CachePopulatorStats(),\n        testUtils.getTestIndexMergerV9(),\n        EasyMock.createNiceMock(DruidNodeAnnouncer.class),\n        EasyMock.createNiceMock(DruidNode.class),\n        new LookupNodeService(\"tier\"),\n        new DataNodeService(\"tier\", 1000, ServerType.INDEXER_EXECUTOR, 0),\n        new SingleFileTaskReportFileWriter(reportsFile),\n        null,\n        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n        new NoopChatHandlerProvider(),\n        testUtils.getRowIngestionMetersFactory(),\n        new TestAppenderatorsManager(),\n        new NoopIndexingServiceClient(),\n        null,\n        null,\n        null\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1457,"status":"M"}],"commitId":"9efa6cc9c85aab66b325e9f37f7bad13826aea39","commitMessage":"@@@Make persists concurrent with adding rows in batch ingestion (#11536)\n\n* Make persists concurrent with ingestion\n\n* Remove semaphore but keep concurrent persists (with add) and add push in the backround as well\n\n* Go back to documented default persists (zero)\n\n* Move to debug\n\n* Remove unnecessary Atomics\n\n* Comments on synchronization (or not) for sinks & sinkMetadata\n\n* Some cleanup for unit tests but they still need further work\n\n* Shutdown & wait for persists and push on close\n\n* Provide support for three existing batch appenderators using batchProcessingMode flag\n\n* Fix reference to wrong appenderator\n\n* Fix doc typos\n\n* Add BatchAppenderators class test coverage\n\n* Add log message to batchProcessingMode final value.  fix typo in enum name\n\n* Another typo and minor fix to log message\n\n* LEGACY->OPEN_SEGMENTS.  Edit docs\n\n* Minor update legacy->open segments log message\n\n* More code comments.  mostly small adjustments to naming etc\n\n* fix spelling\n\n* Exclude BtachAppenderators from Jacoco since it is fully tested but Jacoco still refuses to ack coverage\n\n* Coverage for Appenderators & BatchAppenderators.  name change of a method that was still using \"legacy\" rather than \"openSegments\"\n\nCo-authored-by: Clint Wylie <cjwylie@gmail.com>","date":"2021-09-09 04:31:52","modifiedFileCount":"33","status":"M","submitter":"Agustin Gonzalez"}]
