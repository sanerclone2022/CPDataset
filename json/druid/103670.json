[{"authorTime":"2020-04-23 01:43:34","codes":[{"authorDate":"2020-04-23 01:43:34","commitOrder":1,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-23 01:43:34","endLine":92,"groupId":"2523","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/14/c9cac8ac2a901e209e1e02afeb79f4c54b69a1.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":46,"status":"B"},{"authorDate":"2020-04-23 01:43:34","commitOrder":1,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-23 01:43:34","endLine":101,"groupId":"12668","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ce/769bfb59baeb6772fc3aca0eb98103baa4e9c4.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"B"}],"commitId":"16f5ae440510951b247920d41833da98804897d0","commitMessage":"@@@Add integration tests for kafka ingestion (#9724)\n\n* add kafka admin and kafka writer\n\n* refactor kinesis IT\n\n* fix typo refactor\n\n* parallel\n\n* parallel\n\n* parallel\n\n* parallel works now\n\n* add kafka it\n\n* add doc to readme\n\n* fix tests\n\n* fix failing test\n\n* test\n\n* test\n\n* test\n\n* test\n\n* address comments\n\n* addressed comments","date":"2020-04-23 01:43:34","modifiedFileCount":"9","status":"B","submitter":"Maytas Monsereenusorn"},{"authorTime":"2020-04-30 04:18:01","codes":[{"authorDate":"2020-04-30 04:18:01","commitOrder":2,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-30 04:18:01","endLine":120,"groupId":"20234","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/095a310b44e90fdc427e588b657dc2e0ad7f87.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"M"},{"authorDate":"2020-04-30 04:18:01","commitOrder":2,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-30 04:18:01","endLine":126,"groupId":"12668","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3b/b9693dcbdf58f033d8a79a7713456837249d6d.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(String streamName,\n                                                                 String fullDatasourceName,\n                                                                 IntegrationTestingConfig config)\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":49,"status":"M"}],"commitId":"39722bd0646464ca67d1a0bf6966c0b7e4aedaf9","commitMessage":"@@@Integration tests for stream ingestion with various data formats (#9783)\n\n* Integration tests for stream ingestion with various data formats\n\n* fix npe\n\n* better logging; fix tsv\n\n* fix tsv\n\n* exclude kinesis from travis\n\n* some readme","date":"2020-04-30 04:18:01","modifiedFileCount":"19","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-07-13 20:46:05","codes":[{"authorDate":"2020-04-30 04:18:01","commitOrder":3,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-30 04:18:01","endLine":120,"groupId":"20234","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/095a310b44e90fdc427e588b657dc2e0ad7f87.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"N"},{"authorDate":"2020-07-13 20:46:05","commitOrder":3,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-07-13 20:46:05","endLine":129,"groupId":"12668","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/cc/2a22f827d13c87283d96d288e2345789547ee0.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"M"}],"commitId":"2b48de074a855d3c36ff588e90846644fc4b5f42","commitMessage":"@@@Add additional properties for Kafka AdminClient and consumer from test config file (#10137)\n\n* Add kafka test configs from file for AdminClient and consumer\n\n* review comment","date":"2020-07-13 20:46:05","modifiedFileCount":"3","status":"M","submitter":"Nishant Bangarwa"},{"authorTime":"2020-10-05 23:54:29","codes":[{"authorDate":"2020-04-30 04:18:01","commitOrder":4,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-30 04:18:01","endLine":120,"groupId":"20234","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/095a310b44e90fdc427e588b657dc2e0ad7f87.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"N"},{"authorDate":"2020-10-05 23:54:29","commitOrder":4,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-10-05 23:54:29","endLine":129,"groupId":"12668","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/20/4b6ef7259ef7e52931bb3f119d232af42068b4.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"M"}],"commitId":"307c1b072006115dc0780913bb3fd7d1831849b4","commitMessage":"@@@adjustments to Kafka integration tests to allow running against Azure Event Hubs streams (#10463)\n\n* adjustments to kafka integration tests to allow running against azure event hubs in kafka mode\n\n* oops\n\n* make better\n\n* more better","date":"2020-10-05 23:54:29","modifiedFileCount":"6","status":"M","submitter":"Clint Wylie"},{"authorTime":"2021-03-09 00:12:12","codes":[{"authorDate":"2020-04-30 04:18:01","commitOrder":5,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2020-04-30 04:18:01","endLine":120,"groupId":"20234","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b8/095a310b44e90fdc427e588b657dc2e0ad7f87.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"N"},{"authorDate":"2021-03-09 00:12:12","commitOrder":5,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n\n        spec = StringUtils.replace(\n            spec,\n            \"%%SCHEMA_REGISTRY_HOST%%\",\n            StringUtils.format(\"http://%s\", config.getSchemaRegistryInternalHost())\n        );\n\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2021-03-09 00:12:12","endLine":137,"groupId":"12668","id":10,"instanceNumber":2,"isCurCommit":1,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/a11e6992cd28bb6276738a8a63c55eb1da00c2.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"M"}],"commitId":"96889cdebce68cee839b350205b60823227e142b","commitMessage":"@@@add avro + kafka + schema registry integration test (#10929)\n\n* add avro + schema registry integration test\n\n* style\n\n* retry init\n\n* maybe this\n\n* oops heh\n\n* this will fix it\n\n* review stuffs\n\n* fix comment","date":"2021-03-09 00:12:12","modifiedFileCount":"9","status":"M","submitter":"Clint Wylie"},{"authorTime":"2021-03-09 00:12:12","codes":[{"authorDate":"2021-04-09 06:50:04","commitOrder":6,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        spec = StringUtils.replace(\n                spec,\n                \"%%SCHEMA_REGISTRY_HOST%%\",\n                StringUtils.format(\"http://%s\", config.getSchemaRegistryInternalHost())\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2021-04-09 06:50:04","endLine":135,"groupId":"103670","id":11,"instanceNumber":1,"isCurCommit":1,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/58/54a6234445d8b87690be90a47433b5df461488.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kinesis\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"stream\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestSequenceNumber\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"endpoint\"\n        );\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKinesisIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"},{"authorDate":"2021-03-09 00:12:12","commitOrder":6,"curCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n\n        spec = StringUtils.replace(\n            spec,\n            \"%%SCHEMA_REGISTRY_HOST%%\",\n            StringUtils.format(\"http://%s\", config.getSchemaRegistryInternalHost())\n        );\n\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","date":"2021-03-09 00:12:12","endLine":137,"groupId":"103670","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"generateStreamIngestionPropsTransform","params":"(StringstreamName@StringfullDatasourceName@StringparserType@StringparserOrInputFormat@IntegrationTestingConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5e/a11e6992cd28bb6276738a8a63c55eb1da00c2.src","preCode":"  Function<String, String> generateStreamIngestionPropsTransform(\n      String streamName,\n      String fullDatasourceName,\n      String parserType,\n      String parserOrInputFormat,\n      IntegrationTestingConfig config\n  )\n  {\n    final Map<String, Object> consumerConfigs = KafkaConsumerConfigs.getConsumerProperties();\n    final Properties consumerProperties = new Properties();\n    consumerProperties.putAll(consumerConfigs);\n    consumerProperties.setProperty(\"bootstrap.servers\", config.getKafkaInternalHost());\n    KafkaUtil.addPropertiesFromTestConfig(config, consumerProperties);\n    return spec -> {\n      try {\n        spec = StringUtils.replace(\n            spec,\n            \"%%DATASOURCE%%\",\n            fullDatasourceName\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_TYPE%%\",\n            \"kafka\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_KEY%%\",\n            \"topic\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%TOPIC_VALUE%%\",\n            streamName\n        );\n\n        if (AbstractStreamIndexingTest.INPUT_FORMAT.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              \"null\"\n          );\n        } else if (AbstractStreamIndexingTest.INPUT_ROW_PARSER.equals(parserType)) {\n          spec = StringUtils.replace(\n              spec,\n              \"%%PARSER%%\",\n              parserOrInputFormat\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%INPUT_FORMAT%%\",\n              \"null\"\n          );\n        }\n        spec = StringUtils.replace(\n            spec,\n            \"%%USE_EARLIEST_KEY%%\",\n            \"useEarliestOffset\"\n        );\n        spec = StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_KEY%%\",\n            \"consumerProperties\"\n        );\n\n        spec = StringUtils.replace(\n            spec,\n            \"%%SCHEMA_REGISTRY_HOST%%\",\n            StringUtils.format(\"http://%s\", config.getSchemaRegistryInternalHost())\n        );\n\n        return StringUtils.replace(\n            spec,\n            \"%%STREAM_PROPERTIES_VALUE%%\",\n            jsonMapper.writeValueAsString(consumerProperties)\n        );\n      }\n      catch (Exception e) {\n        throw new RuntimeException(e);\n      }\n    };\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/AbstractKafkaIndexingServiceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"N"}],"commitId":"de691808cea7e270250be43685599e33a4d680c5","commitMessage":"@@@[Bug]Kinesis-data-format IT can not work (#11071)\n\n* start schema-resgity and replace json template\n\n* add docs\n\nCo-authored-by: yuezhang <yuezhang@freewheel.tv>","date":"2021-04-09 06:50:04","modifiedFileCount":"1","status":"M","submitter":"zhangyue19921010"}]
