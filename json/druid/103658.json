[{"authorTime":"2019-12-10 15:05:49","codes":[{"authorDate":"2019-12-10 15:05:49","commitOrder":1,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","date":"2019-12-10 15:05:49","endLine":122,"groupId":"10296","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0c/975b208e654d37063b6810c332b94b9f6349a7.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITBestEffortRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"B"},{"authorDate":"2019-12-10 15:05:49","commitOrder":1,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","date":"2019-12-10 15:05:49","endLine":112,"groupId":"3712","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/03/442032de036ace6f188f1e3afdd9c98b243b2a.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITPerfectRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"B"}],"commitId":"bab78fc80e8ee2929d6d2c277d3999695c8402a4","commitMessage":"@@@Parallel indexing single dim partitions (#8925)\n\n* Parallel indexing single dim partitions\n\nImplements single dimension range partitioning for native parallel batch\nindexing as described in #8769. This initial version requires the\ndruid-datasketches extension to be loaded.\n\nThe algorithm has 5 phases that are orchestrated by the supervisor in\n`ParallelIndexSupervisorTask#runRangePartitionMultiPhaseParallel()`.\nThese phases and the main classes involved are described below:\n\n1) In parallel.  determine the distribution of dimension values for each\n   input source split.\n\n   `PartialDimensionDistributionTask` uses `StringSketch` to generate\n   the approximate distribution of dimension values for each input\n   source split. If the rows are ungrouped. \n   `PartialDimensionDistributionTask.UngroupedRowDimensionValueFilter`\n   uses a Bloom filter to skip rows that would be grouped. The final\n   distribution is sent back to the supervisor via\n   `DimensionDistributionReport`.\n\n2) The range partitions are determined.\n\n   In `ParallelIndexSupervisorTask#determineAllRangePartitions()`.  the\n   supervisor uses `StringSketchMerger` to merge the individual\n   `StringSketch`es created in the preceding phase. The merged sketch is\n   then used to create the range partitions.\n\n3) In parallel.  generate partial range-partitioned segments.\n\n   `PartialRangeSegmentGenerateTask` uses the range partitions\n   determined in the preceding phase and\n   `RangePartitionCachingLocalSegmentAllocator` to generate\n   `SingleDimensionShardSpec`s.  The partition information is sent back\n   to the supervisor via `GeneratedGenericPartitionsReport`.\n\n4) The partial range segments are grouped.\n\n   In `ParallelIndexSupervisorTask#groupGenericPartitionLocationsPerPartition()`. \n   the supervisor creates the `PartialGenericSegmentMergeIOConfig`s\n   necessary for the next phase.\n\n5) In parallel.  merge partial range-partitioned segments.\n\n   `PartialGenericSegmentMergeTask` uses `GenericPartitionLocation` to\n   retrieve the partial range-partitioned segments generated earlier and\n   then merges and publishes them.\n\n* Fix dependencies & forbidden apis\n\n* Fixes for integration test\n\n* Address review comments\n\n* Fix docs.  strict compile.  sketch check.  rollup check\n\n* Fix first shard spec.  partition serde.  single subtask\n\n* Fix first partition check in test\n\n* Misc rewording/refactoring to address code review\n\n* Fix doc link\n\n* Split batch index integration test\n\n* Do not run parallel-batch-index twice\n\n* Adjust last partition\n\n* Split ITParallelIndexTest to reduce runtime\n\n* Rename test class\n\n* Allow null values in range partitions\n\n* Indicate which phase failed\n\n* Improve asserts in tests\n","date":"2019-12-10 15:05:49","modifiedFileCount":"18","status":"B","submitter":"Chi Cao Minh"},{"authorTime":"2020-02-06 07:33:42","codes":[{"authorDate":"2020-02-06 07:33:42","commitOrder":2,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true,\n          true,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","date":"2020-02-06 07:33:42","endLine":126,"groupId":"10296","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/0b/14f92dc561a87b4892b6e84ae9168671863ed3.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITBestEffortRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"},{"authorDate":"2020-02-06 07:33:42","commitOrder":2,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","date":"2020-02-06 07:33:42","endLine":114,"groupId":"3712","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/06/7c22455683b1dc4fb88195f314d07c1f4d2e6a.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITPerfectRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"2e1dbe598ce26a4668dffcbd996ec2b57cf3761a","commitMessage":"@@@Create new dynamic config to pause coordinator helpers when needed (#9224)\n\n* Create new dynamic config to pause coordinator helpers when needed\n\n* Fix spelling mistakes flagged in Travis build\n\n* Add an integration test for coordinator pause dynamic config\n\n* Improve documentation for new dynamic coordinator config and remove un-needed info logs in favor of debug\n\n* address naming convention of 'deep store' vs 'deep storage' in new configs doc line\n\n* Fix newline at end of configuration index.md\n\n* Last try to resolve newline issue in configuration readme\n\n* fix spell checks from travis build\n\n* Fix another flagges spelling error from Travis\n","date":"2020-02-06 07:33:42","modifiedFileCount":"9","status":"M","submitter":"Lucas Capistrant"},{"authorTime":"2021-04-09 12:03:00","codes":[{"authorDate":"2021-04-09 12:03:00","commitOrder":3,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%SEGMENT_AVAIL_TIMEOUT_MILLIS%%\",\n              jsonMapper.writeValueAsString(\"0\")\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true,\n          new Pair<>(false, false)\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true,\n          true,\n          true,\n          new Pair<>(false, false)\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE,\n          new Pair<>(false, false)\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE,\n          new Pair<>(false, false)\n      );\n    }\n  }\n","date":"2021-04-09 12:03:00","endLine":150,"groupId":"103658","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a4/63e389d79ed2be0bbd9ec94f95377a87a3809c.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertFalse(forceGuaranteedRollup, \"parititionSpec does not support best-effort rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(false)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true\n      );\n\n      \r\n      \r\n      doIndexTest(\n          INDEX_DATASOURCE,\n          REINDEX_TASK,\n          rollupTransform,\n          REINDEX_QUERIES_RESOURCE,\n          true,\n          true,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          REINDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITBestEffortRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"M"},{"authorDate":"2021-04-09 12:03:00","commitOrder":3,"curCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          spec = StringUtils.replace(\n              spec,\n              \"%%SEGMENT_AVAIL_TIMEOUT_MILLIS%%\",\n              jsonMapper.writeValueAsString(\"0\")\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true,\n          new Pair<>(false, false)\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE,\n          new Pair<>(false, false)\n\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE,\n          new Pair<>(false, false)\n      );\n    }\n  }\n","date":"2021-04-09 12:03:00","endLine":128,"groupId":"103658","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testIndexData","params":"(PartitionsSpecpartitionsSpec)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/1b/b1a79bd49cea3ca9b6e2d6edfc7bb962f3b9e8.src","preCode":"  public void testIndexData(PartitionsSpec partitionsSpec) throws Exception\n  {\n    try (\n        final Closeable ignored1 = unloader(INDEX_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored2 = unloader(INDEX_INGEST_SEGMENT_DATASOURCE + config.getExtraDatasourceNameSuffix());\n        final Closeable ignored3 = unloader(INDEX_DRUID_INPUT_SOURCE_DATASOURCE + config.getExtraDatasourceNameSuffix())\n    ) {\n      boolean forceGuaranteedRollup = partitionsSpec.isForceGuaranteedRollupCompatible();\n      Assert.assertTrue(forceGuaranteedRollup, \"parititionSpec does not support perfect rollup\");\n\n      final Function<String, String> rollupTransform = spec -> {\n        try {\n          spec = StringUtils.replace(\n              spec,\n              \"%%FORCE_GUARANTEED_ROLLUP%%\",\n              Boolean.toString(true)\n          );\n          return StringUtils.replace(\n              spec,\n              \"%%PARTITIONS_SPEC%%\",\n              jsonMapper.writeValueAsString(partitionsSpec)\n          );\n        }\n        catch (JsonProcessingException e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      doIndexTest(\n          INDEX_DATASOURCE,\n          INDEX_TASK,\n          rollupTransform,\n          INDEX_QUERIES_RESOURCE,\n          false,\n          true,\n          true\n      );\n\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_INGEST_SEGMENT_DATASOURCE,\n          rollupTransform,\n          INDEX_INGEST_SEGMENT_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n\n      \r\n      doReindexTest(\n          INDEX_DATASOURCE,\n          INDEX_DRUID_INPUT_SOURCE_DATASOURCE,\n          rollupTransform,\n          INDEX_DRUID_INPUT_SOURCE_TASK,\n          INDEX_QUERIES_RESOURCE\n      );\n    }\n  }\n","realPath":"integration-tests/src/test/java/org/apache/druid/tests/indexer/ITPerfectRollupParallelIndexTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"8264203cee688607091232897749e959e7706010","commitMessage":"@@@Allow client to configure batch ingestion task to wait to complete until segments are confirmed to be available by other (#10676)\n\n* Add ability to wait for segment availability for batch jobs\n\n* IT updates\n\n* fix queries in legacy hadoop IT\n\n* Fix broken indexing integration tests\n\n* address an lgtm flag\n\n* spell checker still flagging for hadoop doc. adding under that file header too\n\n* fix compaction IT\n\n* Updates to wait for availability method\n\n* improve unit testing for patch\n\n* fix bad indentation\n\n* refactor waitForSegmentAvailability\n\n* Fixes based off of review comments\n\n* cleanup to get compile after merging with master\n\n* fix failing test after previous logic update\n\n* add back code that must have gotten deleted during conflict resolution\n\n* update some logging code\n\n* fixes to get compilation working after merge with master\n\n* reset interrupt flag in catch block after code review pointed it out\n\n* small changes following self-review\n\n* fixup some issues brought on by merge with master\n\n* small changes after review\n\n* cleanup a little bit after merge with master\n\n* Fix potential resource leak in AbstractBatchIndexTask\n\n* syntax fix\n\n* Add a Compcation TuningConfig type\n\n* add docs stipulating the lack of support by Compaction tasks for the new config\n\n* Fixup compilation errors after merge with master\n\n* Remove erreneous newline","date":"2021-04-09 12:03:00","modifiedFileCount":"106","status":"M","submitter":"Lucas Capistrant"}]
