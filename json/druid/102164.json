[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","date":"2018-08-31 00:56:26","endLine":179,"groupId":"11211","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/834ca18c141c4b53032fab9f1109c9e6b1b6fe.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","date":"2018-08-31 00:56:26","endLine":220,"groupId":"6638","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/834ca18c141c4b53032fab9f1109c9e6b1b6fe.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":182,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-10-10 23:53:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","date":"2018-08-31 00:56:26","endLine":179,"groupId":"11211","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/79/834ca18c141c4b53032fab9f1109c9e6b1b6fe.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"N"},{"authorDate":"2018-10-10 23:53:26","commitOrder":2,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS, false);\n  }\n","date":"2018-10-10 23:53:26","endLine":220,"groupId":"6638","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/a7/13101c3ba2c3a905619ad6ca1b064e7b5db0f9.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":182,"status":"M"}],"commitId":"e69a2f217b378b6a5dd416c791531e9b1cfb208e","commitMessage":"@@@Fix avro parser issue while deserializing sketches  (#6440)\n\n* Fix object transform for avro parser\n\n* Remove unwanted space\n","date":"2018-10-10 23:53:26","modifiedFileCount":"3","status":"M","submitter":"Atul Mohan"},{"authorTime":"2019-06-15 05:18:58","codes":[{"authorDate":"2019-06-15 05:18:58","commitOrder":3,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","date":"2019-06-15 05:18:58","endLine":185,"groupId":"8197","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/df7a96dd5086730071076fa9e343b9de67bdb8.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"M"},{"authorDate":"2019-06-15 05:18:58","commitOrder":3,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","date":"2019-06-15 05:18:58","endLine":226,"groupId":"6638","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ca/df7a96dd5086730071076fa9e343b9de67bdb8.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<String, Integer>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS, false);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"M"}],"commitId":"f581118f05a8dcbd5e642d03025fc125bcc0bad8","commitMessage":"@@@Remove Apache Pig from the tests (#7810)\n\n* Remove Apache Pig from the tests\n\n* Remove the Pig specific part\n\n* Fix the Checkstyle issues\n\n* Cleanup a bit\n\n* Add an additional test\n\n* Revert the abstract class\n","date":"2019-06-15 05:18:58","modifiedFileCount":"13","status":"M","submitter":"Fokko Driesprong"},{"authorTime":"2019-07-07 00:33:12","codes":[{"authorDate":"2019-07-07 00:33:12","commitOrder":4,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    Assert.assertEquals(parser, parser2);\n  }\n","date":"2019-07-07 00:33:12","endLine":184,"groupId":"8197","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/1210eb45c00d89706217697b64392f23f039f9.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":171,"status":"M"},{"authorDate":"2019-07-07 00:33:12","commitOrder":4,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","date":"2019-07-07 00:33:12","endLine":225,"groupId":"8197","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/1210eb45c00d89706217697b64392f23f039f9.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<Integer, Schema, String>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":187,"status":"M"}],"commitId":"1166bbcb75d432817715fdd429737f86730b5591","commitMessage":"@@@Remove static imports from tests (#8036)\n\nMake static imports forbidden in tests and remove all occurrences to be\nconsistent with the non-test code.\n\nAlso.  various changes to files affected by above:\n- Reformat to adhere to druid style guide\n- Fix various IntelliJ warnings\n- Fix various SonarLint warnings (e.g..  the expected/actual args to\n  Assert.assertEquals() were flipped)","date":"2019-07-07 00:33:12","modifiedFileCount":"98","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2020-02-11 13:53:11","codes":[{"authorDate":"2019-07-07 00:33:12","commitOrder":5,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    Assert.assertEquals(parser, parser2);\n  }\n","date":"2019-07-07 00:33:12","endLine":184,"groupId":"8197","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/29/1210eb45c00d89706217697b64392f23f039f9.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    Assert.assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":171,"status":"N"},{"authorDate":"2020-02-11 13:53:11","commitOrder":5,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS, false);\n  }\n","date":"2020-02-11 13:53:11","endLine":229,"groupId":"8197","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/70/8e89ecab93b1d81efef389b4c3711eefc8b71d.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":191,"status":"M"}],"commitId":"7968524b013d95e0f4701a1c2752960e8be92850","commitMessage":"@@@Add Pig-specific file handling to Avro parser (#9258)\n\n* Add processing for data files from AvroStorage\n\n* Add words to spellings file\n","date":"2020-02-11 13:53:11","modifiedFileCount":"8","status":"M","submitter":"Atul Mohan"},{"authorTime":"2021-07-07 13:05:41","codes":[{"authorDate":"2021-07-07 13:05:41","commitOrder":6,"curCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository),\n        false,\n        false\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    Assert.assertEquals(parser, parser2);\n  }\n","date":"2021-07-07 13:05:41","endLine":190,"groupId":"102164","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSerde","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8e/d9f44fc06218f7251d2670ed3e366f2cf9c837.src","preCode":"  public void testSerde() throws IOException\n  {\n    Repository repository = new Avro1124RESTRepositoryClientWrapper(\"http://github.io\");\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n\n    Assert.assertEquals(parser, parser2);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":175,"status":"M"},{"authorDate":"2021-07-07 13:05:41","commitOrder":6,"curCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository),\n        false,\n        false\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS, false);\n  }\n","date":"2021-07-07 13:05:41","endLine":233,"groupId":"102164","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testParse","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/8e/d9f44fc06218f7251d2670ed3e366f2cf9c837.src","preCode":"  public void testParse() throws SchemaValidationException, IOException\n  {\n    \r\n    Repository repository = new InMemoryRepository(null);\n    AvroStreamInputRowParser parser = new AvroStreamInputRowParser(\n        PARSE_SPEC,\n        new SchemaRepoBasedAvroBytesDecoder<>(new Avro1124SubjectAndIdConverter(TOPIC), repository)\n    );\n    ByteBufferInputRowParser parser2 = jsonMapper.readValue(\n        jsonMapper.writeValueAsString(parser),\n        ByteBufferInputRowParser.class\n    );\n    repository = ((SchemaRepoBasedAvroBytesDecoder) ((AvroStreamInputRowParser) parser2).getAvroBytesDecoder()).getSchemaRepository();\n\n    \r\n    GenericRecord someAvroDatum = buildSomeAvroDatum();\n\n    \r\n    Avro1124SubjectAndIdConverter converter = new Avro1124SubjectAndIdConverter(TOPIC);\n    TypedSchemaRepository<Integer, Schema, String> repositoryClient = new TypedSchemaRepository<>(\n        repository,\n        new IntegerConverter(),\n        new AvroSchemaConverter(),\n        new IdentityConverter()\n    );\n    Integer id = repositoryClient.registerSchema(TOPIC, SomeAvroDatum.getClassSchema());\n    ByteBuffer byteBuffer = ByteBuffer.allocate(4);\n    converter.putSubjectAndId(id, byteBuffer);\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    out.write(byteBuffer.array());\n    \r\n    DatumWriter<GenericRecord> writer = new SpecificDatumWriter<>(someAvroDatum.getSchema());\n    \r\n    writer.write(someAvroDatum, EncoderFactory.get().directBinaryEncoder(out, null));\n\n    InputRow inputRow = parser2.parseBatch(ByteBuffer.wrap(out.toByteArray())).get(0);\n\n    assertInputRowCorrect(inputRow, DIMENSIONS, false);\n  }\n","realPath":"extensions-core/avro-extensions/src/test/java/org/apache/druid/data/input/AvroStreamInputRowParserTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":193,"status":"M"}],"commitId":"d5e8d4d68007899df17f390a756422d511d746d5","commitMessage":"@@@Avro union support (#10505)\n\n* Avro union support\n\n* Document new union support\n\n* Add support for AvroStreamInputFormat and fix checkstyle\n\n* Extend multi-member union test schema and format\n\n* Some additional docs and add Enums to spelling\n\n* Rename explodeUnions -> extractUnions\n\n* explode -> extract\n\n* ByType\n\n* Correct spelling error","date":"2021-07-07 13:05:41","modifiedFileCount":"15","status":"M","submitter":"Joseph Glanville"}]
