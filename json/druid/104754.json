[{"authorTime":"2019-11-16 01:22:09","codes":[{"authorDate":"2019-12-10 15:05:49","commitOrder":4,"curCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2019-12-10 15:05:49","endLine":320,"groupId":"13980","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/c2d185162c56a64bb053e9f136efe872c280c5.src","preCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"B"},{"authorDate":"2019-11-16 01:22:09","commitOrder":4,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getSegmentLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = timeline.findFullyOvershadowed()\n                                                 .stream()\n                                                 .flatMap(holder -> holder.getObject().stream())\n                                                 .map(PartitionChunk::getObject)\n                                                 .collect(Collectors.toSet());\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","date":"2019-11-16 01:22:09","endLine":249,"groupId":"15604","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/64/08299d084f9517b7ff15511aaf174333d6bc89.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getSegmentLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = timeline.findFullyOvershadowed()\n                                                 .stream()\n                                                 .flatMap(holder -> holder.getObject().stream())\n                                                 .map(PartitionChunk::getObject)\n                                                 .collect(Collectors.toSet());\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":207,"status":"NB"}],"commitId":"bab78fc80e8ee2929d6d2c277d3999695c8402a4","commitMessage":"@@@Parallel indexing single dim partitions (#8925)\n\n* Parallel indexing single dim partitions\n\nImplements single dimension range partitioning for native parallel batch\nindexing as described in #8769. This initial version requires the\ndruid-datasketches extension to be loaded.\n\nThe algorithm has 5 phases that are orchestrated by the supervisor in\n`ParallelIndexSupervisorTask#runRangePartitionMultiPhaseParallel()`.\nThese phases and the main classes involved are described below:\n\n1) In parallel.  determine the distribution of dimension values for each\n   input source split.\n\n   `PartialDimensionDistributionTask` uses `StringSketch` to generate\n   the approximate distribution of dimension values for each input\n   source split. If the rows are ungrouped. \n   `PartialDimensionDistributionTask.UngroupedRowDimensionValueFilter`\n   uses a Bloom filter to skip rows that would be grouped. The final\n   distribution is sent back to the supervisor via\n   `DimensionDistributionReport`.\n\n2) The range partitions are determined.\n\n   In `ParallelIndexSupervisorTask#determineAllRangePartitions()`.  the\n   supervisor uses `StringSketchMerger` to merge the individual\n   `StringSketch`es created in the preceding phase. The merged sketch is\n   then used to create the range partitions.\n\n3) In parallel.  generate partial range-partitioned segments.\n\n   `PartialRangeSegmentGenerateTask` uses the range partitions\n   determined in the preceding phase and\n   `RangePartitionCachingLocalSegmentAllocator` to generate\n   `SingleDimensionShardSpec`s.  The partition information is sent back\n   to the supervisor via `GeneratedGenericPartitionsReport`.\n\n4) The partial range segments are grouped.\n\n   In `ParallelIndexSupervisorTask#groupGenericPartitionLocationsPerPartition()`. \n   the supervisor creates the `PartialGenericSegmentMergeIOConfig`s\n   necessary for the next phase.\n\n5) In parallel.  merge partial range-partitioned segments.\n\n   `PartialGenericSegmentMergeTask` uses `GenericPartitionLocation` to\n   retrieve the partial range-partitioned segments generated earlier and\n   then merges and publishes them.\n\n* Fix dependencies & forbidden apis\n\n* Fixes for integration test\n\n* Address review comments\n\n* Fix docs.  strict compile.  sketch check.  rollup check\n\n* Fix first shard spec.  partition serde.  single subtask\n\n* Fix first partition check in test\n\n* Misc rewording/refactoring to address code review\n\n* Fix doc link\n\n* Split batch index integration test\n\n* Do not run parallel-batch-index twice\n\n* Adjust last partition\n\n* Split ITParallelIndexTest to reduce runtime\n\n* Rename test class\n\n* Allow null values in range partitions\n\n* Indicate which phase failed\n\n* Improve asserts in tests\n","date":"2019-12-10 15:05:49","modifiedFileCount":"18","status":"M","submitter":"Chi Cao Minh"},{"authorTime":"2020-02-08 08:23:07","codes":[{"authorDate":"2019-12-10 15:05:49","commitOrder":5,"curCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2019-12-10 15:05:49","endLine":320,"groupId":"13980","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/c2d185162c56a64bb053e9f136efe872c280c5.src","preCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"N"},{"authorDate":"2020-02-08 08:23:07","commitOrder":5,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = timeline.findFullyOvershadowed()\n                                                 .stream()\n                                                 .flatMap(holder -> holder.getObject().stream())\n                                                 .map(PartitionChunk::getObject)\n                                                 .collect(Collectors.toSet());\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","date":"2020-02-08 08:23:07","endLine":234,"groupId":"15604","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/5b/9d1f5c34b44723e7f2209deb4f7915c397355e.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getSegmentLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = timeline.findFullyOvershadowed()\n                                                 .stream()\n                                                 .flatMap(holder -> holder.getObject().stream())\n                                                 .map(PartitionChunk::getObject)\n                                                 .collect(Collectors.toSet());\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"}],"commitId":"e81230f9abd092b2ac742258abf534f6e17f35e8","commitMessage":"@@@Refactoring some codes around ingestion (#9274)\n\n* Refactoring codes around ingestion:\n\n- Parallel index task and simple task now use the same segment allocator implementation. This is reusable for the future implementation as well.\n- Added PartitionAnalysis to store the analysis of the partitioning\n- Move some util methods to SegmentLockHelper and rename it to TaskLockHelper\n\n* fix build\n\n* fix SingleDimensionShardSpecFactory\n\n* optimize SingledimensionShardSpecFactory\n\n* fix test\n\n* shard spec builder\n\n* import order\n\n* shardSpecBuilder -> partialShardSpec\n\n* build -> complete\n\n* fix comment; add unit tests for partitionBoundaries\n\n* add more tests and fix javadoc\n\n* fix toString(); add serde tests for HashBasedNumberedPartialShardSpec and SegmentAllocateAction\n\n* fix test\n\n* add equality test for hash and range partial shard specs\n","date":"2020-02-08 08:23:07","modifiedFileCount":"49","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-03-11 04:22:19","codes":[{"authorDate":"2019-12-10 15:05:49","commitOrder":6,"curCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2019-12-10 15:05:49","endLine":320,"groupId":"13980","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/c2d185162c56a64bb053e9f136efe872c280c5.src","preCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"N"},{"authorDate":"2020-03-11 04:22:19","commitOrder":6,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","date":"2020-03-11 04:22:19","endLine":235,"groupId":"15604","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/9f/1dc52c1ff4f31470dc5b820ec0d548e22ef467.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = timeline.findFullyOvershadowed()\n                                                 .stream()\n                                                 .flatMap(holder -> holder.getObject().stream())\n                                                 .map(PartitionChunk::getObject)\n                                                 .collect(Collectors.toSet());\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":194,"status":"M"}],"commitId":"7401bb3f9315bf0622b6e0fe7c7fd855d1c65052","commitMessage":"@@@Improve OvershadowableManager performance (#9441)\n\n* Use the iterator instead of higherKey(); use the iterator API instead of stream\n\n* Fix tests; fix a concurrency bug in timeline\n\n* fix test\n\n* add tests for findNonOvershadowedObjectsInInterval\n\n* fix test\n\n* add missing tests; fix a bug in QueueEntry\n\n* equals tests\n\n* fix test","date":"2020-03-11 04:22:19","modifiedFileCount":"18","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-06-26 05:41:22","codes":[{"authorDate":"2019-12-10 15:05:49","commitOrder":7,"curCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2019-12-10 15:05:49","endLine":320,"groupId":"13980","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/60/c2d185162c56a64bb053e9f136efe872c280c5.src","preCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"N"},{"authorDate":"2020-06-26 05:41:22","commitOrder":7,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        toolbox.getIndexingTmpDir()\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","date":"2020-06-26 05:41:22","endLine":230,"groupId":"13980","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b4/a7c8b95f22b9d01ef2c1c78a1c68f8d0d4e749.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final File tmpDir = toolbox.getIndexingTmpDir();\n    \r\n    FileUtils.forceMkdir(tmpDir);\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        tmpDir\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":193,"status":"M"}],"commitId":"f6594fff608d4b2e071c7bdd6d86d7f87398ce4f","commitMessage":"@@@Fix missing temp dir for native single_dim (#10046)\n\n* Fix missing temp dir for native single_dim\n\nNative single dim indexing throws a file not found exception from\nInputEntityIteratingReader.java:81.  This MR creates the required\ntemporary directory when setting up the\nPartialDimensionDistributionTask.  The change was tested on a Druid\ncluster.  After installing the change native single_dim indexing\ncompletes successfully.\n\n* Fix indentation\n\n* Use SinglePhaseSubTask as example for creating the temp dir\n\n* Move temporary indexing dir creation in to TaskToolbox\n\n* Remove unused dependency\n\nCo-authored-by: Morri Feldman <morri@appsflyer.com>","date":"2020-06-26 05:41:22","modifiedFileCount":"6","status":"M","submitter":"morrifeldman"},{"authorTime":"2020-08-27 08:08:12","codes":[{"authorDate":"2020-08-27 08:08:12","commitOrder":8,"curCode":"  private void sendReport(TaskToolbox toolbox, DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n        new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2020-08-27 08:08:12","endLine":302,"groupId":"13980","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(TaskToolboxtoolbox@DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d7/1102bc1a24878bb335bbe714944934a6ace0f7.src","preCode":"  private void sendReport(DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":292,"status":"M"},{"authorDate":"2020-08-27 08:08:12","commitOrder":8,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n        new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        toolbox.getIndexingTmpDir()\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","date":"2020-08-27 08:08:12","endLine":217,"groupId":"13980","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ba/1316f0ed8d413db531e59300c1a43b469a8cbc.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final ParallelIndexSupervisorTaskClient taskClient = taskClientFactory.build(\n        new ClientBasedTaskInfoProvider(indexingServiceClient),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        toolbox.getIndexingTmpDir()\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"M"}],"commitId":"f82fd22fa7de175200b7127c34c2eb2900bf7317","commitMessage":"@@@Move tools for indexing to TaskToolbox instead of injecting them in constructor (#10308)\n\n* Move tools for indexing to TaskToolbox instead of injecting them in constructor\n\n* oops.  other changes\n\n* fix test\n\n* unnecessary new file\n\n* fix test\n\n* fix build","date":"2020-08-27 08:08:12","modifiedFileCount":"67","status":"M","submitter":"Jihoon Son"},{"authorTime":"2021-09-17 02:58:11","codes":[{"authorDate":"2020-08-27 08:08:12","commitOrder":9,"curCode":"  private void sendReport(TaskToolbox toolbox, DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n        new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","date":"2020-08-27 08:08:12","endLine":302,"groupId":"104754","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"sendReport","params":"(TaskToolboxtoolbox@DimensionDistributionReportreport)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/d7/1102bc1a24878bb335bbe714944934a6ace0f7.src","preCode":"  private void sendReport(TaskToolbox toolbox, DimensionDistributionReport report)\n  {\n    final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n        new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    taskClient.report(supervisorTaskId, report);\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialDimensionDistributionTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":292,"status":"N"},{"authorDate":"2021-09-17 02:58:11","commitOrder":9,"curCode":"  public TaskStatus runTask(final TaskToolbox toolbox)\n  {\n    try {\n      if (missingIntervalsInOverwriteMode) {\n        LOG.warn(\n            \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n            + \"Forced to use timeChunk lock.\"\n        );\n      }\n      this.authorizerMapper = toolbox.getAuthorizerMapper();\n\n      toolbox.getChatHandlerProvider().register(getId(), this, false);\n\n      rowIngestionMeters = toolbox.getRowIngestionMetersFactory().createRowIngestionMeters();\n      parseExceptionHandler = new ParseExceptionHandler(\n          rowIngestionMeters,\n          ingestionSchema.getTuningConfig().isLogParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxParseExceptions(),\n          ingestionSchema.getTuningConfig().getMaxSavedParseExceptions()\n      );\n\n      final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n          ingestionSchema.getDataSchema().getParser()\n      );\n\n      final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n          new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n          getId(),\n          1, \r\n          ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n          ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n      );\n      ingestionState = IngestionState.BUILD_SEGMENTS;\n      final Set<DataSegment> pushedSegments = generateAndPushSegments(\n          toolbox,\n          taskClient,\n          inputSource,\n          toolbox.getIndexingTmpDir()\n      );\n      \n      \r\n      final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n      allSegments.addAll(pushedSegments);\n      final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n      final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                         .transformAndConcat(TimelineObjectHolder::getObject)\n                                                         .transform(PartitionChunk::getObject)\n                                                         .toSet();\n\n      Map<String, TaskReport> taskReport = getTaskCompletionReports();\n      taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments, taskReport));\n\n      toolbox.getTaskReportFileWriter().write(getId(), taskReport);\n\n      return TaskStatus.success(getId());\n    }\n    catch (Exception e) {\n      LOG.error(e, \"Encountered exception in parallel sub task.\");\n      errorMsg = Throwables.getStackTraceAsString(e);\n      toolbox.getTaskReportFileWriter().write(getId(), getTaskCompletionReports());\n      return TaskStatus.failure(\n          getId(),\n          errorMsg\n      );\n    }\n    finally {\n      toolbox.getChatHandlerProvider().unregister(getId());\n    }\n  }\n","date":"2021-09-17 02:58:11","endLine":294,"groupId":"104754","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"runTask","params":"(finalTaskToolboxtoolbox)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/08/cba47f6f8985100e813f95111a95c891f91bb1.src","preCode":"  public TaskStatus runTask(final TaskToolbox toolbox) throws Exception\n  {\n    if (missingIntervalsInOverwriteMode) {\n      LOG.warn(\n          \"Intervals are missing in granularitySpec while this task is potentially overwriting existing segments. \"\n          + \"Forced to use timeChunk lock.\"\n      );\n    }\n    final InputSource inputSource = ingestionSchema.getIOConfig().getNonNullInputSource(\n        ingestionSchema.getDataSchema().getParser()\n    );\n\n    final ParallelIndexSupervisorTaskClient taskClient = toolbox.getSupervisorTaskClientFactory().build(\n        new ClientBasedTaskInfoProvider(toolbox.getIndexingServiceClient()),\n        getId(),\n        1, \r\n        ingestionSchema.getTuningConfig().getChatHandlerTimeout(),\n        ingestionSchema.getTuningConfig().getChatHandlerNumRetries()\n    );\n    final Set<DataSegment> pushedSegments = generateAndPushSegments(\n        toolbox,\n        taskClient,\n        inputSource,\n        toolbox.getIndexingTmpDir()\n    );\n\n    \r\n    final Set<DataSegment> allSegments = new HashSet<>(getTaskLockHelper().getLockedExistingSegments());\n    allSegments.addAll(pushedSegments);\n    final VersionedIntervalTimeline<String, DataSegment> timeline = VersionedIntervalTimeline.forSegments(allSegments);\n    final Set<DataSegment> oldSegments = FluentIterable.from(timeline.findFullyOvershadowed())\n                                                       .transformAndConcat(TimelineObjectHolder::getObject)\n                                                       .transform(PartitionChunk::getObject)\n                                                       .toSet();\n    taskClient.report(supervisorTaskId, new PushedSegmentsReport(getId(), oldSegments, pushedSegments));\n\n    return TaskStatus.success(getId());\n  }\n","realPath":"indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":226,"status":"M"}],"commitId":"22b41ddbbfe2b07b085e295ba171bcdc07e04900","commitMessage":"@@@Task reports for parallel task: single phase and sequential mode (#11688)\n\n* Task reports for parallel task: single phase and sequential mode\n\n* Address comments\n\n* Add null check for currentSubTaskHolder","date":"2021-09-17 02:58:11","modifiedFileCount":"13","status":"M","submitter":"Jonathan Wei"}]
