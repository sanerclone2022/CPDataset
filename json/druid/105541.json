[{"authorTime":"2020-06-19 09:40:43","codes":[{"authorDate":"2020-02-08 08:23:07","commitOrder":2,"curCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimension, that.partitionDimension) &&\n           Objects.equals(start, that.start) &&\n           Objects.equals(end, that.end);\n  }\n","date":"2020-02-08 08:23:07","endLine":134,"groupId":"14442","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/22/ca97d3fe191bdb72290aa0ae0d0141a52bb666.src","preCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimension, that.partitionDimension) &&\n           Objects.equals(start, that.start) &&\n           Objects.equals(end, that.end);\n  }\n","realPath":"core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":120,"status":"NB"},{"authorDate":"2020-06-19 09:40:43","commitOrder":2,"curCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    HashBucketShardSpec that = (HashBucketShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimensions, that.partitionDimensions);\n  }\n","date":"2020-06-19 09:40:43","endLine":112,"groupId":"14442","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/32/4c020449853acb73ff4f9dbf689212e970a1eb.src","preCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    HashBucketShardSpec that = (HashBucketShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimensions, that.partitionDimensions);\n  }\n","realPath":"core/src/main/java/org/apache/druid/timeline/partition/HashBucketShardSpec.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"B"}],"commitId":"d644a27f1a545105a4b1a4110f3ed83d7c46a46f","commitMessage":"@@@Create packed core partitions for hash/range-partitioned segments in native batch ingestion (#10025)\n\n* Fill in the core partition set size properly for batch ingestion with\ndynamic partitioning\n\n* incomplete javadoc\n\n* Address comments\n\n* fix tests\n\n* fix json serde.  add tests\n\n* checkstyle\n\n* Set core partition set size for hash-partitioned segments properly in\nbatch ingestion\n\n* test for both parallel and single-threaded task\n\n* unused variables\n\n* fix test\n\n* unused imports\n\n* add hash/range buckets\n\n* some test adjustment and missing json serde\n\n* centralized partition id allocation in parallel and simple tasks\n\n* remove string partition chunk\n\n* revive string partition chunk\n\n* fill numCorePartitions for hadoop\n\n* clean up hash stuffs\n\n* resolved todos\n\n* javadocs\n\n* Fix tests\n\n* add more tests\n\n* doc\n\n* unused imports","date":"2020-06-19 09:40:43","modifiedFileCount":"78","status":"M","submitter":"Jihoon Son"},{"authorTime":"2020-09-25 07:32:56","codes":[{"authorDate":"2020-02-08 08:23:07","commitOrder":3,"curCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimension, that.partitionDimension) &&\n           Objects.equals(start, that.start) &&\n           Objects.equals(end, that.end);\n  }\n","date":"2020-02-08 08:23:07","endLine":134,"groupId":"105541","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/22/ca97d3fe191bdb72290aa0ae0d0141a52bb666.src","preCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimension, that.partitionDimension) &&\n           Objects.equals(start, that.start) &&\n           Objects.equals(end, that.end);\n  }\n","realPath":"core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":120,"status":"N"},{"authorDate":"2020-09-25 07:32:56","commitOrder":3,"curCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    HashBucketShardSpec that = (HashBucketShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimensions, that.partitionDimensions) &&\n           partitionFunction == that.partitionFunction;\n  }\n","date":"2020-09-25 07:32:56","endLine":127,"groupId":"105541","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ce/f6686e9a1bcfd5e51d68fa13b24f82b10d7e51.src","preCode":"  public boolean equals(Object o)\n  {\n    if (this == o) {\n      return true;\n    }\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n    HashBucketShardSpec that = (HashBucketShardSpec) o;\n    return bucketId == that.bucketId &&\n           numBuckets == that.numBuckets &&\n           Objects.equals(partitionDimensions, that.partitionDimensions);\n  }\n","realPath":"core/src/main/java/org/apache/druid/timeline/partition/HashBucketShardSpec.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"M"}],"commitId":"0cc9eb4903e7bddb4c1484984bf87c8fab7648df","commitMessage":"@@@Store hash partition function in dataSegment and allow segment pruning only when hash partition function is provided (#10288)\n\n* Store hash partition function in dataSegment and allow segment pruning only when hash partition function is provided\n\n* query context\n\n* fix tests; add more test\n\n* javadoc\n\n* docs and more tests\n\n* remove default and hadoop tests\n\n* consistent name and fix javadoc\n\n* spelling and field name\n\n* default function for partitionsSpec\n\n* other comments\n\n* address comments\n\n* fix tests and spelling\n\n* test\n\n* doc","date":"2020-09-25 07:32:56","modifiedFileCount":"50","status":"M","submitter":"Jihoon Son"}]
