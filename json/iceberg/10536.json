[{"authorTime":"2020-12-02 12:11:44","codes":[{"authorDate":"2020-08-25 08:36:31","commitOrder":5,"curCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","date":"2020-08-25 08:36:31","endLine":88,"groupId":"2259","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"newAppender","params":"(OutputFilefile@FileFormatfileFormat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/33/83fe7c29f739841854b33596a18f02b43af27f.src","preCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/source/SparkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"NB"},{"authorDate":"2020-12-02 12:11:44","commitOrder":5,"curCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","date":"2020-12-02 12:11:44","endLine":131,"groupId":"67","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"newAppender","params":"(OutputFileoutputFile@FileFormatformat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/1d/df0929fbdc5a81f0e36c4b0592ce048ef48bb9.src","preCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","realPath":"flink/src/main/java/org/apache/iceberg/flink/sink/FlinkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"B"}],"commitId":"4383ad4960feb0f22b85dd26a463d7776b64c077","commitMessage":"@@@Core: Add data and delete writers in FileAppenderFactory. (#1836)\n\n","date":"2020-12-02 12:11:44","modifiedFileCount":"12","status":"M","submitter":"openinx"},{"authorTime":"2021-01-07 11:19:00","codes":[{"authorDate":"2020-08-25 08:36:31","commitOrder":6,"curCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","date":"2020-08-25 08:36:31","endLine":88,"groupId":"2259","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"newAppender","params":"(OutputFilefile@FileFormatfileFormat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/33/83fe7c29f739841854b33596a18f02b43af27f.src","preCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/source/SparkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2021-01-07 11:19:00","commitOrder":6,"curCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","date":"2021-01-07 11:19:00","endLine":132,"groupId":"67","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"newAppender","params":"(OutputFileoutputFile@FileFormatformat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/94/297ba7a4d339a80b26cee98f29acbf99a6f69e.src","preCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","realPath":"flink/src/main/java/org/apache/iceberg/flink/sink/FlinkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"M"}],"commitId":"a89de2d071c1ee995075817c25ec244e2b1cc2c8","commitMessage":"@@@ORC: Respect metrics config in Flink and Generic Appenders (#1960)\n\n","date":"2021-01-07 11:19:00","modifiedFileCount":"2","status":"M","submitter":"yyanyy"},{"authorTime":"2021-02-03 10:00:37","codes":[{"authorDate":"2020-08-25 08:36:31","commitOrder":7,"curCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","date":"2020-08-25 08:36:31","endLine":88,"groupId":"10536","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"newAppender","params":"(OutputFilefile@FileFormatfileFormat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/33/83fe7c29f739841854b33596a18f02b43af27f.src","preCode":"  public FileAppender<InternalRow> newAppender(OutputFile file, FileFormat fileFormat) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(properties);\n    try {\n      switch (fileFormat) {\n        case PARQUET:\n          return Parquet.write(file)\n              .createWriterFunc(msgType -> SparkParquetWriters.buildWriter(dsSchema, msgType))\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case AVRO:\n          return Avro.write(file)\n              .createWriterFunc(ignored -> new SparkAvroWriter(dsSchema))\n              .setAll(properties)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(file)\n              .createWriterFunc(SparkOrcWriter::new)\n              .setAll(properties)\n              .metricsConfig(metricsConfig)\n              .schema(writeSchema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown format: \" + fileFormat);\n      }\n    } catch (IOException e) {\n      throw new RuntimeIOException(e);\n    }\n  }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/source/SparkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2021-02-03 10:00:37","commitOrder":7,"curCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .metricsConfig(metricsConfig)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","date":"2021-02-03 10:00:37","endLine":133,"groupId":"10536","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"newAppender","params":"(OutputFileoutputFile@FileFormatformat)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/e3/9d470ec7ed92688ef9cb6578fbd9d617f47c9e.src","preCode":"  public FileAppender<RowData> newAppender(OutputFile outputFile, FileFormat format) {\n    MetricsConfig metricsConfig = MetricsConfig.fromProperties(props);\n    try {\n      switch (format) {\n        case AVRO:\n          return Avro.write(outputFile)\n              .createWriterFunc(ignore -> new FlinkAvroWriter(flinkSchema))\n              .setAll(props)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case ORC:\n          return ORC.write(outputFile)\n              .createWriterFunc((iSchema, typDesc) -> FlinkOrcWriter.buildWriter(flinkSchema, iSchema))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        case PARQUET:\n          return Parquet.write(outputFile)\n              .createWriterFunc(msgType -> FlinkParquetWriters.buildWriter(flinkSchema, msgType))\n              .setAll(props)\n              .metricsConfig(metricsConfig)\n              .schema(schema)\n              .overwrite()\n              .build();\n\n        default:\n          throw new UnsupportedOperationException(\"Cannot write unknown file format: \" + format);\n      }\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n  }\n","realPath":"flink/src/main/java/org/apache/iceberg/flink/sink/FlinkAppenderFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"M"}],"commitId":"6cc5d997998ad818354c2d6a86c54ebc613890ae","commitMessage":"@@@Avro: Add MetricsAwareDatumWriter (#1946)\n\n","date":"2021-02-03 10:00:37","modifiedFileCount":"10","status":"M","submitter":"yyanyy"}]
