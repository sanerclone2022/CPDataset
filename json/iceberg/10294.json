[{"authorTime":"2021-07-12 07:50:36","codes":[{"authorDate":"2021-07-12 07:50:36","commitOrder":1,"curCode":"  public void testSingleCommitWithCommitFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100));\n\n    BaseRewriteDataFilesSparkAction spyRewrite = spy(realRewrite);\n    RewriteDataFilesCommitManager util = spy(new RewriteDataFilesCommitManager(table));\n\n    \r\n    doThrow(new RuntimeException(\"Commit Failure\"))\n        .when(util)\n        .commitFileGroups(any());\n\n    doReturn(util)\n        .when(spyRewrite)\n        .commitManager();\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if commit fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","date":"2021-07-12 07:50:36","endLine":411,"groupId":"3400","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSingleCommitWithCommitFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/40/69d01bd1cc4cb8e82e00d7b80ba5d8ac7c96db.src","preCode":"  public void testSingleCommitWithCommitFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100));\n\n    BaseRewriteDataFilesSparkAction spyRewrite = spy(realRewrite);\n    RewriteDataFilesCommitManager util = spy(new RewriteDataFilesCommitManager(table));\n\n    \r\n    doThrow(new RuntimeException(\"Commit Failure\"))\n        .when(util)\n        .commitFileGroups(any());\n\n    doReturn(util)\n        .when(spyRewrite)\n        .commitManager();\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if commit fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/actions/TestNewRewriteDataFilesAction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":377,"status":"B"},{"authorDate":"2021-07-12 07:50:36","commitOrder":1,"curCode":"  public void testParallelSingleCommitWithRewriteFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100))\n                .option(RewriteDataFiles.MAX_CONCURRENT_FILE_GROUP_REWRITES, \"3\");\n\n    BaseRewriteDataFilesSparkAction spyRewrite = Mockito.spy(realRewrite);\n\n    \r\n    GroupInfoMatcher failGroup = new GroupInfoMatcher(1, 3, 7);\n    doThrow(new RuntimeException(\"Rewrite Failed\"))\n        .when(spyRewrite)\n        .rewriteFiles(any(), argThat(failGroup));\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if part fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","date":"2021-07-12 07:50:36","endLine":445,"groupId":"3399","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testParallelSingleCommitWithRewriteFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/40/69d01bd1cc4cb8e82e00d7b80ba5d8ac7c96db.src","preCode":"  public void testParallelSingleCommitWithRewriteFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100))\n                .option(RewriteDataFiles.MAX_CONCURRENT_FILE_GROUP_REWRITES, \"3\");\n\n    BaseRewriteDataFilesSparkAction spyRewrite = Mockito.spy(realRewrite);\n\n    \r\n    GroupInfoMatcher failGroup = new GroupInfoMatcher(1, 3, 7);\n    doThrow(new RuntimeException(\"Rewrite Failed\"))\n        .when(spyRewrite)\n        .rewriteFiles(any(), argThat(failGroup));\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if part fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/actions/TestNewRewriteDataFilesAction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":414,"status":"B"}],"commitId":"25eaebacbd1e250d2d884b49fc753a23b6aa6eaf","commitMessage":"@@@Spark: Reimplement RewriteDatafilesAction with partial progress (#2591)\n\n","date":"2021-07-12 07:50:36","modifiedFileCount":"8","status":"B","submitter":"Russell Spitzer"},{"authorTime":"2021-07-12 07:50:36","codes":[{"authorDate":"2021-07-27 23:59:53","commitOrder":2,"curCode":"  public void testSingleCommitWithCommitFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100));\n\n    BaseRewriteDataFilesSparkAction spyRewrite = spy(realRewrite);\n    RewriteDataFilesCommitManager util = spy(new RewriteDataFilesCommitManager(table));\n\n    \r\n    doThrow(new RuntimeException(\"Commit Failure\"))\n        .when(util)\n        .commitFileGroups(any());\n\n    doReturn(util)\n        .when(spyRewrite)\n        .commitManager(table.currentSnapshot().snapshotId());\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if commit fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","date":"2021-07-27 23:59:53","endLine":411,"groupId":"10294","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testSingleCommitWithCommitFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/85/000659c682bfac8bde720d0ef9d21b509e2114.src","preCode":"  public void testSingleCommitWithCommitFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100));\n\n    BaseRewriteDataFilesSparkAction spyRewrite = spy(realRewrite);\n    RewriteDataFilesCommitManager util = spy(new RewriteDataFilesCommitManager(table));\n\n    \r\n    doThrow(new RuntimeException(\"Commit Failure\"))\n        .when(util)\n        .commitFileGroups(any());\n\n    doReturn(util)\n        .when(spyRewrite)\n        .commitManager();\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if commit fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/actions/TestNewRewriteDataFilesAction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":377,"status":"M"},{"authorDate":"2021-07-12 07:50:36","commitOrder":2,"curCode":"  public void testParallelSingleCommitWithRewriteFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100))\n                .option(RewriteDataFiles.MAX_CONCURRENT_FILE_GROUP_REWRITES, \"3\");\n\n    BaseRewriteDataFilesSparkAction spyRewrite = Mockito.spy(realRewrite);\n\n    \r\n    GroupInfoMatcher failGroup = new GroupInfoMatcher(1, 3, 7);\n    doThrow(new RuntimeException(\"Rewrite Failed\"))\n        .when(spyRewrite)\n        .rewriteFiles(any(), argThat(failGroup));\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if part fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","date":"2021-07-12 07:50:36","endLine":445,"groupId":"10294","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testParallelSingleCommitWithRewriteFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/40/69d01bd1cc4cb8e82e00d7b80ba5d8ac7c96db.src","preCode":"  public void testParallelSingleCommitWithRewriteFailure() {\n    Table table = createTable(20);\n    int fileSize = averageFileSize(table);\n\n    List<Object[]> originalData = currentData();\n\n    BaseRewriteDataFilesSparkAction realRewrite =\n        (org.apache.iceberg.spark.actions.BaseRewriteDataFilesSparkAction)\n            basicRewrite(table)\n                .option(RewriteDataFiles.MAX_FILE_GROUP_SIZE_BYTES, Integer.toString(fileSize * 2 + 100))\n                .option(RewriteDataFiles.MAX_CONCURRENT_FILE_GROUP_REWRITES, \"3\");\n\n    BaseRewriteDataFilesSparkAction spyRewrite = Mockito.spy(realRewrite);\n\n    \r\n    GroupInfoMatcher failGroup = new GroupInfoMatcher(1, 3, 7);\n    doThrow(new RuntimeException(\"Rewrite Failed\"))\n        .when(spyRewrite)\n        .rewriteFiles(any(), argThat(failGroup));\n\n    AssertHelpers.assertThrows(\"Should fail entire rewrite if part fails\", RuntimeException.class,\n        () -> spyRewrite.execute());\n\n    table.refresh();\n\n    List<Object[]> postRewriteData = currentData();\n    assertEquals(\"We shouldn't have changed the data\", originalData, postRewriteData);\n\n    shouldHaveSnapshots(table, 1);\n    shouldHaveNoOrphans(table);\n    shouldHaveACleanCache(table);\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/actions/TestNewRewriteDataFilesAction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":414,"status":"N"}],"commitId":"a1bd63d56751999ecee89b871992d7bac395fd52","commitMessage":"@@@Core: Add validation for row-level deletes with rewrites (#2865)\n\n","date":"2021-07-27 23:59:53","modifiedFileCount":"10","status":"M","submitter":"Ryan Blue"}]
