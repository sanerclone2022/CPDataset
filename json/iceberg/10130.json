[{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      this.columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      this.setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        this.columns[i] = reader.column();\n        this.setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      if (children.size() > 0) {\n        this.column = children.get(0);\n      } else {\n        this.column = NullReader.NULL_COLUMN;\n      }\n    }\n","date":"2019-03-21 07:25:05","endLine":612,"groupId":"5014","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"StructReader","params":"(List<Type>types@List<ParquetValueReader<?>>readers)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/ac/61983b2c29e804e58a4a96b95a969554cdbe9a.src","preCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      this.columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      this.setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        this.columns[i] = reader.column();\n        this.setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      if (children.size() > 0) {\n        this.column = children.get(0);\n      } else {\n        this.column = NullReader.NULL_COLUMN;\n      }\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":591,"status":"B"},{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","date":"2019-03-21 07:25:05","endLine":247,"groupId":"2994","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"StructWriter","params":"(List<ValueWriter<?>>writers@List<DataType>types)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/41/dd26be66c7e94bc93bd4b389d0396988dec215.src","preCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkValueWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"B"}],"commitId":"c20927801a369104e5ea510470e1cf7c8e28b808","commitMessage":"@@@Rename packages to org.apache.iceberg (#138)\n\n* Move all packages by directory (but don't change references)\n* Rename all references from com.netflix.iceberg to org.apache.iceberg\n* Reorganize all imports due to new package name.\n  Previous commit only did a string find-replace.  which made all the imports out of order. Use an IDE to auto-sort all imports.\n\n","date":"2019-03-21 07:25:05","modifiedFileCount":"0","status":"B","submitter":"mccheah"},{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-09-05 01:51:12","commitOrder":2,"curCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      this.columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      this.setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        this.columns[i] = reader.column();\n        this.setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      this.column = firstNonNullColumn(children);\n    }\n","date":"2019-09-05 01:51:12","endLine":639,"groupId":"5014","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"StructReader","params":"(List<Type>types@List<ParquetValueReader<?>>readers)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/da/f219ce3766bc312c9945a286998a25e377b9f7.src","preCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      this.columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      this.setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        this.columns[i] = reader.column();\n        this.setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      if (children.size() > 0) {\n        this.column = children.get(0);\n      } else {\n        this.column = NullReader.NULL_COLUMN;\n      }\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":622,"status":"M"},{"authorDate":"2019-03-21 07:25:05","commitOrder":2,"curCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","date":"2019-03-21 07:25:05","endLine":247,"groupId":"2994","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"StructWriter","params":"(List<ValueWriter<?>>writers@List<DataType>types)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/41/dd26be66c7e94bc93bd4b389d0396988dec215.src","preCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkValueWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"N"}],"commitId":"d158818cb90beed3298be48a0a9de2366ba3cdb5","commitMessage":"@@@Use constant readers for Pig partition values. (#444)\n\n","date":"2019-09-05 01:51:12","modifiedFileCount":"3","status":"M","submitter":"Ryan Blue"},{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-10-23 02:17:28","commitOrder":3,"curCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      TripleIterator<?>[] columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      Setter<I>[] setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        columns[i] = reader.column();\n        setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      this.column = firstNonNullColumn(children);\n    }\n","date":"2019-10-23 02:17:28","endLine":638,"groupId":"10130","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"StructReader","params":"(List<Type>types@List<ParquetValueReader<?>>readers)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/18/f1cd666293f7f430e1b90ae926765d30804cde.src","preCode":"    protected StructReader(List<Type> types, List<ParquetValueReader<?>> readers) {\n      this.readers = (ParquetValueReader<?>[]) Array.newInstance(\n          ParquetValueReader.class, readers.size());\n      this.columns = (TripleIterator<?>[]) Array.newInstance(TripleIterator.class, readers.size());\n      this.setters = (Setter<I>[]) Array.newInstance(Setter.class, readers.size());\n\n      ImmutableList.Builder<TripleIterator<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < readers.size(); i += 1) {\n        ParquetValueReader<?> reader = readers.get(i);\n        this.readers[i] = readers.get(i);\n        this.columns[i] = reader.column();\n        this.setters[i] = newSetter(reader, types.get(i));\n        columnsBuilder.addAll(reader.columns());\n      }\n\n      this.children = columnsBuilder.build();\n      this.column = firstNonNullColumn(children);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":621,"status":"M"},{"authorDate":"2019-03-21 07:25:05","commitOrder":3,"curCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","date":"2019-03-21 07:25:05","endLine":247,"groupId":"10130","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"StructWriter","params":"(List<ValueWriter<?>>writers@List<DataType>types)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/41/dd26be66c7e94bc93bd4b389d0396988dec215.src","preCode":"    private StructWriter(List<ValueWriter<?>> writers, List<DataType> types) {\n      this.writers = (ValueWriter<?>[]) Array.newInstance(ValueWriter.class, writers.size());\n      this.types = new DataType[writers.size()];\n      for (int i = 0; i < writers.size(); i += 1) {\n        this.writers[i] = writers.get(i);\n        this.types[i] = types.get(i);\n      }\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkValueWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"N"}],"commitId":"336174b0a4438ed68cdb8e208833e380adaa15fc","commitMessage":"@@@Baseline: Add Baseline to iceberg-parquet (#526)\n\n","date":"2019-10-23 02:17:28","modifiedFileCount":"29","status":"M","submitter":"Fokko Driesprong"}]
