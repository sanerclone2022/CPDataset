[{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    public ParquetValueWriter<?> list(GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type elementType = repeated.getType(0);\n      int elementD = type.getMaxDefinitionLevel(path(elementType.getName()));\n\n      DataType elementSparkType = convert(schema.findType(elementType.getId().intValue()));\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          option(elementType, elementD, elementWriter),\n          elementSparkType);\n    }\n","date":"2019-03-21 07:25:05","endLine":111,"groupId":"2696","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"list","params":"(GroupTypearray@ParquetValueWriter<?>elementWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/57/4b014bf7ebadaec8235422b5be16d51adf0828.src","preCode":"    public ParquetValueWriter<?> list(GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type elementType = repeated.getType(0);\n      int elementD = type.getMaxDefinitionLevel(path(elementType.getName()));\n\n      DataType elementSparkType = convert(schema.findType(elementType.getId().intValue()));\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          option(elementType, elementD, elementWriter),\n          elementSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"B"},{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    public ParquetValueWriter<?> map(GroupType map,\n                                     ParquetValueWriter<?> keyWriter,\n                                     ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type keyType = repeatedKeyValue.getType(0);\n      int keyD = type.getMaxDefinitionLevel(path(keyType.getName()));\n      DataType keySparkType = convert(schema.findType(keyType.getId().intValue()));\n      org.apache.parquet.schema.Type valueType = repeatedKeyValue.getType(1);\n      int valueD = type.getMaxDefinitionLevel(path(valueType.getName()));\n      DataType valueSparkType = convert(schema.findType(valueType.getId().intValue()));\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          option(keyType, keyD, keyWriter), option(valueType, valueD, valueWriter),\n          keySparkType, valueSparkType);\n    }\n","date":"2019-03-21 07:25:05","endLine":133,"groupId":"3601","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"map","params":"(GroupTypemap@ParquetValueWriter<?>keyWriter@ParquetValueWriter<?>valueWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/57/4b014bf7ebadaec8235422b5be16d51adf0828.src","preCode":"    public ParquetValueWriter<?> map(GroupType map,\n                                     ParquetValueWriter<?> keyWriter,\n                                     ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type keyType = repeatedKeyValue.getType(0);\n      int keyD = type.getMaxDefinitionLevel(path(keyType.getName()));\n      DataType keySparkType = convert(schema.findType(keyType.getId().intValue()));\n      org.apache.parquet.schema.Type valueType = repeatedKeyValue.getType(1);\n      int valueD = type.getMaxDefinitionLevel(path(valueType.getName()));\n      DataType valueSparkType = convert(schema.findType(valueType.getId().intValue()));\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          option(keyType, keyD, keyWriter), option(valueType, valueD, valueWriter),\n          keySparkType, valueSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"B"}],"commitId":"c20927801a369104e5ea510470e1cf7c8e28b808","commitMessage":"@@@Rename packages to org.apache.iceberg (#138)\n\n* Move all packages by directory (but don't change references)\n* Rename all references from com.netflix.iceberg to org.apache.iceberg\n* Reorganize all imports due to new package name.\n  Previous commit only did a string find-replace.  which made all the imports out of order. Use an IDE to auto-sort all imports.\n\n","date":"2019-03-21 07:25:05","modifiedFileCount":"0","status":"B","submitter":"mccheah"},{"authorTime":"2019-06-24 23:57:49","codes":[{"authorDate":"2019-06-24 23:57:49","commitOrder":2,"curCode":"    public ParquetValueWriter<?> list(GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type elementType = repeated.getType(0);\n      int elementD = type.getMaxDefinitionLevel(path(elementType.getName()));\n\n      DataType elementSparkType = SparkSchemaUtil.convert(schema.findType(elementType.getId().intValue()));\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          ParquetValueWriters.option(elementType, elementD, elementWriter),\n          elementSparkType);\n    }\n","date":"2019-06-24 23:57:49","endLine":109,"groupId":"2696","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"list","params":"(GroupTypearray@ParquetValueWriter<?>elementWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d4/068c3832b1a639a924b96ae9d35f30ff1b078e.src","preCode":"    public ParquetValueWriter<?> list(GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type elementType = repeated.getType(0);\n      int elementD = type.getMaxDefinitionLevel(path(elementType.getName()));\n\n      DataType elementSparkType = convert(schema.findType(elementType.getId().intValue()));\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          option(elementType, elementD, elementWriter),\n          elementSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":94,"status":"M"},{"authorDate":"2019-06-24 23:57:49","commitOrder":2,"curCode":"    public ParquetValueWriter<?> map(GroupType map,\n                                     ParquetValueWriter<?> keyWriter,\n                                     ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type keyType = repeatedKeyValue.getType(0);\n      int keyD = type.getMaxDefinitionLevel(path(keyType.getName()));\n      DataType keySparkType = SparkSchemaUtil.convert(schema.findType(keyType.getId().intValue()));\n      org.apache.parquet.schema.Type valueType = repeatedKeyValue.getType(1);\n      int valueD = type.getMaxDefinitionLevel(path(valueType.getName()));\n      DataType valueSparkType = SparkSchemaUtil.convert(schema.findType(valueType.getId().intValue()));\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          ParquetValueWriters.option(keyType, keyD, keyWriter),\n          ParquetValueWriters.option(valueType, valueD, valueWriter),\n          keySparkType, valueSparkType);\n    }\n","date":"2019-06-24 23:57:49","endLine":132,"groupId":"3601","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"map","params":"(GroupTypemap@ParquetValueWriter<?>keyWriter@ParquetValueWriter<?>valueWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d4/068c3832b1a639a924b96ae9d35f30ff1b078e.src","preCode":"    public ParquetValueWriter<?> map(GroupType map,\n                                     ParquetValueWriter<?> keyWriter,\n                                     ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type keyType = repeatedKeyValue.getType(0);\n      int keyD = type.getMaxDefinitionLevel(path(keyType.getName()));\n      DataType keySparkType = convert(schema.findType(keyType.getId().intValue()));\n      org.apache.parquet.schema.Type valueType = repeatedKeyValue.getType(1);\n      int valueD = type.getMaxDefinitionLevel(path(valueType.getName()));\n      DataType valueSparkType = convert(schema.findType(valueType.getId().intValue()));\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          option(keyType, keyD, keyWriter), option(valueType, valueD, valueWriter),\n          keySparkType, valueSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"}],"commitId":"5f6fc3be3400cfae858a938213ba8516acc983a5","commitMessage":"@@@[Baseline] Apply Baseline plugin to iceberg-spark (#226)\n\n","date":"2019-06-24 23:57:49","modifiedFileCount":"36","status":"M","submitter":"Anton Okolnychyi"},{"authorTime":"2020-05-07 23:55:01","codes":[{"authorDate":"2020-05-07 23:55:01","commitOrder":3,"curCode":"    public ParquetValueWriter<?> list(ArrayType sArray, GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          newOption(repeated.getType(0), elementWriter),\n          sArray.elementType());\n    }\n","date":"2020-05-07 23:55:01","endLine":104,"groupId":"10493","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"list","params":"(ArrayTypesArray@GroupTypearray@ParquetValueWriter<?>elementWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/99/c957c5277aa4912491ecd2bf881284edd7e0ae.src","preCode":"    public ParquetValueWriter<?> list(GroupType array, ParquetValueWriter<?> elementWriter) {\n      GroupType repeated = array.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type elementType = repeated.getType(0);\n      int elementD = type.getMaxDefinitionLevel(path(elementType.getName()));\n\n      DataType elementSparkType = SparkSchemaUtil.convert(schema.findType(elementType.getId().intValue()));\n\n      return new ArrayDataWriter<>(repeatedD, repeatedR,\n          ParquetValueWriters.option(elementType, elementD, elementWriter),\n          elementSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":94,"status":"M"},{"authorDate":"2020-05-07 23:55:01","commitOrder":3,"curCode":"    public ParquetValueWriter<?> map(MapType sMap, GroupType map,\n                                     ParquetValueWriter<?> keyWriter, ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          newOption(repeatedKeyValue.getType(0), keyWriter),\n          newOption(repeatedKeyValue.getType(1), valueWriter),\n          sMap.keyType(), sMap.valueType());\n    }\n","date":"2020-05-07 23:55:01","endLine":119,"groupId":"10493","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"map","params":"(MapTypesMap@GroupTypemap@ParquetValueWriter<?>keyWriter@ParquetValueWriter<?>valueWriter)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/99/c957c5277aa4912491ecd2bf881284edd7e0ae.src","preCode":"    public ParquetValueWriter<?> map(GroupType map,\n                                     ParquetValueWriter<?> keyWriter,\n                                     ParquetValueWriter<?> valueWriter) {\n      GroupType repeatedKeyValue = map.getFields().get(0).asGroupType();\n      String[] repeatedPath = currentPath();\n\n      int repeatedD = type.getMaxDefinitionLevel(repeatedPath);\n      int repeatedR = type.getMaxRepetitionLevel(repeatedPath);\n\n      org.apache.parquet.schema.Type keyType = repeatedKeyValue.getType(0);\n      int keyD = type.getMaxDefinitionLevel(path(keyType.getName()));\n      DataType keySparkType = SparkSchemaUtil.convert(schema.findType(keyType.getId().intValue()));\n      org.apache.parquet.schema.Type valueType = repeatedKeyValue.getType(1);\n      int valueD = type.getMaxDefinitionLevel(path(valueType.getName()));\n      DataType valueSparkType = SparkSchemaUtil.convert(schema.findType(valueType.getId().intValue()));\n\n      return new MapDataWriter<>(repeatedD, repeatedR,\n          ParquetValueWriters.option(keyType, keyD, keyWriter),\n          ParquetValueWriters.option(valueType, valueD, valueWriter),\n          keySparkType, valueSparkType);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"}],"commitId":"699e68a919c708ccbb43179928e3e7fb4fec58f6","commitMessage":"@@@Spark: Pass correct types to get data from InternalRow (#999)\n\n","date":"2020-05-07 23:55:01","modifiedFileCount":"14","status":"M","submitter":"Ryan Blue"}]
