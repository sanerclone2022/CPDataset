[{"authorTime":"2020-08-29 01:19:33","codes":[{"authorDate":"2020-08-29 01:19:33","commitOrder":2,"curCode":"  public void testPromotedFlinkDataType() throws Exception {\n    Schema iSchema = new Schema(\n        Types.NestedField.required(1, \"tinyint\", Types.IntegerType.get()),\n        Types.NestedField.required(2, \"smallint\", Types.IntegerType.get()),\n        Types.NestedField.optional(3, \"int\", Types.IntegerType.get())\n    );\n    TableSchema flinkSchema = TableSchema.builder()\n        .field(\"tinyint\", DataTypes.TINYINT().notNull())\n        .field(\"smallint\", DataTypes.SMALLINT().notNull())\n        .field(\"int\", DataTypes.INT().nullable())\n        .build();\n\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(iSchema).identity(\"smallint\").identity(\"tinyint\").identity(\"int\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n\n    String location = tempFolder.newFolder().getAbsolutePath();\n    Map<String, String> props = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format.name());\n    Table icebergTable = new HadoopTables().create(iSchema, spec, props, location);\n\n    List<RowData> rows = Lists.newArrayList(\n        GenericRowData.of((byte) 0x01, (short) -32768, 101),\n        GenericRowData.of((byte) 0x02, (short) 0, 102),\n        GenericRowData.of((byte) 0x03, (short) 32767, 103)\n    );\n\n    Record record = GenericRecord.create(iSchema);\n    List<Record> expected = Lists.newArrayList(\n        record.copy(ImmutableMap.of(\"tinyint\", 1, \"smallint\", -32768, \"int\", 101)),\n        record.copy(ImmutableMap.of(\"tinyint\", 2, \"smallint\", 0, \"int\", 102)),\n        record.copy(ImmutableMap.of(\"tinyint\", 3, \"smallint\", 32767, \"int\", 103))\n    );\n\n    try (OneInputStreamOperatorTestHarness<RowData, DataFile> testHarness = createIcebergStreamWriter(icebergTable,\n        flinkSchema)) {\n      for (RowData row : rows) {\n        testHarness.processElement(row, 1);\n      }\n      testHarness.prepareSnapshotPreBarrier(1);\n      Assert.assertEquals(partitioned ? 3 : 1, testHarness.extractOutputValues().size());\n\n      \r\n      AppendFiles appendFiles = icebergTable.newAppend();\n      testHarness.extractOutputValues().forEach(appendFiles::appendFile);\n      appendFiles.commit();\n    }\n\n    SimpleDataUtil.assertTableRecords(location, expected);\n  }\n","date":"2020-08-29 01:19:33","endLine":312,"groupId":"1539","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPromotedFlinkDataType","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/f4/e10d56c330b5500071e1523280ed9c3fe81931.src","preCode":"  public void testPromotedFlinkDataType() throws Exception {\n    Schema iSchema = new Schema(\n        Types.NestedField.required(1, \"tinyint\", Types.IntegerType.get()),\n        Types.NestedField.required(2, \"smallint\", Types.IntegerType.get()),\n        Types.NestedField.optional(3, \"int\", Types.IntegerType.get())\n    );\n    TableSchema flinkSchema = TableSchema.builder()\n        .field(\"tinyint\", DataTypes.TINYINT().notNull())\n        .field(\"smallint\", DataTypes.SMALLINT().notNull())\n        .field(\"int\", DataTypes.INT().nullable())\n        .build();\n\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(iSchema).identity(\"smallint\").identity(\"tinyint\").identity(\"int\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n\n    String location = tempFolder.newFolder().getAbsolutePath();\n    Map<String, String> props = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format.name());\n    Table icebergTable = new HadoopTables().create(iSchema, spec, props, location);\n\n    List<RowData> rows = Lists.newArrayList(\n        GenericRowData.of((byte) 0x01, (short) -32768, 101),\n        GenericRowData.of((byte) 0x02, (short) 0, 102),\n        GenericRowData.of((byte) 0x03, (short) 32767, 103)\n    );\n\n    Record record = GenericRecord.create(iSchema);\n    List<Record> expected = Lists.newArrayList(\n        record.copy(ImmutableMap.of(\"tinyint\", 1, \"smallint\", -32768, \"int\", 101)),\n        record.copy(ImmutableMap.of(\"tinyint\", 2, \"smallint\", 0, \"int\", 102)),\n        record.copy(ImmutableMap.of(\"tinyint\", 3, \"smallint\", 32767, \"int\", 103))\n    );\n\n    try (OneInputStreamOperatorTestHarness<RowData, DataFile> testHarness = createIcebergStreamWriter(icebergTable,\n        flinkSchema)) {\n      for (RowData row : rows) {\n        testHarness.processElement(row, 1);\n      }\n      testHarness.prepareSnapshotPreBarrier(1);\n      Assert.assertEquals(partitioned ? 3 : 1, testHarness.extractOutputValues().size());\n\n      \r\n      AppendFiles appendFiles = icebergTable.newAppend();\n      testHarness.extractOutputValues().forEach(appendFiles::appendFile);\n      appendFiles.commit();\n    }\n\n    SimpleDataUtil.assertTableRecords(location, expected);\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergStreamWriter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"B"},{"authorDate":"2020-08-29 01:19:33","commitOrder":2,"curCode":"  public static Table createTable(String path, Map<String, String> properties, boolean partitioned) {\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n    return new HadoopTables().create(SCHEMA, spec, properties, path);\n  }\n","date":"2020-08-29 01:19:33","endLine":84,"groupId":"1539","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createTable","params":"(Stringpath@Map<String@String>properties@booleanpartitioned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/b3/77e54cde078bbe57dfe44d6640a0220f76b636.src","preCode":"  public static Table createTable(String path, Map<String, String> properties, boolean partitioned) {\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n    return new HadoopTables().create(SCHEMA, spec, properties, path);\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/SimpleDataUtil.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"MB"}],"commitId":"f950a3e63c98e88b1f8905faacf33a1d5d31e4c0","commitMessage":"@@@Flink: Add operator to collect data files and append to a table (#1185)\n\n","date":"2020-08-29 01:19:33","modifiedFileCount":"2","status":"M","submitter":"openinx"},{"authorTime":"2020-08-29 01:19:33","codes":[{"authorDate":"2020-12-19 01:57:04","commitOrder":3,"curCode":"  public void testPromotedFlinkDataType() throws Exception {\n    Schema iSchema = new Schema(\n        Types.NestedField.required(1, \"tinyint\", Types.IntegerType.get()),\n        Types.NestedField.required(2, \"smallint\", Types.IntegerType.get()),\n        Types.NestedField.optional(3, \"int\", Types.IntegerType.get())\n    );\n    TableSchema flinkSchema = TableSchema.builder()\n        .field(\"tinyint\", DataTypes.TINYINT().notNull())\n        .field(\"smallint\", DataTypes.SMALLINT().notNull())\n        .field(\"int\", DataTypes.INT().nullable())\n        .build();\n\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(iSchema).identity(\"smallint\").identity(\"tinyint\").identity(\"int\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n\n    String location = tempFolder.newFolder().getAbsolutePath();\n    Map<String, String> props = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format.name());\n    Table icebergTable = new HadoopTables().create(iSchema, spec, props, location);\n\n    List<RowData> rows = Lists.newArrayList(\n        GenericRowData.of((byte) 0x01, (short) -32768, 101),\n        GenericRowData.of((byte) 0x02, (short) 0, 102),\n        GenericRowData.of((byte) 0x03, (short) 32767, 103)\n    );\n\n    Record record = GenericRecord.create(iSchema);\n    List<Record> expected = Lists.newArrayList(\n        record.copy(ImmutableMap.of(\"tinyint\", 1, \"smallint\", -32768, \"int\", 101)),\n        record.copy(ImmutableMap.of(\"tinyint\", 2, \"smallint\", 0, \"int\", 102)),\n        record.copy(ImmutableMap.of(\"tinyint\", 3, \"smallint\", 32767, \"int\", 103))\n    );\n\n    try (OneInputStreamOperatorTestHarness<RowData, WriteResult> testHarness = createIcebergStreamWriter(icebergTable,\n        flinkSchema)) {\n      for (RowData row : rows) {\n        testHarness.processElement(row, 1);\n      }\n      testHarness.prepareSnapshotPreBarrier(1);\n      WriteResult result = WriteResult.builder().addAll(testHarness.extractOutputValues()).build();\n      Assert.assertEquals(0, result.deleteFiles().length);\n      Assert.assertEquals(partitioned ? 3 : 1, result.dataFiles().length);\n\n      \r\n      AppendFiles appendFiles = icebergTable.newAppend();\n      Arrays.stream(result.dataFiles()).forEach(appendFiles::appendFile);\n      appendFiles.commit();\n    }\n\n    SimpleDataUtil.assertTableRecords(location, expected);\n  }\n","date":"2020-12-19 01:57:04","endLine":332,"groupId":"102222","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPromotedFlinkDataType","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/28/db89456f7e510f35030829765640f84f560de1.src","preCode":"  public void testPromotedFlinkDataType() throws Exception {\n    Schema iSchema = new Schema(\n        Types.NestedField.required(1, \"tinyint\", Types.IntegerType.get()),\n        Types.NestedField.required(2, \"smallint\", Types.IntegerType.get()),\n        Types.NestedField.optional(3, \"int\", Types.IntegerType.get())\n    );\n    TableSchema flinkSchema = TableSchema.builder()\n        .field(\"tinyint\", DataTypes.TINYINT().notNull())\n        .field(\"smallint\", DataTypes.SMALLINT().notNull())\n        .field(\"int\", DataTypes.INT().nullable())\n        .build();\n\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(iSchema).identity(\"smallint\").identity(\"tinyint\").identity(\"int\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n\n    String location = tempFolder.newFolder().getAbsolutePath();\n    Map<String, String> props = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format.name());\n    Table icebergTable = new HadoopTables().create(iSchema, spec, props, location);\n\n    List<RowData> rows = Lists.newArrayList(\n        GenericRowData.of((byte) 0x01, (short) -32768, 101),\n        GenericRowData.of((byte) 0x02, (short) 0, 102),\n        GenericRowData.of((byte) 0x03, (short) 32767, 103)\n    );\n\n    Record record = GenericRecord.create(iSchema);\n    List<Record> expected = Lists.newArrayList(\n        record.copy(ImmutableMap.of(\"tinyint\", 1, \"smallint\", -32768, \"int\", 101)),\n        record.copy(ImmutableMap.of(\"tinyint\", 2, \"smallint\", 0, \"int\", 102)),\n        record.copy(ImmutableMap.of(\"tinyint\", 3, \"smallint\", 32767, \"int\", 103))\n    );\n\n    try (OneInputStreamOperatorTestHarness<RowData, DataFile> testHarness = createIcebergStreamWriter(icebergTable,\n        flinkSchema)) {\n      for (RowData row : rows) {\n        testHarness.processElement(row, 1);\n      }\n      testHarness.prepareSnapshotPreBarrier(1);\n      Assert.assertEquals(partitioned ? 3 : 1, testHarness.extractOutputValues().size());\n\n      \r\n      AppendFiles appendFiles = icebergTable.newAppend();\n      testHarness.extractOutputValues().forEach(appendFiles::appendFile);\n      appendFiles.commit();\n    }\n\n    SimpleDataUtil.assertTableRecords(location, expected);\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergStreamWriter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2020-08-29 01:19:33","commitOrder":3,"curCode":"  public static Table createTable(String path, Map<String, String> properties, boolean partitioned) {\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n    return new HadoopTables().create(SCHEMA, spec, properties, path);\n  }\n","date":"2020-08-29 01:19:33","endLine":84,"groupId":"102222","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createTable","params":"(Stringpath@Map<String@String>properties@booleanpartitioned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/b3/77e54cde078bbe57dfe44d6640a0220f76b636.src","preCode":"  public static Table createTable(String path, Map<String, String> properties, boolean partitioned) {\n    PartitionSpec spec;\n    if (partitioned) {\n      spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n    } else {\n      spec = PartitionSpec.unpartitioned();\n    }\n    return new HadoopTables().create(SCHEMA, spec, properties, path);\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/SimpleDataUtil.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"}],"commitId":"77c5617c102c2ab27fbf35cac3fd75380a887d5d","commitMessage":"@@@Flink: Commit both data files and delete files (#1939)\n\n","date":"2020-12-19 01:57:04","modifiedFileCount":"9","status":"M","submitter":"openinx"}]
