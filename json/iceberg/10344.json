[{"authorTime":"2021-09-21 06:13:46","codes":[{"authorDate":"2021-09-20 13:08:11","commitOrder":2,"curCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema,\n                                                            Schema positionDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .positionDeleteRowSchema(positionDeleteRowSchema)\n        .build();\n  }\n","date":"2021-09-20 13:08:11","endLine":53,"groupId":"4283","id":1,"instanceNumber":1,"isCurCommit":1,"methodName":"newWriterFactory","params":"(SchemadataSchema@List<Integer>equalityFieldIds@SchemaequalityDeleteRowSchema@SchemapositionDeleteRowSchema)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/70/2e8ab98990a0f237c5255e863f736782666649.src","preCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema,\n                                                            Schema positionDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .positionDeleteRowSchema(positionDeleteRowSchema)\n        .build();\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/source/TestSparkFileWriterFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"NB"},{"authorDate":"2021-09-21 06:13:46","commitOrder":2,"curCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .build();\n  }\n","date":"2021-09-21 06:13:46","endLine":48,"groupId":"4283","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"newWriterFactory","params":"(SchemadataSchema@List<Integer>equalityFieldIds@SchemaequalityDeleteRowSchema)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/3e/a2353f2cdf903ab96122dc96e309f542a16d77.src","preCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .build();\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/source/TestSparkRollingFileWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"B"}],"commitId":"7eeeada0dc027025664310c1ca619e9b44fec764","commitMessage":"@@@Core: Add new rolling file writers (#3158)\n\n","date":"2021-09-21 06:13:46","modifiedFileCount":"1","status":"M","submitter":"Anton Okolnychyi"},{"authorTime":"2021-09-24 07:25:33","codes":[{"authorDate":"2021-09-20 13:08:11","commitOrder":3,"curCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema,\n                                                            Schema positionDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .positionDeleteRowSchema(positionDeleteRowSchema)\n        .build();\n  }\n","date":"2021-09-20 13:08:11","endLine":53,"groupId":"10344","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"newWriterFactory","params":"(SchemadataSchema@List<Integer>equalityFieldIds@SchemaequalityDeleteRowSchema@SchemapositionDeleteRowSchema)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/70/2e8ab98990a0f237c5255e863f736782666649.src","preCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema,\n                                                            Schema positionDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .positionDeleteRowSchema(positionDeleteRowSchema)\n        .build();\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/source/TestSparkFileWriterFactory.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"},{"authorDate":"2021-09-24 07:25:33","commitOrder":3,"curCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema,\n                                                            Schema positionDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .positionDeleteRowSchema(positionDeleteRowSchema)\n        .build();\n  }\n","date":"2021-09-24 07:25:33","endLine":50,"groupId":"10344","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"newWriterFactory","params":"(SchemadataSchema@List<Integer>equalityFieldIds@SchemaequalityDeleteRowSchema@SchemapositionDeleteRowSchema)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/90/23195dcc6adb02748919780287afa7ab94ce28.src","preCode":"  protected FileWriterFactory<InternalRow> newWriterFactory(Schema dataSchema, List<Integer> equalityFieldIds,\n                                                            Schema equalityDeleteRowSchema) {\n    return SparkFileWriterFactory.builderFor(table)\n        .dataSchema(table.schema())\n        .dataFileFormat(format())\n        .deleteFileFormat(format())\n        .equalityFieldIds(ArrayUtil.toIntArray(equalityFieldIds))\n        .equalityDeleteRowSchema(equalityDeleteRowSchema)\n        .build();\n  }\n","realPath":"spark/src/test/java/org/apache/iceberg/spark/source/TestSparkRollingFileWriters.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"}],"commitId":"11f327a2f08d95fdf8fea68412f0ae1687a3b63f","commitMessage":"@@@Core: Add PartitioningWriter (#3164)\n\n","date":"2021-09-24 07:25:33","modifiedFileCount":"8","status":"M","submitter":"Anton Okolnychyi"}]
