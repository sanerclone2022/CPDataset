[{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","date":"2019-03-21 07:25:05","endLine":122,"groupId":"4974","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaries)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d3/c009eaf5527b086825bdea6dbe71e30557d4d3.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"B"},{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","date":"2019-03-21 07:25:05","endLine":102,"groupId":"1312","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/9b/66ed812835c91fde9cfc6449838ddf9e306be4.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"B"}],"commitId":"c20927801a369104e5ea510470e1cf7c8e28b808","commitMessage":"@@@Rename packages to org.apache.iceberg (#138)\n\n* Move all packages by directory (but don't change references)\n* Rename all references from com.netflix.iceberg to org.apache.iceberg\n* Reorganize all imports due to new package name.\n  Previous commit only did a string find-replace.  which made all the imports out of order. Use an IDE to auto-sort all imports.\n\n","date":"2019-03-21 07:25:05","modifiedFileCount":"0","status":"B","submitter":"mccheah"},{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-03-25 06:44:37","commitOrder":2,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","date":"2019-03-25 06:44:37","endLine":125,"groupId":"4974","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaries)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/57/f728ce39ff67834bc487f2b58c4e108205dc19.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2019-03-21 07:25:05","commitOrder":2,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","date":"2019-03-21 07:25:05","endLine":102,"groupId":"1312","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/9b/66ed812835c91fde9cfc6449838ddf9e306be4.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"N"}],"commitId":"783fa7af5d68ca6ed32d00b464b9049d9d42c6da","commitMessage":"@@@Fix row group dictionary filter handling of null values. (#86)\n\n","date":"2019-03-25 06:44:37","modifiedFileCount":"2","status":"M","submitter":"Ryan Blue"},{"authorTime":"2019-09-07 04:02:29","codes":[{"authorDate":"2019-09-07 04:02:29","commitOrder":3,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-09-07 04:02:29","endLine":129,"groupId":"4974","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaries)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d3/c1c6e6cd4ac8e0d078614937dd9035f6f1cfa0.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"M"},{"authorDate":"2019-09-07 04:02:29","commitOrder":3,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-09-07 04:02:29","endLine":106,"groupId":"1312","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/e8/f4eef6657b765187482b3c3b79160f79e26789.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visit(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"M"}],"commitId":"1c77e99c00a4d54e993beeef0d1e16316f69c37f","commitMessage":"@@@Add short-circuit logic to evaluators (#442)\n\n","date":"2019-09-07 04:02:29","modifiedFileCount":"7","status":"M","submitter":"Volodymyr Vysotskyi"},{"authorTime":"2019-10-23 02:17:28","codes":[{"authorDate":"2019-10-23 02:17:28","commitOrder":4,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-10-23 02:17:28","endLine":123,"groupId":"4139","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaryReadStore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/a7/d341e1a0dfe7c975cf952a5eb302b3910433af.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaries) {\n      this.dictionaries = dictionaries;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":95,"status":"M"},{"authorDate":"2019-10-23 02:17:28","commitOrder":4,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-10-23 02:17:28","endLine":106,"groupId":"1312","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/6c/b3f99dbbc1c2b3bb93d4cc82aaaa95663c04b8.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"M"}],"commitId":"336174b0a4438ed68cdb8e208833e380adaa15fc","commitMessage":"@@@Baseline: Add Baseline to iceberg-parquet (#526)\n\n","date":"2019-10-23 02:17:28","modifiedFileCount":"29","status":"M","submitter":"Fokko Driesprong"},{"authorTime":"2019-10-23 02:17:28","codes":[{"authorDate":"2019-12-31 01:50:00","commitOrder":5,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-12-31 01:50:00","endLine":120,"groupId":"4139","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaryReadStore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/6d/c1f6de47a3de7608e8773ec09ff8122031f99e.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":92,"status":"M"},{"authorDate":"2019-10-23 02:17:28","commitOrder":5,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-10-23 02:17:28","endLine":106,"groupId":"1312","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/6c/b3f99dbbc1c2b3bb93d4cc82aaaa95663c04b8.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"N"}],"commitId":"3c88ef1d89800dde9edb61e59b851e64ffef0f33","commitMessage":"@@@Vectorization: Parquet additions to support batch reads (#710)\n\nCo-authored-by: gautamkowshik@gmail.com\nCo-authored-by: anjalinorwood@gmail.com","date":"2019-12-31 01:50:00","modifiedFileCount":"4","status":"M","submitter":"Samarth Jain"},{"authorTime":"2019-10-23 02:17:28","codes":[{"authorDate":"2020-06-30 02:06:41","commitOrder":6,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      try {\n        return ExpressionVisitors.visitEvaluator(expr, this);\n\n      } finally {\n        \r\n        this.dictionaries = null;\n        this.dictCache = null;\n        this.isFallback = null;\n        this.mayContainNulls = null;\n        this.cols = null;\n        this.conversions = null;\n      }\n    }\n","date":"2020-06-30 02:06:41","endLine":131,"groupId":"4139","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaryReadStore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/0a/3ade8fe1a037b2261b97ab605368c102491d3c.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":92,"status":"M"},{"authorDate":"2019-10-23 02:17:28","commitOrder":6,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-10-23 02:17:28","endLine":106,"groupId":"1312","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/6c/b3f99dbbc1c2b3bb93d4cc82aaaa95663c04b8.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"N"}],"commitId":"e168f59d91469e4f6aae32dbb78f8fc504a64eb2","commitMessage":"@@@Parquet: Fix executor memory leak in row group filter (#1139)\n\n","date":"2020-06-30 02:06:41","modifiedFileCount":"1","status":"M","submitter":"Ryan Blue"},{"authorTime":"2019-10-23 02:17:28","codes":[{"authorDate":"2020-07-07 01:49:24","commitOrder":7,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2020-07-07 01:49:24","endLine":112,"groupId":"4139","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaryReadStore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/c1/395211e42a0a1f3534b4583bc4d9fd568c5ce2.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      try {\n        return ExpressionVisitors.visitEvaluator(expr, this);\n\n      } finally {\n        \r\n        this.dictionaries = null;\n        this.dictCache = null;\n        this.isFallback = null;\n        this.mayContainNulls = null;\n        this.cols = null;\n        this.conversions = null;\n      }\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2019-10-23 02:17:28","commitOrder":7,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2019-10-23 02:17:28","endLine":106,"groupId":"1312","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/6c/b3f99dbbc1c2b3bb93d4cc82aaaa95663c04b8.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"N"}],"commitId":"4d1fc91d6528db88548c506a0b110b50121d67ff","commitMessage":"@@@Remove thread local objects and use new visitors to fix executor memory leaks (#1169)\n\n","date":"2020-07-07 01:49:24","modifiedFileCount":"7","status":"M","submitter":"jun-he"},{"authorTime":"2021-02-13 12:38:57","codes":[{"authorDate":"2021-02-13 12:38:57","commitOrder":8,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          Type icebergType = schema.findType(id);\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType, icebergType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2021-02-13 12:38:57","endLine":118,"groupId":"1081","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup@DictionaryPageReadStoredictionaryReadStore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/37/c7d6e513f5d56c7cf613df44c5788c42ac9238.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup,\n                         DictionaryPageReadStore dictionaryReadStore) {\n      this.dictionaries = dictionaryReadStore;\n      this.dictCache = Maps.newHashMap();\n      this.isFallback = Maps.newHashMap();\n      this.mayContainNulls = Maps.newHashMap();\n      this.cols = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n\n      for (ColumnDescriptor desc : fileSchema.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(desc.getPath()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          cols.put(id, desc);\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      for (ColumnChunkMetaData meta : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(meta.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          isFallback.put(id, ParquetUtil.hasNonDictionaryPages(meta));\n          mayContainNulls.put(id, mayContainNull(meta));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetDictionaryRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":89,"status":"M"},{"authorDate":"2021-02-13 12:38:57","commitOrder":8,"curCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          Type icebergType = schema.findType(id);\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType, icebergType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","date":"2021-02-13 12:38:57","endLine":104,"groupId":"1081","id":16,"instanceNumber":2,"isCurCommit":1,"methodName":"eval","params":"(MessageTypefileSchema@BlockMetaDatarowGroup)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/f8/3d70100443e514c0d9a005c5487711b29d5865.src","preCode":"    private boolean eval(MessageType fileSchema, BlockMetaData rowGroup) {\n      if (rowGroup.getRowCount() <= 0) {\n        return ROWS_CANNOT_MATCH;\n      }\n\n      this.stats = Maps.newHashMap();\n      this.valueCounts = Maps.newHashMap();\n      this.conversions = Maps.newHashMap();\n      for (ColumnChunkMetaData col : rowGroup.getColumns()) {\n        PrimitiveType colType = fileSchema.getType(col.getPath().toArray()).asPrimitiveType();\n        if (colType.getId() != null) {\n          int id = colType.getId().intValue();\n          stats.put(id, col.getStatistics());\n          valueCounts.put(id, col.getValueCount());\n          conversions.put(id, ParquetConversions.converterFromParquet(colType));\n        }\n      }\n\n      return ExpressionVisitors.visitEvaluator(expr, this);\n    }\n","realPath":"parquet/src/main/java/org/apache/iceberg/parquet/ParquetMetricsRowGroupFilter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"}],"commitId":"5218f43c245323e6fb4a5c48cb71848b178b4478","commitMessage":"@@@Parquet: Fix row group filters with promoted types (#2232)\n\nThis fixes Parquet row group filters when types have been promoted from int to long or from float to double.\n\nThe filters are passed the file schema after ids are added.  which is used to convert dictionary values or lower/upper bounds. That conversion currently uses the file's types to deserialize.  but the filter expression is bound to the table types. If the types differ.  then comparison in the evaluator fails.\n\nThis updates the conversion to first deserialize the Parquet value and then promote it if the table's type has changed. Only int to long and float to double are needed because those are the only type promotions that use a different representation.","date":"2021-02-13 12:38:57","modifiedFileCount":"5","status":"M","submitter":"Ryan Blue"}]
