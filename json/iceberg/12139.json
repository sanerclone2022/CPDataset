[{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName()))-1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","date":"2019-03-21 07:25:05","endLine":111,"groupId":"3247","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/29/4a849fd8e8678106a13921aa4c7396ab7d17d7.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName()))-1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"B"},{"authorDate":"2019-03-21 07:25:05","commitOrder":1,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields, partitionValues);\n    }\n","date":"2019-03-21 07:25:05","endLine":116,"groupId":"3247","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/fe/2e438f6adcf5ba153502dcf79411b5c1ffb1ca.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields, partitionValues);\n    }\n","realPath":"pig/src/main/java/org/apache/iceberg/pig/PigParquetReader.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"B"}],"commitId":"c20927801a369104e5ea510470e1cf7c8e28b808","commitMessage":"@@@Rename packages to org.apache.iceberg (#138)\n\n* Move all packages by directory (but don't change references)\n* Rename all references from com.netflix.iceberg to org.apache.iceberg\n* Reorganize all imports due to new package name.\n  Previous commit only did a string find-replace.  which made all the imports out of order. Use an IDE to auto-sort all imports.\n\n","date":"2019-03-21 07:25:05","modifiedFileCount":"0","status":"B","submitter":"mccheah"},{"authorTime":"2019-03-21 07:25:05","codes":[{"authorDate":"2019-06-24 23:57:49","commitOrder":2,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct,\n                                        List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","date":"2019-06-24 23:57:49","endLine":111,"groupId":"2225","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/9a/36266ffdf222c4dac237d44b43c458ba5bfe9b.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName()))-1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"M"},{"authorDate":"2019-03-21 07:25:05","commitOrder":2,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields, partitionValues);\n    }\n","date":"2019-03-21 07:25:05","endLine":116,"groupId":"3247","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/fe/2e438f6adcf5ba153502dcf79411b5c1ffb1ca.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields, partitionValues);\n    }\n","realPath":"pig/src/main/java/org/apache/iceberg/pig/PigParquetReader.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"N"}],"commitId":"5f6fc3be3400cfae858a938213ba8516acc983a5","commitMessage":"@@@[Baseline] Apply Baseline plugin to iceberg-spark (#226)\n\n","date":"2019-06-24 23:57:49","modifiedFileCount":"36","status":"M","submitter":"Anton Okolnychyi"},{"authorTime":"2019-09-05 01:51:12","codes":[{"authorDate":"2019-06-24 23:57:49","commitOrder":3,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct,\n                                        List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","date":"2019-06-24 23:57:49","endLine":111,"groupId":"2225","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/9a/36266ffdf222c4dac237d44b43c458ba5bfe9b.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct,\n                                        List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2019-09-05 01:51:12","commitOrder":3,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields);\n    }\n","date":"2019-09-05 01:51:12","endLine":112,"groupId":"3247","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/de/b80d20091e507eb7dbe04cd9d50f8e9ac75fe2.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields, partitionValues);\n    }\n","realPath":"pig/src/main/java/org/apache/iceberg/pig/PigParquetReader.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"}],"commitId":"d158818cb90beed3298be48a0a9de2366ba3cdb5","commitMessage":"@@@Use constant readers for Pig partition values. (#444)\n\n","date":"2019-09-05 01:51:12","modifiedFileCount":"3","status":"M","submitter":"Ryan Blue"},{"authorTime":"2019-10-28 05:06:22","codes":[{"authorDate":"2019-06-24 23:57:49","commitOrder":4,"curCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct,\n                                        List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","date":"2019-06-24 23:57:49","endLine":111,"groupId":"12139","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/9a/36266ffdf222c4dac237d44b43c458ba5bfe9b.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct,\n                                        List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new InternalRowReader(types, newFields);\n    }\n","realPath":"spark/src/main/java/org/apache/iceberg/spark/data/SparkParquetReaders.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2019-10-28 05:06:22","commitOrder":4,"curCode":"    public ParquetValueReader<?> struct(\n        Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = getMessageType().getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(ParquetValueReaders.option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields);\n    }\n","date":"2019-10-28 05:06:22","endLine":112,"groupId":"12139","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"struct","params":"(Types.StructTypeignored@GroupTypestruct@List<ParquetValueReader<?>>fieldReaders)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/aa/3f1dc7d6a423647980e090c67f868e9174860f.src","preCode":"    public ParquetValueReader<?> struct(Types.StructType ignored, GroupType struct, List<ParquetValueReader<?>> fieldReaders) {\n      \r\n      List<ParquetValueReader<?>> newFields = Lists.newArrayListWithExpectedSize(\n          fieldReaders.size());\n      List<Type> types = Lists.newArrayListWithExpectedSize(fieldReaders.size());\n      List<Type> fields = struct.getFields();\n      for (int i = 0; i < fields.size(); i += 1) {\n        Type fieldType = fields.get(i);\n        int fieldD = type.getMaxDefinitionLevel(path(fieldType.getName())) - 1;\n        newFields.add(option(fieldType, fieldD, fieldReaders.get(i)));\n        types.add(fieldType);\n      }\n\n      return new TupleReader(types, newFields);\n    }\n","realPath":"pig/src/main/java/org/apache/iceberg/pig/PigParquetReader.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"}],"commitId":"040b272f360f796196f689c7a3f654413e0c4f66","commitMessage":"@@@Apply Baseline to iceberg-pig (#525)\n\n","date":"2019-10-28 05:06:22","modifiedFileCount":"5","status":"M","submitter":"Fokko Driesprong"}]
