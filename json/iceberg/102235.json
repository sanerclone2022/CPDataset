[{"authorTime":"2021-01-14 12:35:25","codes":[{"authorDate":"2021-01-14 12:35:25","commitOrder":1,"curCode":"  public void testConsumeWithoutStartSnapshotId() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction function = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, function);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      function.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n  }\n","date":"2021-01-14 12:35:25","endLine":122,"groupId":"4360","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testConsumeWithoutStartSnapshotId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/dc/d41dcb97c5d4b535bb5e465885fa4b5f7568d0.src","preCode":"  public void testConsumeWithoutStartSnapshotId() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction function = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, function);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      function.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/source/TestStreamingMonitorFunction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"B"},{"authorDate":"2021-01-14 12:35:25","commitOrder":1,"curCode":"  public void testCheckpointRestore() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction func = createFunction(scanContext);\n    OperatorSubtaskState state;\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(func)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, func);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      state = harness.snapshot(1, 1);\n\n      \r\n      func.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n\n    List<List<Record>> newRecordsList = generateRecordsAndCommitTxn(10);\n    StreamingMonitorFunction newFunc = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(newFunc)) {\n      harness.setup();\n      \r\n      harness.initializeState(state);\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, newFunc);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      newFunc.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(newRecordsList)), SCHEMA);\n    }\n  }\n","date":"2021-01-14 12:35:25","endLine":208,"groupId":"4362","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCheckpointRestore","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/dc/d41dcb97c5d4b535bb5e465885fa4b5f7568d0.src","preCode":"  public void testCheckpointRestore() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction func = createFunction(scanContext);\n    OperatorSubtaskState state;\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(func)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, func);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      state = harness.snapshot(1, 1);\n\n      \r\n      func.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n\n    List<List<Record>> newRecordsList = generateRecordsAndCommitTxn(10);\n    StreamingMonitorFunction newFunc = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(newFunc)) {\n      harness.setup();\n      \r\n      harness.initializeState(state);\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, newFunc);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      newFunc.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(newRecordsList)), SCHEMA);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/source/TestStreamingMonitorFunction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":159,"status":"B"}],"commitId":"14331c4e5f61e14cdc527a567f5dafc7fd95c3e7","commitMessage":"@@@Flink: Support streaming reader. (#1793)\n\n","date":"2021-01-14 12:35:25","modifiedFileCount":"8","status":"B","submitter":"openinx"},{"authorTime":"2021-03-05 11:21:11","codes":[{"authorDate":"2021-03-05 11:21:11","commitOrder":2,"curCode":"  public void testConsumeWithoutStartSnapshotId() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction function = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, function);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      function.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestHelpers.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n  }\n","date":"2021-03-05 11:21:11","endLine":123,"groupId":"102235","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testConsumeWithoutStartSnapshotId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/84/fbf42c604cdef9cfdf8f75e99becf87ce8a34e.src","preCode":"  public void testConsumeWithoutStartSnapshotId() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction function = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, function);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      function.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/source/TestStreamingMonitorFunction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2021-03-05 11:21:11","commitOrder":2,"curCode":"  public void testCheckpointRestore() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction func = createFunction(scanContext);\n    OperatorSubtaskState state;\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(func)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, func);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      state = harness.snapshot(1, 1);\n\n      \r\n      func.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestHelpers.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n\n    List<List<Record>> newRecordsList = generateRecordsAndCommitTxn(10);\n    StreamingMonitorFunction newFunc = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(newFunc)) {\n      harness.setup();\n      \r\n      harness.initializeState(state);\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, newFunc);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      newFunc.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestHelpers.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(newRecordsList)), SCHEMA);\n    }\n  }\n","date":"2021-03-05 11:21:11","endLine":209,"groupId":"102235","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testCheckpointRestore","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/84/fbf42c604cdef9cfdf8f75e99becf87ce8a34e.src","preCode":"  public void testCheckpointRestore() throws Exception {\n    List<List<Record>> recordsList = generateRecordsAndCommitTxn(10);\n    ScanContext scanContext = ScanContext.builder()\n        .monitorInterval(Duration.ofMillis(100))\n        .build();\n\n    StreamingMonitorFunction func = createFunction(scanContext);\n    OperatorSubtaskState state;\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(func)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, func);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      state = harness.snapshot(1, 1);\n\n      \r\n      func.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(recordsList)), SCHEMA);\n    }\n\n    List<List<Record>> newRecordsList = generateRecordsAndCommitTxn(10);\n    StreamingMonitorFunction newFunc = createFunction(scanContext);\n    try (AbstractStreamOperatorTestHarness<FlinkInputSplit> harness = createHarness(newFunc)) {\n      harness.setup();\n      \r\n      harness.initializeState(state);\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(1);\n      TestSourceContext sourceContext = new TestSourceContext(latch);\n      runSourceFunctionInTask(sourceContext, newFunc);\n\n      Assert.assertTrue(\"Should have expected elements.\", latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS));\n      Thread.sleep(1000L);\n\n      \r\n      newFunc.close();\n\n      Assert.assertEquals(\"Should produce the expected splits\", 1, sourceContext.splits.size());\n      TestFlinkScan.assertRecords(sourceContext.toRows(), Lists.newArrayList(Iterables.concat(newRecordsList)), SCHEMA);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/source/TestStreamingMonitorFunction.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":160,"status":"M"}],"commitId":"343104c8e40bbcacbf6297445cc9dfc82769afe8","commitMessage":"@@@Flink: Refactor flink source tests for FLIP-27 unified source. (#2047)\n\n","date":"2021-03-05 11:21:11","modifiedFileCount":"8","status":"M","submitter":"Steven Zhen Wu"}]
