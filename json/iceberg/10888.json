[{"authorTime":"2020-11-21 06:37:57","codes":[{"authorDate":"2020-11-21 06:37:57","commitOrder":1,"curCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    \r\n    SparkMergeScan that = (SparkMergeScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        ignoreResiduals == that.ignoreResiduals &&\n        Objects.equals(snapshotId, that.snapshotId);\n  }\n","date":"2020-11-21 06:37:57","endLine":165,"groupId":"2680","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/8e/b4690e0f3298e6f835b8116be55ed14ef940f3.src","preCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    \r\n    SparkMergeScan that = (SparkMergeScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        ignoreResiduals == that.ignoreResiduals &&\n        Objects.equals(snapshotId, that.snapshotId);\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/source/SparkMergeScan.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"B"},{"authorDate":"2020-11-21 06:37:57","commitOrder":1,"curCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    SparkBatchQueryScan that = (SparkBatchQueryScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        Objects.equals(snapshotId, that.snapshotId) &&\n        Objects.equals(startSnapshotId, that.startSnapshotId) &&\n        Objects.equals(endSnapshotId, that.endSnapshotId) &&\n        Objects.equals(asOfTimestamp, that.asOfTimestamp);\n  }\n","date":"2020-11-21 06:37:57","endLine":152,"groupId":"2680","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d6/e0a3f131483f1beefa35b80b636d5524d84e53.src","preCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    SparkBatchQueryScan that = (SparkBatchQueryScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        Objects.equals(snapshotId, that.snapshotId) &&\n        Objects.equals(startSnapshotId, that.startSnapshotId) &&\n        Objects.equals(endSnapshotId, that.endSnapshotId) &&\n        Objects.equals(asOfTimestamp, that.asOfTimestamp);\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchQueryScan.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":135,"status":"B"}],"commitId":"1e52c817d05add2f3106e6e6767bb06f566b1c04","commitMessage":"@@@Spark: Add SparkMergeScan (#1782)\n\n","date":"2020-11-21 06:37:57","modifiedFileCount":"2","status":"B","submitter":"Anton Okolnychyi"},{"authorTime":"2020-11-21 06:37:57","codes":[{"authorDate":"2020-12-05 03:28:59","commitOrder":2,"curCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    SparkMergeScan that = (SparkMergeScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        ignoreResiduals == that.ignoreResiduals &&\n        Objects.equals(snapshotId, that.snapshotId) &&\n        Objects.equals(filteredLocations, that.filteredLocations);\n  }\n","date":"2020-12-05 03:28:59","endLine":181,"groupId":"10888","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/66/2e8ef94f242bd5a35d02b25a6e04fc1c8f3178.src","preCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    \r\n    SparkMergeScan that = (SparkMergeScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        ignoreResiduals == that.ignoreResiduals &&\n        Objects.equals(snapshotId, that.snapshotId);\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/source/SparkMergeScan.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":165,"status":"M"},{"authorDate":"2020-11-21 06:37:57","commitOrder":2,"curCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    SparkBatchQueryScan that = (SparkBatchQueryScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        Objects.equals(snapshotId, that.snapshotId) &&\n        Objects.equals(startSnapshotId, that.startSnapshotId) &&\n        Objects.equals(endSnapshotId, that.endSnapshotId) &&\n        Objects.equals(asOfTimestamp, that.asOfTimestamp);\n  }\n","date":"2020-11-21 06:37:57","endLine":152,"groupId":"10888","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"equals","params":"(Objecto)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d6/e0a3f131483f1beefa35b80b636d5524d84e53.src","preCode":"  public boolean equals(Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    SparkBatchQueryScan that = (SparkBatchQueryScan) o;\n    return table().name().equals(that.table().name()) &&\n        readSchema().equals(that.readSchema()) && \r\n        filterExpressions().toString().equals(that.filterExpressions().toString()) &&\n        Objects.equals(snapshotId, that.snapshotId) &&\n        Objects.equals(startSnapshotId, that.startSnapshotId) &&\n        Objects.equals(endSnapshotId, that.endSnapshotId) &&\n        Objects.equals(asOfTimestamp, that.asOfTimestamp);\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchQueryScan.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":135,"status":"N"}],"commitId":"af5f60068c75195c0bb41ca85065e05282fe2fe8","commitMessage":"@@@Spark: Implement copy-on-write DELETE (#1862)\n\n","date":"2020-12-05 03:28:59","modifiedFileCount":"6","status":"M","submitter":"Anton Okolnychyi"}]
