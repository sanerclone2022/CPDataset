[{"authorTime":"2020-09-17 04:05:55","codes":[{"authorDate":"2020-08-29 01:19:33","commitOrder":2,"curCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(dataFile1, ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","date":"2020-08-29 01:19:33","endLine":334,"groupId":"8","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testRecoveryFromValidSnapshot","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/e5/a9a8d4766bfb64ab0af5a242b3dc34f9f377ce.src","preCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(dataFile1, ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":287,"status":"NB"},{"authorDate":"2020-09-17 04:05:55","commitOrder":2,"curCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n    }\n\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","date":"2020-09-17 04:05:55","endLine":370,"groupId":"4757","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoveryFromSnapshotWithoutCompletedNotification","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/67/f742984645aec8d38715d66a5897fe2bb0b8a7.src","preCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n    }\n\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"B"}],"commitId":"88ec6d0f144c89a77286c6de5b96dcf52f2c9dc5","commitMessage":"@@@Flink: Add job id to state backend for handling job redeployment (#1404)\n\n","date":"2020-09-17 04:05:55","modifiedFileCount":"2","status":"M","submitter":"openinx"},{"authorTime":"2020-10-28 12:06:53","codes":[{"authorDate":"2020-10-28 12:06:53","commitOrder":3,"curCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(dataFile1, ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","date":"2020-10-28 12:06:53","endLine":334,"groupId":"8","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testRecoveryFromValidSnapshot","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/58/3b6f18e336b3e4c2ffb4518a11ccf655d0ef76.src","preCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(dataFile1, ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2020-10-28 12:06:53","commitOrder":3,"curCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n      assertFlinkManifests(1);\n    }\n\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      \r\n      assertFlinkManifests(0);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","date":"2020-10-28 12:06:53","endLine":424,"groupId":"4757","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoveryFromSnapshotWithoutCompletedNotification","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/58/3b6f18e336b3e4c2ffb4518a11ccf655d0ef76.src","preCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n    }\n\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":337,"status":"M"}],"commitId":"b9634c9511c8a028074e8e5bdc54f0db47058668","commitMessage":"@@@Flink: maintain the complete data files into manifest before checkpoint finished. (#1477)\n\n","date":"2020-10-28 12:06:53","modifiedFileCount":"3","status":"M","submitter":"openinx"},{"authorTime":"2020-12-19 01:57:04","codes":[{"authorDate":"2020-12-19 01:57:04","commitOrder":4,"curCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<WriteResult, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(of(dataFile1), ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(table, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<WriteResult, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(of(dataFile), ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","date":"2020-12-19 01:57:04","endLine":344,"groupId":"102213","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testRecoveryFromValidSnapshot","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/5e/c246b7af0789e09bc0d60caa755747bb78b8a1.src","preCode":"  public void testRecoveryFromValidSnapshot() throws Exception {\n    long checkpointId = 0;\n    long timestamp = 0;\n    List<RowData> expectedRows = Lists.newArrayList();\n    OperatorSubtaskState snapshot;\n\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile1 = writeDataFile(\"data-1\", ImmutableList.of(row));\n\n      harness.processElement(dataFile1, ++timestamp);\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of(row));\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n\n    \r\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":289,"status":"M"},{"authorDate":"2020-12-19 01:57:04","commitOrder":4,"curCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<WriteResult, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(of(dataFile), ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(table, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n      assertFlinkManifests(1);\n    }\n\n    try (OneInputStreamOperatorTestHarness<WriteResult, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      \r\n      assertFlinkManifests(0);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(of(dataFile), ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<WriteResult, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(of(dataFile), ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(table, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","date":"2020-12-19 01:57:04","endLine":434,"groupId":"102213","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoveryFromSnapshotWithoutCompletedNotification","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/5e/c246b7af0789e09bc0d60caa755747bb78b8a1.src","preCode":"  public void testRecoveryFromSnapshotWithoutCompletedNotification() throws Exception {\n    \r\n    \r\n    long checkpointId = 0;\n    long timestamp = 0;\n    OperatorSubtaskState snapshot;\n    List<RowData> expectedRows = Lists.newArrayList();\n    JobID jobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.open();\n\n      assertSnapshotSize(0);\n      assertMaxCommittedCheckpointId(jobId, -1L);\n\n      RowData row = SimpleDataUtil.createRowData(1, \"hello\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-1\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      SimpleDataUtil.assertTableRows(tablePath, ImmutableList.of());\n      assertMaxCommittedCheckpointId(jobId, -1L);\n      assertFlinkManifests(1);\n    }\n\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(jobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      \r\n      assertFlinkManifests(0);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(2);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n\n      RowData row = SimpleDataUtil.createRowData(2, \"world\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-2\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      snapshot = harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n    }\n\n    \r\n    JobID newJobId = new JobID();\n    try (OneInputStreamOperatorTestHarness<DataFile, Void> harness = createStreamSink(newJobId)) {\n      harness.setup();\n      harness.initializeState(snapshot);\n      harness.open();\n\n      \r\n      assertFlinkManifests(0);\n\n      assertMaxCommittedCheckpointId(newJobId, -1);\n      assertMaxCommittedCheckpointId(jobId, checkpointId);\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(3);\n\n      RowData row = SimpleDataUtil.createRowData(3, \"foo\");\n      expectedRows.add(row);\n      DataFile dataFile = writeDataFile(\"data-3\", ImmutableList.of(row));\n      harness.processElement(dataFile, ++timestamp);\n\n      harness.snapshot(++checkpointId, ++timestamp);\n      assertFlinkManifests(1);\n\n      harness.notifyOfCompletedCheckpoint(checkpointId);\n      assertFlinkManifests(0);\n\n      SimpleDataUtil.assertTableRows(tablePath, expectedRows);\n      assertSnapshotSize(4);\n      assertMaxCommittedCheckpointId(newJobId, checkpointId);\n    }\n  }\n","realPath":"flink/src/test/java/org/apache/iceberg/flink/sink/TestIcebergFilesCommitter.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":347,"status":"M"}],"commitId":"77c5617c102c2ab27fbf35cac3fd75380a887d5d","commitMessage":"@@@Flink: Commit both data files and delete files (#1939)\n\n","date":"2020-12-19 01:57:04","modifiedFileCount":"9","status":"M","submitter":"openinx"}]
