[{"authorTime":"2020-06-30 08:56:05","codes":[{"authorDate":"2020-06-30 08:56:05","commitOrder":1,"curCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties));\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","date":"2020-06-30 08:56:05","endLine":139,"groupId":"60","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"stageCreate","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/22/2194b6355ba7298a1e92eef715c6a3efef039a.src","preCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties));\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":130,"status":"B"},{"authorDate":"2020-06-30 08:56:05","commitOrder":1,"curCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newReplaceTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties,\n          false ));\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","date":"2020-06-30 08:56:05","endLine":152,"groupId":"60","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"stageReplace","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/22/2194b6355ba7298a1e92eef715c6a3efef039a.src","preCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newReplaceTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties,\n          false ));\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"B"}],"commitId":"51c930e33867e54b3d7e0159b11d6b9c4bc81f1a","commitMessage":"@@@Spark: Add Spark 3 data source classes (#1124)\n\n","date":"2020-06-30 08:56:05","modifiedFileCount":"7","status":"B","submitter":"Ryan Blue"},{"authorTime":"2020-07-15 00:37:54","codes":[{"authorDate":"2020-07-15 00:37:54","commitOrder":2,"curCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(\n          buildIdentifier(ident),\n          icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n          properties.get(\"location\"),\n          Spark3Util.rebuildCreateProperties(properties)));\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","date":"2020-07-15 00:37:54","endLine":161,"groupId":"60","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"stageCreate","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/c1/15b840cc46ec026d0ab632d478cc70585553a0.src","preCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties));\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":148,"status":"M"},{"authorDate":"2020-07-15 00:37:54","commitOrder":2,"curCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newReplaceTableTransaction(\n          buildIdentifier(ident),\n          icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n          properties.get(\"location\"),\n          Spark3Util.rebuildCreateProperties(properties),\n          false ));\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","date":"2020-07-15 00:37:54","endLine":178,"groupId":"60","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"stageReplace","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/c1/15b840cc46ec026d0ab632d478cc70585553a0.src","preCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newReplaceTableTransaction(buildIdentifier(ident), icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms), properties.get(\"location\"), properties,\n          false ));\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":164,"status":"M"}],"commitId":"f5e4bc4add18e2a07924fa1ff7e16068b26466d8","commitMessage":"@@@Spark: Fix USING clause in SparkCatalog (#1194)\n\n","date":"2020-07-15 00:37:54","modifiedFileCount":"1","status":"M","submitter":"Ryan Blue"},{"authorTime":"2020-12-09 06:20:25","codes":[{"authorDate":"2020-12-09 06:20:25","commitOrder":3,"curCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .createTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","date":"2020-12-09 06:20:25","endLine":179,"groupId":"2335","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"stageCreate","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/65/6f3c46a5f6d4e6c861fa24352eab9a84c6651f.src","preCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(\n          buildIdentifier(ident),\n          icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n          properties.get(\"location\"),\n          Spark3Util.rebuildCreateProperties(properties)));\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"M"},{"authorDate":"2020-12-09 06:20:25","commitOrder":3,"curCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .replaceTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","date":"2020-12-09 06:20:25","endLine":195,"groupId":"2335","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"stageReplace","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/65/6f3c46a5f6d4e6c861fa24352eab9a84c6651f.src","preCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      return new StagedSparkTable(icebergCatalog.newReplaceTableTransaction(\n          buildIdentifier(ident),\n          icebergSchema,\n          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n          properties.get(\"location\"),\n          Spark3Util.rebuildCreateProperties(properties),\n          false ));\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":182,"status":"M"}],"commitId":"f3dc93faece50e174287fbf4d00ffd115a54e179","commitMessage":"@@@Spark: Support loading paths in SparkCatalog (#1843)\n\n","date":"2020-12-09 06:20:25","modifiedFileCount":"2","status":"M","submitter":"Ryan Murray"},{"authorTime":"2021-07-16 01:06:44","codes":[{"authorDate":"2021-07-16 01:06:44","commitOrder":4,"curCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema, useTimestampsWithoutZone);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .createTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","date":"2021-07-16 01:06:44","endLine":160,"groupId":"10892","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"stageCreate","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d0/99291fc3537bfbc3ecd15f313b91feef135ffa.src","preCode":"  public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                 Map<String, String> properties) throws TableAlreadyExistsException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .createTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (AlreadyExistsException e) {\n      throw new TableAlreadyExistsException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":147,"status":"M"},{"authorDate":"2021-07-16 01:06:44","commitOrder":4,"curCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema, useTimestampsWithoutZone);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .replaceTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","date":"2021-07-16 01:06:44","endLine":176,"groupId":"10892","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"stageReplace","params":"(Identifierident@StructTypeschema@Transform[]transforms@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d0/99291fc3537bfbc3ecd15f313b91feef135ffa.src","preCode":"  public StagedTable stageReplace(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws NoSuchTableException {\n    Schema icebergSchema = SparkSchemaUtil.convert(schema);\n    try {\n      Catalog.TableBuilder builder = newBuilder(ident, icebergSchema);\n      Transaction transaction = builder.withPartitionSpec(Spark3Util.toPartitionSpec(icebergSchema, transforms))\n          .withLocation(properties.get(\"location\"))\n          .withProperties(Spark3Util.rebuildCreateProperties(properties))\n          .replaceTransaction();\n      return new StagedSparkTable(transaction);\n    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n      throw new NoSuchTableException(ident);\n    }\n  }\n","realPath":"spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"M"}],"commitId":"9a0d154b0ba5e6d10d79e30470295c91c89c1e09","commitMessage":"@@@Add support for reading/writing timestamps without timezone.  (#2757)\n\nPreviously Spark could not handle Iceberg tables which contained Timestamp.withoutTimeZone. New parameters are introduced to allow Timestamp without TimeZone to be treated as Timestamp with Timezone.  \n\nCo-authored-by: bkahloon <kahlonbakht@gmail.com>\nCo-authored-by: shardulm94 ","date":"2021-07-16 01:06:44","modifiedFileCount":"15","status":"M","submitter":"sshkvar"}]
