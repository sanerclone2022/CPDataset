[{"authorTime":"2020-07-09 07:03:50","codes":[{"authorDate":"2020-07-09 07:03:50","commitOrder":1,"curCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","date":"2020-07-09 07:03:50","endLine":142,"groupId":"944","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testRTAS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/2b/de262bad9eaa0aef6b4dfb633fd197e4c8e1aa.src","preCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"B"},{"authorDate":"2020-07-09 07:03:50","commitOrder":1,"curCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","date":"2020-07-09 07:03:50","endLine":260,"groupId":"944","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testDataFrameV2Replace","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/2b/de262bad9eaa0aef6b4dfb633fd197e4c8e1aa.src","preCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":211,"status":"B"}],"commitId":"115a1450c0e62edd835d0dd77a6513ff3717479c","commitMessage":"@@@Add Spark 3 SQL tests (#1156)\n\n","date":"2020-07-09 07:03:50","modifiedFileCount":"9","status":"B","submitter":"Ryan Blue"},{"authorTime":"2020-07-09 08:25:54","codes":[{"authorDate":"2020-07-09 08:25:54","commitOrder":2,"curCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n  }\n","date":"2020-07-09 08:25:54","endLine":137,"groupId":"2388","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testRTAS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d0/2b852bc9932210c2af514005c2635db2a06c2a.src","preCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2020-07-09 08:25:54","commitOrder":2,"curCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n  }\n","date":"2020-07-09 08:25:54","endLine":247,"groupId":"2388","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testDataFrameV2Replace","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d0/2b852bc9932210c2af514005c2635db2a06c2a.src","preCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    \r\n    \r\n    boolean isAtomic = !\"spark_catalog\".equals(catalogName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    int specId = isAtomic ? 1 : 0;\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(specId)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        isAtomic ? 2 : 1, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"M"}],"commitId":"a81ba17e15b593c91efe6a629197150f2fff097d","commitMessage":"@@@Support atomic CTAS and RTAS with SparkSessionCatalog (#1183)\n\n","date":"2020-07-09 08:25:54","modifiedFileCount":"2","status":"M","submitter":"Ryan Blue"},{"authorTime":"2020-07-09 08:25:54","codes":[{"authorDate":"2020-10-24 02:24:09","commitOrder":3,"curCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg TBLPROPERTIES ('prop1'='val1', 'prop2'='val2')\" +\n        \"AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) TBLPROPERTIES ('prop1'='newval1', 'prop3'='val3') AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n\n    Assert.assertEquals(\"Should have updated table property\",\n        \"newval1\", rtasTable.properties().get(\"prop1\"));\n    Assert.assertEquals(\"Should have preserved table property\",\n        \"val2\", rtasTable.properties().get(\"prop2\"));\n    Assert.assertEquals(\"Should have new table property\",\n        \"val3\", rtasTable.properties().get(\"prop3\"));\n  }\n","date":"2020-10-24 02:24:09","endLine":145,"groupId":"10806","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testRTAS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/3c/a8c890d7b1f19acca4acb286225971fa351d71.src","preCode":"  public void testRTAS() {\n    sql(\"CREATE TABLE %s USING iceberg AS SELECT * FROM %s\", tableName, sourceName);\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    sql(\"REPLACE TABLE %s USING iceberg PARTITIONED BY (part) AS \" +\n        \"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n        \"FROM %s ORDER BY 3, 1\", tableName, sourceName);\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2020-07-09 08:25:54","commitOrder":3,"curCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n  }\n","date":"2020-07-09 08:25:54","endLine":247,"groupId":"10806","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testDataFrameV2Replace","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-iceberg-10-0.7/blobInfo/CC_OUT/blobs/d0/2b852bc9932210c2af514005c2635db2a06c2a.src","preCode":"  public void testDataFrameV2Replace() throws Exception {\n    spark.table(sourceName).writeTo(tableName).using(\"iceberg\").create();\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT * FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    spark.table(sourceName)\n        .select(\n            col(\"id\"),\n            col(\"data\"),\n            when(col(\"id\").mod(lit(2)).equalTo(lit(0)), lit(\"even\")).otherwise(\"odd\").as(\"part\"))\n        .orderBy(\"part\", \"id\")\n        .writeTo(tableName)\n        .partitionedBy(col(\"part\"))\n        .using(\"iceberg\")\n        .replace();\n\n    Schema expectedSchema = new Schema(\n        Types.NestedField.optional(1, \"id\", Types.LongType.get()),\n        Types.NestedField.optional(2, \"data\", Types.StringType.get()),\n        Types.NestedField.optional(3, \"part\", Types.StringType.get())\n    );\n\n    PartitionSpec expectedSpec = PartitionSpec.builderFor(expectedSchema)\n        .identity(\"part\")\n        .withSpecId(1)\n        .build();\n\n    Table rtasTable = validationCatalog.loadTable(tableIdent);\n\n    \r\n    Assert.assertEquals(\"Should have expected nullable schema\",\n        expectedSchema.asStruct(), rtasTable.schema().asStruct());\n    Assert.assertEquals(\"Should be partitioned by part\",\n        expectedSpec, rtasTable.spec());\n\n    assertEquals(\"Should have rows matching the source table\",\n        sql(\"SELECT id, data, CASE WHEN (id %% 2) = 0 THEN 'even' ELSE 'odd' END AS part \" +\n            \"FROM %s ORDER BY id\", sourceName),\n        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n\n    Assert.assertEquals(\"Table should have expected snapshots\",\n        2, Iterables.size(rtasTable.snapshots()));\n  }\n","realPath":"spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java","repoName":"iceberg","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"N"}],"commitId":"d578b66c940a6257785100f8eb96fba37fd1e206","commitMessage":"@@@Docs: Document property behavior for Spark REPLACE TABLE (#1644)\n\n","date":"2020-10-24 02:24:09","modifiedFileCount":"1","status":"M","submitter":"Sunitha Kambhampati"}]
