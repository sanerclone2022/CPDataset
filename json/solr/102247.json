[{"authorTime":"2015-03-28 08:02:40","codes":[{"authorDate":"2015-03-16 12:40:23","commitOrder":2,"curCode":"  public NamedList<Integer> getCounts(SolrIndexSearcher searcher, DocSet baseDocs, int offset, int limit, Integer mincount, boolean missing, String sort, String prefix) throws IOException {\n    use.incrementAndGet();\n\n    FieldType ft = searcher.getSchema().getFieldType(field);\n\n    NamedList<Integer> res = new NamedList<>();  \r\n\n    DocSet docs = baseDocs;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize >= mincount) {\n\n      final int[] index = this.index;\n      \r\n      \r\n      final int[] counts = new int[numTermsInField + 1];\n\n      \r\n      \r\n      \r\n      int startTerm = 0;\n      int endTerm = numTermsInField;  \r\n\n      TermsEnum te = getOrdTermsEnum(searcher.getLeafReader());\n      if (te != null && prefix != null && prefix.length() > 0) {\n        final BytesRefBuilder prefixBr = new BytesRefBuilder();\n        prefixBr.copyChars(prefix);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          startTerm = numTermsInField;\n        } else {\n          startTerm = (int) te.ord();\n        }\n        prefixBr.append(UnicodeUtil.BIG_TERM);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          endTerm = numTermsInField;\n        } else {\n          endTerm = (int) te.ord();\n        }\n      }\n\n      \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n\n      boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0\n          && startTerm==0 && endTerm==numTermsInField\n          && docs instanceof BitDocSet;\n\n      if (doNegative) {\n        FixedBitSet bs = ((BitDocSet)docs).getBits().clone();\n        bs.flip(0, maxDoc);\n        \r\n        \r\n        docs = new BitDocSet(bs, maxDoc - baseSize);\n        \r\n        \r\n        \r\n      }\n\n      \r\n      for (TopTerm tt : bigTerms.values()) {\n        \r\n        \r\n        if (tt.termNum >= startTerm && tt.termNum < endTerm) {\n          counts[tt.termNum] = searcher.numDocs(new TermQuery(new Term(field, tt.term)), docs);\n          \r\n        } else {\n          \r\n        }\n      }\n\n      \r\n      \r\n\n      \r\n      \r\n      \r\n      \r\n      \r\n\n      if (termInstances > 0) {\n        DocIterator iter = docs.iterator();\n        while (iter.hasNext()) {\n          int doc = iter.nextDoc();\n          \r\n          int code = index[doc];\n\n          if ((code & 0xff)==1) {\n            \r\n            int pos = code>>>8;\n            int whichArray = (doc >>> 16) & 0xff;\n            byte[] arr = tnums[whichArray];\n            int tnum = 0;\n            for(;;) {\n              int delta = 0;\n              for(;;) {\n                byte b = arr[pos++];\n                delta = (delta << 7) | (b & 0x7f);\n                if ((b & 0x80) == 0) break;\n              }\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              \r\n              counts[tnum]++;\n            }\n          } else {\n            \r\n            int tnum = 0;\n            int delta = 0;\n            for (;;) {\n              delta = (delta << 7) | (code & 0x7f);\n              if ((code & 0x80)==0) {\n                if (delta==0) break;\n                tnum += delta - TNUM_OFFSET;\n                \r\n                counts[tnum]++;\n                delta = 0;\n              }\n              code >>>= 8;\n            }\n          }\n        }\n      }\n      final CharsRefBuilder charsRef = new CharsRefBuilder();\n\n      int off=offset;\n      int lim=limit>=0 ? limit : Integer.MAX_VALUE;\n\n      if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n        int maxsize = limit>0 ? offset+limit : Integer.MAX_VALUE-1;\n        maxsize = Math.min(maxsize, numTermsInField);\n        LongPriorityQueue queue = new LongPriorityQueue(Math.min(maxsize,1000), maxsize, Long.MIN_VALUE);\n\n        int min=mincount-1;  \r\n        \r\n        for (int i=startTerm; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c>min) {\n            \r\n            \r\n            \r\n\n            \r\n            long pair = (((long)c)<<32) + (Integer.MAX_VALUE - i);\n            boolean displaced = queue.insert(pair);\n            if (displaced) min=(int)(queue.top() >>> 32);\n          }\n        }\n\n        \r\n\n        \r\n        int collectCount = Math.max(0, queue.size() - off);\n        assert collectCount <= lim;\n\n        \r\n        int sortedIdxStart = queue.size() - (collectCount - 1);\n        int sortedIdxEnd = queue.size() + 1;\n        final long[] sorted = queue.sort(collectCount);\n\n        final int[] indirect = counts;  \r\n        assert indirect.length >= sortedIdxEnd;\n\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          long pair = sorted[i];\n          int c = (int)(pair >>> 32);\n          int tnum = Integer.MAX_VALUE - (int)pair;\n\n          indirect[i] = i;   \r\n          sorted[i] = tnum;  \r\n\n          \r\n          res.add(null, c);\n        }\n\n        \r\n        PrimUtils.sort(sortedIdxStart, sortedIdxEnd, indirect, new PrimUtils.IntComparator() {\n          @Override\n          public int compare(int a, int b) {\n            return (int)sorted[a] - (int)sorted[b];\n          }\n\n          @Override\n          public boolean lessThan(int a, int b) {\n            return sorted[a] < sorted[b];\n          }\n\n          @Override\n          public boolean equals(int a, int b) {\n            return sorted[a] == sorted[b];\n          }\n        });\n\n        \r\n        \r\n        \r\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          int idx = indirect[i];\n          int tnum = (int)sorted[idx];\n          final String label = getReadableValue(getTermValue(te, tnum), ft, charsRef);\n          \r\n          res.setName(idx - sortedIdxStart, label);\n        }\n\n      } else {\n        \r\n        int i=startTerm;\n        if (mincount<=0) {\n          \r\n          \r\n          i=startTerm+off;\n          off=0;\n        }\n\n        for (; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c<mincount || --off>=0) continue;\n          if (--lim<0) break;\n\n          final String label = getReadableValue(getTermValue(te, i), ft, charsRef);\n          res.add(label, c);\n        }\n      }\n    }\n\n\n    if (missing) {\n      \r\n      res.add(null, SimpleFacets.getFieldMissingCount(searcher, baseDocs, field));\n    }\n\n    \r\n\n    return res;\n  }\n","date":"2015-03-16 12:40:23","endLine":561,"groupId":"13038","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(SolrIndexSearchersearcher@DocSetbaseDocs@intoffset@intlimit@Integermincount@booleanmissing@Stringsort@Stringprefix)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/6b/4ac8b201e58b6cf44496e291af16a4f1bd2531.src","preCode":"  public NamedList<Integer> getCounts(SolrIndexSearcher searcher, DocSet baseDocs, int offset, int limit, Integer mincount, boolean missing, String sort, String prefix) throws IOException {\n    use.incrementAndGet();\n\n    FieldType ft = searcher.getSchema().getFieldType(field);\n\n    NamedList<Integer> res = new NamedList<>();  \r\n\n    DocSet docs = baseDocs;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize >= mincount) {\n\n      final int[] index = this.index;\n      \r\n      \r\n      final int[] counts = new int[numTermsInField + 1];\n\n      \r\n      \r\n      \r\n      int startTerm = 0;\n      int endTerm = numTermsInField;  \r\n\n      TermsEnum te = getOrdTermsEnum(searcher.getLeafReader());\n      if (te != null && prefix != null && prefix.length() > 0) {\n        final BytesRefBuilder prefixBr = new BytesRefBuilder();\n        prefixBr.copyChars(prefix);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          startTerm = numTermsInField;\n        } else {\n          startTerm = (int) te.ord();\n        }\n        prefixBr.append(UnicodeUtil.BIG_TERM);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          endTerm = numTermsInField;\n        } else {\n          endTerm = (int) te.ord();\n        }\n      }\n\n      \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n\n      boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0\n          && startTerm==0 && endTerm==numTermsInField\n          && docs instanceof BitDocSet;\n\n      if (doNegative) {\n        FixedBitSet bs = ((BitDocSet)docs).getBits().clone();\n        bs.flip(0, maxDoc);\n        \r\n        \r\n        docs = new BitDocSet(bs, maxDoc - baseSize);\n        \r\n        \r\n        \r\n      }\n\n      \r\n      for (TopTerm tt : bigTerms.values()) {\n        \r\n        \r\n        if (tt.termNum >= startTerm && tt.termNum < endTerm) {\n          counts[tt.termNum] = searcher.numDocs(new TermQuery(new Term(field, tt.term)), docs);\n          \r\n        } else {\n          \r\n        }\n      }\n\n      \r\n      \r\n\n      \r\n      \r\n      \r\n      \r\n      \r\n\n      if (termInstances > 0) {\n        DocIterator iter = docs.iterator();\n        while (iter.hasNext()) {\n          int doc = iter.nextDoc();\n          \r\n          int code = index[doc];\n\n          if ((code & 0xff)==1) {\n            \r\n            int pos = code>>>8;\n            int whichArray = (doc >>> 16) & 0xff;\n            byte[] arr = tnums[whichArray];\n            int tnum = 0;\n            for(;;) {\n              int delta = 0;\n              for(;;) {\n                byte b = arr[pos++];\n                delta = (delta << 7) | (b & 0x7f);\n                if ((b & 0x80) == 0) break;\n              }\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              \r\n              counts[tnum]++;\n            }\n          } else {\n            \r\n            int tnum = 0;\n            int delta = 0;\n            for (;;) {\n              delta = (delta << 7) | (code & 0x7f);\n              if ((code & 0x80)==0) {\n                if (delta==0) break;\n                tnum += delta - TNUM_OFFSET;\n                \r\n                counts[tnum]++;\n                delta = 0;\n              }\n              code >>>= 8;\n            }\n          }\n        }\n      }\n      final CharsRefBuilder charsRef = new CharsRefBuilder();\n\n      int off=offset;\n      int lim=limit>=0 ? limit : Integer.MAX_VALUE;\n\n      if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n        int maxsize = limit>0 ? offset+limit : Integer.MAX_VALUE-1;\n        maxsize = Math.min(maxsize, numTermsInField);\n        LongPriorityQueue queue = new LongPriorityQueue(Math.min(maxsize,1000), maxsize, Long.MIN_VALUE);\n\n        int min=mincount-1;  \r\n        \r\n        for (int i=startTerm; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c>min) {\n            \r\n            \r\n            \r\n\n            \r\n            long pair = (((long)c)<<32) + (Integer.MAX_VALUE - i);\n            boolean displaced = queue.insert(pair);\n            if (displaced) min=(int)(queue.top() >>> 32);\n          }\n        }\n\n        \r\n\n        \r\n        int collectCount = Math.max(0, queue.size() - off);\n        assert collectCount <= lim;\n\n        \r\n        int sortedIdxStart = queue.size() - (collectCount - 1);\n        int sortedIdxEnd = queue.size() + 1;\n        final long[] sorted = queue.sort(collectCount);\n\n        final int[] indirect = counts;  \r\n        assert indirect.length >= sortedIdxEnd;\n\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          long pair = sorted[i];\n          int c = (int)(pair >>> 32);\n          int tnum = Integer.MAX_VALUE - (int)pair;\n\n          indirect[i] = i;   \r\n          sorted[i] = tnum;  \r\n\n          \r\n          res.add(null, c);\n        }\n\n        \r\n        PrimUtils.sort(sortedIdxStart, sortedIdxEnd, indirect, new PrimUtils.IntComparator() {\n          @Override\n          public int compare(int a, int b) {\n            return (int)sorted[a] - (int)sorted[b];\n          }\n\n          @Override\n          public boolean lessThan(int a, int b) {\n            return sorted[a] < sorted[b];\n          }\n\n          @Override\n          public boolean equals(int a, int b) {\n            return sorted[a] == sorted[b];\n          }\n        });\n\n        \r\n        \r\n        \r\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          int idx = indirect[i];\n          int tnum = (int)sorted[idx];\n          final String label = getReadableValue(getTermValue(te, tnum), ft, charsRef);\n          \r\n          res.setName(idx - sortedIdxStart, label);\n        }\n\n      } else {\n        \r\n        int i=startTerm;\n        if (mincount<=0) {\n          \r\n          \r\n          i=startTerm+off;\n          off=0;\n        }\n\n        for (; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c<mincount || --off>=0) continue;\n          if (--lim<0) break;\n\n          final String label = getReadableValue(getTermValue(te, i), ft, charsRef);\n          res.add(label, c);\n        }\n      }\n    }\n\n\n    if (missing) {\n      \r\n      res.add(null, SimpleFacets.getFieldMissingCount(searcher, baseDocs, field));\n    }\n\n    \r\n\n    return res;\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":318,"status":"NB"},{"authorDate":"2015-03-28 08:02:40","commitOrder":2,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (processor.allBucketsSlot >= 0) {\n            processor.collect(intersection, processor.allBucketsSlot);\n            processor.countAcc.incrementCount(processor.allBucketsSlot, collected);\n          }\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2015-03-28 08:02:40","endLine":541,"groupId":"29815","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d2/39918475e890267e0de5056ef792a9d5fa0874.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (processor.allBucketsSlot >= 0) {\n            processor.collect(intersection, processor.allBucketsSlot);\n            processor.countAcc.incrementCount(processor.allBucketsSlot, collected);\n          }\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":427,"status":"B"}],"commitId":"a4274dff9acd2eb3f30d2d96dc6224f645cb44f8","commitMessage":"@@@SOLR-7214: optimize multi-valued counts-only case\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1669712 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-03-28 08:02:40","modifiedFileCount":"4","status":"M","submitter":"Yonik Seeley"},{"authorTime":"2015-03-28 08:02:40","codes":[{"authorDate":"2015-05-10 04:50:55","commitOrder":3,"curCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  \r\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts.getCount(i);\n      }\n      counts.incrementCount(processor.allBucketsSlot, all);\n    }\n  }\n","date":"2015-05-10 04:50:55","endLine":392,"groupId":"61456","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/44/bd5f40a39c0d0e72b7ae58d2379bf0d17ecd9c.src","preCode":"  public NamedList<Integer> getCounts(SolrIndexSearcher searcher, DocSet baseDocs, int offset, int limit, Integer mincount, boolean missing, String sort, String prefix) throws IOException {\n    use.incrementAndGet();\n\n    FieldType ft = searcher.getSchema().getFieldType(field);\n\n    NamedList<Integer> res = new NamedList<>();  \r\n\n    DocSet docs = baseDocs;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize >= mincount) {\n\n      final int[] index = this.index;\n      \r\n      \r\n      final int[] counts = new int[numTermsInField + 1];\n\n      \r\n      \r\n      \r\n      int startTerm = 0;\n      int endTerm = numTermsInField;  \r\n\n      TermsEnum te = getOrdTermsEnum(searcher.getLeafReader());\n      if (te != null && prefix != null && prefix.length() > 0) {\n        final BytesRefBuilder prefixBr = new BytesRefBuilder();\n        prefixBr.copyChars(prefix);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          startTerm = numTermsInField;\n        } else {\n          startTerm = (int) te.ord();\n        }\n        prefixBr.append(UnicodeUtil.BIG_TERM);\n        if (te.seekCeil(prefixBr.get()) == TermsEnum.SeekStatus.END) {\n          endTerm = numTermsInField;\n        } else {\n          endTerm = (int) te.ord();\n        }\n      }\n\n      \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n\n      boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0\n          && startTerm==0 && endTerm==numTermsInField\n          && docs instanceof BitDocSet;\n\n      if (doNegative) {\n        FixedBitSet bs = ((BitDocSet)docs).getBits().clone();\n        bs.flip(0, maxDoc);\n        \r\n        \r\n        docs = new BitDocSet(bs, maxDoc - baseSize);\n        \r\n        \r\n        \r\n      }\n\n      \r\n      for (TopTerm tt : bigTerms.values()) {\n        \r\n        \r\n        if (tt.termNum >= startTerm && tt.termNum < endTerm) {\n          counts[tt.termNum] = searcher.numDocs(new TermQuery(new Term(field, tt.term)), docs);\n          \r\n        } else {\n          \r\n        }\n      }\n\n      \r\n      \r\n\n      \r\n      \r\n      \r\n      \r\n      \r\n\n      if (termInstances > 0) {\n        DocIterator iter = docs.iterator();\n        while (iter.hasNext()) {\n          int doc = iter.nextDoc();\n          \r\n          int code = index[doc];\n\n          if ((code & 0xff)==1) {\n            \r\n            int pos = code>>>8;\n            int whichArray = (doc >>> 16) & 0xff;\n            byte[] arr = tnums[whichArray];\n            int tnum = 0;\n            for(;;) {\n              int delta = 0;\n              for(;;) {\n                byte b = arr[pos++];\n                delta = (delta << 7) | (b & 0x7f);\n                if ((b & 0x80) == 0) break;\n              }\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              \r\n              counts[tnum]++;\n            }\n          } else {\n            \r\n            int tnum = 0;\n            int delta = 0;\n            for (;;) {\n              delta = (delta << 7) | (code & 0x7f);\n              if ((code & 0x80)==0) {\n                if (delta==0) break;\n                tnum += delta - TNUM_OFFSET;\n                \r\n                counts[tnum]++;\n                delta = 0;\n              }\n              code >>>= 8;\n            }\n          }\n        }\n      }\n      final CharsRefBuilder charsRef = new CharsRefBuilder();\n\n      int off=offset;\n      int lim=limit>=0 ? limit : Integer.MAX_VALUE;\n\n      if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n        int maxsize = limit>0 ? offset+limit : Integer.MAX_VALUE-1;\n        maxsize = Math.min(maxsize, numTermsInField);\n        LongPriorityQueue queue = new LongPriorityQueue(Math.min(maxsize,1000), maxsize, Long.MIN_VALUE);\n\n        int min=mincount-1;  \r\n        \r\n        for (int i=startTerm; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c>min) {\n            \r\n            \r\n            \r\n\n            \r\n            long pair = (((long)c)<<32) + (Integer.MAX_VALUE - i);\n            boolean displaced = queue.insert(pair);\n            if (displaced) min=(int)(queue.top() >>> 32);\n          }\n        }\n\n        \r\n\n        \r\n        int collectCount = Math.max(0, queue.size() - off);\n        assert collectCount <= lim;\n\n        \r\n        int sortedIdxStart = queue.size() - (collectCount - 1);\n        int sortedIdxEnd = queue.size() + 1;\n        final long[] sorted = queue.sort(collectCount);\n\n        final int[] indirect = counts;  \r\n        assert indirect.length >= sortedIdxEnd;\n\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          long pair = sorted[i];\n          int c = (int)(pair >>> 32);\n          int tnum = Integer.MAX_VALUE - (int)pair;\n\n          indirect[i] = i;   \r\n          sorted[i] = tnum;  \r\n\n          \r\n          res.add(null, c);\n        }\n\n        \r\n        PrimUtils.sort(sortedIdxStart, sortedIdxEnd, indirect, new PrimUtils.IntComparator() {\n          @Override\n          public int compare(int a, int b) {\n            return (int)sorted[a] - (int)sorted[b];\n          }\n\n          @Override\n          public boolean lessThan(int a, int b) {\n            return sorted[a] < sorted[b];\n          }\n\n          @Override\n          public boolean equals(int a, int b) {\n            return sorted[a] == sorted[b];\n          }\n        });\n\n        \r\n        \r\n        \r\n        for (int i=sortedIdxStart; i<sortedIdxEnd; i++) {\n          int idx = indirect[i];\n          int tnum = (int)sorted[idx];\n          final String label = getReadableValue(getTermValue(te, tnum), ft, charsRef);\n          \r\n          res.setName(idx - sortedIdxStart, label);\n        }\n\n      } else {\n        \r\n        int i=startTerm;\n        if (mincount<=0) {\n          \r\n          \r\n          i=startTerm+off;\n          off=0;\n        }\n\n        for (; i<endTerm; i++) {\n          int c = doNegative ? maxTermCounts[i] - counts[i] : counts[i];\n          if (c<mincount || --off>=0) continue;\n          if (--lim<0) break;\n\n          final String label = getReadableValue(getTermValue(te, i), ft, charsRef);\n          res.add(label, c);\n        }\n      }\n    }\n\n\n    if (missing) {\n      \r\n      res.add(null, SimpleFacets.getFieldMissingCount(searcher, baseDocs, field));\n    }\n\n    \r\n\n    return res;\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":307,"status":"M"},{"authorDate":"2015-03-28 08:02:40","commitOrder":3,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (processor.allBucketsSlot >= 0) {\n            processor.collect(intersection, processor.allBucketsSlot);\n            processor.countAcc.incrementCount(processor.allBucketsSlot, collected);\n          }\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2015-03-28 08:02:40","endLine":541,"groupId":"29815","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d2/39918475e890267e0de5056ef792a9d5fa0874.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (processor.allBucketsSlot >= 0) {\n            processor.collect(intersection, processor.allBucketsSlot);\n            processor.countAcc.incrementCount(processor.allBucketsSlot, collected);\n          }\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":427,"status":"N"}],"commitId":"fb63b4c3db53ead91b5b0f19e35bf484f9ef0525","commitMessage":"@@@SOLR-7519: SlotAcc resize ability with Resizer\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1678522 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-05-10 04:50:55","modifiedFileCount":"6","status":"M","submitter":"Yonik Seeley"},{"authorTime":"2015-07-10 09:44:47","codes":[{"authorDate":"2015-07-10 09:44:47","commitOrder":4,"curCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2015-07-10 09:44:47","endLine":392,"groupId":"61456","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    if (processor.allBucketsSlot >= 0) {\n      int all = 0;  \r\n      for (int i=0; i<numTermsInField; i++) {\n        all += counts.getCount(i);\n      }\n      counts.incrementCount(processor.allBucketsSlot, all);\n    }\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"M"},{"authorDate":"2015-07-10 09:44:47","commitOrder":4,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              countAcc.incrementCount(arrIdx, 1);\n              processor.collectFirstPhase(segDoc, arrIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2015-07-10 09:44:47","endLine":510,"groupId":"29817","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (processor.allBucketsSlot >= 0) {\n            processor.collect(intersection, processor.allBucketsSlot);\n            processor.countAcc.incrementCount(processor.allBucketsSlot, collected);\n          }\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"M"}],"commitId":"eff521bcd760c1b27a51cc52d5fef0c9d059db69","commitMessage":"@@@SOLR-7455: defer non-sorting facet stats\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1690189 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-07-10 09:44:47","modifiedFileCount":"7","status":"M","submitter":"Yonik Seeley"},{"authorTime":"2016-03-06 07:47:11","codes":[{"authorDate":"2015-07-10 09:44:47","commitOrder":5,"curCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2015-07-10 09:44:47","endLine":392,"groupId":"61456","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"N"},{"authorDate":"2016-03-06 07:47:11","commitOrder":5,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2016-03-06 07:47:33","endLine":516,"groupId":"29817","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/c1/613cde680eec00eb538e698d61c5097c7dab33.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              countAcc.incrementCount(arrIdx, 1);\n              processor.collectFirstPhase(segDoc, arrIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":412,"status":"M"}],"commitId":"85557261431f9314253ebe282eb6d400bf7cae03","commitMessage":"@@@SOLR-8155: fix UnInvertedField.collectDocsGeneric.  used for facet.prefix or non-count sorting\n","date":"2016-03-06 07:47:33","modifiedFileCount":"6","status":"M","submitter":"yonik"},{"authorTime":"2016-08-20 19:36:01","codes":[{"authorDate":"2016-08-20 19:36:01","commitOrder":6,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2016-08-20 19:36:01","endLine":396,"groupId":"61456","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ad/3baf01bc903b55c0e6b8e646b405c3013d3fdc.src","preCode":"  private void getCounts(FacetFieldProcessorUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":308,"status":"M"},{"authorDate":"2016-08-20 19:36:01","commitOrder":6,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2016-08-20 19:36:01","endLine":515,"groupId":"29817","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ad/3baf01bc903b55c0e6b8e646b405c3013d3fdc.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":411,"status":"M"}],"commitId":"e325973119eae1fe8b7a81d505680952ec08964f","commitMessage":"@@@Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/lucene-solr\n","date":"2016-08-20 19:36:01","modifiedFileCount":"105","status":"M","submitter":"Karl Wright"},{"authorTime":"2017-08-22 21:12:38","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":7,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2017-08-22 21:12:38","endLine":400,"groupId":"34174","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0xff) == 1) {\n          int pos = code >>> 8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":312,"status":"M"},{"authorDate":"2017-08-22 21:12:38","commitOrder":7,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2017-08-22 21:12:38","endLine":519,"groupId":"14349","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":415,"status":"M"}],"commitId":"85b89d15a89802d3bf6fbeac6bd55286028dc8e0","commitMessage":"@@@SOLR-11240: Raise UnInvertedField internal limit\n","date":"2017-08-22 21:12:38","modifiedFileCount":"3","status":"M","submitter":"Toke Eskildsen"},{"authorTime":"2018-02-26 14:13:26","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":8,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2017-08-22 21:12:38","endLine":400,"groupId":"34174","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":312,"status":"N"},{"authorDate":"2018-02-26 14:13:26","commitOrder":8,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2018-02-26 14:13:47","endLine":517,"groupId":"14349","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/9c/395b7ec66cec0e893633d6cfa6b0ab5bdcd20a.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":415,"status":"M"}],"commitId":"6164643882f6f2bf371e53376cc9f0a2a184b150","commitMessage":"@@@SOLR-10809: Get precommit lint warnings out of Solr core\n","date":"2018-02-26 14:13:47","modifiedFileCount":"52","status":"M","submitter":"Erick Erickson"},{"authorTime":"2018-05-21 23:22:54","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":9,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2017-08-22 21:12:38","endLine":400,"groupId":"34174","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":312,"status":"N"},{"authorDate":"2018-05-21 23:22:54","commitOrder":9,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2018-05-21 23:22:54","endLine":523,"groupId":"14349","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/33/49bb2115bfb6d46729e7f8602c6bd4f480c0b6.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"M"}],"commitId":"669b9e7a5343c625e265a075c9dbf24fcbff7363","commitMessage":"@@@SOLR-9480: A new 'relatedness()' aggregate function for JSON Faceting to enable building Semantic Knowledge Graphs\n","date":"2018-05-21 23:22:54","modifiedFileCount":"26","status":"M","submitter":"Chris Hostetter"},{"authorTime":"2018-05-21 23:22:54","codes":[{"authorDate":"2020-04-10 21:46:54","commitOrder":10,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - (int) counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2020-04-10 22:00:20","endLine":406,"groupId":"34174","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/01/61d079330d30bb280d096a55bd49fb2022827d.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":318,"status":"M"},{"authorDate":"2018-05-21 23:22:54","commitOrder":10,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2018-05-21 23:22:54","endLine":523,"groupId":"14349","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/33/49bb2115bfb6d46729e7f8602c6bd4f480c0b6.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"N"}],"commitId":"36b280bd0a21952ea54c7567f037eb48dc93205a","commitMessage":"@@@SOLR-11775: return long val for facet count in json facet\n\n* Long value is returned for any count related to json facets\n  irrespective of number of shards\n","date":"2020-04-10 22:00:20","modifiedFileCount":"33","status":"M","submitter":"Munendra S N"},{"authorTime":"2020-05-21 20:59:32","codes":[{"authorDate":"2020-05-21 20:59:32","commitOrder":11,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, SlotAcc.CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - (int) counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2020-05-21 20:59:32","endLine":406,"groupId":"34174","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor@SlotAcc.CountSlotAcccounts)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/04/f88f967d1399414fe7feb7fffdb9b64b4cdb60.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - (int) counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":318,"status":"M"},{"authorDate":"2020-05-21 20:59:32","commitOrder":11,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final SlotAcc.CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2020-05-21 20:59:32","endLine":524,"groupId":"14349","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/04/f88f967d1399414fe7feb7fffdb9b64b4cdb60.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":421,"status":"M"}],"commitId":"9c066f60f1804c26db8be226429a0be046c5a4db","commitMessage":"@@@SOLR-14482: Fix or suppress warnings in solr/search/facet\n","date":"2020-05-21 20:59:32","modifiedFileCount":"57","status":"M","submitter":"Erick Erickson"},{"authorTime":"2020-07-10 09:42:37","codes":[{"authorDate":"2020-07-10 09:42:37","commitOrder":12,"curCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    SweepCountAccStruct baseCountAccStruct = SweepingCountSlotAcc.baseStructOf(processor);\n    final List<SweepCountAccStruct> others = SweepingCountSlotAcc.otherStructsOf(processor);\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet && baseCountAccStruct != null;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n      baseCountAccStruct = new SweepCountAccStruct(baseCountAccStruct, docs);\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      final int termOrd = tt.termNum;\n      Iterator<SweepCountAccStruct> othersIter = others.iterator();\n      SweepCountAccStruct entry = baseCountAccStruct != null ? baseCountAccStruct : othersIter.next();\n      for (;;) {\n        entry.countAcc.incrementCount(termOrd, searcher.numDocs(tt.termQuery, entry.docSet));\n        if (!othersIter.hasNext()) {\n          break;\n        }\n        entry = othersIter.next();\n      }\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      final SweepIteratorAndCounts iterAndCounts = SweepDocIterator.newInstance(baseCountAccStruct, others);\n      final SweepDocIterator iter = iterAndCounts.iter;\n      final SegCountGlobal counts = new SegCountGlobal(iterAndCounts.countAccs);\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int maxIdx = iter.registerCounts(counts);\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum, 1, maxIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum, 1, maxIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      final CountSlotAcc baseCounts = processor.countAcc;\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        baseCounts.incrementCount(i, maxTermCounts[i] - (int) baseCounts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","date":"2020-07-10 09:42:37","endLine":427,"groupId":"102247","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"getCounts","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ee/86fe04745ccae1f4e081a66fe16ad0b54f73b8.src","preCode":"  private void getCounts(FacetFieldProcessorByArrayUIF processor, SlotAcc.CountSlotAcc counts) throws IOException {\n    DocSet docs = processor.fcontext.base;\n    int baseSize = docs.size();\n    int maxDoc = searcher.maxDoc();\n\n    \r\n    if (baseSize < processor.effectiveMincount) {\n      return;\n    }\n\n    final int[] index = this.index;\n\n    boolean doNegative = baseSize > maxDoc >> 1 && termInstances > 0 && docs instanceof BitDocSet;\n\n    if (doNegative) {\n      FixedBitSet bs = ((BitDocSet) docs).getBits().clone();\n      bs.flip(0, maxDoc);\n      \r\n      \r\n      docs = new BitDocSet(bs, maxDoc - baseSize);\n      \r\n      \r\n    }\n\n    \r\n    for (TopTerm tt : bigTerms.values()) {\n      \r\n      counts.incrementCount(tt.termNum, searcher.numDocs(tt.termQuery, docs));\n    }\n\n    \r\n    \r\n\n    if (termInstances > 0) {\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for (; ; ) {\n            int delta = 0;\n            for (; ; ) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            counts.incrementCount(tnum,1);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (; ; ) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80) == 0) {\n              if (delta == 0) break;\n              tnum += delta - TNUM_OFFSET;\n              counts.incrementCount(tnum,1);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n    if (doNegative) {\n      for (int i=0; i<numTermsInField; i++) {\n \r\n        counts.incrementCount(i, maxTermCounts[i] - (int) counts.getCount(i)*2);\n      }\n    }\n\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":322,"status":"M"},{"authorDate":"2020-07-10 09:42:37","commitOrder":12,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n    final SweepCountAccStruct baseCountAccStruct = SweepingCountSlotAcc.baseStructOf(processor);\n    final List<SweepCountAccStruct> others = SweepingCountSlotAcc.otherStructsOf(processor);\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet termSet = searcher.getDocSet(tt.termQuery);\n        DocSet intersection = termSet.intersection(docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        final int termOrd = tt.termNum - startTermIndex;\n        countAcc.incrementCount(termOrd, collected);\n        for (SweepCountAccStruct entry : others) {\n          entry.countAcc.incrementCount(termOrd, termSet.intersectionSize(entry.docSet));\n        }\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      SweepIteratorAndCounts sweepIterAndCounts = SweepDocIterator.newInstance(baseCountAccStruct, others);\n      final SweepDocIterator iter = sweepIterAndCounts.iter;\n      final CountSlotAcc[] countAccs = sweepIterAndCounts.countAccs;\n      final SegCountGlobal counts = new SegCountGlobal(countAccs);\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int maxIdx = iter.registerCounts(counts);\n        boolean collectBase = iter.collectBase();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            counts.incrementCount(arrIdx, 1, maxIdx);\n            if (collectBase) {\n              processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                counts.incrementCount(arrIdx, 1, maxIdx);\n                if (collectBase) {\n                  processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n                }\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2020-07-10 09:42:37","endLine":561,"groupId":"102247","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ee/86fe04745ccae1f4e081a66fe16ad0b54f73b8.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final SlotAcc.CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"M"}],"commitId":"40e2122b5a5b89f446e51692ef0d72e48c7b71e5","commitMessage":"@@@SOLR-13132: JSON Facet perf improvements to support \"sweeping\" collection of \"relatedness()\"\n\nThis adds a lot of \"under the covers\" improvements to how JSON Faceting FacetField processors work.  to enable\n\"sweeping\" support when the SlotAcc used for sorting support it (currently just \"relatedness()\")\n\nThis is a squash commit of all changes on https://github.com/magibney/lucene-solr/tree/SOLR-13132\nUp to and including ca7a8e0b39840d00af9022c048346a7d84bf280d.\n\nCo-authored-by: Chris Hostetter <hossman@apache.org>\nCo-authored-by: Michael Gibney <michael@michaelgibney.net>\n","date":"2020-07-10 09:42:37","modifiedFileCount":"9","status":"M","submitter":"Michael Gibney"}]
