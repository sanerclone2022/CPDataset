[{"authorTime":"2018-01-23 20:35:14","codes":[{"authorDate":"2016-06-24 02:19:14","commitOrder":2,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n\n    docsSeed = random().nextLong();\n  }\n","date":"2016-06-24 02:19:28","endLine":139,"groupId":"63407","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/88/7ebfe79c859fec9d3819497c7308d55958ff53.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n\n    docsSeed = random().nextLong();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"NB"},{"authorDate":"2018-01-23 20:35:14","commitOrder":2,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n","date":"2018-01-23 20:35:14","endLine":138,"groupId":"63407","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/58/ac17dd1f74e18b362b4b3ea5a8e2a6f6b8e7d3.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"B"}],"commitId":"653935bbdfd70fa9490f8c363ffcf9832d3141a5","commitMessage":"@@@Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/lucene-solr\n","date":"2018-01-23 20:35:14","modifiedFileCount":"279","status":"M","submitter":"Karl Wright"},{"authorTime":"2019-02-21 05:24:46","codes":[{"authorDate":"2016-06-24 02:19:14","commitOrder":3,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n\n    docsSeed = random().nextLong();\n  }\n","date":"2016-06-24 02:19:28","endLine":139,"groupId":"63407","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/88/7ebfe79c859fec9d3819497c7308d55958ff53.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n\n    docsSeed = random().nextLong();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"N"},{"authorDate":"2019-02-21 05:24:46","commitOrder":3,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n","date":"2019-02-21 05:24:46","endLine":146,"groupId":"63407","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/c7/963941e4301b2c4e877bd623328bcfe65b0bdf.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"M"}],"commitId":"bcd90f15613a14a1c619c999bac4a591c50c5ad1","commitMessage":"@@@SOLR-12708: CREATE collection request doesn't fail or cleanup when the request fails (#568)\n\nWhen performing an async CREATE requests.  responses to internal requests are also included inside the \"success\" or \"failed\" elements of the general response. This will make the operation cleanup in case of failure.  the same way as we do when the request is synchronous.\n","date":"2019-02-21 05:24:46","modifiedFileCount":"10","status":"M","submitter":"Tomas Fernandez Lobbe"},{"authorTime":"2019-03-13 01:06:19","codes":[{"authorDate":"2019-03-13 01:06:19","commitOrder":4,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n    \n    docsSeed = random().nextLong();\n  }\n","date":"2019-03-19 03:25:36","endLine":141,"groupId":"63407","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/f5/1c4acfd3ca5898652b978a9b5890502d60b57e.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n    \n    docsSeed = random().nextLong();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"M"},{"authorDate":"2019-03-13 01:06:19","commitOrder":4,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n","date":"2019-03-19 03:25:36","endLine":145,"groupId":"63407","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/0d/876db58132e67d290720e3c0703390d165f45a.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"M"}],"commitId":"cf828163bdfa010c87f1171b6919e444bd0ff01c","commitMessage":"@@@SOLR-13330: Improve HDFS tests\n\nRelated JIRAs:\n* SOLR-11010\n* SOLR-11381\n* SOLR-12040\n* SOLR-13297\n\nChanges:\n* Consolidate hdfs configuration into HdfsTestUtil\n* Ensure socketTimeout long enough for HDFS tests\n* Ensure HdfsTestUtil.getClientConfiguration used in tests\n* Replace deprecated HDFS calls\n* Use try-with-resources to ensure closing of HDFS resources\n\nSigned-off-by: Kevin Risden <krisden@apache.org>\n","date":"2019-03-19 03:25:36","modifiedFileCount":"23","status":"M","submitter":"Kevin Risden"},{"authorTime":"2021-04-04 03:55:56","codes":[{"authorDate":"2019-03-13 01:06:19","commitOrder":5,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n    \n    docsSeed = random().nextLong();\n  }\n","date":"2019-03-19 03:25:36","endLine":141,"groupId":"103366","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/f5/1c4acfd3ca5898652b978a9b5890502d60b57e.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(1)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(HDFS_REPO_SOLR_XML)\n    .configure();\n    \n    docsSeed = random().nextLong();\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/TestHdfsBackupRestoreCore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2021-04-04 03:55:56","commitOrder":5,"curCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-subdirs\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-subdirs\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigSetService.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n","date":"2021-04-04 03:55:56","endLine":149,"groupId":"103366","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"setupClass","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/da/e02d4db79ca1f98a8c83f15b83c33a3313443b.src","preCode":"  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        \r\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            \r\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)\r\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"}],"commitId":"1a922dc99aa252177f361a9832f901a9fdf55fb0","commitMessage":"@@@SOLR-15258: ConfigSetService add CRUD operations.  subsume ZkConfigManager (#23)\n\nTo allow for viable alternative implementations of where ConfigSets come from.\n\nCo-authored-by: Nazerke Seidan <nseidan@salesforce.com>\nCo-authored-by: David Smiley <dsmiley@salesforce.com>","date":"2021-04-04 03:55:56","modifiedFileCount":"46","status":"M","submitter":"Nazerke Seidan"}]
