[{"authorTime":"2017-03-28 11:53:55","codes":[{"authorDate":"2013-04-22 22:26:55","commitOrder":5,"curCode":"  public void testCharFilterAnalysis() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"charfilthtmlmap\");\n    request.setFieldValue(\"<html><body>wh������t������v������r</body></html>\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"charfilthtmlmap\");\n    assertNotNull(\"expecting result for field type 'charfilthtmlmap'\", textType);\n\n    NamedList indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'charfilthtmlmap'\", indexPart);\n    \n    assertEquals(\"\\n\\nwh������t������v������r\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.HTMLStripCharFilter\"));\n    assertEquals(\"\\n\\nwhatever\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.MappingCharFilter\"));\n\n    List<NamedList> tokenList = (List<NamedList>)indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(tokenList.size(), 1);\n    assertToken(tokenList.get(0), new TokenInfo(\"whatever\", null, \"word\", 12, 20, 1, new int[]{1}, null, false));\n  }\n","date":"2013-04-22 22:26:55","endLine":335,"groupId":"43613","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCharFilterAnalysis","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/43/18bcc8d45affbe06d426faeabf81eb4455e231.src","preCode":"  public void testCharFilterAnalysis() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"charfilthtmlmap\");\n    request.setFieldValue(\"<html><body>wh������t������v������r</body></html>\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"charfilthtmlmap\");\n    assertNotNull(\"expecting result for field type 'charfilthtmlmap'\", textType);\n\n    NamedList indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'charfilthtmlmap'\", indexPart);\n    \n    assertEquals(\"\\n\\nwh������t������v������r\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.HTMLStripCharFilter\"));\n    assertEquals(\"\\n\\nwhatever\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.MappingCharFilter\"));\n\n    List<NamedList> tokenList = (List<NamedList>)indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(tokenList.size(), 1);\n    assertToken(tokenList.get(0), new TokenInfo(\"whatever\", null, \"word\", 12, 20, 1, new int[]{1}, null, false));\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"NB"},{"authorDate":"2017-03-28 11:53:55","commitOrder":5,"curCode":"  public void testPositionHistoryWithWDGF() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"skutype1\");\n    request.setFieldValue(\"hi, 3456-12 a Test\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"skutype1\");\n    assertNotNull(\"expecting result for field type 'skutype1'\", textType);\n\n    NamedList<List<NamedList>> indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'skutype1'\", indexPart);\n\n    List<NamedList> tokenList = indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expcting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi,\", null, \"word\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"3456-12\", null, \"word\", 4, 11, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"a\", null, \"word\", 12, 13, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Test\", null, \"word\", 14, 18, 4, new int[]{4}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.miscellaneous.WordDelimiterGraphFilter\");\n    assertNotNull(\"Expcting WordDelimiterGraphFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Test\", null, \"word\", 14, 18, 5, new int[]{4,5}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expcting LowerCaseFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"test\", null, \"word\", 14, 18, 5, new int[]{4,5,5}, null, false));\n  }\n","date":"2017-03-28 11:53:55","endLine":428,"groupId":"3508","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testPositionHistoryWithWDGF","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/fc/0f6bedbedc893cd7abada260560c24ad542603.src","preCode":"  public void testPositionHistoryWithWDGF() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"skutype1\");\n    request.setFieldValue(\"hi, 3456-12 a Test\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"skutype1\");\n    assertNotNull(\"expecting result for field type 'skutype1'\", textType);\n\n    NamedList<List<NamedList>> indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'skutype1'\", indexPart);\n\n    List<NamedList> tokenList = indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expcting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi,\", null, \"word\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"3456-12\", null, \"word\", 4, 11, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"a\", null, \"word\", 12, 13, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Test\", null, \"word\", 14, 18, 4, new int[]{4}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.miscellaneous.WordDelimiterGraphFilter\");\n    assertNotNull(\"Expcting WordDelimiterGraphFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Test\", null, \"word\", 14, 18, 5, new int[]{4,5}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expcting LowerCaseFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"test\", null, \"word\", 14, 18, 5, new int[]{4,5,5}, null, false));\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":385,"status":"B"}],"commitId":"b46b8278c60102eeaeb45dddf239356746da7de8","commitMessage":"@@@SOLR-10344: Update Solr default/example and test configs to use WordDelimiterGraphFilterFactory\n","date":"2017-03-28 11:53:55","modifiedFileCount":"4","status":"M","submitter":"Steve Rowe"},{"authorTime":"2020-06-18 05:51:41","codes":[{"authorDate":"2020-06-18 05:51:41","commitOrder":6,"curCode":"  public void testCharFilterAnalysis() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"charfilthtmlmap\");\n    request.setFieldValue(\"<html><body>wh������t������v������r</body></html>\");\n    request.setShowMatch(false);\n\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    NamedList<NamedList> textType = fieldTypes.get(\"charfilthtmlmap\");\n    assertNotNull(\"expecting result for field type 'charfilthtmlmap'\", textType);\n\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'charfilthtmlmap'\", indexPart);\n\n    assertEquals(\"\\n\\nwh������t������v������r\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.HTMLStripCharFilter\"));\n    assertEquals(\"\\n\\nwhatever\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.MappingCharFilter\"));\n\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    List<NamedList> tokenList = (List<NamedList>)indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(tokenList.size(), 1);\n    assertToken(tokenList.get(0), new TokenInfo(\"whatever\", null, \"word\", 12, 20, 1, new int[]{1}, null, false));\n  }\n","date":"2020-06-18 05:51:41","endLine":392,"groupId":"103457","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testCharFilterAnalysis","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/4d/905e2c5b68b6e91834b09c7e840a4749b85f43.src","preCode":"  public void testCharFilterAnalysis() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"charfilthtmlmap\");\n    request.setFieldValue(\"<html><body>wh������t������v������r</body></html>\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"charfilthtmlmap\");\n    assertNotNull(\"expecting result for field type 'charfilthtmlmap'\", textType);\n\n    NamedList indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'charfilthtmlmap'\", indexPart);\n\n    assertEquals(\"\\n\\nwh������t������v������r\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.HTMLStripCharFilter\"));\n    assertEquals(\"\\n\\nwhatever\\n\\n\", indexPart.get(\"org.apache.lucene.analysis.charfilter.MappingCharFilter\"));\n\n    List<NamedList> tokenList = (List<NamedList>)indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(tokenList.size(), 1);\n    assertToken(tokenList.get(0), new TokenInfo(\"whatever\", null, \"word\", 12, 20, 1, new int[]{1}, null, false));\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":362,"status":"M"},{"authorDate":"2020-06-18 05:51:41","commitOrder":6,"curCode":"  public void testPositionHistoryWithWDGF() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"skutype1\");\n    request.setFieldValue(\"hi, 3456-12 a Test\");\n    request.setShowMatch(false);\n\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    NamedList<NamedList> textType = fieldTypes.get(\"skutype1\");\n    assertNotNull(\"expecting result for field type 'skutype1'\", textType);\n\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    NamedList<List<NamedList>> indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'skutype1'\", indexPart);\n\n    @SuppressWarnings({\"rawtypes\"})\n    List<NamedList> tokenList = indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expcting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi,\", null, \"word\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"3456-12\", null, \"word\", 4, 11, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"a\", null, \"word\", 12, 13, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Test\", null, \"word\", 14, 18, 4, new int[]{4}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.miscellaneous.WordDelimiterGraphFilter\");\n    assertNotNull(\"Expcting WordDelimiterGraphFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Test\", null, \"word\", 14, 18, 5, new int[]{4,5}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expcting LowerCaseFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"test\", null, \"word\", 14, 18, 5, new int[]{4,5,5}, null, false));\n  }\n","date":"2020-06-18 05:51:41","endLine":443,"groupId":"103457","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testPositionHistoryWithWDGF","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/4d/905e2c5b68b6e91834b09c7e840a4749b85f43.src","preCode":"  public void testPositionHistoryWithWDGF() throws Exception {\n\n    FieldAnalysisRequest request = new FieldAnalysisRequest();\n    request.addFieldType(\"skutype1\");\n    request.setFieldValue(\"hi, 3456-12 a Test\");\n    request.setShowMatch(false);\n\n    NamedList<NamedList> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n\n    NamedList<NamedList> fieldTypes = result.get(\"field_types\");\n    assertNotNull(\"field_types should never be null\", fieldTypes);\n    NamedList<NamedList> textType = fieldTypes.get(\"skutype1\");\n    assertNotNull(\"expecting result for field type 'skutype1'\", textType);\n\n    NamedList<List<NamedList>> indexPart = textType.get(\"index\");\n    assertNotNull(\"expecting an index token analysis for field type 'skutype1'\", indexPart);\n\n    List<NamedList> tokenList = indexPart.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expcting MockTokenizer analysis breakdown\", tokenList);\n    assertEquals(4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi,\", null, \"word\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"3456-12\", null, \"word\", 4, 11, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"a\", null, \"word\", 12, 13, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Test\", null, \"word\", 14, 18, 4, new int[]{4}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.miscellaneous.WordDelimiterGraphFilter\");\n    assertNotNull(\"Expcting WordDelimiterGraphFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Test\", null, \"word\", 14, 18, 5, new int[]{4,5}, null, false));\n    tokenList = indexPart.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expcting LowerCaseFilter analysis breakdown\", tokenList);\n    assertEquals(6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"hi\", null, \"word\", 0, 2, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"345612\", null, \"word\", 4, 11, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"3456\", null, \"word\", 4, 8, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"12\", null, \"word\", 9, 11, 3, new int[]{2,3,3}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4,4}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"test\", null, \"word\", 14, 18, 5, new int[]{4,5,5}, null, false));\n  }\n","realPath":"solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":395,"status":"M"}],"commitId":"b01e249c9ec724b6df120a5d731020cfe4de3fce","commitMessage":"@@@SOLR-14574: Fix or suppress warnings in solr/core/src/test (part 1)\n","date":"2020-06-18 05:51:41","modifiedFileCount":"213","status":"M","submitter":"Erick Erickson"}]
