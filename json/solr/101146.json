[{"authorTime":"2017-03-03 02:18:16","codes":[{"authorDate":"2017-12-16 00:24:18","commitOrder":5,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              resolvedDest = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolvedDest)) {\n                destField = doc.getField(resolvedDest);\n              } else {\n                SolrInputField targetField = destMap.get(resolvedDest);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolvedDest);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolvedDest, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2017-12-16 00:24:18","endLine":565,"groupId":"29907","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d0/0df2bcba1bbb9e9fe080ca40b2f84ee6c32ebf.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              resolvedDest = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolvedDest)) {\n                destField = doc.getField(resolvedDest);\n              } else {\n                SolrInputField targetField = destMap.get(resolvedDest);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolvedDest);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolvedDest, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":443,"status":"B"},{"authorDate":"2017-03-03 02:18:16","commitOrder":5,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (String dest : destMap.keySet()) {\n          doc.put(dest, destMap.get(dest));\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2017-03-03 02:18:16","endLine":465,"groupId":"46315","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/2f/fc5b9ff597de1075e95fe4042dd7f5a5232956.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (String dest : destMap.keySet()) {\n          doc.put(dest, destMap.get(dest));\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":408,"status":"NB"}],"commitId":"3e2f9e62d772218bf1fcae6d58542fad3ec43742","commitMessage":"@@@LUCENE-2899: Add OpenNLP Analysis capabilities as a module\n","date":"2017-12-16 00:24:18","modifiedFileCount":"3","status":"M","submitter":"Steve Rowe"},{"authorTime":"2017-03-03 02:18:16","codes":[{"authorDate":"2018-07-23 15:58:46","commitOrder":6,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2018-07-23 15:58:46","endLine":571,"groupId":"28478","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d6/9c367f1b74ddb6a0eca83f57d25029b0b25acb.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              resolvedDest = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolvedDest)) {\n                destField = doc.getField(resolvedDest);\n              } else {\n                SolrInputField targetField = destMap.get(resolvedDest);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolvedDest);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolvedDest, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"M"},{"authorDate":"2017-03-03 02:18:16","commitOrder":6,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (String dest : destMap.keySet()) {\n          doc.put(dest, destMap.get(dest));\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2017-03-03 02:18:16","endLine":465,"groupId":"46315","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/2f/fc5b9ff597de1075e95fe4042dd7f5a5232956.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (String dest : destMap.keySet()) {\n          doc.put(dest, destMap.get(dest));\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":408,"status":"N"}],"commitId":"995a902d1ad40860ee082b57e4e47c1be52c856e","commitMessage":"@@@SOLR-12570: OpenNLPExtractNamedEntitiesUpdateProcessor cannot support multi fields because pattern replacement doesn't work correctly\n","date":"2018-07-23 15:58:46","modifiedFileCount":"2","status":"M","submitter":"koji"},{"authorTime":"2019-10-15 00:36:19","codes":[{"authorDate":"2018-07-23 15:58:46","commitOrder":7,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2018-07-23 15:58:46","endLine":571,"groupId":"28478","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d6/9c367f1b74ddb6a0eca83f57d25029b0b25acb.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"N"},{"authorDate":"2019-10-15 00:36:19","commitOrder":7,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2019-10-15 00:36:19","endLine":467,"groupId":"46315","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/f0/f3308904d0e63e9d9617d8ff6e44a08edd89dc.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (String dest : destMap.keySet()) {\n          doc.put(dest, destMap.get(dest));\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"M"}],"commitId":"04786244d0ae37eef88948c7fdfb5ccb84ca47da","commitMessage":"@@@LUCENE-8979: Code Cleanup: Use entryset for map iteration wherever possible. - part 2\n\n","date":"2019-10-15 00:36:19","modifiedFileCount":"38","status":"M","submitter":"Koen De Groote"},{"authorTime":"2020-04-21 09:08:15","codes":[{"authorDate":"2018-07-23 15:58:46","commitOrder":8,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2018-07-23 15:58:46","endLine":571,"groupId":"28478","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d6/9c367f1b74ddb6a0eca83f57d25029b0b25acb.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"N"},{"authorDate":"2020-04-21 09:08:15","commitOrder":8,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate('{}') returned true, \" +\n                    \"but replacement pattern did not match, field skipped.\", fname);\n              }\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2020-04-21 09:08:15","endLine":469,"groupId":"0","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/e2/b7a58d2d60f4a98d3c94fb6a32d19074a9ee5b.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"M"}],"commitId":"c94770c2b9c00ccdc2d617d595d62f85a332dc0c","commitMessage":"@@@LUCENE-7788: fail precommit on unparameterised log messages and examine for wasted work/objects\n","date":"2020-04-21 09:08:15","modifiedFileCount":"38","status":"M","submitter":"Erick Erickson"},{"authorTime":"2020-04-23 10:32:49","codes":[{"authorDate":"2018-07-23 15:58:46","commitOrder":9,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2018-07-23 15:58:46","endLine":571,"groupId":"28478","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d6/9c367f1b74ddb6a0eca83f57d25029b0b25acb.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"N"},{"authorDate":"2020-04-23 10:32:49","commitOrder":9,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate('{}') returned true, but replacement pattern did not match, field skipped.\"\n                    , fname);\n              }\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2020-04-23 10:32:49","endLine":469,"groupId":"37685","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/3c/ffc11479a8e9b0cbc14918d9fb944f1a372bb7.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate('{}') returned true, \" +\n                    \"but replacement pattern did not match, field skipped.\", fname);\n              }\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"M"}],"commitId":"e43b17962a116111af4348cf7548ee2e7a2375b8","commitMessage":"@@@LUCENE-7788: fail precommit on unparameterised log messages and examine for wasted work/objects\n","date":"2020-04-23 10:32:49","modifiedFileCount":"102","status":"M","submitter":"Erick Erickson"},{"authorTime":"2020-04-23 10:32:49","codes":[{"authorDate":"2020-05-02 01:06:57","commitOrder":10,"curCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate('{}') returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","date":"2020-05-02 01:06:57","endLine":571,"groupId":"101146","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/34/14d156207ff4a120908a514c28c70358cbffef.src","preCode":"  public final UpdateRequestProcessor getInstance\n      (SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      private final NLPNERTaggerOp nerTaggerOp;\n      private Analyzer analyzer = null;\n      {\n        try {\n          nerTaggerOp = OpenNLPOpsFactory.getNERTagger(modelFile);\n          FieldType fieldType = req.getSchema().getFieldTypeByName(analyzerFieldType);\n          if (fieldType == null) {\n            throw new SolrException\n                (SERVER_ERROR, ANALYZER_FIELD_TYPE_PARAM + \" '\" + analyzerFieldType + \"' not found in the schema.\");\n          }\n          analyzer = fieldType.getIndexAnalyzer();\n        } catch (IOException e) {\n          throw new IllegalArgumentException(e);\n        }\n      }\n\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if ( ! srcSelector.shouldMutate(fname)) continue;\n\n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if (srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n\n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              log.debug(\"srcSelector.shouldMutate(\\\"{}\\\") returned true, \" +\n                  \"but replacement pattern did not match, field skipped.\", fname);\n              continue;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            for (Pair<String,String> entity : extractTypedNamedEntities(val)) {\n              SolrInputField destField = null;\n              String entityName = entity.first();\n              String entityType = entity.second();\n              final String resolved = resolvedDest.replace(ENTITY_TYPE, entityType);\n              if (doc.containsKey(resolved)) {\n                destField = doc.getField(resolved);\n              } else {\n                SolrInputField targetField = destMap.get(resolved);\n                if (targetField == null) {\n                  destField = new SolrInputField(resolved);\n                } else {\n                  destField = targetField;\n                }\n              }\n              destField.addValue(entityName);\n\n              \r\n              destMap.put(resolved, destField);\n            }\n          }\n        }\n\n        for (Map.Entry<String,SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n\n      \n      private List<Pair<String,String>> extractTypedNamedEntities(Object srcFieldValue) throws IOException {\n        List<Pair<String,String>> entitiesWithType = new ArrayList<>();\n        List<String> terms = new ArrayList<>();\n        List<Integer> startOffsets = new ArrayList<>();\n        List<Integer> endOffsets = new ArrayList<>();\n        String fullText = srcFieldValue.toString();\n        TokenStream tokenStream = analyzer.tokenStream(\"\", fullText);\n        CharTermAttribute termAtt = tokenStream.addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);\n        FlagsAttribute flagsAtt = tokenStream.addAttribute(FlagsAttribute.class);\n        tokenStream.reset();\n        synchronized (nerTaggerOp) {\n          while (tokenStream.incrementToken()) {\n            terms.add(termAtt.toString());\n            startOffsets.add(offsetAtt.startOffset());\n            endOffsets.add(offsetAtt.endOffset());\n            boolean endOfSentence = 0 != (flagsAtt.getFlags() & OpenNLPTokenizer.EOS_FLAG_BIT);\n            if (endOfSentence) {    \r\n              extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n            }\n          }\n          tokenStream.end();\n          tokenStream.close();\n          if (!terms.isEmpty()) { \r\n            extractEntitiesFromSentence(fullText, terms, startOffsets, endOffsets, entitiesWithType);\n          }\n          nerTaggerOp.reset();      \r\n        }\n        return entitiesWithType;\n      }\n\n      private void extractEntitiesFromSentence(String fullText, List<String> terms, List<Integer> startOffsets,\n                                               List<Integer> endOffsets, List<Pair<String,String>> entitiesWithType) {\n        for (Span span : nerTaggerOp.getNames(terms.toArray(new String[terms.size()]))) {\n          String text = fullText.substring(startOffsets.get(span.getStart()), endOffsets.get(span.getEnd() - 1));\n          entitiesWithType.add(new Pair<>(text, span.getType()));\n        }\n        terms.clear();\n        startOffsets.clear();\n        endOffsets.clear();\n      }\n    };\n  }\n","realPath":"solr/contrib/analysis-extras/src/java/org/apache/solr/update/processor/OpenNLPExtractNamedEntitiesUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"M"},{"authorDate":"2020-04-23 10:32:49","commitOrder":10,"curCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate('{}') returned true, but replacement pattern did not match, field skipped.\"\n                    , fname);\n              }\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","date":"2020-04-23 10:32:49","endLine":469,"groupId":"101146","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"getInstance","params":"(SolrQueryRequestreq@SolrQueryResponsersp@UpdateRequestProcessornext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/3c/ffc11479a8e9b0cbc14918d9fb944f1a372bb7.src","preCode":"  public final UpdateRequestProcessor getInstance(SolrQueryRequest req,\n                                                  SolrQueryResponse rsp,\n                                                  UpdateRequestProcessor next) {\n    final FieldNameSelector srcSelector = getSourceSelector();\n    return new UpdateRequestProcessor(next) {\n      @Override\n      public void processAdd(AddUpdateCommand cmd) throws IOException {\n\n        final SolrInputDocument doc = cmd.getSolrInputDocument();\n\n        \r\n        Map<String,SolrInputField> destMap = new HashMap<>();\n\n        \r\n        for (final String fname : doc.getFieldNames()) {\n          if (! srcSelector.shouldMutate(fname)) continue;\n          \n          Collection<Object> srcFieldValues = doc.getFieldValues(fname);\n          if(srcFieldValues == null || srcFieldValues.isEmpty()) continue;\n          \n          String resolvedDest = dest;\n\n          if (pattern != null) {\n            Matcher matcher = pattern.matcher(fname);\n            if (matcher.find()) {\n              resolvedDest = matcher.replaceAll(dest);\n            } else {\n              if (log.isDebugEnabled()) {\n                log.debug(\"CloneFieldUpdateProcessor.srcSelector.shouldMutate('{}') returned true, but replacement pattern did not match, field skipped.\"\n                    , fname);\n              }\n              continue;\n            }\n          }\n          SolrInputField destField;\n          if (doc.containsKey(resolvedDest)) {\n            destField = doc.getField(resolvedDest);\n          } else {\n            SolrInputField targetField = destMap.get(resolvedDest);\n            if (targetField == null) {\n              destField = new SolrInputField(resolvedDest);\n            } else {\n              destField = targetField;\n            }\n          }\n\n          for (Object val : srcFieldValues) {\n            destField.addValue(val);\n          }\n          \r\n          destMap.put(resolvedDest, destField);\n        }\n\n        for (Map.Entry<String, SolrInputField> entry : destMap.entrySet()) {\n          doc.put(entry.getKey(), entry.getValue());\n        }\n        super.processAdd(cmd);\n      }\n    };\n  }\n","realPath":"solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"N"}],"commitId":"217c2faa2cd7b540d8e9933355dbd878a4d32057","commitMessage":"@@@LUCENE-7788: fail precommit on unparameterised log messages and examine for wasted work/objects\n","date":"2020-05-02 01:06:57","modifiedFileCount":"11","status":"M","submitter":"Erick Erickson"}]
