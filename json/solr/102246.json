[{"authorTime":"2015-07-10 09:44:47","codes":[{"authorDate":"2015-07-10 09:44:47","commitOrder":2,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2015-07-10 09:44:47","endLine":288,"groupId":"29817","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":253,"status":"B"},{"authorDate":"2015-07-10 09:44:47","commitOrder":2,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              countAcc.incrementCount(arrIdx, 1);\n              processor.collectFirstPhase(segDoc, arrIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2015-07-10 09:44:47","endLine":510,"groupId":"29817","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              countAcc.incrementCount(arrIdx, 1);\n              processor.collectFirstPhase(segDoc, arrIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"MB"}],"commitId":"eff521bcd760c1b27a51cc52d5fef0c9d059db69","commitMessage":"@@@SOLR-7455: defer non-sorting facet stats\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1690189 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-07-10 09:44:47","modifiedFileCount":"7","status":"M","submitter":"Yonik Seeley"},{"authorTime":"2016-03-06 07:47:11","codes":[{"authorDate":"2015-07-10 09:44:47","commitOrder":3,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2015-07-10 09:44:47","endLine":288,"groupId":"29817","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":253,"status":"N"},{"authorDate":"2016-03-06 07:47:11","commitOrder":3,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2016-03-06 07:47:33","endLine":516,"groupId":"29817","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/c1/613cde680eec00eb538e698d61c5097c7dab33.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              countAcc.incrementCount(arrIdx, 1);\n              processor.collectFirstPhase(segDoc, arrIdx);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":412,"status":"M"}],"commitId":"85557261431f9314253ebe282eb6d400bf7cae03","commitMessage":"@@@SOLR-8155: fix UnInvertedField.collectDocsGeneric.  used for facet.prefix or non-count sorting\n","date":"2016-03-06 07:47:33","modifiedFileCount":"6","status":"M","submitter":"yonik"},{"authorTime":"2016-08-20 19:36:01","codes":[{"authorDate":"2015-07-10 09:44:47","commitOrder":4,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2015-07-10 09:44:47","endLine":288,"groupId":"29817","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/d4/a738c168812d14b21dc33a7e94b95bb5585c2c.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":253,"status":"N"},{"authorDate":"2016-08-20 19:36:01","commitOrder":4,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2016-08-20 19:36:01","endLine":515,"groupId":"29817","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ad/3baf01bc903b55c0e6b8e646b405c3013d3fdc.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":411,"status":"M"}],"commitId":"e325973119eae1fe8b7a81d505680952ec08964f","commitMessage":"@@@Merge branch 'master' of https://git-wip-us.apache.org/repos/asf/lucene-solr\n","date":"2016-08-20 19:36:01","modifiedFileCount":"105","status":"M","submitter":"Karl Wright"},{"authorTime":"2017-08-22 21:12:38","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":5,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2017-08-22 21:12:38","endLine":296,"groupId":"29817","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"M"},{"authorDate":"2017-08-22 21:12:38","commitOrder":5,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2017-08-22 21:12:38","endLine":519,"groupId":"14349","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":415,"status":"M"}],"commitId":"85b89d15a89802d3bf6fbeac6bd55286028dc8e0","commitMessage":"@@@SOLR-11240: Raise UnInvertedField internal limit\n","date":"2017-08-22 21:12:38","modifiedFileCount":"3","status":"M","submitter":"Toke Eskildsen"},{"authorTime":"2018-02-26 14:13:26","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":6,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2017-08-22 21:12:38","endLine":296,"groupId":"29817","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"N"},{"authorDate":"2018-02-26 14:13:26","commitOrder":6,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2018-02-26 14:13:47","endLine":517,"groupId":"14349","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/9c/395b7ec66cec0e893633d6cfa6b0ab5bdcd20a.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        try ( DocSet intersection = searcher.getDocSet(tt.termQuery, docs); )\n        {\n          int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n          countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":415,"status":"M"}],"commitId":"6164643882f6f2bf371e53376cc9f0a2a184b150","commitMessage":"@@@SOLR-10809: Get precommit lint warnings out of Solr core\n","date":"2018-02-26 14:13:47","modifiedFileCount":"52","status":"M","submitter":"Erick Erickson"},{"authorTime":"2018-05-21 23:22:54","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":7,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2017-08-22 21:12:38","endLine":296,"groupId":"29817","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"N"},{"authorDate":"2018-05-21 23:22:54","commitOrder":7,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2018-05-21 23:22:54","endLine":523,"groupId":"14349","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/33/49bb2115bfb6d46729e7f8602c6bd4f480c0b6.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex);\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"M"}],"commitId":"669b9e7a5343c625e265a075c9dbf24fcbff7363","commitMessage":"@@@SOLR-9480: A new 'relatedness()' aggregate function for JSON Faceting to enable building Semantic Knowledge Graphs\n","date":"2018-05-21 23:22:54","modifiedFileCount":"26","status":"M","submitter":"Chris Hostetter"},{"authorTime":"2020-05-21 20:59:32","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":8,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2017-08-22 21:12:38","endLine":296,"groupId":"29817","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"N"},{"authorDate":"2020-05-21 20:59:32","commitOrder":8,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final SlotAcc.CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2020-05-21 20:59:32","endLine":524,"groupId":"14349","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/04/f88f967d1399414fe7feb7fffdb9b64b4cdb60.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":421,"status":"M"}],"commitId":"9c066f60f1804c26db8be226429a0be046c5a4db","commitMessage":"@@@SOLR-14482: Fix or suppress warnings in solr/search/facet\n","date":"2020-05-21 20:59:32","modifiedFileCount":"57","status":"M","submitter":"Erick Erickson"},{"authorTime":"2020-07-10 09:42:37","codes":[{"authorDate":"2017-08-22 21:12:38","commitOrder":9,"curCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","date":"2017-08-22 21:12:38","endLine":296,"groupId":"102246","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"getSmallTerms","params":"(intdoc@Callbacktarget)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/17/54175cb3a15a0bf599cb94bf8e141d5292dad5.src","preCode":"    public void getSmallTerms(int doc, Callback target) {\n      if (termInstances > 0) {\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            target.call(tnum);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              target.call(tnum);\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"N"},{"authorDate":"2020-07-10 09:42:37","commitOrder":9,"curCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final CountSlotAcc countAcc = processor.countAcc;\n    final SweepCountAccStruct baseCountAccStruct = SweepingCountSlotAcc.baseStructOf(processor);\n    final List<SweepCountAccStruct> others = SweepingCountSlotAcc.otherStructsOf(processor);\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet termSet = searcher.getDocSet(tt.termQuery);\n        DocSet intersection = termSet.intersection(docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        final int termOrd = tt.termNum - startTermIndex;\n        countAcc.incrementCount(termOrd, collected);\n        for (SweepCountAccStruct entry : others) {\n          entry.countAcc.incrementCount(termOrd, termSet.intersectionSize(entry.docSet));\n        }\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      SweepIteratorAndCounts sweepIterAndCounts = SweepDocIterator.newInstance(baseCountAccStruct, others);\n      final SweepDocIterator iter = sweepIterAndCounts.iter;\n      final CountSlotAcc[] countAccs = sweepIterAndCounts.countAccs;\n      final SegCountGlobal counts = new SegCountGlobal(countAccs);\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n        int maxIdx = iter.registerCounts(counts);\n        boolean collectBase = iter.collectBase();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            counts.incrementCount(arrIdx, 1, maxIdx);\n            if (collectBase) {\n              processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                counts.incrementCount(arrIdx, 1, maxIdx);\n                if (collectBase) {\n                  processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n                }\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","date":"2020-07-10 09:42:37","endLine":561,"groupId":"102246","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"collectDocsGeneric","params":"(FacetFieldProcessorByArrayUIFprocessor)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/ee/86fe04745ccae1f4e081a66fe16ad0b54f73b8.src","preCode":"  public void collectDocsGeneric(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n    DocSet docs = processor.fcontext.base;\n\n    int uniqueTerms = 0;\n    final SlotAcc.CountSlotAcc countAcc = processor.countAcc;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        \r\n        DocSet intersection = searcher.getDocSet(tt.termQuery, docs);\n        int collected = processor.collectFirstPhase(intersection, tt.termNum - startTermIndex,\n                                                    slotNum -> { return new SlotContext(tt.termQuery); });\n        countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n        if (collected > 0) {\n          uniqueTerms++;\n        }\n      }\n    }\n\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      \r\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              \r\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReaderFirstPhase(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0x80000000)!=0) {\n          int pos = code & 0x7fffffff;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            countAcc.incrementCount(arrIdx, 1);\n            processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx >= 0) {\n                if (arrIdx >= nTerms) break;\n                countAcc.incrementCount(arrIdx, 1);\n                processor.collectFirstPhase(segDoc, arrIdx, processor.slotContext);\n              }\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n","realPath":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"M"}],"commitId":"40e2122b5a5b89f446e51692ef0d72e48c7b71e5","commitMessage":"@@@SOLR-13132: JSON Facet perf improvements to support \"sweeping\" collection of \"relatedness()\"\n\nThis adds a lot of \"under the covers\" improvements to how JSON Faceting FacetField processors work.  to enable\n\"sweeping\" support when the SlotAcc used for sorting support it (currently just \"relatedness()\")\n\nThis is a squash commit of all changes on https://github.com/magibney/lucene-solr/tree/SOLR-13132\nUp to and including ca7a8e0b39840d00af9022c048346a7d84bf280d.\n\nCo-authored-by: Chris Hostetter <hossman@apache.org>\nCo-authored-by: Michael Gibney <michael@michaelgibney.net>\n","date":"2020-07-10 09:42:37","modifiedFileCount":"9","status":"M","submitter":"Michael Gibney"}]
