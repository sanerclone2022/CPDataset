[{"authorTime":"2020-02-12 05:58:57","codes":[{"authorDate":"2020-02-12 05:58:57","commitOrder":1,"curCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes = null;\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    \r\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-02-12 05:58:57","endLine":174,"groupId":"1601","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/c5/acdb027ef2f5fed2c7439618b3e909a8abf69f.src","preCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes = null;\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    \r\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"B"},{"authorDate":"2020-02-12 05:58:57","commitOrder":1,"curCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      logger.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n    return serializedBytes;\n  }\n","date":"2020-02-12 05:58:57","endLine":104,"groupId":"7234","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/89/850b0f7dc681000a93faa90d70f24b24c63f04.src","preCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      logger.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"B"}],"commitId":"b227b3b72b3ed0e347464f8d8e5279365a6e5acb","commitMessage":"@@@Add metrics-common.  zookeeper-api.  helix-common modules (#684)\n\nWe want to create a new module called zookeeper-api in order to decouple Helix's ZooKeeper APIs from helix-core. The goal is to enable non-Helix applications to use Helix's ZooKeeper APIs. This change also allows for better modularity and separation of concerns.","date":"2020-02-12 05:58:57","modifiedFileCount":"361","status":"B","submitter":"Hunter Lee"},{"authorTime":"2020-03-01 01:19:31","codes":[{"authorDate":"2020-03-01 01:19:31","commitOrder":2,"curCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkClientException(e);\n    }\n    \r\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkClientException(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-03-01 01:19:31","endLine":182,"groupId":"1601","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/5c/8579cd6195013cd95f1c96d03103dcbc3ad3e2.src","preCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes = null;\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    \r\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"M"},{"authorDate":"2020-03-01 01:19:31","commitOrder":2,"curCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkClientException(e);\n    }\n\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkClientException(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-03-01 01:19:31","endLine":114,"groupId":"3026","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/bf/2c4bf89284b0451bf854942de4bbc0f5a73c8b.src","preCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      logger.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n      }\n    } catch (Exception e) {\n      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n          + new String(baos.toByteArray()).substring(0, 1024), e);\n      throw new ZkClientException(e);\n    }\n    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n          + \". Will not write to zk. Data (first 1k): \"\n          + new String(serializedBytes).substring(0, 1024));\n      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n    }\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"}],"commitId":"0f3c64be152d07db272d8560a50fcdcedff2e5b6","commitMessage":"@@@Add system property options to config write size limit for ZNRecord Serializer (#809)\n\nWith default value 1 MB of ZNRecord size limit in ZNRecord serializers.  serialized data may still fail to be written to Zookeeper. This commit adds system property options to config ZNRecord's write size limit and auto compression enabled in ZNRecord serializers.","date":"2020-03-01 01:19:31","modifiedFileCount":"4","status":"M","submitter":"Huizhi Lu"},{"authorTime":"2020-03-03 09:25:25","codes":[{"authorDate":"2020-03-03 09:25:25","commitOrder":3,"curCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n    \r\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-03-03 09:25:25","endLine":181,"groupId":"1601","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/60/4ca881d427245e093f928753fe07c288afd525.src","preCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkClientException(e);\n    }\n    \r\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkClientException(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"},{"authorDate":"2020-03-03 09:25:25","commitOrder":3,"curCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-03-03 09:25:25","endLine":114,"groupId":"3026","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/7b/e3ace2b691cc5824f25eca82d48bfbe4d78c5b.src","preCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkClientException(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkClientException(e);\n    }\n\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkClientException(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"}],"commitId":"496d573811a8ffddac31b8a3081d504cfaf134d1","commitMessage":"@@@Async write operation should not throw Exception for serializing error (#845)\n\nThis change will make the async write operations return error through the async callback instead of throwing exceptions. This change will fix the batch write/create failure due to one single node serializing failure.\nIn addition.  according to the serializer interface definition.  change ZK related serializers to throw ZkMarshallingError instead of ZkClientException.\n","date":"2020-03-03 09:25:25","modifiedFileCount":"6","status":"M","submitter":"Jiajun Wang"},{"authorTime":"2020-08-21 10:06:09","codes":[{"authorDate":"2020-03-03 09:25:25","commitOrder":4,"curCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n    \r\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-03-03 09:25:25","endLine":181,"groupId":"101029","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/60/4ca881d427245e093f928753fe07c288afd525.src","preCode":"  public byte[] serialize(Object data) throws ZkMarshallingError {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    \r\n    ZNRecord record = (ZNRecord) data;\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      JsonFactory f = new JsonFactory();\n      JsonGenerator g = f.createJsonGenerator(baos);\n\n      g.writeStartObject();\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeStringField(\"id\", record.getId());\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"simpleFields\");\n      for (String key : record.getSimpleFields().keySet()) {\n        g.writeRaw(\"\\n    \");\n        g.writeStringField(key, record.getSimpleField(key));\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"listFields\");\n      for (String key : record.getListFields().keySet()) {\n        \r\n\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeArrayFieldStart(key);\n        List<String> list = record.getListField(key);\n        for (String listValue : list) {\n          g.writeString(listValue);\n        }\n        \r\n        g.writeEndArray();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      \r\n      g.writeRaw(\"\\n  \");\n      g.writeObjectFieldStart(\"mapFields\");\n      for (String key : record.getMapFields().keySet()) {\n        \r\n        g.writeRaw(\"\\n    \");\n        g.writeObjectFieldStart(key);\n        Map<String, String> map = record.getMapField(key);\n        for (String mapKey : map.keySet()) {\n          g.writeRaw(\"\\n      \");\n          g.writeStringField(mapKey, map.get(mapKey));\n        }\n        g.writeRaw(\"\\n    \");\n        g.writeEndObject();\n\n      }\n      g.writeRaw(\"\\n  \");\n      g.writeEndObject(); \r\n\n      byte[] rawPayload = record.getRawPayload();\n      if (rawPayload != null && rawPayload.length > 0) {\n        \r\n        g.writeRaw(\"\\n  \");\n        g.writeStringField(\"rawPayload\", new String(Base64.encodeBase64(rawPayload), \"UTF-8\"));\n      }\n\n      g.writeRaw(\"\\n\");\n      g.writeEndObject(); \r\n\n      \r\n      \r\n      g.close();\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n    \r\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2020-08-21 10:06:09","commitOrder":4,"curCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    mapper.enable(SerializationFeature.INDENT_OUTPUT);\n    mapper.enable(MapperFeature.AUTO_DETECT_FIELDS);\n    mapper.enable(MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS);\n\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","date":"2020-08-21 10:06:09","endLine":115,"groupId":"101029","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"serialize","params":"(Objectdata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/5c/ae87ac36beeaecb666b34f41647464870cf27f.src","preCode":"  public byte[] serialize(Object data) {\n    if (!(data instanceof ZNRecord)) {\n      \r\n      LOG.error(\"Input object must be of type ZNRecord but it is \" + data\n          + \". Will not write to zk\");\n      throw new ZkMarshallingError(\"Input object is not of type ZNRecord (was \" + data + \")\");\n    }\n\n    ZNRecord record = (ZNRecord) data;\n\n    \r\n    int max = getListFieldBound(record);\n    if (max < Integer.MAX_VALUE) {\n      Map<String, List<String>> listMap = record.getListFields();\n      for (String key : listMap.keySet()) {\n        List<String> list = listMap.get(key);\n        if (list.size() > max) {\n          listMap.put(key, list.subList(0, max));\n        }\n      }\n    }\n\n    \r\n    ObjectMapper mapper = new ObjectMapper();\n    SerializationConfig serializationConfig = mapper.getSerializationConfig();\n    serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n    serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n    serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] serializedBytes;\n    boolean isCompressed = false;\n\n    try {\n      mapper.writeValue(baos, data);\n      serializedBytes = baos.toByteArray();\n      \r\n      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n        serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n        isCompressed = true;\n      }\n    } catch (Exception e) {\n      LOG.error(\n          \"Exception during data serialization. ZNRecord ID: {} will not be written to zk.\",\n          record.getId(), e);\n      throw new ZkMarshallingError(e);\n    }\n\n    int writeSizeLimit = ZNRecordUtil.getSerializerWriteSizeLimit();\n    if (serializedBytes.length > writeSizeLimit) {\n      LOG.error(\"Data size: {} is greater than {} bytes, is compressed: {}, ZNRecord.id: {}.\"\n              + \" Data will not be written to Zookeeper.\", serializedBytes.length, writeSizeLimit,\n          isCompressed, record.getId());\n      throw new ZkMarshallingError(\n          \"Data size: \" + serializedBytes.length + \" is greater than \" + writeSizeLimit\n              + \" bytes, is compressed: \" + isCompressed + \", ZNRecord.id: \" + record.getId());\n    }\n\n    return serializedBytes;\n  }\n","realPath":"zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"cd552d9f122dbe3fa4b3648d38b2fc615f663b84","commitMessage":"@@@Replace org.codehaus.jackson with FasterXML.jackson (#1293)\n\nReplace org.codehaus.jackson with FasterXML.jackson","date":"2020-08-21 10:06:09","modifiedFileCount":"86","status":"M","submitter":"xyuanlu"}]
