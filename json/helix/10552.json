[{"authorTime":"2017-04-27 06:34:25","codes":[{"authorDate":"2017-04-27 06:34:25","commitOrder":1,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2017-07-13 04:58:05","endLine":285,"groupId":"3408","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/10/d7cc4f4c87acaa2a5dcd8a19d1b73a33fdf1b1.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"B"},{"authorDate":"2017-04-27 06:34:25","commitOrder":1,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2017-07-13 04:58:05","endLine":319,"groupId":"2783","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/10/d7cc4f4c87acaa2a5dcd8a19d1b73a33fdf1b1.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":293,"status":"B"}],"commitId":"8cbbf834efa30b07c31067e1b48ac6332763b02e","commitMessage":"@@@[HELIX-654] Running task rebalance\n\nAdd a job config RebalanceRunningTask.\n\nFor generic task.  if feature is enabled.  Helix will drop running\ntasks that are assigned differently from the previous assignment. \nwhich will cause cancellation of that running task on participant.\nThe task will then be re-assigned to a new instance.\n\nFor fix target task.  running task always follows the partition.  so\ntasks are always re-assigned as needed.\n\nAdd different test cases for this feature enabled/disabled.\n","date":"2017-07-13 04:58:05","modifiedFileCount":"10","status":"B","submitter":"Weihan Kong"},{"authorTime":"2018-04-21 07:11:27","codes":[{"authorDate":"2018-04-21 07:11:27","commitOrder":2,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-04-25 03:45:43","endLine":277,"groupId":"4458","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/f5/18d5c481235b038d87052a60a6d49f7a60c53b.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"},{"authorDate":"2018-04-21 07:11:27","commitOrder":2,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-04-25 03:45:43","endLine":311,"groupId":"4459","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/f5/18d5c481235b038d87052a60a6d49f7a60c53b.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.TIMEOUT_CONFIG, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":285,"status":"M"}],"commitId":"d2fb22d1f3a3db602b27cba7ed8d814cb931622e","commitMessage":"@@@Fix a few of unstable integration tests.\n","date":"2018-04-25 03:45:43","modifiedFileCount":"18","status":"M","submitter":"Lei Xia"},{"authorTime":"2018-06-13 04:57:09","codes":[{"authorDate":"2018-06-13 04:57:09","commitOrder":3,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-07-14 06:55:35","endLine":268,"groupId":"4458","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/85/56805a10870b055c3a5ac0665bad13e9176e0e.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"},{"authorDate":"2018-06-13 04:57:09","commitOrder":3,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-07-14 06:55:35","endLine":302,"groupId":"4459","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/85/56805a10870b055c3a5ac0665bad13e9176e0e.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    HelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":276,"status":"M"}],"commitId":"4609d94488f4e97e6bf1c233281ca39433c4f72e","commitMessage":"@@@Fix a couple of tests.  and reduce the total test times.\n","date":"2018-07-14 06:55:35","modifiedFileCount":"272","status":"M","submitter":"Lei Xia"},{"authorTime":"2018-06-13 04:57:09","codes":[{"authorDate":"2018-07-14 05:45:41","commitOrder":4,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-07-14 08:38:58","endLine":264,"groupId":"3990","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/3b/5970eb93803b0f8c95bc3dac010fe80c7d5d38.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setFailureThreshold(2)\n        .setMaxAttemptsPerTask(2)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"},{"authorDate":"2018-06-13 04:57:09","commitOrder":4,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-07-14 06:55:35","endLine":302,"groupId":"4459","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/85/56805a10870b055c3a5ac0665bad13e9176e0e.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":276,"status":"N"}],"commitId":"4db61b56e473b64ec9956f694dd2ac6a8d328ed4","commitMessage":"@@@[HELIX-730] Add ThreadCountBasedAssignmentCalculator and integrate with Workflow/JobRebalancer and fix rebalancing logic\n\nFor quota-based scheduling of tasks.  we have added the TaskAssigner interface that takes into account AssignableInstances by way of AssignableInstanceManager. In order to use this in the currently-existing pipeline prior to Task Framework 2.0.  GenericTaskAssignmentCalculator was replaced with ThreadCountBasedAssignmentCalculator.  which is a wrapper around TaskAssigner. Necessary adjustments were made in Workflow/JobRebalancer for this replacement. Also the rebalance logic in Workflow/JobRebalancer was reviewed and fixed. Additionally.  TestQuotaBasedScheduling is added to test quota-based task scheduling. Note that quotas will apply to both generic and targeted jobs.\n\nA few bugs were uncovered during this process such as the faulty retry logic that never really got tasks to restart. For more details.  see the changelist below:\n\nChangelist:\n    1. Add ThreadCountBasedAssignmentCalculator.  a wrapper around ThreadCountBasedTaskAssigner\n    2. Make logic changes in JobRebalancer to enable the use of ThreadCountBasedAssignmentCalculator\n    3. Fix the failing test by using a thread-safe map and rename TestGenericTaskAssignmentCalculator to TestTaskAssignmentCalculator to better reflect what its tests are doing\n    4. Add retry logic that was previously absent for INIT and DROPPED tasks in JobRebalancer\n    5. Add TestQuotaBasedScheduling to test that jobs and tasks were being assigned and scheduled per quota config set in ClusterConfig\n    6. Add more log messages to aid with task-scheduling debugging in AssignableInstance\n    7. In AbstractTaskDispatcher.  for tasks that are STOPPED.  TIMED_OUT.  TASK_ERROR.  the retry logic was newly implemented so that they get re-started correctly\n    8. In AbstractTaskDispatcher.  when enforcing overlapAssign for jobs with isAllowOverlapAssignment().  a fix was implemented so that only jobs whose state is IN_PROGRESS are considered\n    9. In AbstractTaskDispatcher.  isWorkflowFinished() method was modified so that non-active jobs will have their tasks' resource freed from AssignableInstances to prevent resource leak\n   10. In markJobFailed() and markJobCompleted().  non-active jobs will have their tasks' resource freed from AssignableInstances to prevent resource leak\n   11. Fix the logic so that quotas do not apply to targeted jobs\n   12. Fix TestTaskRebalancer (assumes Consistent Hashing.  which is no longer used)\n   13. Fix TestIndependentTaskRebalancer (assumes Consistent Hashing.  no longer used)\n   14. Assignment logic was improved so that incomplete tasks whose assigned participants are no longer live will be re-assigned accordingly\n   15. Fix TestTaskRebalanceFailover (tasks on non-live instances will be re-assigned promptly)\n   16. Fix TestRebalanceRunningTask (targeted jobs will get tasks reassigned upon liveInstance and currentState change)\n   17. Fix a bug in FixedAssignmentCalculator and assignment logic for targeted jobs such that a task index will no longer be assigned multiple times\n   18. Fix TestJobFailureTaskNotStarted (tasks were not being assigned at all due to having reached maximum capacity for quota)\n   19. Add targetedTaskConfigMap field in JobConfig to cache TaskConfig objects for targeted tasks to reduce object creation and GC overload\n   20. Fix JobConfig so that it doesn't write quotaType to ZooKeeper when quotaType is null or not set\n   21. Fix deleteWorkflow() in TaskUtil so that the earliest delete failure will render the entire method as failed (and return prematurely to prevent breaking other ZNodes from incomplete deletion)\n   22. Fix TestDeleteWorkflow by adding another removeProperty() clause to lower failure rate\n","date":"2018-07-14 08:38:58","modifiedFileCount":"36","status":"M","submitter":"Hunter Lee"},{"authorTime":"2018-06-13 04:57:09","codes":[{"authorDate":"2020-05-01 08:48:20","commitOrder":5,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws Exception {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    boolean isMasterOnTwoDifferentNodes = TestHelper.verify(() -> {\n      Set<String> masterInstances = new HashSet<>();\n      ExternalView externalView =\n          _gSetupTool.getClusterManagementTool().getResourceExternalView(CLUSTER_NAME, DATABASE);\n      if (externalView == null) {\n        return false;\n      }\n\n      Map<String, String> stateMap0 = externalView.getStateMap(DATABASE + \"_0\");\n      Map<String, String> stateMap1 = externalView.getStateMap(DATABASE + \"_1\");\n      if (stateMap0 == null || stateMap1 == null) {\n        return false;\n      }\n\n      for (Map.Entry<String, String> entry : stateMap0.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      for (Map.Entry<String, String> entry : stateMap1.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      return masterInstances.size() == 2;\n    }, TestHelper.WAIT_DURATION);\n    Assert.assertTrue(isMasterOnTwoDifferentNodes);\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2020-05-01 08:48:20","endLine":298,"groupId":"3990","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/e6/59797618c61c9a9d44e413ce7b9023ce626b92.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":244,"status":"M"},{"authorDate":"2018-06-13 04:57:09","commitOrder":5,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2018-07-14 06:55:35","endLine":302,"groupId":"4459","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/85/56805a10870b055c3a5ac0665bad13e9176e0e.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder = new JobConfig.Builder()\n        .setWorkflow(WORKFLOW)\n        .setTargetResource(DATABASE)\n        .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n        .setNumConcurrentTasksPerInstance(100)\n        .setRebalanceRunningTask(true)\n        .setCommand(MockTask.TASK_COMMAND)\n        .setJobCommandConfigMap(\n            ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10*1000));\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":276,"status":"N"}],"commitId":"5a10292197b7233e6d37d0c669704e8d40bd7d6d","commitMessage":"@@@Stabilizing 4 flaky tests (#981)\n\nFour tests has been stabilized in this commit.\n\nThese tests are:\n1-TestJobFailure\n2-TestRebalanceRunningTask\n3-TestTaskRebalancerStopResume\n4-TestTaskSchedulingTwoCurrentStates\n\nTestJobFailure was unstable because we get ExternalView of a resources and if the ExternalView is not populated yet by the controller.  we hit NullPointerException.\n\nTestRebalanceRunningTask was unstable. In this PR.  we make sure that the master is existed in two different nodes (master is switched to new instance) and then we check the assigned participants.\n\nTestRebalanceStopAndResume was unstable because of Thread.Sleep usage. Instead of stopping the workflow after some time.  we first make sure that workflow and job is IN_PROGRESS and then stop the workflow.\n\nTestTaskSchedulingTwoCurrent has been stabilized by making sure that master has been switched to new instance after modifying IS. After that we make sure that task is assigned to the correct instance and make sure it does not switched to new instance and cancel is not being called incorrectly.","date":"2020-05-01 08:48:20","modifiedFileCount":"4","status":"M","submitter":"Ali Reza Zamani Zadeh Najari"},{"authorTime":"2020-10-09 07:37:08","codes":[{"authorDate":"2020-05-01 08:48:20","commitOrder":6,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws Exception {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    boolean isMasterOnTwoDifferentNodes = TestHelper.verify(() -> {\n      Set<String> masterInstances = new HashSet<>();\n      ExternalView externalView =\n          _gSetupTool.getClusterManagementTool().getResourceExternalView(CLUSTER_NAME, DATABASE);\n      if (externalView == null) {\n        return false;\n      }\n\n      Map<String, String> stateMap0 = externalView.getStateMap(DATABASE + \"_0\");\n      Map<String, String> stateMap1 = externalView.getStateMap(DATABASE + \"_1\");\n      if (stateMap0 == null || stateMap1 == null) {\n        return false;\n      }\n\n      for (Map.Entry<String, String> entry : stateMap0.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      for (Map.Entry<String, String> entry : stateMap1.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      return masterInstances.size() == 2;\n    }, TestHelper.WAIT_DURATION);\n    Assert.assertTrue(isMasterOnTwoDifferentNodes);\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2020-05-01 08:48:20","endLine":298,"groupId":"3990","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/e6/59797618c61c9a9d44e413ce7b9023ce626b92.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws Exception {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    boolean isMasterOnTwoDifferentNodes = TestHelper.verify(() -> {\n      Set<String> masterInstances = new HashSet<>();\n      ExternalView externalView =\n          _gSetupTool.getClusterManagementTool().getResourceExternalView(CLUSTER_NAME, DATABASE);\n      if (externalView == null) {\n        return false;\n      }\n\n      Map<String, String> stateMap0 = externalView.getStateMap(DATABASE + \"_0\");\n      Map<String, String> stateMap1 = externalView.getStateMap(DATABASE + \"_1\");\n      if (stateMap0 == null || stateMap1 == null) {\n        return false;\n      }\n\n      for (Map.Entry<String, String> entry : stateMap0.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      for (Map.Entry<String, String> entry : stateMap1.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      return masterInstances.size() == 2;\n    }, TestHelper.WAIT_DURATION);\n    Assert.assertTrue(isMasterOnTwoDifferentNodes);\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":244,"status":"N"},{"authorDate":"2020-10-09 07:37:08","commitOrder":6,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setRebalanceRunningTask(true)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE))\n            .setWaitTillVerify(TestHelper.DEFAULT_REBALANCE_PROCESSING_WAIT_TIME)\n            .build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2020-10-09 07:37:08","endLine":333,"groupId":"4459","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/05/8e9b4c3ebcd9c3f0023f4983d8182ccc6a6bcd.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setRebalanceRunningTask(true)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":306,"status":"M"}],"commitId":"12bfbae5024d2b24e453921002e11cf71f98d047","commitMessage":"@@@HelixClusterVerifier verify() with default waitTillVerify time (#1450)\n\nHelixClusterVerifier verify() and related method may return\npre-maturely. The reason is that the verify the converging stable\ncondition too early before controller has a chance to make\nchange. Basically the previous stable state is mistaken as the\nexpected next stable state. Part two.","date":"2020-10-09 07:37:08","modifiedFileCount":"17","status":"M","submitter":"kaisun2000"},{"authorTime":"2020-10-09 07:37:08","codes":[{"authorDate":"2020-11-18 08:24:18","commitOrder":7,"curCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws Exception {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE))\n            .setWaitTillVerify(TestHelper.DEFAULT_REBALANCE_PROCESSING_WAIT_TIME)\n            .build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    boolean isMasterOnTwoDifferentNodes = TestHelper.verify(() -> {\n      Set<String> masterInstances = new HashSet<>();\n      ExternalView externalView =\n          _gSetupTool.getClusterManagementTool().getResourceExternalView(CLUSTER_NAME, DATABASE);\n      if (externalView == null) {\n        return false;\n      }\n\n      Map<String, String> stateMap0 = externalView.getStateMap(DATABASE + \"_0\");\n      Map<String, String> stateMap1 = externalView.getStateMap(DATABASE + \"_1\");\n      if (stateMap0 == null || stateMap1 == null) {\n        return false;\n      }\n\n      for (Map.Entry<String, String> entry : stateMap0.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      for (Map.Entry<String, String> entry : stateMap1.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      return masterInstances.size() == 2;\n    }, TestHelper.WAIT_DURATION);\n    Assert.assertTrue(isMasterOnTwoDifferentNodes);\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2020-11-18 08:24:18","endLine":300,"groupId":"10552","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"testFixedTargetTaskAndDisabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/42/5d6e83dc7b436936ebaac2a15fd6f5c9aa00d9.src","preCode":"  public void testFixedTargetTaskAndDisabledRebalanceAndNodeAdded() throws Exception {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setFailureThreshold(2).setMaxAttemptsPerTask(2)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n    \r\n    System.out.println(\"Start new participant\");\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE)).build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    boolean isMasterOnTwoDifferentNodes = TestHelper.verify(() -> {\n      Set<String> masterInstances = new HashSet<>();\n      ExternalView externalView =\n          _gSetupTool.getClusterManagementTool().getResourceExternalView(CLUSTER_NAME, DATABASE);\n      if (externalView == null) {\n        return false;\n      }\n\n      Map<String, String> stateMap0 = externalView.getStateMap(DATABASE + \"_0\");\n      Map<String, String> stateMap1 = externalView.getStateMap(DATABASE + \"_1\");\n      if (stateMap0 == null || stateMap1 == null) {\n        return false;\n      }\n\n      for (Map.Entry<String, String> entry : stateMap0.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      for (Map.Entry<String, String> entry : stateMap1.entrySet()) {\n        if (entry.getValue().equals(\"MASTER\")) {\n          masterInstances.add(entry.getKey());\n        }\n      }\n      return masterInstances.size() == 2;\n    }, TestHelper.WAIT_DURATION);\n    Assert.assertTrue(isMasterOnTwoDifferentNodes);\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":244,"status":"M"},{"authorDate":"2020-10-09 07:37:08","commitOrder":7,"curCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setRebalanceRunningTask(true)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE))\n            .setWaitTillVerify(TestHelper.DEFAULT_REBALANCE_PROCESSING_WAIT_TIME)\n            .build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","date":"2020-10-09 07:37:08","endLine":333,"groupId":"10552","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testFixedTargetTaskAndEnabledRebalanceAndNodeAdded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/05/8e9b4c3ebcd9c3f0023f4983d8182ccc6a6bcd.src","preCode":"  public void testFixedTargetTaskAndEnabledRebalanceAndNodeAdded() throws InterruptedException {\n    WORKFLOW = TestHelper.getTestMethodName();\n    JobConfig.Builder jobBuilder =\n        new JobConfig.Builder().setWorkflow(WORKFLOW).setTargetResource(DATABASE)\n            .setTargetPartitionStates(Sets.newHashSet(MasterSlaveSMD.States.MASTER.name()))\n            .setNumConcurrentTasksPerInstance(100).setRebalanceRunningTask(true)\n            .setCommand(MockTask.TASK_COMMAND)\n            .setJobCommandConfigMap(ImmutableMap.of(MockTask.JOB_DELAY, \"99999999\")); \r\n\n    Workflow.Builder workflowBuilder = new Workflow.Builder(WORKFLOW).addJob(JOB, jobBuilder);\n\n    _driver.start(workflowBuilder.build());\n\n    \r\n    Assert.assertTrue(checkTasksOnSameInstances());\n\n    \r\n    startParticipant(_initialNumNodes);\n    ZkHelixClusterVerifier clusterVerifier =\n        new BestPossibleExternalViewVerifier.Builder(CLUSTER_NAME).setZkClient(_gZkClient)\n            .setResources(Sets.newHashSet(DATABASE))\n            .setWaitTillVerify(TestHelper.DEFAULT_REBALANCE_PROCESSING_WAIT_TIME)\n            .build();\n    Assert.assertTrue(clusterVerifier.verify(10 * 1000));\n\n    \r\n    Assert.assertTrue(checkTasksOnDifferentInstances());\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/integration/task/TestRebalanceRunningTask.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":306,"status":"N"}],"commitId":"1d6d6076550f4076c2108e7738c6f0d54bd4178d","commitMessage":"@@@Stabilizing several tests by giving a starting up waiting periods  (#1533)\n\nStabilizing several tests by giving a starting up waiting periods up-on constructing BestPossibleExternalViewVerifier.\n\nCo-authored-by: Kai Sun <ksun@ksun-mn1.linkedin.biz>","date":"2020-11-18 08:24:18","modifiedFileCount":"12","status":"M","submitter":"kaisun2000"}]
