[{"authorTime":"2020-03-01 01:19:31","codes":[{"authorDate":"2020-03-01 01:19:31","commitOrder":1,"curCode":"  public void testZNRecordStreamingSerializerWriteSizeLimit() throws Exception {\n    \r\n    final String thresholdProperty =\n        System.getProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n\n    ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer();\n    HelixZkClient zkClient = SharedZkClientFactory.getInstance()\n        .buildZkClient(new HelixZkClient.ZkConnectionConfig(ZK_ADDR));\n\n    try {\n      zkClient.setZkSerializer(serializer);\n\n      String root = getShortClassName();\n\n      byte[] buf = new byte[1024];\n      for (int i = 0; i < 1024; i++) {\n        buf[i] = 'a';\n      }\n      String bufStr = new String(buf);\n\n      \r\n      \r\n      int rawZnRecordSize = 700;\n      int writeSizeLimitKb = 800;\n      int writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      String path = \"/\" + root + \"/normal\";\n      zkClient.createPersistent(path, true);\n      zkClient.writeData(path, normalSizeRecord);\n\n      ZNRecord record = zkClient.readData(path);\n\n      \r\n      Assert.assertEquals(normalSizeRecord, record);\n\n      int length = serializer.serialize(record).length;\n\n      \r\n      Assert.assertTrue(length < writeSizeLimit);\n\n      \r\n      \r\n      rawZnRecordSize = 2000;\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        largeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      path = \"/\" + root + \"/large\";\n      zkClient.createPersistent(path, true);\n\n      try {\n        zkClient.writeData(path, largeRecord);\n        Assert.fail(\"Data should not written to ZK because data size exceeds writeSizeLimit!\");\n      } catch (ZkClientException expected) {\n        Assert.assertTrue(\n            expected.getMessage().contains(\" is greater than \" + writeSizeLimit + \" bytes\"));\n      }\n\n      \r\n      ZKHelixAdmin admin = new ZKHelixAdmin(ZK_ADDR);\n      admin.addCluster(root, true);\n      InstanceConfig instanceConfig = new InstanceConfig(\"localhost_12918\");\n      admin.addInstance(root, instanceConfig);\n\n      \r\n      writeSizeLimitKb = 10;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      ZKHelixDataAccessor accessor =\n          new ZKHelixDataAccessor(root, new ZkBaseDataAccessor<>(ZK_ADDR));\n      Builder keyBuilder = accessor.keyBuilder();\n\n      IdealState idealState = new IdealState(\"currentState\");\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      boolean succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB0\"), idealState);\n      Assert.assertTrue(succeed);\n      HelixProperty property = accessor.getProperty(\n          keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_1\", \"partition_1\"));\n      Assert.assertNull(property);\n\n      \r\n      idealState.getRecord().getSimpleFields().clear();\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 900; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertTrue(succeed);\n      record = accessor.getProperty(keyBuilder.idealStates(\"TestDB1\")).getRecord();\n      Assert.assertTrue(serializer.serialize(record).length < writeSizeLimit);\n\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n      for (int i = 900; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      succeed = accessor.updateProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertFalse(succeed,\n          \"Update property should not succeed because data exceeds znode write limit!\");\n\n      \r\n      deletePath(zkClient, \"/\" + root);\n    } finally {\n      zkClient.close();\n    }\n\n    \r\n    if (thresholdProperty != null) {\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          thresholdProperty);\n    } else {\n      System.clearProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n    }\n  }\n","date":"2020-03-01 01:19:31","endLine":600,"groupId":"5876","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testZNRecordStreamingSerializerWriteSizeLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/30/d6349661c26b8b9d264feaa33bed5675f60318.src","preCode":"  public void testZNRecordStreamingSerializerWriteSizeLimit() throws Exception {\n    \r\n    final String thresholdProperty =\n        System.getProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n\n    ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer();\n    HelixZkClient zkClient = SharedZkClientFactory.getInstance()\n        .buildZkClient(new HelixZkClient.ZkConnectionConfig(ZK_ADDR));\n\n    try {\n      zkClient.setZkSerializer(serializer);\n\n      String root = getShortClassName();\n\n      byte[] buf = new byte[1024];\n      for (int i = 0; i < 1024; i++) {\n        buf[i] = 'a';\n      }\n      String bufStr = new String(buf);\n\n      \r\n      \r\n      int rawZnRecordSize = 700;\n      int writeSizeLimitKb = 800;\n      int writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      String path = \"/\" + root + \"/normal\";\n      zkClient.createPersistent(path, true);\n      zkClient.writeData(path, normalSizeRecord);\n\n      ZNRecord record = zkClient.readData(path);\n\n      \r\n      Assert.assertEquals(normalSizeRecord, record);\n\n      int length = serializer.serialize(record).length;\n\n      \r\n      Assert.assertTrue(length < writeSizeLimit);\n\n      \r\n      \r\n      rawZnRecordSize = 2000;\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        largeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      path = \"/\" + root + \"/large\";\n      zkClient.createPersistent(path, true);\n\n      try {\n        zkClient.writeData(path, largeRecord);\n        Assert.fail(\"Data should not written to ZK because data size exceeds writeSizeLimit!\");\n      } catch (ZkClientException expected) {\n        Assert.assertTrue(\n            expected.getMessage().contains(\" is greater than \" + writeSizeLimit + \" bytes\"));\n      }\n\n      \r\n      ZKHelixAdmin admin = new ZKHelixAdmin(ZK_ADDR);\n      admin.addCluster(root, true);\n      InstanceConfig instanceConfig = new InstanceConfig(\"localhost_12918\");\n      admin.addInstance(root, instanceConfig);\n\n      \r\n      writeSizeLimitKb = 10;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      ZKHelixDataAccessor accessor =\n          new ZKHelixDataAccessor(root, new ZkBaseDataAccessor<>(ZK_ADDR));\n      Builder keyBuilder = accessor.keyBuilder();\n\n      IdealState idealState = new IdealState(\"currentState\");\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      boolean succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB0\"), idealState);\n      Assert.assertTrue(succeed);\n      HelixProperty property = accessor.getProperty(\n          keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_1\", \"partition_1\"));\n      Assert.assertNull(property);\n\n      \r\n      idealState.getRecord().getSimpleFields().clear();\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 900; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertTrue(succeed);\n      record = accessor.getProperty(keyBuilder.idealStates(\"TestDB1\")).getRecord();\n      Assert.assertTrue(serializer.serialize(record).length < writeSizeLimit);\n\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n      for (int i = 900; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      succeed = accessor.updateProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertFalse(succeed,\n          \"Update property should not succeed because data exceeds znode write limit!\");\n\n      \r\n      deletePath(zkClient, \"/\" + root);\n    } finally {\n      zkClient.close();\n    }\n\n    \r\n    if (thresholdProperty != null) {\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          thresholdProperty);\n    } else {\n      System.clearProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n    }\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/manager/zk/TestZNRecordSizeLimit.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":452,"status":"B"},{"authorDate":"2020-03-01 01:19:31","commitOrder":1,"curCode":"  private ZNRecord createZNRecord(final int recordSizeKb) {\n    byte[] buf = new byte[1024];\n    for (int i = 0; i < 1024; i++) {\n      buf[i] = 'a';\n    }\n    String bufStr = new String(buf);\n\n    ZNRecord record = new ZNRecord(\"record\");\n    for (int i = 0; i < recordSizeKb; i++) {\n      record.setSimpleField(Integer.toString(i), bufStr);\n    }\n\n    return record;\n  }\n","date":"2020-03-01 01:19:31","endLine":178,"groupId":"5876","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createZNRecord","params":"(finalintrecordSizeKb)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/12/f98ac86b63f3d934614bca60371c02cefee6be.src","preCode":"  private ZNRecord createZNRecord(final int recordSizeKb) {\n    byte[] buf = new byte[1024];\n    for (int i = 0; i < 1024; i++) {\n      buf[i] = 'a';\n    }\n    String bufStr = new String(buf);\n\n    ZNRecord record = new ZNRecord(\"record\");\n    for (int i = 0; i < recordSizeKb; i++) {\n      record.setSimpleField(Integer.toString(i), bufStr);\n    }\n\n    return record;\n  }\n","realPath":"zookeeper-api/src/test/java/org/apache/helix/zookeeper/datamodel/serializer/TestZNRecordSerializeWriteSizeLimit.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":165,"status":"B"}],"commitId":"0f3c64be152d07db272d8560a50fcdcedff2e5b6","commitMessage":"@@@Add system property options to config write size limit for ZNRecord Serializer (#809)\n\nWith default value 1 MB of ZNRecord size limit in ZNRecord serializers.  serialized data may still fail to be written to Zookeeper. This commit adds system property options to config ZNRecord's write size limit and auto compression enabled in ZNRecord serializers.","date":"2020-03-01 01:19:31","modifiedFileCount":"4","status":"B","submitter":"Huizhi Lu"},{"authorTime":"2020-03-01 01:19:31","codes":[{"authorDate":"2020-03-03 09:25:25","commitOrder":2,"curCode":"  public void testZNRecordStreamingSerializerWriteSizeLimit() throws Exception {\n    \r\n    final String thresholdProperty =\n        System.getProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n\n    ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer();\n    HelixZkClient zkClient = SharedZkClientFactory.getInstance()\n        .buildZkClient(new HelixZkClient.ZkConnectionConfig(ZK_ADDR));\n\n    try {\n      zkClient.setZkSerializer(serializer);\n\n      String root = getShortClassName();\n\n      byte[] buf = new byte[1024];\n      for (int i = 0; i < 1024; i++) {\n        buf[i] = 'a';\n      }\n      String bufStr = new String(buf);\n\n      \r\n      \r\n      int rawZnRecordSize = 700;\n      int writeSizeLimitKb = 800;\n      int writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      String path = \"/\" + root + \"/normal\";\n      zkClient.createPersistent(path, true);\n      zkClient.writeData(path, normalSizeRecord);\n\n      ZNRecord record = zkClient.readData(path);\n\n      \r\n      Assert.assertEquals(normalSizeRecord, record);\n\n      int length = serializer.serialize(record).length;\n\n      \r\n      Assert.assertTrue(length < writeSizeLimit);\n\n      \r\n      \r\n      rawZnRecordSize = 2000;\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        largeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      path = \"/\" + root + \"/large\";\n      zkClient.createPersistent(path, true);\n\n      try {\n        zkClient.writeData(path, largeRecord);\n        Assert.fail(\"Data should not written to ZK because data size exceeds writeSizeLimit!\");\n      } catch (ZkMarshallingError expected) {\n        Assert.assertTrue(\n            expected.getMessage().contains(\" is greater than \" + writeSizeLimit + \" bytes\"));\n      }\n\n      \r\n      ZKHelixAdmin admin = new ZKHelixAdmin(ZK_ADDR);\n      admin.addCluster(root, true);\n      InstanceConfig instanceConfig = new InstanceConfig(\"localhost_12918\");\n      admin.addInstance(root, instanceConfig);\n\n      \r\n      writeSizeLimitKb = 10;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      ZKHelixDataAccessor accessor =\n          new ZKHelixDataAccessor(root, new ZkBaseDataAccessor<>(ZK_ADDR));\n      Builder keyBuilder = accessor.keyBuilder();\n\n      IdealState idealState = new IdealState(\"currentState\");\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      boolean succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB0\"), idealState);\n      Assert.assertTrue(succeed);\n      HelixProperty property = accessor.getProperty(\n          keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_1\", \"partition_1\"));\n      Assert.assertNull(property);\n\n      \r\n      idealState.getRecord().getSimpleFields().clear();\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 900; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertTrue(succeed);\n      record = accessor.getProperty(keyBuilder.idealStates(\"TestDB1\")).getRecord();\n      Assert.assertTrue(serializer.serialize(record).length < writeSizeLimit);\n\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n      for (int i = 900; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      succeed = accessor.updateProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertFalse(succeed,\n          \"Update property should not succeed because data exceeds znode write limit!\");\n\n      \r\n      deletePath(zkClient, \"/\" + root);\n    } finally {\n      zkClient.close();\n      \r\n      if (thresholdProperty != null) {\n        System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n            thresholdProperty);\n      } else {\n        System.clearProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n      }\n    }\n  }\n","date":"2020-03-03 09:25:25","endLine":597,"groupId":"10242","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testZNRecordStreamingSerializerWriteSizeLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/8c/8d649efff6599cb6f4a0ff3309fbd0888a43bb.src","preCode":"  public void testZNRecordStreamingSerializerWriteSizeLimit() throws Exception {\n    \r\n    final String thresholdProperty =\n        System.getProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n\n    ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer();\n    HelixZkClient zkClient = SharedZkClientFactory.getInstance()\n        .buildZkClient(new HelixZkClient.ZkConnectionConfig(ZK_ADDR));\n\n    try {\n      zkClient.setZkSerializer(serializer);\n\n      String root = getShortClassName();\n\n      byte[] buf = new byte[1024];\n      for (int i = 0; i < 1024; i++) {\n        buf[i] = 'a';\n      }\n      String bufStr = new String(buf);\n\n      \r\n      \r\n      int rawZnRecordSize = 700;\n      int writeSizeLimitKb = 800;\n      int writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      String path = \"/\" + root + \"/normal\";\n      zkClient.createPersistent(path, true);\n      zkClient.writeData(path, normalSizeRecord);\n\n      ZNRecord record = zkClient.readData(path);\n\n      \r\n      Assert.assertEquals(normalSizeRecord, record);\n\n      int length = serializer.serialize(record).length;\n\n      \r\n      Assert.assertTrue(length < writeSizeLimit);\n\n      \r\n      \r\n      rawZnRecordSize = 2000;\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n      for (int i = 0; i < rawZnRecordSize; i++) {\n        largeRecord.setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      path = \"/\" + root + \"/large\";\n      zkClient.createPersistent(path, true);\n\n      try {\n        zkClient.writeData(path, largeRecord);\n        Assert.fail(\"Data should not written to ZK because data size exceeds writeSizeLimit!\");\n      } catch (ZkClientException expected) {\n        Assert.assertTrue(\n            expected.getMessage().contains(\" is greater than \" + writeSizeLimit + \" bytes\"));\n      }\n\n      \r\n      ZKHelixAdmin admin = new ZKHelixAdmin(ZK_ADDR);\n      admin.addCluster(root, true);\n      InstanceConfig instanceConfig = new InstanceConfig(\"localhost_12918\");\n      admin.addInstance(root, instanceConfig);\n\n      \r\n      writeSizeLimitKb = 10;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      ZKHelixDataAccessor accessor =\n          new ZKHelixDataAccessor(root, new ZkBaseDataAccessor<>(ZK_ADDR));\n      Builder keyBuilder = accessor.keyBuilder();\n\n      IdealState idealState = new IdealState(\"currentState\");\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      boolean succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB0\"), idealState);\n      Assert.assertTrue(succeed);\n      HelixProperty property = accessor.getProperty(\n          keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_1\", \"partition_1\"));\n      Assert.assertNull(property);\n\n      \r\n      idealState.getRecord().getSimpleFields().clear();\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n\n      for (int i = 0; i < 900; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n      succeed = accessor.setProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertTrue(succeed);\n      record = accessor.getProperty(keyBuilder.idealStates(\"TestDB1\")).getRecord();\n      Assert.assertTrue(serializer.serialize(record).length < writeSizeLimit);\n\n      \r\n      writeSizeLimitKb = 1;\n      writeSizeLimit = writeSizeLimitKb * 1024;\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          String.valueOf(writeSizeLimit));\n\n      \r\n      idealState.setStateModelDefRef(\"MasterSlave\");\n      idealState.setRebalanceMode(RebalanceMode.SEMI_AUTO);\n      idealState.setNumPartitions(10);\n      for (int i = 900; i < 1024; i++) {\n        idealState.getRecord().setSimpleField(Integer.toString(i), bufStr);\n      }\n\n      succeed = accessor.updateProperty(keyBuilder.idealStates(\"TestDB1\"), idealState);\n      Assert.assertFalse(succeed,\n          \"Update property should not succeed because data exceeds znode write limit!\");\n\n      \r\n      deletePath(zkClient, \"/\" + root);\n    } finally {\n      zkClient.close();\n    }\n\n    \r\n    if (thresholdProperty != null) {\n      System.setProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES,\n          thresholdProperty);\n    } else {\n      System.clearProperty(ZkSystemPropertyKeys.ZK_SERIALIZER_ZNRECORD_WRITE_SIZE_LIMIT_BYTES);\n    }\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/manager/zk/TestZNRecordSizeLimit.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":450,"status":"M"},{"authorDate":"2020-03-01 01:19:31","commitOrder":2,"curCode":"  private ZNRecord createZNRecord(final int recordSizeKb) {\n    byte[] buf = new byte[1024];\n    for (int i = 0; i < 1024; i++) {\n      buf[i] = 'a';\n    }\n    String bufStr = new String(buf);\n\n    ZNRecord record = new ZNRecord(\"record\");\n    for (int i = 0; i < recordSizeKb; i++) {\n      record.setSimpleField(Integer.toString(i), bufStr);\n    }\n\n    return record;\n  }\n","date":"2020-03-01 01:19:31","endLine":178,"groupId":"10242","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createZNRecord","params":"(finalintrecordSizeKb)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/12/f98ac86b63f3d934614bca60371c02cefee6be.src","preCode":"  private ZNRecord createZNRecord(final int recordSizeKb) {\n    byte[] buf = new byte[1024];\n    for (int i = 0; i < 1024; i++) {\n      buf[i] = 'a';\n    }\n    String bufStr = new String(buf);\n\n    ZNRecord record = new ZNRecord(\"record\");\n    for (int i = 0; i < recordSizeKb; i++) {\n      record.setSimpleField(Integer.toString(i), bufStr);\n    }\n\n    return record;\n  }\n","realPath":"zookeeper-api/src/test/java/org/apache/helix/zookeeper/datamodel/serializer/TestZNRecordSerializeWriteSizeLimit.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":165,"status":"N"}],"commitId":"496d573811a8ffddac31b8a3081d504cfaf134d1","commitMessage":"@@@Async write operation should not throw Exception for serializing error (#845)\n\nThis change will make the async write operations return error through the async callback instead of throwing exceptions. This change will fix the batch write/create failure due to one single node serializing failure.\nIn addition.  according to the serializer interface definition.  change ZK related serializers to throw ZkMarshallingError instead of ZkClientException.\n","date":"2020-03-03 09:25:25","modifiedFileCount":"6","status":"M","submitter":"Jiajun Wang"}]
