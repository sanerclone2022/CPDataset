[{"authorTime":"2020-04-04 09:57:34","codes":[{"authorDate":"2020-04-04 09:57:34","commitOrder":1,"curCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    assertEquals(provider.getCheckpoint(), \"topic1,0:300,1:200\");\n  }\n","date":"2020-04-04 09:57:34","endLine":75,"groupId":"60","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testValidKafkaConnectPath","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/fe/d8e46e01494f30aa2b87dfebbdefab4a333bc3.src","preCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    assertEquals(provider.getCheckpoint(), \"topic1,0:300,1:200\");\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":49,"status":"B"},{"authorDate":"2020-04-04 09:57:34","commitOrder":1,"curCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    provider.getCheckpoint();\n  }\n","date":"2020-04-04 09:57:34","endLine":93,"groupId":"62","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testMissingPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/fe/d8e46e01494f30aa2b87dfebbdefab4a333bc3.src","preCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    provider.getCheckpoint();\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":78,"status":"B"}],"commitId":"575d87cf7d6f0f743cb7cec6520d80e6fcc3e20a","commitMessage":"@@@HUDI-644 kafka connect checkpoint provider (#1453)\n\n","date":"2020-04-04 09:57:34","modifiedFileCount":"0","status":"B","submitter":"YanJia-Gary-Li"},{"authorTime":"2020-04-15 05:51:04","codes":[{"authorDate":"2020-04-15 05:51:04","commitOrder":2,"curCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertEquals(provider.getCheckpoint(), \"topic1,0:300,1:200\");\n  }\n","date":"2020-04-15 05:51:04","endLine":75,"groupId":"60","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testValidKafkaConnectPath","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/e7/9a574a9b5d9734b8264c4463f2054401ae6a71.src","preCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    assertEquals(provider.getCheckpoint(), \"topic1,0:300,1:200\");\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":46,"status":"M"},{"authorDate":"2020-04-15 05:51:04","commitOrder":2,"curCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    provider.getCheckpoint();\n  }\n","date":"2020-04-15 05:51:04","endLine":96,"groupId":"62","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testMissingPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/e7/9a574a9b5d9734b8264c4463f2054401ae6a71.src","preCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(new Path(topicPath), fs);\n    provider.getCheckpoint();\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":78,"status":"M"}],"commitId":"14d4fea8339913c0df8ea829036a45a187c55208","commitMessage":"@@@[HUDI-759] Integrate checkpoint provider with delta streamer (#1486)\n\n","date":"2020-04-15 05:51:04","modifiedFileCount":"7","status":"M","submitter":"Gary Li"},{"authorTime":"2020-04-22 14:10:25","codes":[{"authorDate":"2020-04-22 14:10:25","commitOrder":3,"curCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertEquals(\"topic1,0:300,1:200\", provider.getCheckpoint());\n  }\n","date":"2020-04-22 14:10:25","endLine":77,"groupId":"60","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testValidKafkaConnectPath","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8a/59bf909c9ce9456c90feb3b230ddd4c271a99f.src","preCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertEquals(provider.getCheckpoint(), \"topic1,0:300,1:200\");\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"M"},{"authorDate":"2020-04-22 14:10:25","commitOrder":3,"curCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertThrows(HoodieException.class, provider::getCheckpoint);\n  }\n","date":"2020-04-22 14:10:25","endLine":98,"groupId":"62","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testMissingPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8a/59bf909c9ce9456c90feb3b230ddd4c271a99f.src","preCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    provider.getCheckpoint();\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"6e15eebd81da41b1076179a8ddcedcf07d1c9043","commitMessage":"@@@[HUDI-809] Migrate CommonTestHarness to JUnit 5 (#1530)\n\n","date":"2020-04-22 14:10:25","modifiedFileCount":"12","status":"M","submitter":"Raymond Xu"},{"authorTime":"2020-07-06 07:44:31","codes":[{"authorDate":"2020-07-06 07:44:31","commitOrder":4,"curCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    Path topicPath = tempDir.resolve(\"topic1\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertEquals(\"topic1,0:300,1:200\", provider.getCheckpoint());\n  }\n","date":"2020-07-06 07:44:31","endLine":67,"groupId":"60","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testValidKafkaConnectPath","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5b/5282ae198c665cf779bcec523de36afcff357c.src","preCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    topicPath = basePath + \"/topic1\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertEquals(\"topic1,0:300,1:200\", provider.getCheckpoint());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"M"},{"authorDate":"2020-07-06 07:44:31","commitOrder":4,"curCode":"  public void testMissingPartition() throws Exception {\n    Path topicPath = tempDir.resolve(\"topic2\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertThrows(HoodieException.class, provider::getCheckpoint);\n  }\n","date":"2020-07-06 07:44:31","endLine":88,"groupId":"5644","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testMissingPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5b/5282ae198c665cf779bcec523de36afcff357c.src","preCode":"  public void testMissingPartition() throws Exception {\n    topicPath = basePath + \"/topic2\";\n    new File(topicPath).mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath);\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(hadoopConf);\n    assertThrows(HoodieException.class, provider::getCheckpoint);\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":70,"status":"M"}],"commitId":"3b9a30528bd6a6369181702303f3384162b04a7f","commitMessage":"@@@[HUDI-996] Add functional test suite for hudi-utilities (#1746)\n\n- Share resources for functional tests\n- Add suite for functional test classes from hudi-utilities\n","date":"2020-07-06 07:44:31","modifiedFileCount":"8","status":"M","submitter":"Raymond Xu"},{"authorTime":"2021-05-12 01:01:45","codes":[{"authorDate":"2021-05-12 01:01:45","commitOrder":5,"curCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    Path topicPath = tempDir.resolve(\"topic1\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400\" + BASE_FILE_EXTENSION).createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200\" + BASE_FILE_EXTENSION).createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200\" + BASE_FILE_EXTENSION).createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300\" + BASE_FILE_EXTENSION).createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1\" + BASE_FILE_EXTENSION).createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2\" + BASE_FILE_EXTENSION).createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertEquals(\"topic1,0:300,1:200\", provider.getCheckpoint());\n  }\n","date":"2021-05-12 01:01:45","endLine":69,"groupId":"10288","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testValidKafkaConnectPath","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c8/cb15f31e0b7bce60a74fe0b5bbbef88c12f913.src","preCode":"  public void testValidKafkaConnectPath() throws Exception {\n    \r\n    \r\n    Path topicPath = tempDir.resolve(\"topic1\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP\").mkdirs();\n    \r\n    new File(topicPath + \"/TMP/\" + \"topic1+0+301+400.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+1+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"random_snappy_1.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"random_snappy_2.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertEquals(\"topic1,0:300,1:200\", provider.getCheckpoint());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"M"},{"authorDate":"2021-05-12 01:01:45","commitOrder":5,"curCode":"  public void testMissingPartition() throws Exception {\n    Path topicPath = tempDir.resolve(\"topic2\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200\" + BASE_FILE_EXTENSION).createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200\" + BASE_FILE_EXTENSION).createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300\" + BASE_FILE_EXTENSION).createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertThrows(HoodieException.class, provider::getCheckpoint);\n  }\n","date":"2021-05-12 01:01:45","endLine":90,"groupId":"10288","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testMissingPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c8/cb15f31e0b7bce60a74fe0b5bbbef88c12f913.src","preCode":"  public void testMissingPartition() throws Exception {\n    Path topicPath = tempDir.resolve(\"topic2\");\n    Files.createDirectories(topicPath);\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\").mkdirs();\n    new File(topicPath + \"/year=2016/month=05/day=02/\").mkdirs();\n    \r\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+0+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=01/\"\n        + \"topic1+2+100+200.parquet\").createNewFile();\n    new File(topicPath + \"/year=2016/month=05/day=02/\"\n        + \"topic1+0+201+300.parquet\").createNewFile();\n    final TypedProperties props = new TypedProperties();\n    props.put(\"hoodie.deltastreamer.checkpoint.provider.path\", topicPath.toString());\n    final InitialCheckPointProvider provider = new KafkaConnectHdfsProvider(props);\n    provider.init(HoodieTestUtils.getDefaultHadoopConf());\n    assertThrows(HoodieException.class, provider::getCheckpoint);\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/checkpointing/TestKafkaConnectHdfsProvider.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"M"}],"commitId":"be9db2c4f5a570fcaa555618b34ad11109ed6b00","commitMessage":"@@@[HUDI-1055] Remove hardcoded parquet in tests (#2740)\n\n* Remove hardcoded parquet in tests\n* Use DataFileUtils.getInstance\n* Renaming DataFileUtils to BaseFileUtils\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2021-05-12 01:01:45","modifiedFileCount":"40","status":"M","submitter":"TeRS-K"}]
