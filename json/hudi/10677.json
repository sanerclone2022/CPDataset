[{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testArchiveCommitSavepointNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createSavepointFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(6, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    assertTrue(archiveLog.archiveIfRequired(context));\n    timeline = metaClient.getActiveTimeline().reload().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(5, timeline.countInstants(),\n        \"Since we have a savepoint at 101, we should never archive any commit after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"101\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Archived commits should always be safe\");\n  }\n","date":"2020-10-02 05:25:29","endLine":376,"groupId":"2815","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testArchiveCommitSavepointNoHole","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveCommitSavepointNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createSavepointFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(6, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    assertTrue(archiveLog.archiveIfRequired(context));\n    timeline = metaClient.getActiveTimeline().reload().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(5, timeline.countInstants(),\n        \"Since we have a savepoint at 101, we should never archive any commit after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"101\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Archived commits should always be safe\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":348,"status":"B"},{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testArchiveCommitCompactionNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"106\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"107\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsAndCompactionTimeline();\n    assertEquals(8, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    timeline = metaClient.getActiveTimeline().reload().getCommitsAndCompactionTimeline();\n    assertFalse(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"100\")),\n        \"Instants before oldest pending compaction can be removed\");\n    assertEquals(7, timeline.countInstants(),\n        \"Since we have a pending compaction at 101, we should never archive any commit \"\n            + \"after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\")),\n        \"Requested Compaction must still be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"105\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"106\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"107\")),\n        \"Instants greater than oldest pending compaction must be present\");\n  }\n","date":"2020-10-02 05:25:29","endLine":423,"groupId":"4262","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testArchiveCommitCompactionNoHole","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveCommitCompactionNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"106\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"107\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsAndCompactionTimeline();\n    assertEquals(8, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    timeline = metaClient.getActiveTimeline().reload().getCommitsAndCompactionTimeline();\n    assertFalse(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"100\")),\n        \"Instants before oldest pending compaction can be removed\");\n    assertEquals(7, timeline.countInstants(),\n        \"Since we have a pending compaction at 101, we should never archive any commit \"\n            + \"after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\")),\n        \"Requested Compaction must still be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"105\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"106\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"107\")),\n        \"Instants greater than oldest pending compaction must be present\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":379,"status":"B"}],"commitId":"1f7add92916c37b05be270d9c75a9042134ec506","commitMessage":"@@@[HUDI-1089] Refactor hudi-client to support multi-engine (#1827)\n\n- This change breaks `hudi-client` into `hudi-client-common` and `hudi-spark-client` modules \n- Simple usages of Spark using jsc.parallelize() has been redone using EngineContext#map.  EngineContext#flatMap etc\n- Code changes in the PR.  break classes into `BaseXYZ` parent classes with no spark dependencies living in `hudi-client-common`\n- Classes on `hudi-spark-client` are named `SparkXYZ` extending the parent classes with all the Spark dependencies\n- To simplify/cleanup.  HoodieIndex#fetchRecordLocation has been removed and its usages in tests replaced with alternatives\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-10-02 05:25:29","modifiedFileCount":"31","status":"B","submitter":"Mathieu"},{"authorTime":"2021-02-20 12:12:22","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":2,"curCode":"  public void testArchiveCommitSavepointNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createSavepointFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(6, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    assertTrue(archiveLog.archiveIfRequired(context));\n    timeline = metaClient.getActiveTimeline().reload().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(5, timeline.countInstants(),\n        \"Since we have a savepoint at 101, we should never archive any commit after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"101\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Archived commits should always be safe\");\n  }\n","date":"2020-10-02 05:25:29","endLine":376,"groupId":"10677","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testArchiveCommitSavepointNoHole","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveCommitSavepointNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createSavepointFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(6, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    assertTrue(archiveLog.archiveIfRequired(context));\n    timeline = metaClient.getActiveTimeline().reload().getCommitsTimeline().filterCompletedInstants();\n    assertEquals(5, timeline.countInstants(),\n        \"Since we have a savepoint at 101, we should never archive any commit after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"101\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Archived commits should always be safe\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Archived commits should always be safe\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":348,"status":"N"},{"authorDate":"2021-02-20 12:12:22","commitOrder":2,"curCode":"  public void testArchiveCommitCompactionNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"106\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"107\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getWriteTimeline();\n    assertEquals(8, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    timeline = metaClient.getActiveTimeline().reload().getWriteTimeline();\n    assertFalse(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"100\")),\n        \"Instants before oldest pending compaction can be removed\");\n    assertEquals(7, timeline.countInstants(),\n        \"Since we have a pending compaction at 101, we should never archive any commit \"\n            + \"after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\")),\n        \"Requested Compaction must still be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"105\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"106\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"107\")),\n        \"Instants greater than oldest pending compaction must be present\");\n  }\n","date":"2021-02-20 12:12:22","endLine":435,"groupId":"10677","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testArchiveCommitCompactionNoHole","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/60/f605c69b6bf4aa59c0b5e8742f331c90fd2ac2.src","preCode":"  public void testArchiveCommitCompactionNoHole() throws IOException {\n    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 5).build())\n        .build();\n    HoodieTestDataGenerator.createCommitFile(basePath, \"100\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"101\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"102\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"103\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionRequestedFile(basePath, \"104\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCompactionAuxiliaryMetadata(basePath,\n        new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\"), wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"105\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"106\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"107\", wrapperFs.getConf());\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n\n    HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsAndCompactionTimeline();\n    assertEquals(8, timeline.countInstants(), \"Loaded 6 commits and the count should match\");\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    timeline = metaClient.getActiveTimeline().reload().getCommitsAndCompactionTimeline();\n    assertFalse(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"100\")),\n        \"Instants before oldest pending compaction can be removed\");\n    assertEquals(7, timeline.countInstants(),\n        \"Since we have a pending compaction at 101, we should never archive any commit \"\n            + \"after 101 (we only archive 100)\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"101\")),\n        \"Requested Compaction must still be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"102\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"103\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, \"104\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"105\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"106\")),\n        \"Instants greater than oldest pending compaction must be present\");\n    assertTrue(timeline.containsInstant(new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"107\")),\n        \"Instants greater than oldest pending compaction must be present\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":391,"status":"M"}],"commitId":"ffcfb58bacab377bc72d20041baa54a3fd8fc812","commitMessage":"@@@[HUDI-1486] Remove inline inflight rollback in hoodie writer (#2359)\n\n1. Refactor rollback and move cleaning failed commits logic into cleaner\n2. Introduce hoodie heartbeat to ascertain failed commits\n3. Fix test cases","date":"2021-02-20 12:12:22","modifiedFileCount":"56","status":"M","submitter":"n3nash"}]
