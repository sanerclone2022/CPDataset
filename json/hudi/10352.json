[{"authorTime":"2021-06-25 11:26:26","codes":[{"authorDate":"2021-01-06 20:49:44","commitOrder":2,"curCode":"  private static HoodieCommitMetadata createPartition(String partitionPath, boolean isParquetSchemaSimple,\n      boolean useSchemaFromCommitMetadata, String instantTime) throws IOException, URISyntaxException {\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    Path partPath = new Path(hiveSyncConfig.basePath + \"/\" + partitionPath);\n    fileSystem.makeQualified(partPath);\n    fileSystem.mkdirs(partPath);\n    List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, instantTime);\n    writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    addSchemaToCommitMetadata(commitMetadata, isParquetSchemaSimple, useSchemaFromCommitMetadata);\n    return commitMetadata;\n  }\n","date":"2021-01-06 20:49:44","endLine":287,"groupId":"744","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createPartition","params":"(StringpartitionPath@booleanisParquetSchemaSimple@booleanuseSchemaFromCommitMetadata@StringinstantTime)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/09/090532bf919c80a1f8267fbdf03fbfd3f4c686.src","preCode":"  private static HoodieCommitMetadata createPartition(String partitionPath, boolean isParquetSchemaSimple,\n      boolean useSchemaFromCommitMetadata, String instantTime) throws IOException, URISyntaxException {\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    Path partPath = new Path(hiveSyncConfig.basePath + \"/\" + partitionPath);\n    fileSystem.makeQualified(partPath);\n    fileSystem.mkdirs(partPath);\n    List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, instantTime);\n    writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    addSchemaToCommitMetadata(commitMetadata, isParquetSchemaSimple, useSchemaFromCommitMetadata);\n    return commitMetadata;\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/testutils/HiveTestUtil.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":277,"status":"NB"},{"authorDate":"2021-06-25 11:26:26","commitOrder":2,"curCode":"  private HoodieCommitMetadata createPartitions(int numberOfPartitions, boolean isParquetSchemaSimple,\n      DateTime startFrom, String commitTime, String basePath) throws IOException, URISyntaxException {\n    startFrom = startFrom.withTimeAtStartOfDay();\n\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    for (int i = 0; i < numberOfPartitions; i++) {\n      String partitionPath = dtfOut.print(startFrom);\n      Path partPath = new Path(basePath + \"/\" + partitionPath);\n      dfsCluster.getFileSystem().makeQualified(partPath);\n      dfsCluster.getFileSystem().mkdirs(partPath);\n      List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, commitTime);\n      startFrom = startFrom.minusDays(1);\n      writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    }\n    return commitMetadata;\n  }\n","date":"2021-06-25 11:26:26","endLine":203,"groupId":"5744","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createPartitions","params":"(intnumberOfPartitions@booleanisParquetSchemaSimple@DateTimestartFrom@StringcommitTime@StringbasePath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6a/077e10a833028002c6ef64a2bea5bd25f9425a.src","preCode":"  private HoodieCommitMetadata createPartitions(int numberOfPartitions, boolean isParquetSchemaSimple,\n      DateTime startFrom, String commitTime, String basePath) throws IOException, URISyntaxException {\n    startFrom = startFrom.withTimeAtStartOfDay();\n\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    for (int i = 0; i < numberOfPartitions; i++) {\n      String partitionPath = dtfOut.print(startFrom);\n      Path partPath = new Path(basePath + \"/\" + partitionPath);\n      dfsCluster.getFileSystem().makeQualified(partPath);\n      dfsCluster.getFileSystem().mkdirs(partPath);\n      List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, commitTime);\n      startFrom = startFrom.minusDays(1);\n      writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    }\n    return commitMetadata;\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/testutils/TestCluster.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"B"}],"commitId":"0fb8556b0d9274aef650a46bb82a8cf495d4450b","commitMessage":"@@@Add ability to provide multi-region (global) data consistency across HMS in different regions (#2542)\n\n[global-hive-sync-tool] Add a global hive sync tool to sync hudi table across clusters. Add a way to rollback the replicated time stamp if we fail to sync or if we partly sync\n\nCo-authored-by: Jagmeet Bali <jsbali@uber.com>","date":"2021-06-25 11:26:26","modifiedFileCount":"14","status":"M","submitter":"s-sanjay"},{"authorTime":"2021-08-11 11:25:41","codes":[{"authorDate":"2021-01-06 20:49:44","commitOrder":3,"curCode":"  private static HoodieCommitMetadata createPartition(String partitionPath, boolean isParquetSchemaSimple,\n      boolean useSchemaFromCommitMetadata, String instantTime) throws IOException, URISyntaxException {\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    Path partPath = new Path(hiveSyncConfig.basePath + \"/\" + partitionPath);\n    fileSystem.makeQualified(partPath);\n    fileSystem.mkdirs(partPath);\n    List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, instantTime);\n    writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    addSchemaToCommitMetadata(commitMetadata, isParquetSchemaSimple, useSchemaFromCommitMetadata);\n    return commitMetadata;\n  }\n","date":"2021-01-06 20:49:44","endLine":287,"groupId":"10352","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"createPartition","params":"(StringpartitionPath@booleanisParquetSchemaSimple@booleanuseSchemaFromCommitMetadata@StringinstantTime)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/09/090532bf919c80a1f8267fbdf03fbfd3f4c686.src","preCode":"  private static HoodieCommitMetadata createPartition(String partitionPath, boolean isParquetSchemaSimple,\n      boolean useSchemaFromCommitMetadata, String instantTime) throws IOException, URISyntaxException {\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    Path partPath = new Path(hiveSyncConfig.basePath + \"/\" + partitionPath);\n    fileSystem.makeQualified(partPath);\n    fileSystem.mkdirs(partPath);\n    List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, instantTime);\n    writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    addSchemaToCommitMetadata(commitMetadata, isParquetSchemaSimple, useSchemaFromCommitMetadata);\n    return commitMetadata;\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/testutils/HiveTestUtil.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":277,"status":"N"},{"authorDate":"2021-08-11 11:25:41","commitOrder":3,"curCode":"  private HoodieCommitMetadata createPartitions(int numberOfPartitions, boolean isParquetSchemaSimple,\n      ZonedDateTime startFrom, String commitTime, String basePath) throws IOException, URISyntaxException {\n    startFrom = startFrom.truncatedTo(ChronoUnit.DAYS);\n\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    for (int i = 0; i < numberOfPartitions; i++) {\n      String partitionPath = startFrom.format(dtfOut);\n      Path partPath = new Path(basePath + \"/\" + partitionPath);\n      dfsCluster.getFileSystem().makeQualified(partPath);\n      dfsCluster.getFileSystem().mkdirs(partPath);\n      List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, commitTime);\n      startFrom = startFrom.minusDays(1);\n      writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    }\n    return commitMetadata;\n  }\n","date":"2021-08-11 11:25:41","endLine":204,"groupId":"10352","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createPartitions","params":"(intnumberOfPartitions@booleanisParquetSchemaSimple@ZonedDateTimestartFrom@StringcommitTime@StringbasePath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/a5/631d04427986522bacead47cf45b7dfb361c67.src","preCode":"  private HoodieCommitMetadata createPartitions(int numberOfPartitions, boolean isParquetSchemaSimple,\n      DateTime startFrom, String commitTime, String basePath) throws IOException, URISyntaxException {\n    startFrom = startFrom.withTimeAtStartOfDay();\n\n    HoodieCommitMetadata commitMetadata = new HoodieCommitMetadata();\n    for (int i = 0; i < numberOfPartitions; i++) {\n      String partitionPath = dtfOut.print(startFrom);\n      Path partPath = new Path(basePath + \"/\" + partitionPath);\n      dfsCluster.getFileSystem().makeQualified(partPath);\n      dfsCluster.getFileSystem().mkdirs(partPath);\n      List<HoodieWriteStat> writeStats = createTestData(partPath, isParquetSchemaSimple, commitTime);\n      startFrom = startFrom.minusDays(1);\n      writeStats.forEach(s -> commitMetadata.addWriteStat(partitionPath, s));\n    }\n    return commitMetadata;\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/testutils/TestCluster.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":189,"status":"M"}],"commitId":"8255a86cb4d7f2173f0adcf0d752096b0b4df78c","commitMessage":"@@@[HUDI-1939] remove joda time in hivesync module (#3430)\n\n","date":"2021-08-11 11:25:41","modifiedFileCount":"5","status":"M","submitter":"Raymond Xu"}]
