[{"authorTime":"2021-03-18 20:21:52","codes":[{"authorDate":"2021-03-18 20:21:52","commitOrder":1,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSourceContext sourceContext1 = MockSourceContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSourceContext sourceContext2 = MockSourceContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-03-18 20:21:52","endLine":123,"groupId":"3830","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/44/c030aaf4f67b4387cc2564e7ecc6d8b5f6024e.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSourceContext sourceContext1 = MockSourceContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSourceContext sourceContext2 = MockSourceContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":94,"status":"B"},{"authorDate":"2021-03-18 20:21:52","commitOrder":1,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSinkContext sinkContext1 = MockSinkContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSinkContext sinkContext2 = MockSinkContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-03-18 20:21:52","endLine":171,"groupId":"3830","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/44/c030aaf4f67b4387cc2564e7ecc6d8b5f6024e.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSinkContext sinkContext1 = MockSinkContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSinkContext sinkContext2 = MockSinkContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"B"}],"commitId":"f1e0018f12b66770ba3785be7aa8f5f6a80bab6f","commitMessage":"@@@[HUDI-1704] Use PRIMARY KEY syntax to define record keys for Flink Hudi table (#2694)\n\nThe SQL PRIMARY KEY semantics is very same with Hoodie record key.  using\nPRIMARY KEY is more straight-forward way instead of a table option:\nhoodie.datasource.write.recordkey.field.\n\nAfter this change.  both PRIMARY KEY and table option can define hoodie\nrecord key.  while the PRIMARY KEY has higher priority if both are\ndefined.\n\nNote: a column with PRIMARY KEY constraint is forced to be non-nullable.","date":"2021-03-18 20:21:52","modifiedFileCount":"4","status":"B","submitter":"Danny Chan"},{"authorTime":"2021-03-26 14:25:57","codes":[{"authorDate":"2021-03-26 14:25:57","commitOrder":2,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-03-26 14:25:57","endLine":122,"groupId":"3830","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/bb/b59640f468a5c561959443b6d72c74ec3150e7.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSourceContext sourceContext1 = MockSourceContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSourceContext sourceContext2 = MockSourceContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":93,"status":"M"},{"authorDate":"2021-03-26 14:25:57","commitOrder":2,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-03-26 14:25:57","endLine":170,"groupId":"3830","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/bb/b59640f468a5c561959443b6d72c74ec3150e7.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockSinkContext sinkContext1 = MockSinkContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockSinkContext sinkContext2 = MockSinkContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":141,"status":"M"}],"commitId":"8b774fe3313757a8b94ca408079327c62b4a664c","commitMessage":"@@@[HUDI-1495] Bump Flink version to 1.12.2 (#2718)\n\n","date":"2021-03-26 14:25:57","modifiedFileCount":"20","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-04-21 20:07:27","codes":[{"authorDate":"2021-04-21 20:07:27","commitOrder":3,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-04-21 20:07:27","endLine":131,"groupId":"3830","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/1f/2059e2c2809d38550cdf1ee793e81d9a93938a.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":94,"status":"M"},{"authorDate":"2021-04-21 20:07:27","commitOrder":3,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-04-21 20:07:27","endLine":187,"groupId":"3830","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/1f/2059e2c2809d38550cdf1ee793e81d9a93938a.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"M"}],"commitId":"ac3589f00659985c39ef29e5edd089279f6c2f70","commitMessage":"@@@[HUDI-1814] Non partitioned table for Flink writer (#2859)\n\n","date":"2021-04-21 20:07:27","modifiedFileCount":"4","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-05-11 11:11:19","codes":[{"authorDate":"2021-05-11 11:11:19","commitOrder":4,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-05-11 11:11:19","endLine":173,"groupId":"6011","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/d7/ec69321a918104a70a0d237a7c8e5ea4f3d166.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"},{"authorDate":"2021-05-11 11:11:19","commitOrder":4,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-05-11 11:11:19","endLine":260,"groupId":"4400","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/d7/ec69321a918104a70a0d237a7c8e5ea4f3d166.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":221,"status":"M"}],"commitId":"7a5af806cfe54474014db5c70641c0c6269fff03","commitMessage":"@@@[HUDI-1818] Validate required fields for Flink HoodieTable (#2930)\n\n","date":"2021-05-11 11:11:19","modifiedFileCount":"2","status":"M","submitter":"hiscat"},{"authorTime":"2021-08-16 18:14:05","codes":[{"authorDate":"2021-08-16 18:14:05","commitOrder":5,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-08-16 18:14:05","endLine":177,"groupId":"6011","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/04/39c4d08ad795bf0ccc23b1f746518eb31ff94b.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"M"},{"authorDate":"2021-08-16 18:14:05","commitOrder":5,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-08-16 18:14:05","endLine":289,"groupId":"4400","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/04/39c4d08ad795bf0ccc23b1f746518eb31ff94b.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    TableSchema schema1 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    TableSchema schema2 = TableSchema.builder()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"}],"commitId":"66f951322a3872073b86896fa5c10b51a0f6e4ab","commitMessage":"@@@[HUDI-2191] Bump flink version to 1.13.1 (#3291)\n\n","date":"2021-08-16 18:14:05","modifiedFileCount":"17","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-08-20 04:36:40","codes":[{"authorDate":"2021-08-20 04:36:40","commitOrder":6,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-08-20 04:36:40","endLine":177,"groupId":"3846","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6e/4b215987221dece834f553fd1002024885a802.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"M"},{"authorDate":"2021-08-20 04:36:40","commitOrder":6,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-08-20 04:36:40","endLine":289,"groupId":"3846","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6e/4b215987221dece834f553fd1002024885a802.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS, FlinkOptions.KEYGEN_CLASS.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"}],"commitId":"c350d05dd3301f14fa9d688746c9de2416db3f11","commitMessage":"@@@Restore 0.8.0 config keys with deprecated annotation (#3506)\n\nCo-authored-by: Sagar Sumit <sagarsumit09@gmail.com>\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2021-08-20 04:36:40","modifiedFileCount":"109","status":"M","submitter":"Udit Mehrotra"},{"authorTime":"2021-09-11 13:17:16","codes":[{"authorDate":"2021-09-11 13:17:16","commitOrder":7,"curCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.BIGINT())\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-09-11 13:17:16","endLine":178,"groupId":"10400","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSource","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/15/72dd446950fb91805071dbaa7c7a44e439aac7.src","preCode":"  void testSetupHoodieKeyOptionsForSource() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sourceContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSource tableSource1 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext1);\n    final Configuration conf1 = tableSource1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sourceContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSource tableSource2 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext2);\n    final Configuration conf2 = tableSource2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sourceContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSource tableSource3 = (HoodieTableSource) new HoodieTableFactory().createDynamicTableSource(sourceContext3);\n    final Configuration conf3 = tableSource3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"M"},{"authorDate":"2021-09-11 13:17:16","commitOrder":7,"curCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.BIGINT())\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","date":"2021-09-11 13:17:16","endLine":290,"groupId":"10400","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testSetupHoodieKeyOptionsForSink","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/15/72dd446950fb91805071dbaa7c7a44e439aac7.src","preCode":"  void testSetupHoodieKeyOptionsForSink() {\n    this.conf.setString(FlinkOptions.RECORD_KEY_FIELD, \"dummyField\");\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, \"dummyKeyGenClass\");\n    \r\n    ResolvedSchema schema1 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20))\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\")\n        .build();\n    final MockContext sinkContext1 = MockContext.getInstance(this.conf, schema1, \"f2\");\n    final HoodieTableSink tableSink1 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext1);\n    final Configuration conf1 = tableSink1.getConf();\n    assertThat(conf1.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0\"));\n    assertThat(conf1.get(FlinkOptions.KEYGEN_CLASS_NAME), is(\"dummyKeyGenClass\"));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    ResolvedSchema schema2 = SchemaBuilder.instance()\n        .field(\"f0\", DataTypes.INT().notNull())\n        .field(\"f1\", DataTypes.VARCHAR(20).notNull())\n        .field(\"f2\", DataTypes.TIMESTAMP(3))\n        .field(\"ts\", DataTypes.TIMESTAMP(3))\n        .primaryKey(\"f0\", \"f1\")\n        .build();\n    final MockContext sinkContext2 = MockContext.getInstance(this.conf, schema2, \"f2\");\n    final HoodieTableSink tableSink2 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext2);\n    final Configuration conf2 = tableSink2.getConf();\n    assertThat(conf2.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf2.get(FlinkOptions.KEYGEN_CLASS_NAME), is(ComplexAvroKeyGenerator.class.getName()));\n\n    \r\n    this.conf.setString(FlinkOptions.KEYGEN_CLASS_NAME, FlinkOptions.KEYGEN_CLASS_NAME.defaultValue());\n    final MockContext sinkContext3 = MockContext.getInstance(this.conf, schema2, \"\");\n    final HoodieTableSink tableSink3 = (HoodieTableSink) new HoodieTableFactory().createDynamicTableSink(sinkContext3);\n    final Configuration conf3 = tableSink3.getConf();\n    assertThat(conf3.get(FlinkOptions.RECORD_KEY_FIELD), is(\"f0,f1\"));\n    assertThat(conf3.get(FlinkOptions.KEYGEN_CLASS_NAME), is(NonpartitionedAvroKeyGenerator.class.getName()));\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/TestHoodieTableFactory.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":251,"status":"M"}],"commitId":"b30c5bdaef77aee9f564ac24f80f5c364014bb17","commitMessage":"@@@[HUDI-2412] Add timestamp based partitioning for flink writer (#3638)\n\n","date":"2021-09-11 13:17:16","modifiedFileCount":"11","status":"M","submitter":"Danny Chan"}]
