[{"authorTime":"2020-08-06 12:34:55","codes":[{"authorDate":"2020-08-06 12:34:55","commitOrder":1,"curCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n  }\n","date":"2020-08-06 12:34:55","endLine":458,"groupId":"1283","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testMultiPartitionKeySync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":432,"status":"B"},{"authorDate":"2020-08-06 12:34:55","commitOrder":1,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2020-08-06 12:34:55","endLine":487,"groupId":"1283","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"B"}],"commitId":"51ea27d665d8053895dd047ca85e3338b357a81d","commitMessage":"@@@[HUDI-875] Abstract hudi-sync-common.  and support hudi-hive-sync.  hudi-dla-sync (#1810)\n\n- Generalize the hive-sync module for syncing to multiple metastores\n- Added new options for datasource\n- Added new command line for delta streamer \n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-08-06 12:34:55","modifiedFileCount":"3","status":"B","submitter":"lw0090"},{"authorTime":"2020-08-06 12:34:55","codes":[{"authorDate":"2021-01-06 20:49:44","commitOrder":2,"curCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one paritition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","date":"2021-01-06 20:49:44","endLine":536,"groupId":"1283","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testMultiPartitionKeySync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8a/1ea4f893927a4249235bf00abad5ff9f1613d2.src","preCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":466,"status":"M"},{"authorDate":"2020-08-06 12:34:55","commitOrder":2,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2020-08-06 12:34:55","endLine":487,"groupId":"1283","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"N"}],"commitId":"da2919a75f564be6c3d731a2c503959e416ebe71","commitMessage":"@@@[HUDI-1383] Fixing sorting of partition vals for hive sync computation (#2402)\n\n","date":"2021-01-06 20:49:44","modifiedFileCount":"3","status":"M","submitter":"Sivabalan Narayanan"},{"authorTime":"2020-08-06 12:34:55","codes":[{"authorDate":"2021-04-19 16:27:13","commitOrder":3,"curCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","date":"2021-04-19 16:27:13","endLine":537,"groupId":"1283","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testMultiPartitionKeySync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/75/ba97c8358973b86dd0841257435aacc29186f6.src","preCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one paritition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":467,"status":"M"},{"authorDate":"2020-08-06 12:34:55","commitOrder":3,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2020-08-06 12:34:55","endLine":487,"groupId":"1283","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"N"}],"commitId":"f7b6b680632115da7eb63eceadf95bd99f02d355","commitMessage":"@@@[MINOR][hudi-sync] Fix typos (#2844)\n\n","date":"2021-04-19 16:27:13","modifiedFileCount":"1","status":"M","submitter":"Roc Marshal"},{"authorTime":"2021-07-04 22:30:36","codes":[{"authorDate":"2021-07-04 22:30:36","commitOrder":4,"curCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","date":"2021-07-04 22:30:36","endLine":603,"groupId":"1283","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testMultiPartitionKeySync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":532,"status":"M"},{"authorDate":"2021-07-04 22:30:36","commitOrder":4,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2021-07-04 22:30:36","endLine":633,"groupId":"1283","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":607,"status":"M"}],"commitId":"6a71412f7804c9cbd34e4c6fc01545a994523bb4","commitMessage":"@@@[HUDI-2116] Support batch synchronization of partition datas to  hive metastore to avoid oom problem (#3209)\n\n","date":"2021-07-04 22:30:36","modifiedFileCount":"4","status":"M","submitter":"xiarixiaoyao"},{"authorTime":"2021-07-24 00:03:15","codes":[{"authorDate":"2021-07-24 00:03:15","commitOrder":5,"curCode":"  public void testMultiPartitionKeySync(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","date":"2021-07-24 00:03:15","endLine":810,"groupId":"10331","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testMultiPartitionKeySync","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    hiveSyncConfig.partitionValueExtractorClass = MultiPartKeysValueExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"multi_part_key\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(instantTime, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    \r\n    \r\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartition(\"2010/01/02\", true, true, commitTime2);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(instantTime));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n\n    \r\n    String commitTime3 = \"102\";\n    HiveTestUtil.addCOWPartition(\"2010/02/01\", true, true, commitTime3);\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size() + 3,\n        \"Hive Schema should match the table schema + partition fields\");\n    assertEquals(7, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime3, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n    assertEquals(1, hiveClient.getPartitionsWrittenToSince(Option.of(commitTime2)).size());\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":738,"status":"M"},{"authorDate":"2021-07-24 00:03:15","commitOrder":5,"curCode":"  public void testNonPartitionedSync(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2021-07-24 00:03:15","endLine":841,"groupId":"10331","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":814,"status":"M"}],"commitId":"66207ed91a75ce8e91ccc0c417dc0d310dc36a5c","commitMessage":"@@@[HUDI-1848] Adding support for HMS for running DDL queries in hive-sy? (#2879)\n\n* [HUDI-1848] Adding support for HMS for running DDL queries in hive-sync-tool\n\n* [HUDI-1848] Fixing test cases\n\n* [HUDI-1848] CR changes\n\n* [HUDI-1848] Fix checkstyle violations\n\n* [HUDI-1848] Fixed a bug when metastore api fails for complex schemas with multiple levels.\n\n* [HUDI-1848] Adding the complex schema and resolving merge conflicts\n\n* [HUDI-1848] Adding some more javadocs\n\n* [HUDI-1848] Added javadocs for DDLExecutor impls\n\n* [HUDI-1848] Fixed style issue","date":"2021-07-24 00:03:15","modifiedFileCount":"9","status":"M","submitter":"jsbali"}]
