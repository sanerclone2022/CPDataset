[{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testArchiveEmptyTable() throws IOException {\n    HoodieWriteConfig cfg =\n        HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n            .withParallelism(2, 2).forTable(\"test-trip-table\").build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n  }\n","date":"2020-10-02 05:25:29","endLine":92,"groupId":"412","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testArchiveEmptyTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveEmptyTable() throws IOException {\n    HoodieWriteConfig cfg =\n        HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n            .withParallelism(2, 2).forTable(\"test-trip-table\").build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"B"},{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testArchiveCommitTimeline() throws IOException {\n    HoodieWriteConfig cfg =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n                    .build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"1\", wrapperFs.getConf());\n    HoodieInstant instant1 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"1\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"2\", wrapperFs.getConf());\n    Path markerPath = new Path(metaClient.getMarkerFolderPath(\"2\"));\n    wrapperFs.mkdirs(markerPath);\n    HoodieInstant instant2 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"2\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"3\", wrapperFs.getConf());\n    HoodieInstant instant3 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"3\");\n\n    \r\n    HoodieTestDataGenerator.createCommitFile(basePath, \"4\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"5\", wrapperFs.getConf());\n\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    HoodieArchivedTimeline archivedTimeline = metaClient.getArchivedTimeline();\n    List<HoodieInstant> archivedInstants = Arrays.asList(instant1, instant2, instant3);\n    assertEquals(new HashSet<>(archivedInstants), archivedTimeline.getInstants().collect(Collectors.toSet()));\n    assertFalse(wrapperFs.exists(markerPath));\n  }\n","date":"2020-10-02 05:25:29","endLine":455,"groupId":"4419","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testArchiveCommitTimeline","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveCommitTimeline() throws IOException {\n    HoodieWriteConfig cfg =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n                    .build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"1\", wrapperFs.getConf());\n    HoodieInstant instant1 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"1\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"2\", wrapperFs.getConf());\n    Path markerPath = new Path(metaClient.getMarkerFolderPath(\"2\"));\n    wrapperFs.mkdirs(markerPath);\n    HoodieInstant instant2 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"2\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"3\", wrapperFs.getConf());\n    HoodieInstant instant3 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"3\");\n\n    \r\n    HoodieTestDataGenerator.createCommitFile(basePath, \"4\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"5\", wrapperFs.getConf());\n\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    HoodieArchivedTimeline archivedTimeline = metaClient.getArchivedTimeline();\n    List<HoodieInstant> archivedInstants = Arrays.asList(instant1, instant2, instant3);\n    assertEquals(new HashSet<>(archivedInstants), archivedTimeline.getInstants().collect(Collectors.toSet()));\n    assertFalse(wrapperFs.exists(markerPath));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":426,"status":"B"}],"commitId":"1f7add92916c37b05be270d9c75a9042134ec506","commitMessage":"@@@[HUDI-1089] Refactor hudi-client to support multi-engine (#1827)\n\n- This change breaks `hudi-client` into `hudi-client-common` and `hudi-spark-client` modules \n- Simple usages of Spark using jsc.parallelize() has been redone using EngineContext#map.  EngineContext#flatMap etc\n- Code changes in the PR.  break classes into `BaseXYZ` parent classes with no spark dependencies living in `hudi-client-common`\n- Classes on `hudi-spark-client` are named `SparkXYZ` extending the parent classes with all the Spark dependencies\n- To simplify/cleanup.  HoodieIndex#fetchRecordLocation has been removed and its usages in tests replaced with alternatives\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-10-02 05:25:29","modifiedFileCount":"31","status":"B","submitter":"Mathieu"},{"authorTime":"2021-04-08 15:35:33","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":2,"curCode":"  public void testArchiveEmptyTable() throws IOException {\n    HoodieWriteConfig cfg =\n        HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n            .withParallelism(2, 2).forTable(\"test-trip-table\").build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n  }\n","date":"2020-10-02 05:25:29","endLine":92,"groupId":"10675","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testArchiveEmptyTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/88/f755a44d0a2011d10e9e14d7afaa5eeef3ef8b.src","preCode":"  public void testArchiveEmptyTable() throws IOException {\n    HoodieWriteConfig cfg =\n        HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n            .withParallelism(2, 2).forTable(\"test-trip-table\").build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"N"},{"authorDate":"2021-04-08 15:35:33","commitOrder":2,"curCode":"  public void testArchiveCommitTimeline() throws IOException {\n    HoodieWriteConfig cfg =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n                    .build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"1\", wrapperFs.getConf());\n    HoodieInstant instant1 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"1\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"2\", wrapperFs.getConf());\n    Path markerPath = new Path(metaClient.getMarkerFolderPath(\"2\"));\n    wrapperFs.mkdirs(markerPath);\n    HoodieInstant instant2 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"2\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"3\", wrapperFs.getConf());\n    HoodieInstant instant3 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"3\");\n\n    \r\n    HoodieTestDataGenerator.createCommitFile(basePath, \"4\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"5\", wrapperFs.getConf());\n\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    HoodieArchivedTimeline archivedTimeline = metaClient.getArchivedTimeline();\n    List<HoodieInstant> archivedInstants = Arrays.asList(instant1, instant2, instant3);\n    assertEquals(new HashSet<>(archivedInstants),\n        archivedTimeline.filterCompletedInstants().getInstants().collect(Collectors.toSet()));\n    assertFalse(wrapperFs.exists(markerPath));\n  }\n","date":"2021-04-08 15:35:33","endLine":470,"groupId":"10675","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testArchiveCommitTimeline","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/f0/f13923e100fe0e164cf4b26e91546079f87459.src","preCode":"  public void testArchiveCommitTimeline() throws IOException {\n    HoodieWriteConfig cfg =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n                    .build();\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    HoodieTestDataGenerator.createCommitFile(basePath, \"1\", wrapperFs.getConf());\n    HoodieInstant instant1 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"1\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"2\", wrapperFs.getConf());\n    Path markerPath = new Path(metaClient.getMarkerFolderPath(\"2\"));\n    wrapperFs.mkdirs(markerPath);\n    HoodieInstant instant2 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"2\");\n    HoodieTestDataGenerator.createCommitFile(basePath, \"3\", wrapperFs.getConf());\n    HoodieInstant instant3 = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"3\");\n\n    \r\n    HoodieTestDataGenerator.createCommitFile(basePath, \"4\", wrapperFs.getConf());\n    HoodieTestDataGenerator.createCommitFile(basePath, \"5\", wrapperFs.getConf());\n\n    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n    boolean result = archiveLog.archiveIfRequired(context);\n    assertTrue(result);\n    HoodieArchivedTimeline archivedTimeline = metaClient.getArchivedTimeline();\n    List<HoodieInstant> archivedInstants = Arrays.asList(instant1, instant2, instant3);\n    assertEquals(new HashSet<>(archivedInstants), archivedTimeline.getInstants().collect(Collectors.toSet()));\n    assertFalse(wrapperFs.exists(markerPath));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":440,"status":"M"}],"commitId":"ecdbd2517fd8157d9e96f3d9abf195a589e191ae","commitMessage":"@@@[HUDI-699] Fix CompactionCommand and add unit test for CompactionCommand (#2325)\n\n","date":"2021-04-08 15:35:33","modifiedFileCount":"9","status":"M","submitter":"hongdd"}]
