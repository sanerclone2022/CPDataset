[{"authorTime":"2021-03-17 07:43:53","codes":[{"authorDate":"2021-03-17 07:43:53","commitOrder":1,"curCode":"  private void createReplaceRequested(String instantTime) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addRequestedReplace(instantTime, requestedReplaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","date":"2021-03-17 07:43:53","endLine":388,"groupId":"2030","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createReplaceRequested","params":"(StringinstantTime)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/94/83d61fb57cec803249c72c7560f264fc5a3590.src","preCode":"  private void createReplaceRequested(String instantTime) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addRequestedReplace(instantTime, requestedReplaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","realPath":"hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/transaction/TestSimpleConcurrentFileWritesConflictResolutionStrategy.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":369,"status":"B"},{"authorDate":"2021-03-17 07:43:53","commitOrder":1,"curCode":"  private void createReplace(String instantTime, WriteOperationType writeOperationType) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieReplaceCommitMetadata replaceMetadata = new HoodieReplaceCommitMetadata();\n    Map<String, List<String>> partitionFileIds = new HashMap<>();\n    partitionFileIds.put(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, Arrays.asList(fileId2));\n    replaceMetadata.setPartitionToReplaceFileIds(partitionFileIds);\n    HoodieWriteStat writeStat = new HoodieWriteStat();\n    writeStat.setFileId(\"file-1\");\n    replaceMetadata.addWriteStat(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, writeStat);\n    replaceMetadata.setOperationType(writeOperationType);\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addReplaceCommit(instantTime, requestedReplaceMetadata, replaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","date":"2021-03-17 07:43:53","endLine":418,"groupId":"2030","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createReplace","params":"(StringinstantTime@WriteOperationTypewriteOperationType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/94/83d61fb57cec803249c72c7560f264fc5a3590.src","preCode":"  private void createReplace(String instantTime, WriteOperationType writeOperationType) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieReplaceCommitMetadata replaceMetadata = new HoodieReplaceCommitMetadata();\n    Map<String, List<String>> partitionFileIds = new HashMap<>();\n    partitionFileIds.put(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, Arrays.asList(fileId2));\n    replaceMetadata.setPartitionToReplaceFileIds(partitionFileIds);\n    HoodieWriteStat writeStat = new HoodieWriteStat();\n    writeStat.setFileId(\"file-1\");\n    replaceMetadata.addWriteStat(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, writeStat);\n    replaceMetadata.setOperationType(writeOperationType);\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addReplaceCommit(instantTime, requestedReplaceMetadata, replaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","realPath":"hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/transaction/TestSimpleConcurrentFileWritesConflictResolutionStrategy.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":390,"status":"B"}],"commitId":"74241947c123c860a1b0344f25cef316440a70d6","commitMessage":"@@@[HUDI-845] Added locking capability to allow multiple writers (#2374)\n\n* [HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions","date":"2021-03-17 07:43:53","modifiedFileCount":"48","status":"B","submitter":"n3nash"},{"authorTime":"2021-05-22 04:52:13","codes":[{"authorDate":"2021-05-22 04:52:13","commitOrder":2,"curCode":"  private void createReplaceRequested(String instantTime) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addRequestedReplace(instantTime, Option.of(requestedReplaceMetadata))\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","date":"2021-05-22 04:52:13","endLine":388,"groupId":"10793","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"createReplaceRequested","params":"(StringinstantTime)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ab/e2a945628a4b4f633b39d076632e88f3194b6d.src","preCode":"  private void createReplaceRequested(String instantTime) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addRequestedReplace(instantTime, requestedReplaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","realPath":"hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/transaction/TestSimpleConcurrentFileWritesConflictResolutionStrategy.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":369,"status":"M"},{"authorDate":"2021-05-22 04:52:13","commitOrder":2,"curCode":"  private void createReplace(String instantTime, WriteOperationType writeOperationType) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieReplaceCommitMetadata replaceMetadata = new HoodieReplaceCommitMetadata();\n    Map<String, List<String>> partitionFileIds = new HashMap<>();\n    partitionFileIds.put(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, Arrays.asList(fileId2));\n    replaceMetadata.setPartitionToReplaceFileIds(partitionFileIds);\n    HoodieWriteStat writeStat = new HoodieWriteStat();\n    writeStat.setFileId(\"file-1\");\n    replaceMetadata.addWriteStat(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, writeStat);\n    replaceMetadata.setOperationType(writeOperationType);\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addReplaceCommit(instantTime, Option.of(requestedReplaceMetadata), Option.empty(), replaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","date":"2021-05-22 04:52:13","endLine":418,"groupId":"10793","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"createReplace","params":"(StringinstantTime@WriteOperationTypewriteOperationType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ab/e2a945628a4b4f633b39d076632e88f3194b6d.src","preCode":"  private void createReplace(String instantTime, WriteOperationType writeOperationType) throws Exception {\n    String fileId1 = \"file-1\";\n    String fileId2 = \"file-2\";\n\n    \r\n    HoodieReplaceCommitMetadata replaceMetadata = new HoodieReplaceCommitMetadata();\n    Map<String, List<String>> partitionFileIds = new HashMap<>();\n    partitionFileIds.put(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, Arrays.asList(fileId2));\n    replaceMetadata.setPartitionToReplaceFileIds(partitionFileIds);\n    HoodieWriteStat writeStat = new HoodieWriteStat();\n    writeStat.setFileId(\"file-1\");\n    replaceMetadata.addWriteStat(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, writeStat);\n    replaceMetadata.setOperationType(writeOperationType);\n    \r\n    HoodieRequestedReplaceMetadata requestedReplaceMetadata = new HoodieRequestedReplaceMetadata();\n    requestedReplaceMetadata.setOperationType(WriteOperationType.CLUSTER.name());\n    HoodieClusteringPlan clusteringPlan = new HoodieClusteringPlan();\n    HoodieClusteringGroup clusteringGroup = new HoodieClusteringGroup();\n    HoodieSliceInfo sliceInfo = new HoodieSliceInfo();\n    sliceInfo.setFileId(fileId1);\n    sliceInfo.setPartitionPath(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH);\n    clusteringGroup.setSlices(Arrays.asList(sliceInfo));\n    clusteringPlan.setInputGroups(Arrays.asList(clusteringGroup));\n    requestedReplaceMetadata.setClusteringPlan(clusteringPlan);\n    requestedReplaceMetadata.setVersion(TimelineLayoutVersion.CURR_VERSION);\n    HoodieTestTable.of(metaClient)\n        .addReplaceCommit(instantTime, requestedReplaceMetadata, replaceMetadata)\n        .withBaseFilesInPartition(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH, fileId1, fileId2);\n  }\n","realPath":"hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/transaction/TestSimpleConcurrentFileWritesConflictResolutionStrategy.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":390,"status":"M"}],"commitId":"685f77b5dda92bb4ecd3a5480a1a5ed2eaee5fef","commitMessage":"@@@[HUDI-1740] Fix insert-overwrite API archival (#2784)\n\n- fix problem of archiving replace commits\n- Fix problem when getting empty replacecommit.requested\n- Improved the logic of handling empty and non-empty requested/inflight commit files. Added unit tests to cover both empty and non-empty inflight files cases and cleaned up some unused test util methods\n\nCo-authored-by: yorkzero831 <yorkzero8312@gmail.com>\nCo-authored-by: zheren.yu <zheren.yu@paypay-corp.co.jp>","date":"2021-05-22 04:52:13","modifiedFileCount":"10","status":"M","submitter":"Susu Dong"}]
