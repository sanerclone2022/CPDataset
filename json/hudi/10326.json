[{"authorTime":"2021-06-17 19:18:21","codes":[{"authorDate":"2021-06-17 19:18:21","commitOrder":1,"curCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","date":"2021-06-17 19:18:21","endLine":317,"groupId":"2799","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncCOWTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/43/24a64f7b507e51896b233a145ef91fc35665c5.src","preCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":267,"status":"B"},{"authorDate":"2021-06-17 19:18:21","commitOrder":1,"curCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n    }\n  }\n","date":"2021-06-17 19:18:21","endLine":384,"groupId":"2799","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSyncMORTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/43/24a64f7b507e51896b233a145ef91fc35665c5.src","preCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":321,"status":"B"}],"commitId":"ad53cf450ef01806ff8b2cfe8ff76fa350a7b4c5","commitMessage":"@@@[HUDI-1879] Fix RO Tables Returning Snapshot Result (#2925)\n\n","date":"2021-06-17 19:18:21","modifiedFileCount":"4","status":"B","submitter":"pengzhiwei"},{"authorTime":"2021-07-03 15:55:36","codes":[{"authorDate":"2021-06-17 19:18:21","commitOrder":2,"curCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","date":"2021-06-17 19:18:21","endLine":317,"groupId":"2799","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncCOWTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/43/24a64f7b507e51896b233a145ef91fc35665c5.src","preCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":267,"status":"N"},{"authorDate":"2021-07-03 15:55:36","commitOrder":2,"curCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n    }\n  }\n","date":"2021-07-03 15:55:36","endLine":278,"groupId":"2799","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSyncMORTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/f0/e171b4b216ac13749ebdaca0e74feae2242e36.src","preCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":214,"status":"M"}],"commitId":"4f215e2938f78e13bea940013855cb14a6724601","commitMessage":"@@@[HUDI-2057]  CTAS Generate An External Table When Create Managed Table (#3146)\n\n","date":"2021-07-03 15:55:36","modifiedFileCount":"3","status":"M","submitter":"pengzhiwei"},{"authorTime":"2021-07-04 22:30:36","codes":[{"authorDate":"2021-07-04 22:30:36","commitOrder":3,"curCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","date":"2021-07-04 22:30:36","endLine":212,"groupId":"2799","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncCOWTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":161,"status":"M"},{"authorDate":"2021-07-04 22:30:36","commitOrder":3,"curCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n    }\n  }\n","date":"2021-07-04 22:30:36","endLine":281,"groupId":"2799","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSyncMORTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":216,"status":"M"}],"commitId":"6a71412f7804c9cbd34e4c6fc01545a994523bb4","commitMessage":"@@@[HUDI-2116] Support batch synchronization of partition datas to  hive metastore to avoid oom problem (#3209)\n\n","date":"2021-07-04 22:30:36","modifiedFileCount":"4","status":"M","submitter":"xiarixiaoyao"},{"authorTime":"2021-07-13 22:37:20","codes":[{"authorDate":"2021-07-13 22:37:20","commitOrder":4,"curCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + sparkTableProperties\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    if (syncAsDataSourceTable) {\n      assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='false'\"));\n    }\n  }\n","date":"2021-07-13 22:37:20","endLine":220,"groupId":"2799","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncCOWTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata@booleansyncAsDataSourceTable)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/34/94e4451fbab77aa1e50cc3dd5a1424fdc4ab13.src","preCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='snapshot'\"));\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":165,"status":"M"},{"authorDate":"2021-07-13 22:37:20","commitOrder":4,"curCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] readAsOptimizedResults = new String[] {\"true\", \"false\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String readAsOptimized = readAsOptimizedResults[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + sparkTableProperties\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n      if (syncAsDataSourceTable) {\n        assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='\" + readAsOptimized + \"'\"));\n      }\n    }\n  }\n","date":"2021-07-13 22:37:20","endLine":325,"groupId":"5704","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSyncMORTableWithProperties","params":"(booleanuseJdbc@booleanuseSchemaFromCommitMetadata@booleansyncAsDataSourceTable)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/34/94e4451fbab77aa1e50cc3dd5a1424fdc4ab13.src","preCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n        put(ConfigUtils.SPARK_QUERY_TYPE_KEY, \"hoodie.datasource.query.type\");\n        put(ConfigUtils.SPARK_QUERY_AS_RO_KEY, \"read_optimized\");\n        put(ConfigUtils.SPARK_QUERY_AS_RT_KEY, \"snapshot\");\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] expectQueryTypes = new String[] {\"read_optimized\", \"snapshot\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String expectQueryType = expectQueryTypes[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.contains(\"'hoodie.datasource.query.type'='\" + expectQueryType + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":257,"status":"M"}],"commitId":"f0a2f378ea57b577ef2275dbaf42cd960df9cfd5","commitMessage":"@@@Merge pull request #3120 from pengzhiwei2018/dev_metasync\n\n[HUDI-2045] Support Read Hoodie As DataSource Table For Flink And DeltaStreamer","date":"2021-07-13 22:37:20","modifiedFileCount":"6","status":"M","submitter":"pengzhiwei"},{"authorTime":"2021-07-24 00:03:15","codes":[{"authorDate":"2021-07-24 00:03:15","commitOrder":5,"curCode":"  public void testSyncCOWTableWithProperties(boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable,\n                                             String syncMode) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n\n    hiveSyncConfig.syncMode = syncMode;\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + sparkTableProperties\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    if (syncAsDataSourceTable) {\n      assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='false'\"));\n    }\n  }\n","date":"2021-07-24 00:03:15","endLine":363,"groupId":"10326","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncCOWTableWithProperties","params":"(booleanuseSchemaFromCommitMetadata@booleansyncAsDataSourceTable@StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testSyncCOWTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n    String dbTableName = hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName;\n    hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n    List<String> results = new ArrayList<>();\n    hiveDriver.getResults(results);\n\n    String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n        results.subList(0, results.size() - 1));\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    assertEquals(\n        \"EXTERNAL\\tTRUE\\n\"\n        + \"last_commit_time_sync\\t100\\n\"\n        + sparkTableProperties\n        + \"tp_0\\tp0\\n\"\n        + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n    assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n    results.clear();\n    \r\n    hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n    hiveDriver.getResults(results);\n    String ddl = String.join(\"\\n\", results);\n    assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n    if (syncAsDataSourceTable) {\n      assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='false'\"));\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":307,"status":"M"},{"authorDate":"2021-07-24 00:03:15","commitOrder":5,"curCode":"  public void testSyncMORTableWithProperties(boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable,\n                                             String syncMode) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.syncMode = syncMode;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] readAsOptimizedResults = new String[] {\"true\", \"false\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String readAsOptimized = readAsOptimizedResults[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + sparkTableProperties\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n      if (syncAsDataSourceTable) {\n        assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='\" + readAsOptimized + \"'\"));\n      }\n    }\n  }\n","date":"2021-07-24 00:03:15","endLine":468,"groupId":"10326","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSyncMORTableWithProperties","params":"(booleanuseSchemaFromCommitMetadata@booleansyncAsDataSourceTable@StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testSyncMORTableWithProperties(boolean useJdbc,\n                                             boolean useSchemaFromCommitMetadata,\n                                             boolean syncAsDataSourceTable) throws Exception {\n    HiveSyncConfig hiveSyncConfig = HiveTestUtil.hiveSyncConfig;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 3;\n    Map<String, String> serdeProperties = new HashMap<String, String>() {\n      {\n        put(\"path\", hiveSyncConfig.basePath);\n      }\n    };\n\n    Map<String, String> tableProperties = new HashMap<String, String>() {\n      {\n        put(\"tp_0\", \"p0\");\n        put(\"tp_1\", \"p1\");\n      }\n    };\n    hiveSyncConfig.syncAsSparkDataSourceTable = syncAsDataSourceTable;\n    hiveSyncConfig.useJdbc = useJdbc;\n    hiveSyncConfig.serdeProperties = ConfigUtils.configToString(serdeProperties);\n    hiveSyncConfig.tableProperties = ConfigUtils.configToString(tableProperties);\n    String instantTime = \"100\";\n    String deltaCommitTime = \"101\";\n    HiveTestUtil.createMORTable(instantTime, deltaCommitTime, 5, true,\n        useSchemaFromCommitMetadata);\n\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n\n    String roTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_READ_OPTIMIZED_TABLE;\n    String rtTableName = hiveSyncConfig.tableName + HiveSyncTool.SUFFIX_SNAPSHOT_TABLE;\n\n    String[] tableNames = new String[] {roTableName, rtTableName};\n    String[] readAsOptimizedResults = new String[] {\"true\", \"false\"};\n\n    SessionState.start(HiveTestUtil.getHiveConf());\n    Driver hiveDriver = new org.apache.hadoop.hive.ql.Driver(HiveTestUtil.getHiveConf());\n\n    String sparkTableProperties = getSparkTableProperties(syncAsDataSourceTable, useSchemaFromCommitMetadata);\n    for (int i = 0;i < 2; i++) {\n      String dbTableName = hiveSyncConfig.databaseName + \".\" + tableNames[i];\n      String readAsOptimized = readAsOptimizedResults[i];\n\n      hiveDriver.run(\"SHOW TBLPROPERTIES \" + dbTableName);\n      List<String> results = new ArrayList<>();\n      hiveDriver.getResults(results);\n\n      String tblPropertiesWithoutDdlTime = String.join(\"\\n\",\n          results.subList(0, results.size() - 1));\n      assertEquals(\n          \"EXTERNAL\\tTRUE\\n\"\n          + \"last_commit_time_sync\\t101\\n\"\n          + sparkTableProperties\n          + \"tp_0\\tp0\\n\"\n          + \"tp_1\\tp1\", tblPropertiesWithoutDdlTime);\n      assertTrue(results.get(results.size() - 1).startsWith(\"transient_lastDdlTime\"));\n\n      results.clear();\n      \r\n      hiveDriver.run(\"SHOW CREATE TABLE \" + dbTableName);\n      hiveDriver.getResults(results);\n      String ddl = String.join(\"\\n\", results);\n      assertTrue(ddl.contains(\"'path'='\" + hiveSyncConfig.basePath + \"'\"));\n      assertTrue(ddl.toLowerCase().contains(\"create external table\"));\n      if (syncAsDataSourceTable) {\n        assertTrue(ddl.contains(\"'\" + ConfigUtils.IS_QUERY_AS_RO_TABLE + \"'='\" + readAsOptimized + \"'\"));\n      }\n    }\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":400,"status":"M"}],"commitId":"66207ed91a75ce8e91ccc0c417dc0d310dc36a5c","commitMessage":"@@@[HUDI-1848] Adding support for HMS for running DDL queries in hive-sy? (#2879)\n\n* [HUDI-1848] Adding support for HMS for running DDL queries in hive-sync-tool\n\n* [HUDI-1848] Fixing test cases\n\n* [HUDI-1848] CR changes\n\n* [HUDI-1848] Fix checkstyle violations\n\n* [HUDI-1848] Fixed a bug when metastore api fails for complex schemas with multiple levels.\n\n* [HUDI-1848] Adding the complex schema and resolving merge conflicts\n\n* [HUDI-1848] Adding some more javadocs\n\n* [HUDI-1848] Added javadocs for DDLExecutor impls\n\n* [HUDI-1848] Fixed style issue","date":"2021-07-24 00:03:15","modifiedFileCount":"9","status":"M","submitter":"jsbali"}]
