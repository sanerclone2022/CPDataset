[{"authorTime":"2020-08-04 11:19:21","codes":[{"authorDate":"2020-06-09 21:10:16","commitOrder":2,"curCode":"  public static Schema generateProjectionSchema(Schema writeSchema, Map<String, Schema.Field> schemaFieldsMap,\n                                                List<String> fieldNames) {\n    \r\n\r\n\r\n\r\n\r\n\r\n\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultVal()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(writeSchema.getName(), writeSchema.getDoc(),\n        writeSchema.getNamespace(), writeSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","date":"2020-06-09 21:10:16","endLine":129,"groupId":"1662","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"generateProjectionSchema","params":"(SchemawriteSchema@Map<String@Schema.Field>schemaFieldsMap@List<String>fieldNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6a/f37709ccaf98c45c1f7f8efd303a05d8b44cbd.src","preCode":"  public static Schema generateProjectionSchema(Schema writeSchema, Map<String, Schema.Field> schemaFieldsMap,\n                                                List<String> fieldNames) {\n    \r\n\r\n\r\n\r\n\r\n\r\n\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultVal()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(writeSchema.getName(), writeSchema.getDoc(),\n        writeSchema.getNamespace(), writeSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","realPath":"hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/utils/HoodieRealtimeRecordReaderUtils.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"NB"},{"authorDate":"2020-08-04 11:19:21","commitOrder":2,"curCode":"  public static Schema generateProjectionSchema(Schema originalSchema, List<String> fieldNames) {\n    Map<String, Field> schemaFieldsMap = originalSchema.getFields().stream()\n        .map(r -> Pair.of(r.name().toLowerCase(), r)).collect(Collectors.toMap(Pair::getLeft, Pair::getRight));\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultValue()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(originalSchema.getName(), originalSchema.getDoc(),\n        originalSchema.getNamespace(), originalSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","date":"2020-08-04 11:19:21","endLine":368,"groupId":"1662","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"generateProjectionSchema","params":"(SchemaoriginalSchema@List<String>fieldNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/374d7bb215c870a1a1b8be4ed2c58729e30fe6.src","preCode":"  public static Schema generateProjectionSchema(Schema originalSchema, List<String> fieldNames) {\n    Map<String, Field> schemaFieldsMap = originalSchema.getFields().stream()\n        .map(r -> Pair.of(r.name().toLowerCase(), r)).collect(Collectors.toMap(Pair::getLeft, Pair::getRight));\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultValue()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(originalSchema.getName(), originalSchema.getDoc(),\n        originalSchema.getNamespace(), originalSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","realPath":"hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":350,"status":"B"}],"commitId":"539621bd33893d99a07b8f739a1e965ca72acdc9","commitMessage":"@@@[HUDI-242] Support for RFC-12/Bootstrapping of external datasets to hudi (#1876)\n\n- [HUDI-418] Bootstrap Index Implementation using HFile with unit-test\n - [HUDI-421] FileSystem View Changes to support Bootstrap with unit-tests\n - [HUDI-424] Implement Query Side Integration for querying tables containing bootstrap file slices\n - [HUDI-423] Implement upsert functionality for handling updates to these bootstrap file slices\n - [HUDI-421] Bootstrap Write Client with tests\n - [HUDI-425] Added HoodieDeltaStreamer support\n - [HUDI-899] Add a knob to change partition-path style while performing metadata bootstrap\n - [HUDI-900] Metadata Bootstrap Key Generator needs to handle complex keys correctly\n - [HUDI-424] Simplify Record reader implementation\n - [HUDI-423] Implement upsert functionality for handling updates to these bootstrap file slices\n - [HUDI-420] Hoodie Demo working with hive and sparkSQL. Also.  Hoodie CLI working with bootstrap tables\n\nCo-authored-by: Mehrotra <uditme@amazon.com>\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>\nCo-authored-by: Balaji Varadarajan <varadarb@uber.com>\n","date":"2020-08-04 11:19:21","modifiedFileCount":"89","status":"M","submitter":"vinoth chandar"},{"authorTime":"2021-01-28 08:53:13","codes":[{"authorDate":"2020-06-09 21:10:16","commitOrder":3,"curCode":"  public static Schema generateProjectionSchema(Schema writeSchema, Map<String, Schema.Field> schemaFieldsMap,\n                                                List<String> fieldNames) {\n    \r\n\r\n\r\n\r\n\r\n\r\n\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultVal()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(writeSchema.getName(), writeSchema.getDoc(),\n        writeSchema.getNamespace(), writeSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","date":"2020-06-09 21:10:16","endLine":129,"groupId":"1066","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"generateProjectionSchema","params":"(SchemawriteSchema@Map<String@Schema.Field>schemaFieldsMap@List<String>fieldNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6a/f37709ccaf98c45c1f7f8efd303a05d8b44cbd.src","preCode":"  public static Schema generateProjectionSchema(Schema writeSchema, Map<String, Schema.Field> schemaFieldsMap,\n                                                List<String> fieldNames) {\n    \r\n\r\n\r\n\r\n\r\n\r\n\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultVal()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(writeSchema.getName(), writeSchema.getDoc(),\n        writeSchema.getNamespace(), writeSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","realPath":"hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/utils/HoodieRealtimeRecordReaderUtils.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"N"},{"authorDate":"2021-01-28 08:53:13","commitOrder":3,"curCode":"  public static Schema generateProjectionSchema(Schema originalSchema, List<String> fieldNames) {\n    Map<String, Field> schemaFieldsMap = originalSchema.getFields().stream()\n        .map(r -> Pair.of(r.name().toLowerCase(), r)).collect(Collectors.toMap(Pair::getLeft, Pair::getRight));\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultVal()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(originalSchema.getName(), originalSchema.getDoc(),\n        originalSchema.getNamespace(), originalSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","date":"2021-01-28 08:53:13","endLine":393,"groupId":"1066","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"generateProjectionSchema","params":"(SchemaoriginalSchema@List<String>fieldNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/3b/989db2af1a2028690c7c5efd5d177d98495d9b.src","preCode":"  public static Schema generateProjectionSchema(Schema originalSchema, List<String> fieldNames) {\n    Map<String, Field> schemaFieldsMap = originalSchema.getFields().stream()\n        .map(r -> Pair.of(r.name().toLowerCase(), r)).collect(Collectors.toMap(Pair::getLeft, Pair::getRight));\n    List<Schema.Field> projectedFields = new ArrayList<>();\n    for (String fn : fieldNames) {\n      Schema.Field field = schemaFieldsMap.get(fn.toLowerCase());\n      if (field == null) {\n        throw new HoodieException(\"Field \" + fn + \" not found in log schema. Query cannot proceed! \"\n            + \"Derived Schema Fields: \" + new ArrayList<>(schemaFieldsMap.keySet()));\n      } else {\n        projectedFields.add(new Schema.Field(field.name(), field.schema(), field.doc(), field.defaultValue()));\n      }\n    }\n\n    Schema projectedSchema = Schema.createRecord(originalSchema.getName(), originalSchema.getDoc(),\n        originalSchema.getNamespace(), originalSchema.isError());\n    projectedSchema.setFields(projectedFields);\n    return projectedSchema;\n  }\n","realPath":"hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":375,"status":"M"}],"commitId":"bc0325f6ea0a734f106f21a2fcd4ead413a6cf7b","commitMessage":"@@@[HUDI-1522] Add a new pipeline for Flink writer (#2430)\n\n* [HUDI-1522] Add a new pipeline for Flink writer","date":"2021-01-28 08:53:13","modifiedFileCount":"13","status":"M","submitter":"Danny Chan"}]
