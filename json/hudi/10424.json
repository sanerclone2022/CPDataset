[{"authorTime":"2021-08-04 17:53:20","codes":[{"authorDate":"2021-07-16 18:05:33","commitOrder":11,"curCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"2 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(2));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","date":"2021-07-16 21:36:27","endLine":446,"groupId":"4445","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithMiniBatches","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/e1/45076bc0fd421270facc6484a42966373357b3.src","preCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"2 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(2));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":388,"status":"NB"},{"authorDate":"2021-08-04 17:53:20","commitOrder":11,"curCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","date":"2021-08-04 17:53:20","endLine":609,"groupId":"2532","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testInsertAllowsDuplication","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/29/a7455b684985b98be8cba788639ace2565573a.src","preCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":537,"status":"B"}],"commitId":"b8b9d6db83657cfdf35832eb26eb7e46ca318048","commitMessage":"@@@[HUDI-2087] Support Append only in Flink stream (#3390)\n\nCo-authored-by: ??? <yuzhaojing@bilibili.com>","date":"2021-08-04 17:53:20","modifiedFileCount":"13","status":"M","submitter":"yuzhaojing"},{"authorTime":"2021-08-06 10:30:52","codes":[{"authorDate":"2021-07-16 18:05:33","commitOrder":12,"curCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"2 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(2));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","date":"2021-07-16 21:36:27","endLine":446,"groupId":"4445","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithMiniBatches","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/e1/45076bc0fd421270facc6484a42966373357b3.src","preCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"2 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(2));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":388,"status":"N"},{"authorDate":"2021-08-06 10:30:52","commitOrder":12,"curCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    conf.setBoolean(FlinkOptions.INSERT_DEDUP, false);\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","date":"2021-08-06 10:30:52","endLine":610,"groupId":"2532","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testInsertAllowsDuplication","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/d5/639c58068dedf7a204eedf5e784a5e4a354e23.src","preCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":537,"status":"M"}],"commitId":"b7586a563253082a00d62ac81e3b5acbb378472a","commitMessage":"@@@[HUDI-2274] Allows INSERT duplicates for Flink MOR table (#3403)\n\n","date":"2021-08-06 10:30:52","modifiedFileCount":"9","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-08-06 10:30:52","codes":[{"authorDate":"2021-08-10 20:23:23","commitOrder":13,"curCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0008); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"3 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(3));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","date":"2021-08-10 20:23:23","endLine":466,"groupId":"4445","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithMiniBatches","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8e/7f8099b17c79704451332f4e35f985452e1cb6.src","preCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"2 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(2));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"M"},{"authorDate":"2021-08-06 10:30:52","commitOrder":13,"curCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    conf.setBoolean(FlinkOptions.INSERT_DEDUP, false);\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","date":"2021-08-06 10:30:52","endLine":610,"groupId":"2532","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testInsertAllowsDuplication","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/d5/639c58068dedf7a204eedf5e784a5e4a354e23.src","preCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    conf.setBoolean(FlinkOptions.INSERT_DEDUP, false);\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":537,"status":"N"}],"commitId":"21db6d7a84d4a83ec98c110e92ff9c92d05dd530","commitMessage":"@@@[HUDI-1771] Propagate CDC format for hoodie (#3285)\n\n","date":"2021-08-10 20:23:23","modifiedFileCount":"47","status":"M","submitter":"swuferhong"},{"authorTime":"2021-09-02 16:32:40","codes":[{"authorDate":"2021-08-10 20:23:23","commitOrder":14,"curCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0008); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"3 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(3));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","date":"2021-08-10 20:23:23","endLine":466,"groupId":"10424","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithMiniBatches","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8e/7f8099b17c79704451332f4e35f985452e1cb6.src","preCode":"  public void testInsertWithMiniBatches() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0008); \r\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"Should have 1 data bucket\", dataBuffer.size(), is(1));\n    assertThat(\"3 records expect to flush out as a mini-batch\",\n        dataBuffer.values().stream().findFirst().map(List::size).orElse(-1),\n        is(3));\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = getMiniBatchExpected();\n    checkWrittenData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_DUPLICATES) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    checkWrittenData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"N"},{"authorDate":"2021-09-02 16:32:40","commitOrder":14,"curCode":"  public void testInsertAllowsDuplication() throws Exception {\n    InsertFunctionWrapper<RowData> funcWrapper = new InsertFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    assertNull(funcWrapper.getWriterHelper());\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    assertThat(\"The operator expect to send an event\", event1, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n        .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event2 = funcWrapper.getNextEvent(); \r\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","date":"2021-09-02 16:32:40","endLine":599,"groupId":"10424","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"testInsertAllowsDuplication","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/b4/03f3c657209788f0700b212028e555a13bea70.src","preCode":"  public void testInsertAllowsDuplication() throws Exception {\n    \r\n    conf.setDouble(FlinkOptions.WRITE_BATCH_SIZE, 0.0006); \r\n    conf.setString(FlinkOptions.OPERATION, WriteOperationType.INSERT.value());\n    conf.setBoolean(FlinkOptions.INSERT_DEDUP, false);\n    funcWrapper = new StreamWriteFunctionWrapper<>(tempFile.getAbsolutePath(), conf);\n\n    \r\n    funcWrapper.openFunction();\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    \r\n    funcWrapper.checkpointFunction(1);\n    Map<String, List<HoodieRecord>> dataBuffer = funcWrapper.getDataBuffer();\n    assertThat(\"All data should be flushed out\", dataBuffer.size(), is(0));\n\n    final OperatorEvent event1 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event2 = funcWrapper.getNextEvent();\n    assertThat(\"The operator expect to send an event\", event2, instanceOf(WriteMetadataEvent.class));\n\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event1);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event2);\n    assertNotNull(funcWrapper.getEventBuffer()[0], \"The coordinator missed the event\");\n\n    String instant = funcWrapper.getWriteClient()\n            .getLastPendingInstant(getTableType());\n\n    funcWrapper.checkpointComplete(1);\n\n    Map<String, String> expected = new HashMap<>();\n\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n\n    \r\n    checkInflightInstant(funcWrapper.getWriteClient());\n    checkInstantState(funcWrapper.getWriteClient(), HoodieInstant.State.COMPLETED, instant);\n\n    \r\n    for (RowData rowData : TestData.DATA_SET_INSERT_SAME_KEY) {\n      funcWrapper.invoke(rowData);\n    }\n\n    funcWrapper.checkpointFunction(2);\n\n    final OperatorEvent event3 = funcWrapper.getNextEvent(); \r\n    final OperatorEvent event4 = funcWrapper.getNextEvent();\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event3);\n    funcWrapper.getCoordinator().handleEventFromOperator(0, event4);\n    funcWrapper.checkpointComplete(2);\n\n    \r\n    expected.put(\"par1\", \"[\"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,0,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,1,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,2,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,3,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1, \"\n        + \"id1,par1,id1,Danny,23,4,par1]\");\n    TestData.checkWrittenAllData(tempFile, expected, 1);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/TestWriteCopyOnWrite.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":535,"status":"M"}],"commitId":"7a1bd225cab6b1737d689d3659351a8c950a4d78","commitMessage":"@@@[HUDI-2376] Add pipeline for Append mode (#3573)\n\nCo-authored-by: ??? <yuzhaojing@bilibili.com>","date":"2021-09-02 16:32:40","modifiedFileCount":"35","status":"M","submitter":"yuzhaojing"}]
