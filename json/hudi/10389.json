[{"authorTime":"2021-05-18 13:55:38","codes":[{"authorDate":"2021-05-18 13:55:38","commitOrder":1,"curCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[id1,Phoebe,52,1970-01-01T00:00:08,par4]\");\n  }\n","date":"2021-05-18 13:55:38","endLine":415,"groupId":"4162","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteGlobalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/8707034e58b46b01c1fcf7b0e2ba7bfc2d0bdd.src","preCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[id1,Phoebe,52,1970-01-01T00:00:08,par4]\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"B"},{"authorDate":"2021-05-18 13:55:38","commitOrder":1,"curCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"id1,Stephen,34,1970-01-01T00:00:02,par1, \"\n        + \"id1,Fabian,32,1970-01-01T00:00:04,par2, \"\n        + \"id1,Jane,19,1970-01-01T00:00:06,par3, \"\n        + \"id1,Phoebe,52,1970-01-01T00:00:08,par4]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","date":"2021-05-18 13:55:38","endLine":443,"groupId":"4162","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteLocalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/8707034e58b46b01c1fcf7b0e2ba7bfc2d0bdd.src","preCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"id1,Stephen,34,1970-01-01T00:00:02,par1, \"\n        + \"id1,Fabian,32,1970-01-01T00:00:04,par2, \"\n        + \"id1,Jane,19,1970-01-01T00:00:06,par3, \"\n        + \"id1,Phoebe,52,1970-01-01T00:00:08,par4]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":418,"status":"B"}],"commitId":"46a2399a45803e1b0d863eec47168a09c37ab920","commitMessage":"@@@[HUDI-1902] Global index for flink writer (#2958)\n\nSupports deduplication for record keys with different partition path.","date":"2021-05-18 13:55:38","modifiedFileCount":"7","status":"B","submitter":"Danny Chan"},{"authorTime":"2021-05-18 13:55:38","codes":[{"authorDate":"2021-05-18 17:47:22","commitOrder":2,"curCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"true\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[id1,Phoebe,52,1970-01-01T00:00:08,par4]\");\n  }\n","date":"2021-05-18 17:47:22","endLine":416,"groupId":"4162","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteGlobalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/bb/80cf156f179f861581ae01959d4b9e814f30a5.src","preCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[id1,Phoebe,52,1970-01-01T00:00:08,par4]\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"M"},{"authorDate":"2021-05-18 13:55:38","commitOrder":2,"curCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"id1,Stephen,34,1970-01-01T00:00:02,par1, \"\n        + \"id1,Fabian,32,1970-01-01T00:00:04,par2, \"\n        + \"id1,Jane,19,1970-01-01T00:00:06,par3, \"\n        + \"id1,Phoebe,52,1970-01-01T00:00:08,par4]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","date":"2021-05-18 13:55:38","endLine":443,"groupId":"4162","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteLocalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/8707034e58b46b01c1fcf7b0e2ba7bfc2d0bdd.src","preCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"id1,Stephen,34,1970-01-01T00:00:02,par1, \"\n        + \"id1,Fabian,32,1970-01-01T00:00:04,par2, \"\n        + \"id1,Jane,19,1970-01-01T00:00:06,par3, \"\n        + \"id1,Phoebe,52,1970-01-01T00:00:08,par4]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":418,"status":"N"}],"commitId":"7d2971d4e23b1f2724e9c0ea3f233fa8105f8c1f","commitMessage":"@@@[HUDI-1911] Reuse the partition path and file group id for flink write data buffer (#2961)\n\nReuse to reduce memory footprint.","date":"2021-05-18 17:47:22","modifiedFileCount":"5","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-08-16 18:14:05","codes":[{"authorDate":"2021-08-16 18:14:05","commitOrder":3,"curCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"true\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\");\n  }\n","date":"2021-08-16 18:14:05","endLine":492,"groupId":"4162","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteGlobalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/07/64f5586ea801d7feba77591330d849b66102fc.src","preCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"true\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[id1,Phoebe,52,1970-01-01T00:00:08,par4]\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":472,"status":"M"},{"authorDate":"2021-08-16 18:14:05","commitOrder":3,"curCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"+I[id1, Stephen, 34, 1970-01-01T00:00:02, par1], \"\n        + \"+I[id1, Fabian, 32, 1970-01-01T00:00:04, par2], \"\n        + \"+I[id1, Jane, 19, 1970-01-01T00:00:06, par3], \"\n        + \"+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","date":"2021-08-16 18:14:05","endLine":520,"groupId":"4162","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteLocalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/07/64f5586ea801d7feba77591330d849b66102fc.src","preCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"id1,Stephen,34,1970-01-01T00:00:02,par1, \"\n        + \"id1,Fabian,32,1970-01-01T00:00:04,par2, \"\n        + \"id1,Jane,19,1970-01-01T00:00:06,par3, \"\n        + \"id1,Phoebe,52,1970-01-01T00:00:08,par4]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":495,"status":"M"}],"commitId":"66f951322a3872073b86896fa5c10b51a0f6e4ab","commitMessage":"@@@[HUDI-2191] Bump flink version to 1.13.1 (#3291)\n\n","date":"2021-08-16 18:14:05","modifiedFileCount":"17","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-08-19 23:21:20","codes":[{"authorDate":"2021-08-19 23:21:20","commitOrder":4,"curCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, \"true\")\n        .option(FlinkOptions.INSERT_DROP_DUPS, \"true\")\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\");\n  }\n","date":"2021-08-19 23:21:20","endLine":540,"groupId":"2977","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteGlobalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9e/ffdcc8c67f59ad51cfd9a0e5ed56ecd41b530e.src","preCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"true\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"M"},{"authorDate":"2021-08-19 23:21:20","commitOrder":4,"curCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, \"false\")\n        .option(FlinkOptions.INSERT_DROP_DUPS, \"true\")\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"+I[id1, Stephen, 34, 1970-01-01T00:00:02, par1], \"\n        + \"+I[id1, Fabian, 32, 1970-01-01T00:00:04, par2], \"\n        + \"+I[id1, Jane, 19, 1970-01-01T00:00:06, par3], \"\n        + \"+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","date":"2021-08-19 23:21:20","endLine":567,"groupId":"2977","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteLocalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9e/ffdcc8c67f59ad51cfd9a0e5ed56ecd41b530e.src","preCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    Map<String, String> options = new HashMap<>();\n    options.put(FlinkOptions.PATH.key(), tempFile.getAbsolutePath());\n    options.put(FlinkOptions.INDEX_GLOBAL_ENABLED.key(), \"false\");\n    options.put(FlinkOptions.INSERT_DROP_DUPS.key(), \"true\");\n    String hoodieTableDDL = TestConfigurations.getCreateHoodieTableDDL(\"t1\", options);\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"+I[id1, Stephen, 34, 1970-01-01T00:00:02, par1], \"\n        + \"+I[id1, Fabian, 32, 1970-01-01T00:00:04, par2], \"\n        + \"+I[id1, Jane, 19, 1970-01-01T00:00:06, par3], \"\n        + \"+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":543,"status":"M"}],"commitId":"9762e4c08c0ff953cc62e72b1295db4fd4c002c5","commitMessage":"@@@[MINOR] Some cosmetic changes for Flink (#3503)\n\n","date":"2021-08-19 23:21:20","modifiedFileCount":"6","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-09-11 13:17:16","codes":[{"authorDate":"2021-09-11 13:17:16","commitOrder":5,"curCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, true)\n        .option(FlinkOptions.INSERT_DROP_DUPS, true)\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\");\n  }\n","date":"2021-09-11 13:17:16","endLine":609,"groupId":"10389","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteGlobalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5b/e603f7838e5195aa26e8cf17398d597ca9ee2f.src","preCode":"  void testWriteGlobalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, \"true\")\n        .option(FlinkOptions.INSERT_DROP_DUPS, \"true\")\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    assertRowsEquals(result, \"[+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":589,"status":"M"},{"authorDate":"2021-09-11 13:17:16","commitOrder":5,"curCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, false)\n        .option(FlinkOptions.INSERT_DROP_DUPS, true)\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"+I[id1, Stephen, 34, 1970-01-01T00:00:02, par1], \"\n        + \"+I[id1, Fabian, 32, 1970-01-01T00:00:04, par2], \"\n        + \"+I[id1, Jane, 19, 1970-01-01T00:00:06, par3], \"\n        + \"+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","date":"2021-09-11 13:17:16","endLine":636,"groupId":"10389","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteLocalIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5b/e603f7838e5195aa26e8cf17398d597ca9ee2f.src","preCode":"  void testWriteLocalIndex() {\n    \r\n    String createSource = TestConfigurations.getFileSourceDDL(\n        \"source\", \"test_source_4.data\", 4);\n    streamTableEnv.executeSql(createSource);\n    String hoodieTableDDL = sql(\"t1\")\n        .option(FlinkOptions.PATH, tempFile.getAbsolutePath())\n        .option(FlinkOptions.INDEX_GLOBAL_ENABLED, \"false\")\n        .option(FlinkOptions.INSERT_DROP_DUPS, \"true\")\n        .end();\n    streamTableEnv.executeSql(hoodieTableDDL);\n\n    final String insertInto2 = \"insert into t1 select * from source\";\n\n    execInsertSql(streamTableEnv, insertInto2);\n\n    List<Row> result = CollectionUtil.iterableToList(\n        () -> streamTableEnv.sqlQuery(\"select * from t1\").execute().collect());\n    final String expected = \"[\"\n        + \"+I[id1, Stephen, 34, 1970-01-01T00:00:02, par1], \"\n        + \"+I[id1, Fabian, 32, 1970-01-01T00:00:04, par2], \"\n        + \"+I[id1, Jane, 19, 1970-01-01T00:00:06, par3], \"\n        + \"+I[id1, Phoebe, 52, 1970-01-01T00:00:08, par4]]\";\n    assertRowsEquals(result, expected, 3);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/table/HoodieDataSourceITCase.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":612,"status":"M"}],"commitId":"b30c5bdaef77aee9f564ac24f80f5c364014bb17","commitMessage":"@@@[HUDI-2412] Add timestamp based partitioning for flink writer (#3638)\n\n","date":"2021-09-11 13:17:16","modifiedFileCount":"11","status":"M","submitter":"Danny Chan"}]
