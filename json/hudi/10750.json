[{"authorTime":"2021-03-01 12:29:41","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":2,"curCode":"  public void commitCompaction(String compactionInstantTime, JavaRDD<WriteStatus> writeStatuses, Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieSparkTable<T> table = HoodieSparkTable.create(config, context);\n    HoodieCommitMetadata metadata = SparkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","date":"2020-10-02 05:25:29","endLine":257,"groupId":"3778","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"commitCompaction","params":"(StringcompactionInstantTime@JavaRDD<WriteStatus>writeStatuses@Option<Map<String@String>>extraMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/56/f06898abba2ed1f4e291f65b581c9426fcb1b3.src","preCode":"  public void commitCompaction(String compactionInstantTime, JavaRDD<WriteStatus> writeStatuses, Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieSparkTable<T> table = HoodieSparkTable.create(config, context);\n    HoodieCommitMetadata metadata = SparkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":251,"status":"NB"},{"authorDate":"2021-03-01 12:29:41","commitOrder":2,"curCode":"  public void commitCompaction(\n      String compactionInstantTime,\n      List<WriteStatus> writeStatuses,\n      Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieFlinkTable<T> table = HoodieFlinkTable.create(config, (HoodieFlinkEngineContext) context);\n    HoodieCommitMetadata metadata = FlinkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","date":"2021-03-01 12:29:41","endLine":221,"groupId":"3778","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"commitCompaction","params":"(StringcompactionInstantTime@List<WriteStatus>writeStatuses@Option<Map<String@String>>extraMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5d/86d0a87451f3d81edc2a40103902e497a398cc.src","preCode":"  public void commitCompaction(\n      String compactionInstantTime,\n      List<WriteStatus> writeStatuses,\n      Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieFlinkTable<T> table = HoodieFlinkTable.create(config, (HoodieFlinkEngineContext) context);\n    HoodieCommitMetadata metadata = FlinkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","realPath":"hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":212,"status":"B"}],"commitId":"7a11de12764d8f68f296c6e68a22822318bfbefa","commitMessage":"@@@[HUDI-1632] Supports merge on read write mode for Flink writer (#2593)\n\nAlso supports async compaction with pluggable strategies.","date":"2021-03-01 12:29:41","modifiedFileCount":"20","status":"M","submitter":"Danny Chan"},{"authorTime":"2021-03-29 10:47:29","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":3,"curCode":"  public void commitCompaction(String compactionInstantTime, JavaRDD<WriteStatus> writeStatuses, Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieSparkTable<T> table = HoodieSparkTable.create(config, context);\n    HoodieCommitMetadata metadata = SparkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","date":"2020-10-02 05:25:29","endLine":257,"groupId":"10750","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"commitCompaction","params":"(StringcompactionInstantTime@JavaRDD<WriteStatus>writeStatuses@Option<Map<String@String>>extraMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/56/f06898abba2ed1f4e291f65b581c9426fcb1b3.src","preCode":"  public void commitCompaction(String compactionInstantTime, JavaRDD<WriteStatus> writeStatuses, Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieSparkTable<T> table = HoodieSparkTable.create(config, context);\n    HoodieCommitMetadata metadata = SparkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":251,"status":"N"},{"authorDate":"2021-03-29 10:47:29","commitOrder":3,"curCode":"  public void commitCompaction(\n      String compactionInstantTime,\n      List<WriteStatus> writeStatuses,\n      Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieFlinkTable<T> table = getHoodieTable();\n    HoodieCommitMetadata metadata = FlinkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","date":"2021-03-29 10:47:29","endLine":291,"groupId":"10750","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"commitCompaction","params":"(StringcompactionInstantTime@List<WriteStatus>writeStatuses@Option<Map<String@String>>extraMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/de/4d8ca65483b9ea390a4d32c01b91e3979f5b96.src","preCode":"  public void commitCompaction(\n      String compactionInstantTime,\n      List<WriteStatus> writeStatuses,\n      Option<Map<String, String>> extraMetadata) throws IOException {\n    HoodieFlinkTable<T> table = HoodieFlinkTable.create(config, (HoodieFlinkEngineContext) context);\n    HoodieCommitMetadata metadata = FlinkCompactHelpers.newInstance().createCompactionMetadata(\n        table, compactionInstantTime, writeStatuses, config.getSchema());\n    extraMetadata.ifPresent(m -> m.forEach(metadata::addMetadata));\n    completeCompaction(metadata, writeStatuses, table, compactionInstantTime);\n  }\n","realPath":"hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":282,"status":"M"}],"commitId":"d415d45416707ca4d5b1dbad65dc80e6fccfa378","commitMessage":"@@@[HUDI-1729] Asynchronous Hive sync and commits cleaning for Flink writer (#2732)\n\n","date":"2021-03-29 10:47:29","modifiedFileCount":"16","status":"M","submitter":"Danny Chan"}]
