[{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2021-01-30 02:27:09","commitOrder":2,"curCode":"  protected JavaRDD<WriteStatus> updateIndex(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context, table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    result.setPartitionToReplaceFileIds(getPartitionToReplacedFileIds(statuses));\n    return statuses;\n  }\n","date":"2021-01-30 02:27:09","endLine":222,"groupId":"2764","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"updateIndex","params":"(JavaRDD<WriteStatus>writeStatusRDD@HoodieWriteMetadataresult)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/a9/9b00162d68f28246dcfd40149a4830a085ae39.src","preCode":"  protected JavaRDD<WriteStatus> updateIndex(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context, table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    result.setPartitionToReplaceFileIds(getPartitionToReplacedFileIds(statuses));\n    return statuses;\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/BaseSparkCommitActionExecutor.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":211,"status":"B"},{"authorDate":"2020-10-02 05:25:29","commitOrder":2,"curCode":"  private void updateIndexAndCommitIfNeeded(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata<JavaRDD<WriteStatus>> result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context,\n        table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    commitOnAutoCommit(result);\n  }\n","date":"2020-10-02 05:25:29","endLine":189,"groupId":"2764","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"updateIndexAndCommitIfNeeded","params":"(JavaRDD<WriteStatus>writeStatusRDD@HoodieWriteMetadata<JavaRDD<WriteStatus>>result)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/64/df78c0d42c84b9dc671577f2fa3764e31a809c.src","preCode":"  private void updateIndexAndCommitIfNeeded(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata<JavaRDD<WriteStatus>> result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context,\n        table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    commitOnAutoCommit(result);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"NB"}],"commitId":"2d2d5c83b1ca33ad413746987c4aa816dd43520d","commitMessage":"@@@[HUDI-1555] Remove isEmpty to improve clustering execution performance (#2502)\n\n","date":"2021-01-30 02:27:09","modifiedFileCount":"4","status":"M","submitter":"satishkotha"},{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2021-08-07 10:53:08","commitOrder":3,"curCode":"  protected JavaRDD<WriteStatus> updateIndex(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context, table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    return statuses;\n  }\n","date":"2021-08-07 10:53:08","endLine":241,"groupId":"10724","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"updateIndex","params":"(JavaRDD<WriteStatus>writeStatusRDD@HoodieWriteMetadataresult)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/2b/c1f0302798ea6d6b790711af5180320de76d98.src","preCode":"  protected JavaRDD<WriteStatus> updateIndex(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context, table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    result.setPartitionToReplaceFileIds(getPartitionToReplacedFileIds(statuses));\n    return statuses;\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/BaseSparkCommitActionExecutor.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":231,"status":"M"},{"authorDate":"2020-10-02 05:25:29","commitOrder":3,"curCode":"  private void updateIndexAndCommitIfNeeded(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata<JavaRDD<WriteStatus>> result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context,\n        table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    commitOnAutoCommit(result);\n  }\n","date":"2020-10-02 05:25:29","endLine":189,"groupId":"10724","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"updateIndexAndCommitIfNeeded","params":"(JavaRDD<WriteStatus>writeStatusRDD@HoodieWriteMetadata<JavaRDD<WriteStatus>>result)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/64/df78c0d42c84b9dc671577f2fa3764e31a809c.src","preCode":"  private void updateIndexAndCommitIfNeeded(JavaRDD<WriteStatus> writeStatusRDD, HoodieWriteMetadata<JavaRDD<WriteStatus>> result) {\n    \r\n    \r\n    writeStatusRDD = writeStatusRDD.persist(SparkMemoryUtils.getWriteStatusStorageLevel(config.getProps()));\n    Instant indexStartTime = Instant.now();\n    \r\n    JavaRDD<WriteStatus> statuses = table.getIndex().updateLocation(writeStatusRDD, context,\n        table);\n    result.setIndexUpdateDuration(Duration.between(indexStartTime, Instant.now()));\n    result.setWriteStatuses(statuses);\n    commitOnAutoCommit(result);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"70b6bd485f8d1ef9a9b15999edda2472d0b4d65a","commitMessage":"@@@[HUDI-1468] Support custom clustering strategies and preserve commit metadata as part of clustering (#3419)\n\nCo-authored-by: Satish Kotha <satishkotha@uber.com>","date":"2021-08-07 10:53:08","modifiedFileCount":"24","status":"M","submitter":"Sagar Sumit"}]
