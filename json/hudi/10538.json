[{"authorTime":"2021-01-10 08:53:34","codes":[{"authorDate":"2020-12-13 22:28:53","commitOrder":2,"curCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","date":"2020-12-13 22:28:53","endLine":689,"groupId":"4571","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testKeepLatestCommitsMOR","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/69/c6f98c672379e003ed7d94aa5ee322151b8851.src","preCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":651,"status":"NB"},{"authorDate":"2021-01-10 08:53:34","commitOrder":2,"curCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    testTable.addReplaceCommit(\"00000000000002\", generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    testTable.addReplaceCommit(\"00000000000003\", generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    testTable.addReplaceCommit(\"00000000000004\", generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    testTable.addReplaceCommit(\"00000000000005\", generateReplaceCommitMetadata(p1, file3P1C2, file4P1C4));\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","date":"2021-01-10 08:53:34","endLine":777,"groupId":"5522","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCleanWithReplaceCommits","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/3a/5d7373c53a7f8df63d89fdbc0dce630e368500.src","preCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    testTable.addReplaceCommit(\"00000000000002\", generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    testTable.addReplaceCommit(\"00000000000003\", generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    testTable.addReplaceCommit(\"00000000000004\", generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    testTable.addReplaceCommit(\"00000000000005\", generateReplaceCommitMetadata(p1, file3P1C2, file4P1C4));\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":693,"status":"B"}],"commitId":"65866c45ec04820b01ab701e7de5cf6a406d2a8e","commitMessage":"@@@[HUDI-1276] [HUDI-1459] Make Clustering/ReplaceCommit and Metadata table be compatible (#2422)\n\n* [HUDI-1276] [HUDI-1459] Make Clustering/ReplaceCommit and Metadata table be compatible\n\n* Use filesystemview and json format from metadata. Add tests\n\nCo-authored-by: Satish Kotha <satishkotha@uber.com>","date":"2021-01-10 08:53:34","modifiedFileCount":"17","status":"M","submitter":"vinoth chandar"},{"authorTime":"2021-01-20 13:20:28","codes":[{"authorDate":"2021-01-20 13:20:28","commitOrder":3,"curCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","date":"2021-01-20 13:20:28","endLine":694,"groupId":"4571","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testKeepLatestCommitsMOR","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/4f/ff08abfbcef6651c952fa0d168eff4cfa8682c.src","preCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":655,"status":"M"},{"authorDate":"2021-01-20 13:20:28","commitOrder":3,"curCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    testTable.addReplaceCommit(\"00000000000002\", generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    testTable.addReplaceCommit(\"00000000000003\", generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    testTable.addReplaceCommit(\"00000000000004\", generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    testTable.addReplaceCommit(\"00000000000005\", generateReplaceCommitMetadata(p1, file3P1C2, file4P1C4));\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","date":"2021-01-20 13:20:28","endLine":782,"groupId":"5522","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCleanWithReplaceCommits","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/4f/ff08abfbcef6651c952fa0d168eff4cfa8682c.src","preCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    testTable.addReplaceCommit(\"00000000000002\", generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    testTable.addReplaceCommit(\"00000000000003\", generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    testTable.addReplaceCommit(\"00000000000004\", generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    testTable.addReplaceCommit(\"00000000000005\", generateReplaceCommitMetadata(p1, file3P1C2, file4P1C4));\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":697,"status":"M"}],"commitId":"5ca0625b277efa3a73d2ae0fbdfa4c6163f312d2","commitMessage":"@@@[HUDI 1308] Harden RFC-15 Implementation based on production testing (#2441)\n\nAddresses leaks.  perf degradation observed during testing. These were regressions from the original rfc-15 PoC implementation.\n\n* Pass a single instance of HoodieTableMetadata everywhere\n* Fix tests and add config for enabling metrics\n - Removed special casing of assumeDatePartitioning inside FSUtils#getAllPartitionPaths()\n - Consequently.  IOException is never thrown and many files had to be adjusted\n- More diligent handling of open file handles in metadata table\n - Added config for controlling reuse of connections\n - Added config for turning off fallback to listing.  so we can see tests fail\n - Changed all ipf listing code to cache/amortize the open/close for better performance\n - Timelineserver also reuses connections.  for better performance\n - Without timelineserver.  when metadata table is opened from executors.  reuse is not allowed\n - HoodieMetadataConfig passed into HoodieTableMetadata#create as argument.\n -  Fix TestHoodieBackedTableMetadata#testSync","date":"2021-01-20 13:20:28","modifiedFileCount":"53","status":"M","submitter":"vinoth chandar"},{"authorTime":"2021-03-10 07:56:44","codes":[{"authorDate":"2021-01-20 13:20:28","commitOrder":4,"curCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","date":"2021-01-20 13:20:28","endLine":694,"groupId":"4571","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testKeepLatestCommitsMOR","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/4f/ff08abfbcef6651c952fa0d168eff4cfa8682c.src","preCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":655,"status":"N"},{"authorDate":"2021-03-10 07:56:44","commitOrder":4,"curCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    Pair<HoodieRequestedReplaceMetadata, HoodieReplaceCommitMetadata> replaceMetadata = generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1);\n    testTable.addReplaceCommit(\"00000000000002\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2);\n    testTable.addReplaceCommit(\"00000000000003\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3);\n    testTable.addReplaceCommit(\"00000000000004\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file3P1C2, file4P1C4);\n    testTable.addReplaceCommit(\"00000000000005\", replaceMetadata.getKey(), replaceMetadata.getValue());\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","date":"2021-03-10 07:56:44","endLine":904,"groupId":"4571","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testCleanWithReplaceCommits","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/fd/578bd8b70bc79f75c67a3d966565c29539a8e8.src","preCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    testTable.addReplaceCommit(\"00000000000002\", generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    testTable.addReplaceCommit(\"00000000000003\", generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    testTable.addReplaceCommit(\"00000000000004\", generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3));\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    testTable.addReplaceCommit(\"00000000000005\", generateReplaceCommitMetadata(p1, file3P1C2, file4P1C4));\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":815,"status":"M"}],"commitId":"c4a66324cdd3e289e0bf18bdd150b95ee6e4c66c","commitMessage":"@@@[HUDI-1651] Fix archival of requested replacecommit (#2622)\n\n","date":"2021-03-10 07:56:44","modifiedFileCount":"5","status":"M","submitter":"satishkotha"},{"authorTime":"2021-03-10 07:56:44","codes":[{"authorDate":"2021-05-12 01:01:45","commitOrder":5,"curCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one base and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","date":"2021-05-12 01:01:45","endLine":807,"groupId":"4571","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testKeepLatestCommitsMOR","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/cb/37ed4bcf2732df46a8ab47fda68fa27b9d1582.src","preCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one parquet and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":768,"status":"M"},{"authorDate":"2021-03-10 07:56:44","commitOrder":5,"curCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    Pair<HoodieRequestedReplaceMetadata, HoodieReplaceCommitMetadata> replaceMetadata = generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1);\n    testTable.addReplaceCommit(\"00000000000002\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2);\n    testTable.addReplaceCommit(\"00000000000003\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3);\n    testTable.addReplaceCommit(\"00000000000004\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file3P1C2, file4P1C4);\n    testTable.addReplaceCommit(\"00000000000005\", replaceMetadata.getKey(), replaceMetadata.getValue());\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","date":"2021-03-10 07:56:44","endLine":904,"groupId":"4571","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testCleanWithReplaceCommits","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/fd/578bd8b70bc79f75c67a3d966565c29539a8e8.src","preCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    Pair<HoodieRequestedReplaceMetadata, HoodieReplaceCommitMetadata> replaceMetadata = generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1);\n    testTable.addReplaceCommit(\"00000000000002\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2);\n    testTable.addReplaceCommit(\"00000000000003\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3);\n    testTable.addReplaceCommit(\"00000000000004\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file3P1C2, file4P1C4);\n    testTable.addReplaceCommit(\"00000000000005\", replaceMetadata.getKey(), replaceMetadata.getValue());\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":815,"status":"N"}],"commitId":"be9db2c4f5a570fcaa555618b34ad11109ed6b00","commitMessage":"@@@[HUDI-1055] Remove hardcoded parquet in tests (#2740)\n\n* Remove hardcoded parquet in tests\n* Use DataFileUtils.getInstance\n* Renaming DataFileUtils to BaseFileUtils\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2021-05-12 01:01:45","modifiedFileCount":"40","status":"M","submitter":"TeRS-K"},{"authorTime":"2021-05-22 04:52:13","codes":[{"authorDate":"2021-05-12 01:01:45","commitOrder":6,"curCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one base and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","date":"2021-05-12 01:01:45","endLine":807,"groupId":"10538","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testKeepLatestCommitsMOR","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/cb/37ed4bcf2732df46a8ab47fda68fa27b9d1582.src","preCode":"  public void testKeepLatestCommitsMOR() throws Exception {\n\n    HoodieWriteConfig config =\n            HoodieWriteConfig.newBuilder().withPath(basePath)\n                .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n                    .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n                            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(1).build())\n                    .build();\n\n    HoodieTableMetaClient metaClient = HoodieTestUtils.init(hadoopConf, basePath, HoodieTableType.MERGE_ON_READ);\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n\n    \r\n    String file1P0 = testTable.addDeltaCommit(\"000\").getFileIdsWithBaseFilesInPartitions(p0).get(p0);\n    testTable.forDeltaCommit(\"000\")\n            .withLogFile(p0, file1P0, 1)\n            .withLogFile(p0, file1P0, 2);\n\n    \r\n    testTable.addDeltaCommit(\"001\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 3);\n\n    \r\n    testTable.addDeltaCommit(\"002\")\n            .withBaseFilesInPartition(p0, file1P0)\n            .withLogFile(p0, file1P0, 4);\n\n    List<HoodieCleanStat> hoodieCleanStats = runCleaner(config);\n    assertEquals(3,\n            getCleanStat(hoodieCleanStats, p0).getSuccessDeleteFiles()\n                    .size(), \"Must clean three files, one base and 2 log files\");\n    assertFalse(testTable.baseFileExists(p0, \"000\", file1P0));\n    assertFalse(testTable.logFilesExist(p0, \"000\", file1P0, 1, 2));\n    assertTrue(testTable.baseFileExists(p0, \"001\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"001\", file1P0, 3));\n    assertTrue(testTable.baseFileExists(p0, \"002\", file1P0));\n    assertTrue(testTable.logFileExists(p0, \"002\", file1P0, 4));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":768,"status":"N"},{"authorDate":"2021-05-22 04:52:13","commitOrder":6,"curCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    Pair<HoodieRequestedReplaceMetadata, HoodieReplaceCommitMetadata> replaceMetadata = generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1);\n    testTable.addReplaceCommit(\"00000000000002\", Option.of(replaceMetadata.getKey()), Option.empty(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2);\n    testTable.addReplaceCommit(\"00000000000003\", Option.of(replaceMetadata.getKey()), Option.empty(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3);\n    testTable.addReplaceCommit(\"00000000000004\", Option.of(replaceMetadata.getKey()), Option.empty(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file3P1C2, file4P1C4);\n    testTable.addReplaceCommit(\"00000000000005\", Option.of(replaceMetadata.getKey()), Option.empty(), replaceMetadata.getValue());\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","date":"2021-05-22 04:52:13","endLine":903,"groupId":"10538","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testCleanWithReplaceCommits","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/87/dd26f0c64284ae5522da72b7baa45745c067b0.src","preCode":"  public void testCleanWithReplaceCommits() throws Exception {\n    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n        .withMetadataConfig(HoodieMetadataConfig.newBuilder().withAssumeDatePartitioning(true).build())\n        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n            .withCleanerPolicy(HoodieCleaningPolicy.KEEP_LATEST_COMMITS).retainCommits(2).build())\n        .build();\n\n    HoodieTestTable testTable = HoodieTestTable.of(metaClient);\n    String p0 = \"2020/01/01\";\n    String p1 = \"2020/01/02\";\n\n    \r\n    String file1P0C0 = UUID.randomUUID().toString();\n    String file1P1C0 = UUID.randomUUID().toString();\n    testTable.addInflightCommit(\"00000000000001\").withBaseFilesInPartition(p0, file1P0C0).withBaseFilesInPartition(p1, file1P1C0);\n\n    HoodieCommitMetadata commitMetadata = generateCommitMetadata(\n        Collections.unmodifiableMap(new HashMap<String, List<String>>() {\n          {\n            put(p0, CollectionUtils.createImmutableList(file1P0C0));\n            put(p1, CollectionUtils.createImmutableList(file1P1C0));\n          }\n        })\n    );\n    metaClient.getActiveTimeline().saveAsComplete(\n        new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, \"00000000000001\"),\n        Option.of(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n\n    metaClient = HoodieTableMetaClient.reload(metaClient);\n\n    List<HoodieCleanStat> hoodieCleanStatsOne = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsOne.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId002 = testTable.forReplaceCommit(\"00000000000002\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file2P0C1 = partitionAndFileId002.get(p0);\n    Pair<HoodieRequestedReplaceMetadata, HoodieReplaceCommitMetadata> replaceMetadata = generateReplaceCommitMetadata(p0, file1P0C0, file2P0C1);\n    testTable.addReplaceCommit(\"00000000000002\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsTwo = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsTwo.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId003 = testTable.forReplaceCommit(\"00000000000003\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file3P1C2 = partitionAndFileId003.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p1, file1P1C0, file3P1C2);\n    testTable.addReplaceCommit(\"00000000000003\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsThree = runCleaner(config);\n    assertEquals(0, hoodieCleanStatsThree.size(), \"Must not scan any partitions and clean any files\");\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId004 = testTable.forReplaceCommit(\"00000000000004\").getFileIdsWithBaseFilesInPartitions(p0);\n    String file4P0C3 = partitionAndFileId004.get(p0);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file2P0C1, file4P0C3);\n    testTable.addReplaceCommit(\"00000000000004\", replaceMetadata.getKey(), replaceMetadata.getValue());\n\n    \r\n    List<HoodieCleanStat> hoodieCleanStatsFour = runCleaner(config);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    \r\n    assertTrue(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n\n    \r\n    Map<String, String> partitionAndFileId005 = testTable.forReplaceCommit(\"00000000000005\").getFileIdsWithBaseFilesInPartitions(p1);\n    String file4P1C4 = partitionAndFileId005.get(p1);\n    replaceMetadata = generateReplaceCommitMetadata(p0, file3P1C2, file4P1C4);\n    testTable.addReplaceCommit(\"00000000000005\", replaceMetadata.getKey(), replaceMetadata.getValue());\n    \n    List<HoodieCleanStat> hoodieCleanStatsFive = runCleaner(config, 2);\n    assertTrue(testTable.baseFileExists(p0, \"00000000000004\", file4P0C3));\n    assertTrue(testTable.baseFileExists(p0, \"00000000000002\", file2P0C1));\n    assertTrue(testTable.baseFileExists(p1, \"00000000000003\", file3P1C2));\n    assertFalse(testTable.baseFileExists(p0, \"00000000000001\", file1P0C0));\n    assertFalse(testTable.baseFileExists(p1, \"00000000000001\", file1P1C0));\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/TestCleaner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":810,"status":"M"}],"commitId":"685f77b5dda92bb4ecd3a5480a1a5ed2eaee5fef","commitMessage":"@@@[HUDI-1740] Fix insert-overwrite API archival (#2784)\n\n- fix problem of archiving replace commits\n- Fix problem when getting empty replacecommit.requested\n- Improved the logic of handling empty and non-empty requested/inflight commit files. Added unit tests to cover both empty and non-empty inflight files cases and cleaned up some unused test util methods\n\nCo-authored-by: yorkzero831 <yorkzero8312@gmail.com>\nCo-authored-by: zheren.yu <zheren.yu@paypay-corp.co.jp>","date":"2021-05-22 04:52:13","modifiedFileCount":"10","status":"M","submitter":"Susu Dong"}]
