[{"authorTime":"2020-08-06 12:34:55","codes":[{"authorDate":"2020-08-06 12:34:55","commitOrder":1,"curCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one paritition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be 101\");\n  }\n","date":"2020-08-06 12:34:55","endLine":255,"groupId":"1280","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncIncremental","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one paritition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be 101\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":220,"status":"B"},{"authorDate":"2020-08-06 12:34:55","commitOrder":1,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2020-08-06 12:34:55","endLine":487,"groupId":"1283","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"B"}],"commitId":"51ea27d665d8053895dd047ca85e3338b357a81d","commitMessage":"@@@[HUDI-875] Abstract hudi-sync-common.  and support hudi-hive-sync.  hudi-dla-sync (#1810)\n\n- Generalize the hive-sync module for syncing to multiple metastores\n- Added new options for datasource\n- Added new command line for delta streamer \n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-08-06 12:34:55","modifiedFileCount":"3","status":"B","submitter":"lw0090"},{"authorTime":"2020-08-06 12:34:55","codes":[{"authorDate":"2021-04-19 16:27:13","commitOrder":2,"curCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","date":"2021-04-19 16:27:13","endLine":290,"groupId":"1280","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncIncremental","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/75/ba97c8358973b86dd0841257435aacc29186f6.src","preCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one paritition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was sycned should be 101\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":255,"status":"M"},{"authorDate":"2020-08-06 12:34:55","commitOrder":2,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2020-08-06 12:34:55","endLine":487,"groupId":"1283","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/17/bc2155c31c6798ff5fb95434233842fadd152a.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n            hiveClient.getDataSchema().getColumns().size(),\n            \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n            \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"N"}],"commitId":"f7b6b680632115da7eb63eceadf95bd99f02d355","commitMessage":"@@@[MINOR][hudi-sync] Fix typos (#2844)\n\n","date":"2021-04-19 16:27:13","modifiedFileCount":"1","status":"M","submitter":"Roc Marshal"},{"authorTime":"2021-07-04 22:30:36","codes":[{"authorDate":"2021-07-04 22:30:36","commitOrder":3,"curCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","date":"2021-07-04 22:30:36","endLine":352,"groupId":"1280","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncIncremental","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":316,"status":"M"},{"authorDate":"2021-07-04 22:30:36","commitOrder":3,"curCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2021-07-04 22:30:36","endLine":633,"groupId":"1283","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(booleanuseJdbc)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c4/125337ea9d8f89fd4b103aa96d08392d77e7ff.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":607,"status":"M"}],"commitId":"6a71412f7804c9cbd34e4c6fc01545a994523bb4","commitMessage":"@@@[HUDI-2116] Support batch synchronization of partition datas to  hive metastore to avoid oom problem (#3209)\n\n","date":"2021-07-04 22:30:36","modifiedFileCount":"4","status":"M","submitter":"xiarixiaoyao"},{"authorTime":"2021-07-24 00:03:15","codes":[{"authorDate":"2021-07-24 00:03:15","commitOrder":4,"curCode":"  public void testSyncIncremental(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","date":"2021-07-24 00:03:15","endLine":558,"groupId":"5706","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSyncIncremental","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testSyncIncremental(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(HiveTestUtil.hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(HiveTestUtil.hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(HiveTestUtil.hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":521,"status":"M"},{"authorDate":"2021-07-24 00:03:15","commitOrder":4,"curCode":"  public void testNonPartitionedSync(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2021-07-24 00:03:15","endLine":841,"groupId":"1283","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":814,"status":"M"}],"commitId":"66207ed91a75ce8e91ccc0c417dc0d310dc36a5c","commitMessage":"@@@[HUDI-1848] Adding support for HMS for running DDL queries in hive-sy? (#2879)\n\n* [HUDI-1848] Adding support for HMS for running DDL queries in hive-sync-tool\n\n* [HUDI-1848] Fixing test cases\n\n* [HUDI-1848] CR changes\n\n* [HUDI-1848] Fix checkstyle violations\n\n* [HUDI-1848] Fixed a bug when metastore api fails for complex schemas with multiple levels.\n\n* [HUDI-1848] Adding the complex schema and resolving merge conflicts\n\n* [HUDI-1848] Adding some more javadocs\n\n* [HUDI-1848] Added javadocs for DDLExecutor impls\n\n* [HUDI-1848] Fixed style issue","date":"2021-07-24 00:03:15","modifiedFileCount":"9","status":"M","submitter":"jsbali"},{"authorTime":"2021-07-24 00:03:15","codes":[{"authorDate":"2021-08-11 11:25:41","commitOrder":5,"curCode":"  public void testSyncIncremental(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    ZonedDateTime dateTime = ZonedDateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","date":"2021-08-11 11:25:41","endLine":486,"groupId":"10330","id":9,"instanceNumber":1,"isCurCommit":1,"methodName":"testSyncIncremental","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/fc/b626eb3231099263b43694f1b44490fadcd30e.src","preCode":"  public void testSyncIncremental(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String commitTime1 = \"100\";\n    HiveTestUtil.createCOWTable(commitTime1, 5, true);\n    HoodieHiveClient hiveClient =\n        new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertEquals(5, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table partitions should match the number of partitions we wrote\");\n    assertEquals(commitTime1, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be updated in the TBLPROPERTIES\");\n\n    \r\n    DateTime dateTime = DateTime.now().plusDays(6);\n    String commitTime2 = \"101\";\n    HiveTestUtil.addCOWPartitions(1, true, true, dateTime, commitTime2);\n\n    \r\n    hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    List<String> writtenPartitionsSince = hiveClient.getPartitionsWrittenToSince(Option.of(commitTime1));\n    assertEquals(1, writtenPartitionsSince.size(), \"We should have one partition written after 100 commit\");\n    List<Partition> hivePartitions = hiveClient.scanTablePartitions(hiveSyncConfig.tableName);\n    List<PartitionEvent> partitionEvents = hiveClient.getPartitionEvents(hivePartitions, writtenPartitionsSince);\n    assertEquals(1, partitionEvents.size(), \"There should be only one partition event\");\n    assertEquals(PartitionEventType.ADD, partitionEvents.iterator().next().eventType, \"The one partition event must of type ADD\");\n\n    tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    \r\n    assertEquals(6, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"The one partition we wrote should be added to hive\");\n    assertEquals(commitTime2, hiveClient.getLastCommitTimeSynced(hiveSyncConfig.tableName).get(),\n        \"The last commit that was synced should be 101\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":449,"status":"M"},{"authorDate":"2021-07-24 00:03:15","commitOrder":5,"curCode":"  public void testNonPartitionedSync(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","date":"2021-07-24 00:03:15","endLine":841,"groupId":"10330","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testNonPartitionedSync","params":"(StringsyncMode)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/af/94c16b62f45519cc2c42f9335f83cb6f25c6e3.src","preCode":"  public void testNonPartitionedSync(String syncMode) throws Exception {\n\n    hiveSyncConfig.syncMode = syncMode;\n    HiveTestUtil.hiveSyncConfig.batchSyncNum = 2;\n    String instantTime = \"100\";\n    HiveTestUtil.createCOWTable(instantTime, 5, true);\n\n    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n    \r\n    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n    hiveSyncConfig.tableName = \"non_partitioned\";\n    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n\n    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n    \r\n    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), fileSystem);\n    tool.syncHoodieTable();\n    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n        \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n        hiveClient.getDataSchema().getColumns().size(),\n        \"Hive Schema should match the table schema���������ignoring the partition fields\");\n    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n        \"Table should not have partitions because of the NonPartitionedExtractor\");\n  }\n","realPath":"hudi-sync/hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":814,"status":"N"}],"commitId":"8255a86cb4d7f2173f0adcf0d752096b0b4df78c","commitMessage":"@@@[HUDI-1939] remove joda time in hivesync module (#3430)\n\n","date":"2021-08-11 11:25:41","modifiedFileCount":"5","status":"M","submitter":"Raymond Xu"}]
