[{"authorTime":"2020-03-23 09:06:00","codes":[{"authorDate":"2020-03-25 18:02:24","commitOrder":7,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                HoodieTimeline.LESSER_OR_EQUAL);\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-03-25 18:02:24","endLine":248,"groupId":"1218","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/7d/f630a11e3bb4f3300f4ce28f06568e1b040585.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                HoodieTimeline.LESSER_OR_EQUAL);\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"B"},{"authorDate":"2020-03-23 09:06:00","commitOrder":7,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                  HoodieTimeline.LESSER_OR_EQUAL);\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-03-23 09:06:00","endLine":162,"groupId":"2400","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8c/81ddf356094ed50b21cdeccbfcdea2a275d3aa.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                  HoodieTimeline.LESSER_OR_EQUAL);\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"NB"}],"commitId":"bc82e2be6cf080ab99092758368e91f509a2004c","commitMessage":"@@@[HUDI-711] Refactor exporter main logic (#1436)\n\n* Refactor exporter main logic\n* break main method into multiple readable methods\n* fix bug of passing wrong file list\n* avoid deleting output path when exists\n* throw exception to early abort on multiple cases\n* use JavaSparkContext instead of SparkSession\n* improve unit test for expected exceptions","date":"2020-03-25 18:02:24","modifiedFileCount":"2","status":"M","submitter":"Raymond Xu"},{"authorTime":"2020-05-01 00:19:39","codes":[{"authorDate":"2020-05-01 00:19:39","commitOrder":8,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-05-01 00:19:39","endLine":248,"groupId":"1218","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/39/64ed70d429e3ed1e22da992bb07c369d3d733c.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                HoodieTimeline.LESSER_OR_EQUAL);\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"},{"authorDate":"2020-05-01 00:19:39","commitOrder":8,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-05-01 00:19:39","endLine":162,"groupId":"2400","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/b9/7cd990ff9db5d2273ba70b4621e00654b0d440.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, latestCommitTimestamp,\n                  HoodieTimeline.LESSER_OR_EQUAL);\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"c4b71622b90fc66f20f361d4c083b0a396572b75","commitMessage":"@@@[MINOR] Reorder HoodieTimeline#compareTimestamp arguments for better readability (#1575)\n\n- reads nicely as (instantTime1.  GREATER_THAN_OR_EQUALS.  instantTime2) etc","date":"2020-05-01 00:19:39","modifiedFileCount":"26","status":"M","submitter":"vinoth chandar"},{"authorTime":"2020-05-27 00:23:34","codes":[{"authorDate":"2020-05-01 00:19:39","commitOrder":9,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-05-01 00:19:39","endLine":248,"groupId":"1218","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/39/64ed70d429e3ed1e22da992bb07c369d3d733c.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"N"},{"authorDate":"2020-05-27 00:23:34","commitOrder":9,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-05-27 00:23:34","endLine":162,"groupId":"2400","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/65/1cbbf0e52026cddda36477235f25a67f9571ba.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"6c450957ced051de6231ad047bce22752210b786","commitMessage":"@@@[HUDI-690] Filter out inflight compaction in exporter (#1667)\n\n","date":"2020-05-27 00:23:34","modifiedFileCount":"3","status":"M","submitter":"Raymond Xu"},{"authorTime":"2020-07-20 01:29:25","codes":[{"authorDate":"2020-07-20 01:29:25","commitOrder":10,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.setJobGroup(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-07-20 01:29:25","endLine":251,"groupId":"1218","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/07/43839ff7c6d5150073c52b426329f308f9d722.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":194,"status":"M"},{"authorDate":"2020-07-20 01:29:25","commitOrder":10,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.setJobGroup(this.getClass().getSimpleName(), \"Creating a snapshot\");\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-07-20 01:29:25","endLine":163,"groupId":"0","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/91/6d01905f2b889fe02ee060e4cdf2a69f2ae2af.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"b71f25f210c4004a2dcc97a9967399e74f870fc7","commitMessage":"@@@[HUDI-92] Provide reasonable names for Spark DAG stages in HUDI. (#1289)\n\n","date":"2020-07-20 01:29:25","modifiedFileCount":"24","status":"M","submitter":"Prashant Wason"},{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":11,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-10-02 05:25:29","endLine":257,"groupId":"0","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/cf/69dd2207d80ab3a77dbdb34ab53b1bf02ac22f.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    jsc.setJobGroup(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n    jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n\n      return filePaths.iterator();\n    }).foreach(tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    });\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"M"},{"authorDate":"2020-10-02 05:25:29","commitOrder":11,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-10-02 05:25:29","endLine":169,"groupId":"838","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/05/b46273001c04633c533631d8117f05092b513c.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      jsc.setJobGroup(this.getClass().getSimpleName(), \"Creating a snapshot\");\n      jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.iterator();\n      }).foreach(tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      });\n\n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"1f7add92916c37b05be270d9c75a9042134ec506","commitMessage":"@@@[HUDI-1089] Refactor hudi-client to support multi-engine (#1827)\n\n- This change breaks `hudi-client` into `hudi-client-common` and `hudi-spark-client` modules \n- Simple usages of Spark using jsc.parallelize() has been redone using EngineContext#map.  EngineContext#flatMap etc\n- Code changes in the PR.  break classes into `BaseXYZ` parent classes with no spark dependencies living in `hudi-client-common`\n- Classes on `hudi-spark-client` are named `SparkXYZ` extending the parent classes with all the Spark dependencies\n- To simplify/cleanup.  HoodieIndex#fetchRecordLocation has been removed and its usages in tests replaced with alternatives\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-10-02 05:25:29","modifiedFileCount":"31","status":"M","submitter":"Mathieu"},{"authorTime":"2020-12-10 10:19:19","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":12,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"270","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(new Path(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = new Path(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"M"},{"authorDate":"2020-12-10 10:19:19","commitOrder":12,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":169,"groupId":"838","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/28/2610893df551c2d923d85c5574de3892a6645b.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(new Path(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = new Path(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"bd9cceccb582ede88b989824241498e8c32d4f13","commitMessage":"@@@[HUDI-1395] Fix partition path using FSUtils (#2312)\n\nFixed the logic to get partition path in Copier and Exporter utilities.","date":"2020-12-10 10:19:19","modifiedFileCount":"2","status":"M","submitter":"Raymond Xu"},{"authorTime":"2020-12-31 17:20:02","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":13,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"270","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"},{"authorDate":"2020-12-31 17:20:02","commitOrder":13,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2021-01-04 23:59:47","endLine":178,"groupId":"838","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning@finalbooleanuseFileListingFromMetadata@finalbooleanverifyMetadataFileListing)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/00/66d86d595b57c771896315f6f0dbbc9f0618dc.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n      final boolean shouldAssumeDatePartitioning) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"4e642268442782cdd7ad753981dd2571388cd189","commitMessage":"@@@[HUDI-1450] Use metadata table for listing in HoodieROTablePathFilter (apache#2326)\n\n[HUDI-1394] [RFC-15] Use metadata table (if present) to get all partition paths (apache#2351)\n","date":"2021-01-04 23:59:47","modifiedFileCount":"32","status":"M","submitter":"Udit Mehrotra"},{"authorTime":"2021-01-11 13:19:52","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":14,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"270","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"},{"authorDate":"2021-01-11 13:19:52","commitOrder":14,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, fs, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2021-01-11 13:19:52","endLine":178,"groupId":"838","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning@finalbooleanuseFileListingFromMetadata@finalbooleanverifyMetadataFileListing)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/0c/6b0b339e37136945ff7a07438f22d3659c1269.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(fs, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"7ce3ac778eb475bf23ffa31243dc0843ec7d089a","commitMessage":"@@@[HUDI-1479] Use HoodieEngineContext to parallelize fetching of partiton paths (#2417)\n\n* [HUDI-1479] Use HoodieEngineContext to parallelize fetching of partition paths\n\n* Adding testClass for FileSystemBackedTableMetadata\n\nCo-authored-by: Nishith Agarwal <nagarwal@uber.com>","date":"2021-01-11 13:19:52","modifiedFileCount":"34","status":"M","submitter":"Udit Mehrotra"},{"authorTime":"2021-01-20 13:20:28","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":15,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"270","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"},{"authorDate":"2021-01-20 13:20:28","commitOrder":15,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2021-01-20 13:20:28","endLine":178,"groupId":"838","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning@finalbooleanuseFileListingFromMetadata@finalbooleanverifyMetadataFileListing)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ec/e9b8c93457e9e7d1d97508ba883f90c0bbe8cf.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, fs, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"5ca0625b277efa3a73d2ae0fbdfa4c6163f312d2","commitMessage":"@@@[HUDI 1308] Harden RFC-15 Implementation based on production testing (#2441)\n\nAddresses leaks.  perf degradation observed during testing. These were regressions from the original rfc-15 PoC implementation.\n\n* Pass a single instance of HoodieTableMetadata everywhere\n* Fix tests and add config for enabling metrics\n - Removed special casing of assumeDatePartitioning inside FSUtils#getAllPartitionPaths()\n - Consequently.  IOException is never thrown and many files had to be adjusted\n- More diligent handling of open file handles in metadata table\n - Added config for controlling reuse of connections\n - Added config for turning off fallback to listing.  so we can see tests fail\n - Changed all ipf listing code to cache/amortize the open/close for better performance\n - Timelineserver also reuses connections.  for better performance\n - Without timelineserver.  when metadata table is opened from executors.  reuse is not allowed\n - HoodieMetadataConfig passed into HoodieTableMetadata#create as argument.\n -  Fix TestHoodieBackedTableMetadata#testSync","date":"2021-01-20 13:20:28","modifiedFileCount":"53","status":"M","submitter":"vinoth chandar"},{"authorTime":"2021-02-20 09:54:26","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":16,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"270","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"},{"authorDate":"2021-02-20 09:54:26","commitOrder":16,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = HoodieTableMetaClient.builder().setConf(fs.getConf()).setBasePath(baseDir).build();\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2021-02-20 09:54:26","endLine":178,"groupId":"838","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning@finalbooleanuseFileListingFromMetadata@finalbooleanverifyMetadataFileListing)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/72/d1dbdea60b6e7aaf9c9f67b22e71dbea85ed42.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = new HoodieTableMetaClient(fs.getConf(), baseDir);\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"c9fcf964b2bae56a54cb72951c8d8999eb323ed6","commitMessage":"@@@[HUDI-1315] Adding builder for HoodieTableMetaClient initialization (#2534)\n\n","date":"2021-02-20 09:54:26","modifiedFileCount":"57","status":"M","submitter":"Sivabalan Narayanan"},{"authorTime":"2021-02-20 12:12:22","codes":[{"authorDate":"2020-12-10 10:19:19","commitOrder":17,"curCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","date":"2020-12-10 10:19:19","endLine":257,"groupId":"10291","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"exportAsHudi","params":"(JavaSparkContextjsc@Configcfg@List<String>partitions@StringlatestCommitTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/c6/9d0044ed9336d5a86f938a4d23616ee1565833.src","preCode":"  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n\n    final HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    final SerializableConfiguration serConf = context.getHadoopConf();\n    context.setJobStatus(this.getClass().getSimpleName(), \"Exporting as HUDI dataset\");\n\n    List<Tuple2<String, String>> files = context.flatMap(partitions, partition -> {\n      \r\n      List<Tuple2<String, String>> filePaths = new ArrayList<>();\n      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n      \r\n      Path partitionMetaFile =\n          new Path(FSUtils.getPartitionPath(cfg.sourceBasePath, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n      FileSystem fs = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n      if (fs.exists(partitionMetaFile)) {\n        filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n      }\n      return filePaths.stream();\n    }, partitions.size());\n\n    context.foreach(files, tuple -> {\n      String partition = tuple._1();\n      Path sourceFilePath = new Path(tuple._2());\n      Path toPartitionPath = FSUtils.getPartitionPath(cfg.targetOutputPath, partition);\n      FileSystem fs = FSUtils.getFs(cfg.targetOutputPath, serConf.newCopy());\n\n      if (!fs.exists(toPartitionPath)) {\n        fs.mkdirs(toPartitionPath);\n      }\n      FileUtil.copy(fs, sourceFilePath, fs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n          fs.getConf());\n    }, files.size());\n\n    \r\n    LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n    final FileSystem fileSystem = FSUtils.getFs(cfg.sourceBasePath, jsc.hadoopConfiguration());\n    FileStatus[] commitFilesToCopy =\n        fileSystem.listStatus(new Path(cfg.sourceBasePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n          if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n            return true;\n          } else {\n            String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n            return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n            );\n          }\n        });\n    for (FileStatus commitStatus : commitFilesToCopy) {\n      Path targetFilePath =\n          new Path(cfg.targetOutputPath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n      if (!fileSystem.exists(targetFilePath.getParent())) {\n        fileSystem.mkdirs(targetFilePath.getParent());\n      }\n      if (fileSystem.exists(targetFilePath)) {\n        LOG.error(\n            String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n      }\n      FileUtil.copy(fileSystem, commitStatus.getPath(), fileSystem, targetFilePath, false, fileSystem.getConf());\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"},{"authorDate":"2021-02-20 12:12:22","commitOrder":17,"curCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = HoodieTableMetaClient.builder().setConf(fs.getConf()).setBasePath(baseDir).build();\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getWriteTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getWriteTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","date":"2021-02-20 12:12:22","endLine":178,"groupId":"10291","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"snapshot","params":"(JavaSparkContextjsc@StringbaseDir@finalStringoutputDir@finalbooleanshouldAssumeDatePartitioning@finalbooleanuseFileListingFromMetadata@finalbooleanverifyMetadataFileListing)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/63/78318b96ded0529346ac5dae60230959ae5172.src","preCode":"  public void snapshot(JavaSparkContext jsc, String baseDir, final String outputDir,\n                       final boolean shouldAssumeDatePartitioning,\n                       final boolean useFileListingFromMetadata,\n                       final boolean verifyMetadataFileListing) throws IOException {\n    FileSystem fs = FSUtils.getFs(baseDir, jsc.hadoopConfiguration());\n    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n    final HoodieTableMetaClient tableMetadata = HoodieTableMetaClient.builder().setConf(fs.getConf()).setBasePath(baseDir).build();\n    final BaseFileOnlyView fsView = new HoodieTableFileSystemView(tableMetadata,\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants());\n    HoodieEngineContext context = new HoodieSparkEngineContext(jsc);\n    \r\n    Option<HoodieInstant> latestCommit =\n        tableMetadata.getActiveTimeline().getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n    if (!latestCommit.isPresent()) {\n      LOG.warn(\"No commits present. Nothing to snapshot\");\n      return;\n    }\n    final String latestCommitTimestamp = latestCommit.get().getTimestamp();\n    LOG.info(String.format(\"Starting to snapshot latest version files which are also no-late-than %s.\",\n        latestCommitTimestamp));\n\n    List<String> partitions = FSUtils.getAllPartitionPaths(context, baseDir, useFileListingFromMetadata, verifyMetadataFileListing, shouldAssumeDatePartitioning);\n    if (partitions.size() > 0) {\n      LOG.info(String.format(\"The job needs to copy %d partitions.\", partitions.size()));\n\n      \r\n      Path outputPath = new Path(outputDir);\n      if (fs.exists(outputPath)) {\n        LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n        fs.delete(new Path(outputDir), true);\n      }\n\n      context.setJobStatus(this.getClass().getSimpleName(), \"Creating a snapshot\");\n\n      List<Tuple2<String, String>> filesToCopy = context.flatMap(partitions, partition -> {\n        \r\n        FileSystem fs1 = FSUtils.getFs(baseDir, serConf.newCopy());\n        List<Tuple2<String, String>> filePaths = new ArrayList<>();\n        Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n        dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));\n\n        \r\n        Path partitionMetaFile =\n            new Path(FSUtils.getPartitionPath(baseDir, partition), HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE);\n        if (fs1.exists(partitionMetaFile)) {\n          filePaths.add(new Tuple2<>(partition, partitionMetaFile.toString()));\n        }\n\n        return filePaths.stream();\n      }, partitions.size());\n\n      context.foreach(filesToCopy, tuple -> {\n        String partition = tuple._1();\n        Path sourceFilePath = new Path(tuple._2());\n        Path toPartitionPath = FSUtils.getPartitionPath(outputDir, partition);\n        FileSystem ifs = FSUtils.getFs(baseDir, serConf.newCopy());\n\n        if (!ifs.exists(toPartitionPath)) {\n          ifs.mkdirs(toPartitionPath);\n        }\n        FileUtil.copy(ifs, sourceFilePath, ifs, new Path(toPartitionPath, sourceFilePath.getName()), false,\n            ifs.getConf());\n      }, filesToCopy.size());\n      \n      \r\n      LOG.info(String.format(\"Copying .commit files which are no-late-than %s.\", latestCommitTimestamp));\n      FileStatus[] commitFilesToCopy =\n          fs.listStatus(new Path(baseDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME), (commitFilePath) -> {\n            if (commitFilePath.getName().equals(HoodieTableConfig.HOODIE_PROPERTIES_FILE)) {\n              return true;\n            } else {\n              String instantTime = FSUtils.getCommitFromCommitFile(commitFilePath.getName());\n              return HoodieTimeline.compareTimestamps(instantTime, HoodieTimeline.LESSER_THAN_OR_EQUALS, latestCommitTimestamp\n              );\n            }\n          });\n      for (FileStatus commitStatus : commitFilesToCopy) {\n        Path targetFilePath =\n            new Path(outputDir + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + commitStatus.getPath().getName());\n        if (!fs.exists(targetFilePath.getParent())) {\n          fs.mkdirs(targetFilePath.getParent());\n        }\n        if (fs.exists(targetFilePath)) {\n          LOG.error(\n              String.format(\"The target output commit file (%s targetBasePath) already exists.\", targetFilePath));\n        }\n        FileUtil.copy(fs, commitStatus.getPath(), fs, targetFilePath, false, fs.getConf());\n      }\n    } else {\n      LOG.info(\"The job has 0 partition to copy.\");\n    }\n\n    \r\n    Path successTagPath = new Path(outputDir + \"/_SUCCESS\");\n    if (!fs.exists(successTagPath)) {\n      LOG.info(String.format(\"Creating _SUCCESS under targetBasePath: %s\", outputDir));\n      fs.createNewFile(successTagPath);\n    }\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotCopier.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"ffcfb58bacab377bc72d20041baa54a3fd8fc812","commitMessage":"@@@[HUDI-1486] Remove inline inflight rollback in hoodie writer (#2359)\n\n1. Refactor rollback and move cleaning failed commits logic into cleaner\n2. Introduce hoodie heartbeat to ascertain failed commits\n3. Fix test cases","date":"2021-02-20 12:12:22","modifiedFileCount":"56","status":"M","submitter":"n3nash"}]
