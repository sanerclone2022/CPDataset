[{"authorTime":"2019-08-12 08:48:17","codes":[{"authorDate":"2019-08-12 08:48:17","commitOrder":1,"curCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr,\n      long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(),\n          lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD),\n        KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2019-08-12 08:48:17","endLine":66,"groupId":"5822","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/3b/051ac15815155b8b872b1ee0a642a9b2ee5170.src","preCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr,\n      long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(),\n          lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD),\n        KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"B"},{"authorDate":"2019-08-12 08:48:17","commitOrder":1,"curCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr,\n      long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(),\n          lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    }\n    log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2019-08-12 08:48:17","endLine":62,"groupId":"4577","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/86/7798dcb550a215bdadf44441e2af45637ac321.src","preCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr,\n      long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(),\n          lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    }\n    log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/JsonKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"B"}],"commitId":"a4f9d7575f39bb79089714049ffea12ba5f25ec8","commitMessage":"@@@HUDI-123 Rename code packages/constants to org.apache.hudi (#830)\n\n- Rename com.uber.hoodie to org.apache.hudi\n- Flag to pass com.uber.hoodie Input formats for hoodie-sync\n- Works with HUDI demo. \n- Also tested for backwards compatibility with datasets built by com.uber.hoodie packages\n- Migration guide : https://cwiki.apache.org/confluence/display/HUDI/Migration+Guide+From+com.uber.hoodie+to+org.apache.hudi","date":"2019-08-12 08:48:17","modifiedFileCount":"0","status":"B","submitter":"Balaji Varadarajan"},{"authorTime":"2019-12-10 19:23:38","codes":[{"authorDate":"2019-12-10 19:23:38","commitOrder":2,"curCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2019-12-10 19:23:38","endLine":64,"groupId":"5822","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/18/ebff419717a6d18287e1f28ca72f788a790441.src","preCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2019-12-10 19:23:38","commitOrder":2,"curCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    }\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2019-12-10 19:23:38","endLine":61,"groupId":"4577","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/bd/922ac6bd0c37d54f1eb740ad07b2c8a0b4caf5.src","preCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    }\n    log.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/JsonKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"}],"commitId":"d447e2d7518fc6ee87f1620542e45f1454a5ba0f","commitMessage":"@@@[checkstyle] Unify LOG form (#1092)\n\n","date":"2019-12-10 19:23:38","modifiedFileCount":"100","status":"M","submitter":"lamber-ken"},{"authorTime":"2020-06-14 18:01:44","codes":[{"authorDate":"2020-06-14 18:01:44","commitOrder":3,"curCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2020-06-14 18:01:44","endLine":66,"groupId":"4306","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/66/a38e2a4409a2d668d866b8bbd76f29b40d74c9.src","preCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"},{"authorDate":"2020-06-14 18:01:44","commitOrder":3,"curCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2020-06-14 18:01:44","endLine":64,"groupId":"4306","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/83/3c6c6309bb670922afcf6bd6e4e7fa0b6d93b0.src","preCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    }\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/JsonKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"}],"commitId":"ede6c9bda4dba8a9981252bd05f0725ff1024b95","commitMessage":"@@@[HUDI-1006] Deltastreamer use kafkaSource with offset reset strategy:latest can't consume data (#1719)\n\n","date":"2020-06-14 18:01:44","modifiedFileCount":"5","status":"M","submitter":"Litianye"},{"authorTime":"2020-09-29 13:44:31","codes":[{"authorDate":"2020-09-29 13:44:31","commitOrder":4,"curCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2020-09-29 13:44:31","endLine":70,"groupId":"4306","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/25/6516bd2026f6d26dd95fd74d6af31de402ed4b.src","preCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"},{"authorDate":"2020-09-29 13:44:31","commitOrder":4,"curCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2020-09-29 13:44:31","endLine":68,"groupId":"4306","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ce/daba48c2e3d4d7fa925ab14c1b6e0123570ba7.src","preCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/JsonKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"20b9b399c980270afdd60cc5fbce783c700a8376","commitMessage":"@@@[HUDI-1233] Deltastreamer Kafka consumption delay reporting indicators (#2074)\n\n","date":"2020-09-29 13:44:31","modifiedFileCount":"7","status":"M","submitter":"liujinhui"},{"authorTime":"2020-09-29 13:44:31","codes":[{"authorDate":"2021-08-30 10:01:15","commitOrder":5,"curCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2021-08-30 10:01:15","endLine":100,"groupId":"10303","id":9,"instanceNumber":1,"isCurCommit":1,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ff/8ea5a7aa2da77617e8d97cda55a07a0adb5494.src","preCode":"  protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":91,"status":"M"},{"authorDate":"2020-09-29 13:44:31","commitOrder":5,"curCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","date":"2020-09-29 13:44:31","endLine":68,"groupId":"10303","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"fetchNewData","params":"(Option<String>lastCheckpointStr@longsourceLimit)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/ce/daba48c2e3d4d7fa925ab14c1b6e0123570ba7.src","preCode":"  protected InputBatch<JavaRDD<String>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit, metrics);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), CheckpointUtils.offsetsToStr(offsetRanges));\n    }\n    JavaRDD<String> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), CheckpointUtils.offsetsToStr(offsetRanges));\n  }\n","realPath":"hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/JsonKafkaSource.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"N"}],"commitId":"bf5a52e51bbeaa089995335a0a4c55884792e505","commitMessage":"@@@[HUDI-2320] Add support ByteArrayDeserializer in AvroKafkaSource (#3502)\n\n","date":"2021-08-30 10:01:15","modifiedFileCount":"1","status":"M","submitter":"???"}]
