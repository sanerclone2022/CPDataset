[{"authorTime":"2020-05-14 06:37:03","codes":[{"authorDate":"2020-05-14 06:37:03","commitOrder":1,"curCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(props.getProperty(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME), DummyAvroPayload.class.getName());\n  }\n","date":"2020-05-14 06:37:03","endLine":640,"groupId":"4986","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPayloadClassUpdate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/51/2318fb2f1ed09f24990f720b83f50054b7c0a5.src","preCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(props.getProperty(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME), DummyAvroPayload.class.getName());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":617,"status":"B"},{"authorDate":"2020-05-14 06:37:03","commitOrder":1,"curCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME));\n  }\n","date":"2020-05-14 06:37:03","endLine":666,"groupId":"2133","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testPayloadClassUpdateWithCOWTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/51/2318fb2f1ed09f24990f720b83f50054b7c0a5.src","preCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME));\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":643,"status":"B"}],"commitId":"0d4848b68b625a17d05b38864a84a6cc71189bfa","commitMessage":"@@@[HUDI-811] Restructure test packages (#1607)\n\n* restructure hudi-spark tests\n* restructure hudi-timeline-service tests\n* restructure hudi-hadoop-mr hudi-utilities tests\n* restructure hudi-hive-sync tests","date":"2020-05-14 06:37:03","modifiedFileCount":"11","status":"B","submitter":"Raymond Xu"},{"authorTime":"2020-11-19 13:40:04","codes":[{"authorDate":"2020-11-19 13:40:04","commitOrder":2,"curCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(props.getProperty(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME), DummyAvroPayload.class.getName());\n  }\n","date":"2020-11-19 13:40:04","endLine":777,"groupId":"4986","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPayloadClassUpdate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9b/0097e8ba2570a830627576ce2b91cc8eb21cdb.src","preCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(props.getProperty(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME), DummyAvroPayload.class.getName());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":754,"status":"M"},{"authorDate":"2020-11-19 13:40:04","commitOrder":2,"curCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME));\n  }\n","date":"2020-11-19 13:40:04","endLine":803,"groupId":"4986","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testPayloadClassUpdateWithCOWTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9b/0097e8ba2570a830627576ce2b91cc8eb21cdb.src","preCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, Operation.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME));\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":780,"status":"M"}],"commitId":"a23230c8c2be5e0d6e9d8cbf936892402b7d741f","commitMessage":"@@@[HUDI-1400] Replace Operation enum with WriteOperationType (#2259)\n\n","date":"2020-11-19 13:40:04","modifiedFileCount":"6","status":"M","submitter":"wangxianghu"},{"authorTime":"2021-07-01 05:26:30","codes":[{"authorDate":"2021-07-01 05:26:30","commitOrder":3,"curCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(new HoodieConfig(props).getString(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP), DummyAvroPayload.class.getName());\n  }\n","date":"2021-07-01 05:26:30","endLine":1183,"groupId":"4986","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testPayloadClassUpdate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8a/2648dc4073b890af70b626df8d8a006f1e1490.src","preCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(props.getProperty(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME), DummyAvroPayload.class.getName());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1160,"status":"M"},{"authorDate":"2021-07-01 05:26:30","commitOrder":3,"curCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP.key()));\n  }\n","date":"2021-07-01 05:26:30","endLine":1209,"groupId":"4986","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testPayloadClassUpdateWithCOWTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/8a/2648dc4073b890af70b626df8d8a006f1e1490.src","preCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP_NAME));\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1186,"status":"M"}],"commitId":"d412fb2fe642417460532044cac162bb68f4bec4","commitMessage":"@@@[HUDI-89] Add configOption & refactor all configs based on that (#2833)\n\nCo-authored-by: Wenning Ding <wenningd@amazon.com>","date":"2021-07-01 05:26:30","modifiedFileCount":"138","status":"M","submitter":"wenningd"},{"authorTime":"2021-08-20 04:36:40","codes":[{"authorDate":"2021-08-20 04:36:40","commitOrder":4,"curCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(new HoodieConfig(props).getString(HoodieTableConfig.PAYLOAD_CLASS_NAME), DummyAvroPayload.class.getName());\n  }\n","date":"2021-08-20 04:36:40","endLine":1254,"groupId":"10263","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testPayloadClassUpdate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/aa/b02da238dbfab8d64f2cb27d1f2c6477b2d1bd.src","preCode":"  public void testPayloadClassUpdate() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_mor\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), \"MERGE_ON_READ\");\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertEquals(new HoodieConfig(props).getString(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP), DummyAvroPayload.class.getName());\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1231,"status":"M"},{"authorDate":"2021-08-20 04:36:40","commitOrder":4,"curCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.PAYLOAD_CLASS_NAME.key()));\n  }\n","date":"2021-08-20 04:36:40","endLine":1280,"groupId":"10263","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testPayloadClassUpdateWithCOWTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/aa/b02da238dbfab8d64f2cb27d1f2c6477b2d1bd.src","preCode":"  public void testPayloadClassUpdateWithCOWTable() throws Exception {\n    String dataSetBasePath = dfsBasePath + \"/test_dataset_cow\";\n    HoodieDeltaStreamer.Config cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, false, null, null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf()).sync();\n    TestHelpers.assertRecordCount(1000, dataSetBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    cfg = TestHelpers.makeConfig(dataSetBasePath, WriteOperationType.BULK_INSERT,\n        Collections.singletonList(SqlQueryBasedTransformer.class.getName()), PROPS_FILENAME_TEST_SOURCE, true,\n        true, true, DummyAvroPayload.class.getName(), null);\n    new HoodieDeltaStreamer(cfg, jsc, dfs, hiveServer.getHiveConf());\n\n    \r\n    Properties props = new Properties();\n    String metaPath = dataSetBasePath + \"/.hoodie/hoodie.properties\";\n    FileSystem fs = FSUtils.getFs(cfg.targetBasePath, jsc.hadoopConfiguration());\n    try (FSDataInputStream inputStream = fs.open(new Path(metaPath))) {\n      props.load(inputStream);\n    }\n\n    assertFalse(props.containsKey(HoodieTableConfig.HOODIE_PAYLOAD_CLASS_PROP.key()));\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1257,"status":"M"}],"commitId":"c350d05dd3301f14fa9d688746c9de2416db3f11","commitMessage":"@@@Restore 0.8.0 config keys with deprecated annotation (#3506)\n\nCo-authored-by: Sagar Sumit <sagarsumit09@gmail.com>\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2021-08-20 04:36:40","modifiedFileCount":"109","status":"M","submitter":"Udit Mehrotra"}]
