[{"authorTime":"2021-01-11 13:19:52","codes":[{"authorDate":"2021-01-01 00:57:13","commitOrder":3,"curCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          partitionToFileStatus.put(partitionName, filesInDir);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","date":"2021-01-04 23:59:47","endLine":349,"groupId":"1943","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getPartitionsToFilesMapping","params":"(HoodieTableMetaClientdatasetMetaClient)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/82/3e70c83b6efddc7a546a2c2ab077a50a9500e7.src","preCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          partitionToFileStatus.put(partitionName, filesInDir);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","realPath":"hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"NB"},{"authorDate":"2021-01-11 13:19:52","commitOrder":3,"curCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","date":"2021-01-11 13:19:52","endLine":106,"groupId":"3347","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllPartitionPaths","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/32/6d6fd5431f7322c2cfc6cfbc9b10b9434dc737.src","preCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","realPath":"hudi-common/src/main/java/org/apache/hudi/metadata/FileSystemBackedTableMetadata.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"B"}],"commitId":"7ce3ac778eb475bf23ffa31243dc0843ec7d089a","commitMessage":"@@@[HUDI-1479] Use HoodieEngineContext to parallelize fetching of partiton paths (#2417)\n\n* [HUDI-1479] Use HoodieEngineContext to parallelize fetching of partition paths\n\n* Adding testClass for FileSystemBackedTableMetadata\n\nCo-authored-by: Nishith Agarwal <nagarwal@uber.com>","date":"2021-01-11 13:19:52","modifiedFileCount":"34","status":"M","submitter":"Udit Mehrotra"},{"authorTime":"2021-01-11 13:19:52","codes":[{"authorDate":"2021-02-26 08:52:28","commitOrder":4,"curCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n    final String dirFilterRegex = datasetWriteConfig.getMetadataConfig().getDirectoryFilterRegex();\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        if (!dirFilterRegex.isEmpty() && p.getLeft().getName().matches(dirFilterRegex)) {\n          LOG.info(\"Ignoring directory \" + p.getLeft() + \" which matches the filter regex \" + dirFilterRegex);\n          return;\n        }\n\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          partitionToFileStatus.put(partitionName, filesInDir);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","date":"2021-02-26 08:52:28","endLine":359,"groupId":"707","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getPartitionsToFilesMapping","params":"(HoodieTableMetaClientdatasetMetaClient)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/5a/ae7b768b521174909cd06804b5b0e2b6d4c5a6.src","preCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          partitionToFileStatus.put(partitionName, filesInDir);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","realPath":"hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":314,"status":"M"},{"authorDate":"2021-01-11 13:19:52","commitOrder":4,"curCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","date":"2021-01-11 13:19:52","endLine":106,"groupId":"3347","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllPartitionPaths","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/32/6d6fd5431f7322c2cfc6cfbc9b10b9434dc737.src","preCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","realPath":"hudi-common/src/main/java/org/apache/hudi/metadata/FileSystemBackedTableMetadata.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"N"}],"commitId":"022df0d1b134422f7b6f305cd7ec04b25caa23f0","commitMessage":"@@@[HUDI-1611] Added a configuration to allow specific directories to be filtered out during Metadata Table bootstrap. (#2565)\n\n","date":"2021-02-26 08:52:28","modifiedFileCount":"3","status":"M","submitter":"Prashant Wason"},{"authorTime":"2021-01-11 13:19:52","codes":[{"authorDate":"2021-07-06 11:14:05","commitOrder":5,"curCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n    final String dirFilterRegex = datasetWriteConfig.getMetadataConfig().getDirectoryFilterRegex();\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        if (!dirFilterRegex.isEmpty() && p.getLeft().getName().matches(dirFilterRegex)) {\n          LOG.info(\"Ignoring directory \" + p.getLeft() + \" which matches the filter regex \" + dirFilterRegex);\n          return;\n        }\n\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          \r\n          partitionToFileStatus.put(partitionName, filesInDir.stream()\n              .filter(f -> !f.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME)).collect(Collectors.toList()));\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","date":"2021-07-06 11:14:05","endLine":392,"groupId":"10833","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getPartitionsToFilesMapping","params":"(HoodieTableMetaClientdatasetMetaClient)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/b8/1e00b05940e903ad4da06b0cdf4252d617e99a.src","preCode":"  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(HoodieTableMetaClient datasetMetaClient) {\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n\n    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n    final String dirFilterRegex = datasetWriteConfig.getMetadataConfig().getDirectoryFilterRegex();\n\n    while (!pathsToList.isEmpty()) {\n      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fs = path.getFileSystem(conf.get());\n        return Pair.of(path, fs.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        if (!dirFilterRegex.isEmpty() && p.getLeft().getName().matches(dirFilterRegex)) {\n          LOG.info(\"Ignoring directory \" + p.getLeft() + \" which matches the filter regex \" + dirFilterRegex);\n          return;\n        }\n\n        List<FileStatus> filesInDir = Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .collect(Collectors.toList());\n\n        if (p.getRight().length > filesInDir.size()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetMetaClient.getBasePath()), p.getLeft());\n          partitionToFileStatus.put(partitionName, filesInDir);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n\n    return partitionToFileStatus;\n  }\n","realPath":"hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":346,"status":"M"},{"authorDate":"2021-01-11 13:19:52","commitOrder":5,"curCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","date":"2021-01-11 13:19:52","endLine":106,"groupId":"10833","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllPartitionPaths","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/32/6d6fd5431f7322c2cfc6cfbc9b10b9434dc737.src","preCode":"  public List<String> getAllPartitionPaths() throws IOException {\n    if (assumeDatePartitioning) {\n      FileSystem fs = new Path(datasetBasePath).getFileSystem(hadoopConf.get());\n      return FSUtils.getAllPartitionFoldersThreeLevelsDown(fs, datasetBasePath);\n    }\n\n    List<Path> pathsToList = new LinkedList<>();\n    pathsToList.add(new Path(datasetBasePath));\n    List<String> partitionPaths = new ArrayList<>();\n\n    while (!pathsToList.isEmpty()) {\n      \r\n      int listingParallelism = Math.min(DEFAULT_LISTING_PARALLELISM, pathsToList.size());\n\n      \r\n      List<Pair<Path, FileStatus[]>> dirToFileListing = engineContext.map(pathsToList, path -> {\n        FileSystem fileSystem = path.getFileSystem(hadoopConf.get());\n        return Pair.of(path, fileSystem.listStatus(path));\n      }, listingParallelism);\n      pathsToList.clear();\n\n      \r\n      \r\n      dirToFileListing.forEach(p -> {\n        Option<FileStatus> partitionMetaFile = Option.fromJavaOptional(Arrays.stream(p.getRight()).parallel()\n            .filter(fs -> fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n            .findFirst());\n\n        if (partitionMetaFile.isPresent()) {\n          \r\n          String partitionName = FSUtils.getRelativePartitionPath(new Path(datasetBasePath), p.getLeft());\n          partitionPaths.add(partitionName);\n        } else {\n          \r\n          pathsToList.addAll(Arrays.stream(p.getRight())\n              .filter(fs -> fs.isDirectory() && !fs.getPath().getName().equals(HoodieTableMetaClient.METAFOLDER_NAME))\n              .map(fs -> fs.getPath())\n              .collect(Collectors.toList()));\n        }\n      });\n    }\n    return partitionPaths;\n  }\n","realPath":"hudi-common/src/main/java/org/apache/hudi/metadata/FileSystemBackedTableMetadata.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"N"}],"commitId":"a0f598d371938060a17aca7603c080c22488cf57","commitMessage":"@@@[HUDI-2089]fix the bug that metatable cannot support non_partition table (#3182)\n\n","date":"2021-07-06 11:14:05","modifiedFileCount":"1","status":"M","submitter":"xiarixiaoyao"}]
