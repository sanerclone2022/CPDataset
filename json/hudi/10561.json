[{"authorTime":"2020-10-02 05:25:29","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testUpsertPartitioner() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(0, 200, 100, 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n    assertEquals(2, insertBuckets.size(), \"Total of 2 insert buckets\");\n  }\n","date":"2020-10-02 05:25:29","endLine":186,"groupId":"2806","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testUpsertPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6b/3426b0eaf85803b6c98cfe2c3f591e16ca6f3a.src","preCode":"  public void testUpsertPartitioner() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(0, 200, 100, 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n    assertEquals(2, insertBuckets.size(), \"Total of 2 insert buckets\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"B"},{"authorDate":"2020-10-02 05:25:29","commitOrder":1,"curCode":"  public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(1000 * 1024, 400, 100, 800 * 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n\n    Double[] weights = { 0.5, 0.25, 0.25};\n    Double[] cumulativeWeights = { 0.5, 0.75, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n\n    \r\n    partitioner = getUpsertPartitioner(1000 * 1024, 2400, 100, 800 * 1024, testPartitionPath, true);\n    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(3).bucketType,\n        \"Bucket 3 is INSERT\");\n    assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n\n    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n  }\n","date":"2020-10-02 05:25:29","endLine":292,"groupId":"2808","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpsertPartitionerWithSmallInsertHandling","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6b/3426b0eaf85803b6c98cfe2c3f591e16ca6f3a.src","preCode":"  public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(1000 * 1024, 400, 100, 800 * 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n\n    Double[] weights = { 0.5, 0.25, 0.25};\n    Double[] cumulativeWeights = { 0.5, 0.75, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n\n    \r\n    partitioner = getUpsertPartitioner(1000 * 1024, 2400, 100, 800 * 1024, testPartitionPath, true);\n    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(3).bucketType,\n        \"Bucket 3 is INSERT\");\n    assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n\n    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":254,"status":"B"}],"commitId":"1f7add92916c37b05be270d9c75a9042134ec506","commitMessage":"@@@[HUDI-1089] Refactor hudi-client to support multi-engine (#1827)\n\n- This change breaks `hudi-client` into `hudi-client-common` and `hudi-spark-client` modules \n- Simple usages of Spark using jsc.parallelize() has been redone using EngineContext#map.  EngineContext#flatMap etc\n- Code changes in the PR.  break classes into `BaseXYZ` parent classes with no spark dependencies living in `hudi-client-common`\n- Classes on `hudi-spark-client` are named `SparkXYZ` extending the parent classes with all the Spark dependencies\n- To simplify/cleanup.  HoodieIndex#fetchRecordLocation has been removed and its usages in tests replaced with alternatives\n\nCo-authored-by: Vinoth Chandar <vinoth@apache.org>","date":"2020-10-02 05:25:29","modifiedFileCount":"31","status":"B","submitter":"Mathieu"},{"authorTime":"2020-12-29 11:52:35","codes":[{"authorDate":"2020-10-02 05:25:29","commitOrder":2,"curCode":"  public void testUpsertPartitioner() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(0, 200, 100, 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n    assertEquals(2, insertBuckets.size(), \"Total of 2 insert buckets\");\n  }\n","date":"2020-10-02 05:25:29","endLine":186,"groupId":"10561","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testUpsertPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/6b/3426b0eaf85803b6c98cfe2c3f591e16ca6f3a.src","preCode":"  public void testUpsertPartitioner() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(0, 200, 100, 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n    assertEquals(2, insertBuckets.size(), \"Total of 2 insert buckets\");\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"N"},{"authorDate":"2020-12-29 11:52:35","commitOrder":2,"curCode":"  public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(1000 * 1024, 400, 100, 800 * 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n\n    Double[] weights = { 0.5, 0.25, 0.25};\n    Double[] cumulativeWeights = { 0.5, 0.75, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n\n    \r\n    partitioner = getUpsertPartitioner(1000 * 1024, 2400, 100, 800 * 1024, testPartitionPath, true);\n    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(3).bucketType,\n        \"Bucket 3 is INSERT\");\n    assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n\n    weights = new Double[] { 0.08, 0.42, 0.42, 0.08};\n    cumulativeWeights = new Double[] { 0.08, 0.5, 0.92, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n  }\n","date":"2020-12-29 11:52:35","endLine":307,"groupId":"10561","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpsertPartitionerWithSmallInsertHandling","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/f4/0a97c0bbadccb217468e193b1b5ff54edcf99d.src","preCode":"  public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n    final String testPartitionPath = \"2016/09/26\";\n    \r\n    \r\n    UpsertPartitioner partitioner = getUpsertPartitioner(1000 * 1024, 400, 100, 800 * 1024, testPartitionPath, false);\n    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n\n    Double[] weights = { 0.5, 0.25, 0.25};\n    Double[] cumulativeWeights = { 0.5, 0.75, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n\n    \r\n    partitioner = getUpsertPartitioner(1000 * 1024, 2400, 100, 800 * 1024, testPartitionPath, true);\n    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n\n    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");\n    assertEquals(BucketType.UPDATE, partitioner.getBucketInfo(0).bucketType,\n        \"Bucket 0 is UPDATE\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n        \"Bucket 1 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n        \"Bucket 2 is INSERT\");\n    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(3).bucketType,\n        \"Bucket 3 is INSERT\");\n    assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n\n    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n  }\n","realPath":"hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":269,"status":"M"}],"commitId":"4c17528de021054699c60e292874cdfdbcf592af","commitMessage":"@@@[HUDI-1398] Align insert file size for reducing IO (#2256)\n\n* [HUDI-1398] Align insert file size for reducing IO\n\nCo-authored-by: zhang wen <wen.zhang@dmall.com>","date":"2020-12-29 11:52:35","modifiedFileCount":"2","status":"M","submitter":"steven zhang"}]
