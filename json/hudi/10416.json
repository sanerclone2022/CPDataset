[{"authorTime":"2021-04-06 19:06:41","codes":[{"authorDate":"2021-04-06 19:06:41","commitOrder":1,"curCode":"  public void testInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n  }\n","date":"2021-04-06 19:06:41","endLine":196,"groupId":"3049","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithPartialSmallFiles","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/33/457b5098edb00e81a3fb4907480d82f367cc12.src","preCode":"  public void testInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/partitioner/TestBucketAssigner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"B"},{"authorDate":"2021-04-06 19:06:41","commitOrder":1,"curCode":"  public void testUpdateAndInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner2.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n  }\n","date":"2021-04-06 19:06:41","endLine":291,"groupId":"3050","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateAndInsertWithPartialSmallFiles","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/33/457b5098edb00e81a3fb4907480d82f367cc12.src","preCode":"  public void testUpdateAndInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner2.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/partitioner/TestBucketAssigner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"B"}],"commitId":"9c369c607df2816ea2cd1221fb6d879e3fb8f74c","commitMessage":"@@@[HUDI-1757] Assigns the buckets by record key for Flink writer (#2757)\n\nCurrently we assign the buckets by record partition path which could\ncause hotspot if the partition field is datetime type. Changes to assign\nbuckets by grouping the record whth their key first.  the assignment is\nvalid if only there is no conflict(two task write to the same bucket).\n\nThis patch also changes the coordinator execution to be asynchronous.","date":"2021-04-06 19:06:41","modifiedFileCount":"23","status":"B","submitter":"Danny Chan"},{"authorTime":"2021-07-28 19:26:37","codes":[{"authorDate":"2021-07-28 19:26:37","commitOrder":2,"curCode":"  public void testInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f2\");\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f0\");\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n  }\n","date":"2021-07-28 19:26:37","endLine":257,"groupId":"10416","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testInsertWithPartialSmallFiles","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/be/a86001e05bdc310a75b0275968d40127d22e7d.src","preCode":"  public void testInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    bucketInfo = mockBucketAssigner.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo, \"par3\", BucketType.INSERT);\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par3\");\n    assertBucketEquals(bucketInfo2, \"par3\", BucketType.INSERT);\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/partitioner/TestBucketAssigner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":214,"status":"M"},{"authorDate":"2021-07-28 19:26:37","commitOrder":2,"curCode":"  public void testUpdateAndInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f2\");\n\n    mockBucketAssigner.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f2\");\n\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner2.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner2.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f0\");\n  }\n","date":"2021-07-28 19:26:37","endLine":352,"groupId":"10416","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateAndInsertWithPartialSmallFiles","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/be/a86001e05bdc310a75b0275968d40127d22e7d.src","preCode":"  public void testUpdateAndInsertWithPartialSmallFiles() {\n    SmallFile f0 = new SmallFile();\n    f0.location = new HoodieRecordLocation(\"t0\", \"f0\");\n    f0.sizeBytes = 12;\n\n    SmallFile f1 = new SmallFile();\n    f1.location = new HoodieRecordLocation(\"t0\", \"f1\");\n    f1.sizeBytes = 122879; \r\n\n    SmallFile f2 = new SmallFile();\n    f2.location = new HoodieRecordLocation(\"t0\", \"f2\");\n    f2.sizeBytes = 56;\n\n    Map<String, List<SmallFile>> smallFilesMap = new HashMap<>();\n    smallFilesMap.put(\"par1\", Arrays.asList(f0, f1, f2));\n\n    MockBucketAssigner mockBucketAssigner = new MockBucketAssigner(0, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n    mockBucketAssigner.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner.addInsert(\"par1\");\n    bucketInfo = mockBucketAssigner.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo, \"par1\", BucketType.UPDATE, \"f0\");\n\n\n    MockBucketAssigner mockBucketAssigner2 = new MockBucketAssigner(1, 2, context, writeConfig, smallFilesMap);\n    mockBucketAssigner2.addUpdate(\"par1\", \"f0\");\n\n    BucketInfo bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n\n    mockBucketAssigner2.addUpdate(\"par1\", \"f2\");\n\n    mockBucketAssigner2.addInsert(\"par1\");\n    bucketInfo2 = mockBucketAssigner2.addInsert(\"par1\");\n    assertBucketEquals(bucketInfo2, \"par1\", BucketType.UPDATE, \"f1\");\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/sink/partitioner/TestBucketAssigner.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"M"}],"commitId":"91c221341293e80c28cce19f1642199495a96f66","commitMessage":"@@@[HUDI-2245] BucketAssigner generates the fileId evenly to avoid data skew (#3362)\n\n","date":"2021-07-28 19:26:37","modifiedFileCount":"4","status":"M","submitter":"Danny Chan"}]
