[{"authorTime":"2021-03-11 19:44:06","codes":[{"authorDate":"2021-07-30 14:25:05","commitOrder":3,"curCode":"  public void testConsumeFromLastCommit() throws Exception {\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All instants should have range limit\");\n\n      Thread.sleep(1000L);\n\n      \r\n      latch = new CountDownLatch(4);\n      sourceContext.reset(latch);\n\n      \r\n      TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n\n      \r\n      function.close();\n    }\n  }\n","date":"2021-07-30 14:25:05","endLine":138,"groupId":"4687","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testConsumeFromLastCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/f1/45744465330a165b6cccdd63e902234c53ae10.src","preCode":"  public void testConsumeFromLastCommit() throws Exception {\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All instants should have range limit\");\n\n      Thread.sleep(1000L);\n\n      \r\n      latch = new CountDownLatch(4);\n      sourceContext.reset(latch);\n\n      \r\n      TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n\n      \r\n      function.close();\n    }\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/source/TestStreamReadMonitoringFunction.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"B"},{"authorDate":"2021-03-11 19:44:06","commitOrder":3,"curCode":"  public void testConsumeFromSpecifiedCommit() throws Exception {\n    \r\n    \r\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n    String specifiedCommit = TestUtils.getLatestCommit(tempFile.getAbsolutePath());\n    conf.setString(FlinkOptions.READ_STREAMING_START_COMMIT, specifiedCommit);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getLatestCommit().equals(specifiedCommit)),\n          \"All the splits should be with specified instant time\");\n\n      \r\n      function.close();\n    }\n  }\n","date":"2021-03-11 19:44:06","endLine":140,"groupId":"1544","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testConsumeFromSpecifiedCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/47/33fa07b673bb8f902e45c1a1fd5369f881fd83.src","preCode":"  public void testConsumeFromSpecifiedCommit() throws Exception {\n    \r\n    \r\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n    String specifiedCommit = TestUtils.getLatestCommit(tempFile.getAbsolutePath());\n    conf.setString(FlinkOptions.READ_STREAMING_START_COMMIT, specifiedCommit);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getLatestCommit().equals(specifiedCommit)),\n          \"All the splits should be with specified instant time\");\n\n      \r\n      function.close();\n    }\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/source/TestStreamReadMonitoringFunction.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"NB"}],"commitId":"8b19ec9ca07070a9819502e82091dd14d559ef94","commitMessage":"@@@[HUDI-2252] Default consumes from the latest instant for flink streaming reader (#3368)\n\n","date":"2021-07-30 14:25:05","modifiedFileCount":"4","status":"M","submitter":"swuferhong"},{"authorTime":"2021-09-19 09:06:46","codes":[{"authorDate":"2021-07-30 14:25:05","commitOrder":4,"curCode":"  public void testConsumeFromLastCommit() throws Exception {\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All instants should have range limit\");\n\n      Thread.sleep(1000L);\n\n      \r\n      latch = new CountDownLatch(4);\n      sourceContext.reset(latch);\n\n      \r\n      TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n\n      \r\n      function.close();\n    }\n  }\n","date":"2021-07-30 14:25:05","endLine":138,"groupId":"10435","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testConsumeFromLastCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/f1/45744465330a165b6cccdd63e902234c53ae10.src","preCode":"  public void testConsumeFromLastCommit() throws Exception {\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All instants should have range limit\");\n\n      Thread.sleep(1000L);\n\n      \r\n      latch = new CountDownLatch(4);\n      sourceContext.reset(latch);\n\n      \r\n      TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n\n      \r\n      function.close();\n    }\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/source/TestStreamReadMonitoringFunction.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"N"},{"authorDate":"2021-09-19 09:06:46","commitOrder":4,"curCode":"  public void testConsumeFromSpecifiedCommit() throws Exception {\n    \r\n    \r\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n    String specifiedCommit = TestUtils.getLatestCommit(tempFile.getAbsolutePath());\n    conf.setString(FlinkOptions.READ_START_COMMIT, specifiedCommit);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getLatestCommit().equals(specifiedCommit)),\n          \"All the splits should be with specified instant time\");\n\n      \r\n      function.close();\n    }\n  }\n","date":"2021-09-19 09:06:46","endLine":169,"groupId":"10435","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testConsumeFromSpecifiedCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/36/87e9d7cee4d3ac79c5c4ac11d56784e8365478.src","preCode":"  public void testConsumeFromSpecifiedCommit() throws Exception {\n    \r\n    \r\n    TestData.writeData(TestData.DATA_SET_INSERT, conf);\n    TestData.writeData(TestData.DATA_SET_UPDATE_INSERT, conf);\n    String specifiedCommit = TestUtils.getLatestCommit(tempFile.getAbsolutePath());\n    conf.setString(FlinkOptions.READ_STREAMING_START_COMMIT, specifiedCommit);\n    StreamReadMonitoringFunction function = TestUtils.getMonitorFunc(conf);\n    try (AbstractStreamOperatorTestHarness<MergeOnReadInputSplit> harness = createHarness(function)) {\n      harness.setup();\n      harness.open();\n\n      CountDownLatch latch = new CountDownLatch(4);\n      CollectingSourceContext sourceContext = new CollectingSourceContext(latch);\n\n      runAsync(sourceContext, function);\n\n      assertTrue(latch.await(WAIT_TIME_MILLIS, TimeUnit.MILLISECONDS), \"Should finish splits generation\");\n      assertThat(\"Should produce the expected splits\",\n          sourceContext.getPartitionPaths(), is(\"par1,par2,par3,par4\"));\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getInstantRange().isPresent()),\n          \"All the instants should have range limit\");\n      assertTrue(sourceContext.splits.stream().allMatch(split -> split.getLatestCommit().equals(specifiedCommit)),\n          \"All the splits should be with specified instant time\");\n\n      \r\n      function.close();\n    }\n  }\n","realPath":"hudi-flink/src/test/java/org/apache/hudi/source/TestStreamReadMonitoringFunction.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":141,"status":"M"}],"commitId":"3354fac42f9a2c4dbc8ac73ca4749160e9b9459b","commitMessage":"@@@[HUDI-2449] Incremental read for Flink (#3686)\n\n","date":"2021-09-19 09:06:46","modifiedFileCount":"15","status":"M","submitter":"Danny Chan"}]
