[{"authorTime":"2020-11-19 13:40:04","codes":[{"authorDate":"2021-02-25 20:08:13","commitOrder":3,"curCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords,\"1.parquet\", true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2021-02-25 20:08:13","endLine":1102,"groupId":"4074","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaStreamerTransitionFromParquetToKafkaSource","params":"(booleanautoResetToLatest)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/7f/b5b1862dc9a843f6eb3bba54976833f11fcb67.src","preCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords,\"1.parquet\", true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1064,"status":"B"},{"authorDate":"2020-11-19 13:40:04","commitOrder":3,"curCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2020-11-19 13:40:04","endLine":980,"groupId":"5485","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCsvDFSSource","params":"(booleanhasHeader@charsep@booleanuseSchemaProvider@List<String>transformerClassNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9b/0097e8ba2570a830627576ce2b91cc8eb21cdb.src","preCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":967,"status":"NB"}],"commitId":"617cc24ad1a28196b872df5663e9e0f48cd7f0fa","commitMessage":"@@@[HUDI-1367] Make deltaStreamer transition from dfsSouce to kafkasouce (#2227)\n\n\nCo-authored-by: Sivabalan Narayanan <sivabala@uber.com>","date":"2021-02-25 20:08:13","modifiedFileCount":"5","status":"M","submitter":"liujinhui"},{"authorTime":"2020-11-19 13:40:04","codes":[{"authorDate":"2021-03-08 05:40:40","commitOrder":4,"curCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords, PARQUET_SOURCE_ROOT, FIRST_PARQUET_FILE_NAME, true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT, false);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2021-03-08 05:40:40","endLine":1122,"groupId":"4074","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaStreamerTransitionFromParquetToKafkaSource","params":"(booleanautoResetToLatest)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/75/22c2d29474b99e12e342a453bb594d362936d4.src","preCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords,\"1.parquet\", true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1084,"status":"M"},{"authorDate":"2020-11-19 13:40:04","commitOrder":4,"curCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2020-11-19 13:40:04","endLine":980,"groupId":"5485","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCsvDFSSource","params":"(booleanhasHeader@charsep@booleanuseSchemaProvider@List<String>transformerClassNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/9b/0097e8ba2570a830627576ce2b91cc8eb21cdb.src","preCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":967,"status":"N"}],"commitId":"5cf2f2618b6a59a831543b588fb3bb85bdf5f1e8","commitMessage":"@@@[HUDI-1618] Fixing NPE with Parquet src in multi table delta streamer (#2577)\n\n","date":"2021-03-08 05:40:40","modifiedFileCount":"3","status":"M","submitter":"Sivabalan Narayanan"},{"authorTime":"2021-07-17 12:31:06","codes":[{"authorDate":"2021-07-17 12:31:06","commitOrder":5,"curCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords, PARQUET_SOURCE_ROOT, FIRST_PARQUET_FILE_NAME, true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT, false);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\", null), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\", null), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2021-07-17 12:31:06","endLine":1471,"groupId":"10270","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaStreamerTransitionFromParquetToKafkaSource","params":"(booleanautoResetToLatest)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/db/0ab197f881f4749c9ce849c9cf3eae88bf77ab.src","preCode":"  private void testDeltaStreamerTransitionFromParquetToKafkaSource(boolean autoResetToLatest) throws Exception {\n    \r\n    PARQUET_SOURCE_ROOT = dfsBasePath + \"/parquetFilesDfsToKafka\" + testNum;\n    int parquetRecords = 10;\n    prepareParquetDFSFiles(parquetRecords, PARQUET_SOURCE_ROOT, FIRST_PARQUET_FILE_NAME, true, HoodieTestDataGenerator.TRIP_SCHEMA, HoodieTestDataGenerator.AVRO_TRIP_SCHEMA);\n\n    prepareParquetDFSSource(true, false,\"source_uber.avsc\", \"target_uber.avsc\", PROPS_FILENAME_TEST_PARQUET,\n        PARQUET_SOURCE_ROOT, false);\n    \r\n    String tableBasePath = dfsBasePath + \"/test_dfs_to_kakfa\" + testNum;\n    HoodieDeltaStreamer deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.INSERT, ParquetDFSSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_PARQUET, false,\n            false, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(parquetRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    deltaStreamer.shutdownGracefully();\n\n    \r\n    topicName = \"topic\" + testNum;\n    prepareJsonKafkaDFSFiles(JSON_KAFKA_NUM_RECORDS, true, topicName);\n    prepareJsonKafkaDFSSource(PROPS_FILENAME_TEST_JSON_KAFKA, autoResetToLatest ? \"latest\" : \"earliest\", topicName);\n    \r\n    deltaStreamer = new HoodieDeltaStreamer(\n        TestHelpers.makeConfig(tableBasePath, WriteOperationType.UPSERT, JsonKafkaSource.class.getName(),\n            Collections.EMPTY_LIST, PROPS_FILENAME_TEST_JSON_KAFKA, false,\n            true, 100000, false, null, null, \"timestamp\"), jsc);\n    deltaStreamer.sync();\n    \r\n    int totalExpectedRecords = parquetRecords + ((autoResetToLatest) ? 0 : JSON_KAFKA_NUM_RECORDS);\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n\n    \r\n    prepareJsonKafkaDFSFiles(20, false, topicName);\n    totalExpectedRecords += 20;\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(totalExpectedRecords, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1433,"status":"M"},{"authorDate":"2021-07-17 12:31:06","commitOrder":5,"curCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField, null), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","date":"2021-07-17 12:31:06","endLine":1601,"groupId":"10270","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testCsvDFSSource","params":"(booleanhasHeader@charsep@booleanuseSchemaProvider@List<String>transformerClassNames)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hudi-10-0.7/blobInfo/CC_OUT/blobs/db/0ab197f881f4749c9ce849c9cf3eae88bf77ab.src","preCode":"  private void testCsvDFSSource(\n      boolean hasHeader, char sep, boolean useSchemaProvider, List<String> transformerClassNames) throws Exception {\n    prepareCsvDFSSource(hasHeader, sep, useSchemaProvider, transformerClassNames != null);\n    String tableBasePath = dfsBasePath + \"/test_csv_table\" + testNum;\n    String sourceOrderingField = (hasHeader || useSchemaProvider) ? \"timestamp\" : \"_c0\";\n    HoodieDeltaStreamer deltaStreamer =\n        new HoodieDeltaStreamer(TestHelpers.makeConfig(\n            tableBasePath, WriteOperationType.INSERT, CsvDFSSource.class.getName(),\n            transformerClassNames, PROPS_FILENAME_TEST_CSV, false,\n            useSchemaProvider, 1000, false, null, null, sourceOrderingField), jsc);\n    deltaStreamer.sync();\n    TestHelpers.assertRecordCount(CSV_NUM_RECORDS, tableBasePath + \"/*/*.parquet\", sqlContext);\n    testNum++;\n  }\n","realPath":"hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java","repoName":"hudi","snippetEndLine":0,"snippetStartLine":0,"startLine":1588,"status":"M"}],"commitId":"af837d2f1825d14ae8403b2290cf5eab39780343","commitMessage":"@@@[HUDI-1447] DeltaStreamer kafka source supports consuming from specified timestamp (#2438)\n\n","date":"2021-07-17 12:31:06","modifiedFileCount":"7","status":"M","submitter":"liujinhui"}]
