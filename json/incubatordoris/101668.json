[{"authorTime":"2020-03-01 12:53:50","codes":[{"authorDate":"2020-03-01 12:53:50","commitOrder":1,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n                    conf.set(HDFS_UGI_CONF, hdfsUgi);\n                } else if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                } else {\n                    throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                            \"invalid authentication.\");\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                FileSystem dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-01 12:53:50","endLine":345,"groupId":"8189","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/8b/0274a14e2f94700fb4172529be2a61a8867af8.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n                    conf.set(HDFS_UGI_CONF, hdfsUgi);\n                } else if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                } else {\n                    throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                            \"invalid authentication.\");\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                FileSystem dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":168,"status":"B"},{"authorDate":"2020-03-01 12:53:50","commitOrder":1,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-01 12:53:50","endLine":396,"groupId":"1444","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/8b/0274a14e2f94700fb4172529be2a61a8867af8.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":357,"status":"B"}],"commitId":"078e35a62e07d54236a96e3f1043ddfe0a6c6382","commitMessage":"@@@Support Amazon S3 data source in Broker Load  (#3004)\n\n","date":"2020-03-01 12:53:50","modifiedFileCount":"3","status":"B","submitter":"frwrdt"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2020-03-28 09:14:45","commitOrder":2,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n                    conf.set(HDFS_UGI_CONF, hdfsUgi);\n                } else if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                } else {\n                    throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                            \"invalid authentication.\");\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":351,"groupId":"8189","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n                    conf.set(HDFS_UGI_CONF, hdfsUgi);\n                } else if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                } else {\n                    throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                            \"invalid authentication.\");\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                FileSystem dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":173,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":2,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"M"}],"commitId":"4a5164ab9d1a4b0ca8e9b8a08f876f22a4a2c500","commitMessage":"@@@Fix 'Filesystem closed' in broker load (#3216)\n\n","date":"2020-03-28 09:14:45","modifiedFileCount":"1","status":"M","submitter":"frwrdt"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2020-04-06 22:15:37","commitOrder":3,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-04-06 22:15:37","endLine":359,"groupId":"7512","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/1d/377b1c41a643a89acf41cc503ed320c4fe9324.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n                    conf.set(HDFS_UGI_CONF, hdfsUgi);\n                } else if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                } else {\n                    throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                            \"invalid authentication.\");\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":173,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":3,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"79bac5036111d6bd63339f3ca9c35925fe376023","commitMessage":"@@@Fix the bug that 'username' in broker load is invalid  (#3237)\n\n","date":"2020-04-06 22:15:37","modifiedFileCount":"1","status":"M","submitter":"frwrdt"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2020-06-01 21:03:21","commitOrder":4,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-06-01 21:03:21","endLine":359,"groupId":"7512","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/07/6c09cd3c775bb138bce41a45a54724277b4a07.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":173,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":4,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"ee260d5721320d3cc8bb6731cf2ea1d75300679a","commitMessage":"@@@[Bug][FsBroker] NPE throw when username is empty (#3731)\n\nWhen using Broker with an empty username.  a NPE is thrown.  which is\nnot expected.","date":"2020-06-01 21:03:21","modifiedFileCount":"1","status":"M","submitter":"Mingyu Chen"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2021-02-25 09:53:50","commitOrder":5,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2021-02-25 09:53:50","endLine":369,"groupId":"4035","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/c1/c1c4e5f0b198c045f3ef9e5eb728629b689bcc.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":174,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":5,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"fdd13ea79afe921514c9ae519644e2636bce3de5","commitMessage":"@@@[Broker] Fix broker load fail using SIMPLE auth after KERBEROS auth fail (#5412)\n\nCo-authored-by: liwei5 <liwei5@vipkid.com.cn>","date":"2021-02-25 09:53:50","modifiedFileCount":"1","status":"M","submitter":"francis lee"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2021-04-08 09:12:45","commitOrder":6,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        \r\n                        tmpFilePath = \"/tmp/.\" + principal + \"_\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2021-04-08 09:12:45","endLine":370,"groupId":"4035","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/de/04a0797fe4b2cab21979b04a63fa8340ba5b5a.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        tmpFilePath = \"/tmp/.\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":174,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":6,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"904a2ac86a15895851f93da896d2505245399dd5","commitMessage":"@@@[Bug] keytab file maybe not thread-safe (#5578)\n\n* make keytab file thread-safe\n\n* remove delte file code\n\nCo-authored-by: wangxixu <wangxixu@xiaomi.com>","date":"2021-04-08 09:12:45","modifiedFileCount":"1","status":"M","submitter":"xinghuayu007"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2021-08-05 14:33:18","commitOrder":7,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                UserGroupInformation ugi = null;\n\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        \r\n                        tmpFilePath = \"/tmp/.\" + principal + \"_\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    ugi = UserGroupInformation.loginUserFromKeytabAndReturnUGI(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n                }\n                dfsFileSystem = ugi != null ?\n                        ugi.doAs((PrivilegedExceptionAction<FileSystem>) () -> FileSystem.get(pathUri.getUri(), conf)) :\n                        FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2021-08-05 14:33:18","endLine":366,"groupId":"1445","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/22/9ff032a57271df316a5c2edfbd62d20d3999ea.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        \r\n                        tmpFilePath = \"/tmp/.\" + principal + \"_\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    UserGroupInformation.loginUserFromKeytab(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n\n                    dfsFileSystem = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n                        @Override\n                        public FileSystem run() throws Exception {\n                            return FileSystem.get(pathUri.getUri(), conf);\n                        }\n                    });\n                } else {\n                    dfsFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                }\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":174,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":7,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"1444","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"2f3cd0573afcddcb678ff4db1e2f1759c5e6ae01","commitMessage":"@@@[Broker] Fix ugi confusion bug (#6325)\n\nUse UserGroupInformation.loginUserFromKeytabAndReturnUGI instead of UserGroupInformation.loginUserFromKeytab in multiple principal scenario.","date":"2021-08-05 14:33:18","modifiedFileCount":"1","status":"M","submitter":"tinkerrrr"},{"authorTime":"2020-03-28 09:14:45","codes":[{"authorDate":"2021-08-11 16:39:01","commitOrder":8,"curCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                UserGroupInformation ugi = null;\n\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        \r\n                        tmpFilePath =\"/tmp/.\" +\n                                principal.replace('/', '_') +\n                                \"_\" + Long.toString(currentTime) +\n                                \"_\" + Integer.toString(randNumber);\n                        logger.info(\"create kerberos tmp file\" + tmpFilePath);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    ugi = UserGroupInformation.loginUserFromKeytabAndReturnUGI(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n                }\n                dfsFileSystem = ugi != null ?\n                        ugi.doAs((PrivilegedExceptionAction<FileSystem>) () -> FileSystem.get(pathUri.getUri(), conf)) :\n                        FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2021-08-11 16:39:01","endLine":370,"groupId":"101668","id":15,"instanceNumber":1,"isCurCommit":1,"methodName":"getDistributedFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/56/2e1ac52be4eeb6aa093c1b4bece9a8d657da53.src","preCode":"    public BrokerFileSystem getDistributedFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String host = HDFS_SCHEME + \"://\" + pathUri.getAuthority();\n        if (Strings.isNullOrEmpty(pathUri.getAuthority())) {\n            if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                host = properties.get(FS_DEFAULTFS_KEY);\n                logger.info(\"no schema and authority in path. use fs.defaultFs\");\n            } else {\n                logger.warn(\"invalid hdfs path. authority is null,path:\" + path);\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"invalid hdfs path. authority is null\");\n            }\n        }\n        String username = properties.getOrDefault(USER_NAME_KEY, \"\");\n        String password = properties.getOrDefault(PASSWORD_KEY, \"\");\n        String dfsNameServices = properties.getOrDefault(DFS_NAMESERVICES_KEY, \"\");\n        String authentication = properties.getOrDefault(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n            AUTHENTICATION_SIMPLE);\n        if (Strings.isNullOrEmpty(authentication) || (!authentication.equals(AUTHENTICATION_SIMPLE)\n            && !authentication.equals(AUTHENTICATION_KERBEROS))) {\n            logger.warn(\"invalid authentication:\" + authentication);\n            throw new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                \"invalid authentication:\" + authentication);\n        }\n        String hdfsUgi = username + \",\" + password;\n        FileSystemIdentity fileSystemIdentity = null;\n        BrokerFileSystem fileSystem = null;\n        if (authentication.equals(AUTHENTICATION_SIMPLE)) {\n            fileSystemIdentity = new FileSystemIdentity(host, hdfsUgi);\n        } else {\n            \r\n            String kerberosContent = \"\";\n            if (properties.containsKey(KERBEROS_KEYTAB)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB);\n            } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                kerberosContent = properties.get(KERBEROS_KEYTAB_CONTENT);\n            } else {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"keytab is required for kerberos authentication\");\n            }\n            if (!properties.containsKey(KERBEROS_PRINCIPAL)) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        \"principal is required for kerberos authentication\");\n            } else {\n                kerberosContent = kerberosContent + properties.get(KERBEROS_PRINCIPAL);\n            }\n            try {\n                MessageDigest digest = MessageDigest.getInstance(\"md5\");\n                byte[] result = digest.digest(kerberosContent.getBytes());\n                String kerberosUgi = new String(result);\n                fileSystemIdentity = new FileSystemIdentity(host, kerberosUgi);\n            } catch (NoSuchAlgorithmException e) {\n                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                        e.getMessage());\n            }\n        }\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                UserGroupInformation ugi = null;\n\n                \r\n                Configuration conf = new HdfsConfiguration();\n\n                \r\n                conf.set(CommonConfigurationKeys.IPC_CLIENT_FALLBACK_TO_SIMPLE_AUTH_ALLOWED_KEY, \"true\");\n\n                \r\n                \r\n                String tmpFilePath = null;\n                if (authentication.equals(AUTHENTICATION_KERBEROS)){\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n                            AUTHENTICATION_KERBEROS);\n\n                    String principal = preparePrincipal(properties.get(KERBEROS_PRINCIPAL));\n                    String keytab = \"\";\n                    if (properties.containsKey(KERBEROS_KEYTAB)) {\n                        keytab = properties.get(KERBEROS_KEYTAB);\n                    } else if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        \r\n                        \r\n                        \r\n                        String keytab_content = properties.get(KERBEROS_KEYTAB_CONTENT);\n                        byte[] base64decodedBytes = Base64.getDecoder().decode(keytab_content);\n                        long currentTime = System.currentTimeMillis();\n                        Random random = new Random(currentTime);\n                        int randNumber = random.nextInt(10000);\n                        \r\n                        tmpFilePath = \"/tmp/.\" + principal + \"_\" + Long.toString(currentTime) + \"_\" + Integer.toString(randNumber);\n                        FileOutputStream fileOutputStream = new FileOutputStream(tmpFilePath);\n                        fileOutputStream.write(base64decodedBytes);\n                        fileOutputStream.close();\n                        keytab = tmpFilePath;\n                    } else {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"keytab is required for kerberos authentication\");\n                    }\n                    UserGroupInformation.setConfiguration(conf);\n                    ugi = UserGroupInformation.loginUserFromKeytabAndReturnUGI(principal, keytab);\n                    if (properties.containsKey(KERBEROS_KEYTAB_CONTENT)) {\n                        try {\n                            File file = new File(tmpFilePath);\n                            if(!file.delete()){\n                                logger.warn(\"delete tmp file:\" +  tmpFilePath + \" failed\");\n                            }\n                        } catch (Exception e) {\n                            throw new  BrokerException(TBrokerOperationStatusCode.FILE_NOT_FOUND,\n                                    e.getMessage());\n                        }\n                    }\n                }\n                if (!Strings.isNullOrEmpty(dfsNameServices)) {\n                    \r\n                    final String dfsHaNameNodesKey = DFS_HA_NAMENODES_PREFIX + dfsNameServices;\n                    if (!properties.containsKey(dfsHaNameNodesKey)) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"load request missed necessary arguments for ha mode\");\n                    }\n                    String dfsHaNameNodes =  properties.get(dfsHaNameNodesKey);\n                    conf.set(DFS_NAMESERVICES_KEY, dfsNameServices);\n                    conf.set(dfsHaNameNodesKey, dfsHaNameNodes);\n                    String[] nameNodes = dfsHaNameNodes.split(\",\");\n                    if (nameNodes == null) {\n                        throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                \"invalid \" + dfsHaNameNodesKey + \" configuration\");\n                    } else {\n                        for (String nameNode : nameNodes) {\n                            nameNode = nameNode.trim();\n                            String nameNodeRpcAddress =\n                                    DFS_HA_NAMENODE_RPC_ADDRESS_PREFIX + dfsNameServices + \".\" + nameNode;\n                            if (!properties.containsKey(nameNodeRpcAddress)) {\n                                throw  new BrokerException(TBrokerOperationStatusCode.INVALID_ARGUMENT,\n                                        \"missed \" + nameNodeRpcAddress + \" configuration\");\n                            } else {\n                                conf.set(nameNodeRpcAddress, properties.get(nameNodeRpcAddress));\n                            }\n                        }\n                    }\n\n                    final String dfsClientFailoverProxyProviderKey =\n                            DFS_CLIENT_FAILOVER_PROXY_PROVIDER_PREFIX + dfsNameServices;\n                    if (properties.containsKey(dfsClientFailoverProxyProviderKey)) {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                properties.get(dfsClientFailoverProxyProviderKey));\n                    } else {\n                        conf.set(dfsClientFailoverProxyProviderKey,\n                                DEFAULT_DFS_CLIENT_FAILOVER_PROXY_PROVIDER);\n                    }\n                    if (properties.containsKey(FS_DEFAULTFS_KEY)) {\n                        conf.set(FS_DEFAULTFS_KEY, properties.get(FS_DEFAULTFS_KEY));\n                    }\n                    if (properties.containsKey(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN)) {\n                        conf.set(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN,\n                            properties.get(DFS_HA_NAMENODE_KERBEROS_PRINCIPAL_PATTERN));\n                    }\n                }\n\n                conf.set(FS_HDFS_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem dfsFileSystem = null;\n                if (authentication.equals(AUTHENTICATION_SIMPLE) &&\n                    properties.containsKey(USER_NAME_KEY) && !Strings.isNullOrEmpty(username)) {\n                    \r\n                    ugi = UserGroupInformation.createRemoteUser(username);\n                    \r\n                    \r\n                    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, AUTHENTICATION_SIMPLE);\n                    ugi.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.SIMPLE);\n                }\n                dfsFileSystem = ugi != null ?\n                        ugi.doAs((PrivilegedExceptionAction<FileSystem>) () -> FileSystem.get(pathUri.getUri(), conf)) :\n                        FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(dfsFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":174,"status":"M"},{"authorDate":"2020-03-28 09:14:45","commitOrder":8,"curCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","date":"2020-03-28 09:14:45","endLine":403,"groupId":"101668","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"getS3AFileSystem","params":"(Stringpath@Map<String@String>properties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/e8/0134078953bd5a3c0ed37101ec2c013c084795.src","preCode":"    public BrokerFileSystem getS3AFileSystem(String path, Map<String, String> properties) {\n        WildcardURI pathUri = new WildcardURI(path);\n        String accessKey = properties.getOrDefault(FS_S3A_ACCESS_KEY, \"\");\n        String secretKey = properties.getOrDefault(FS_S3A_SECRET_KEY, \"\");\n        String endpoint = properties.getOrDefault(FS_S3A_ENDPOINT, \"\");\n        String host = S3A_SCHEME + \"://\" + endpoint;\n        String s3aUgi = accessKey + \",\" + secretKey;\n        FileSystemIdentity fileSystemIdentity = new FileSystemIdentity(host, s3aUgi);\n        BrokerFileSystem fileSystem = null;\n        cachedFileSystem.putIfAbsent(fileSystemIdentity, new BrokerFileSystem(fileSystemIdentity));\n        fileSystem = cachedFileSystem.get(fileSystemIdentity);\n        if (fileSystem == null) {\n            \r\n            return null;\n        }\n        fileSystem.getLock().lock();\n        try {\n            if (!cachedFileSystem.containsKey(fileSystemIdentity)) {\n                \r\n                \r\n                return null;\n            }\n            if (fileSystem.getDFSFileSystem() == null) {\n                logger.info(\"could not find file system for path \" + path + \" create a new one\");\n                \r\n                Configuration conf = new Configuration();\n                conf.set(FS_S3A_ACCESS_KEY, accessKey);\n                conf.set(FS_S3A_SECRET_KEY, secretKey);\n                conf.set(FS_S3A_ENDPOINT, endpoint);\n                conf.set(FS_S3A_IMPL_DISABLE_CACHE, \"true\");\n                FileSystem s3AFileSystem = FileSystem.get(pathUri.getUri(), conf);\n                fileSystem.setFileSystem(s3AFileSystem);\n            }\n            return fileSystem;\n        } catch (Exception e) {\n            logger.error(\"errors while connect to \" + path, e);\n            throw new BrokerException(TBrokerOperationStatusCode.NOT_AUTHORIZED, e);\n        } finally {\n            fileSystem.getLock().unlock();\n        }\n    }\n","realPath":"fs_brokers/apache_hdfs_broker/src/main/java/org/apache/doris/broker/hdfs/FileSystemManager.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"N"}],"commitId":"f6bcabe0d1ba28df33f06dcf242e9b57c370db9e","commitMessage":"@@@[Bug] Fixed bug that caused export and backup to fail when principal keytab file was created failed (#6404)\n\nCo-authored-by: Geoffrey <gaofeng01@rd.netease.com>","date":"2021-08-11 16:39:01","modifiedFileCount":"1","status":"M","submitter":"GeoffreyStark"}]
