[{"authorTime":"2020-07-21 12:42:42","codes":[{"authorDate":"2020-07-21 12:42:42","commitOrder":1,"curCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        ColumnSeparator columnSeparator = new ColumnSeparator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","date":"2020-07-21 12:42:42","endLine":88,"groupId":"6137","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testAnalyzeWithDuplicateProperty","params":"(@InjectableAnalyzeranalyzer)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/85/774dcd1ac158fdd3d1296a215bb26d19488745.src","preCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        ColumnSeparator columnSeparator = new ColumnSeparator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/analysis/CreateRoutineLoadStmtTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"B"},{"authorDate":"2020-07-21 12:42:42","commitOrder":1,"curCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","date":"2020-07-21 12:42:42","endLine":335,"groupId":"6137","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"initCreateRoutineLoadStmt","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/ec/e07c24fa7faefc27554dc045efcb0f6092ce51.src","preCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/load/routineload/KafkaRoutineLoadJobTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":317,"status":"B"}],"commitId":"ad17afef9139a9aeedeb2e92638e95886d515f14","commitMessage":"@@@[CodeRefactor] #4098 Make FE multi module (#4099)\n\nThis PR change the FE code structure to maven multi module structure. \nSee ISSUE: #4098 for more info.  such as How to resolve conflicts.","date":"2020-07-21 12:42:42","modifiedFileCount":"0","status":"B","submitter":"Mingyu Chen"},{"authorTime":"2020-08-21 22:57:16","codes":[{"authorDate":"2020-08-21 22:57:16","commitOrder":2,"curCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        ColumnSeparator columnSeparator = new ColumnSeparator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","date":"2020-08-21 22:57:16","endLine":90,"groupId":"6137","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testAnalyzeWithDuplicateProperty","params":"(@InjectableAnalyzeranalyzer)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/69/22bf1f6f525a863554a450934710db331e0990.src","preCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        ColumnSeparator columnSeparator = new ColumnSeparator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/analysis/CreateRoutineLoadStmtTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":46,"status":"M"},{"authorDate":"2020-08-21 22:57:16","commitOrder":2,"curCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","date":"2020-08-21 22:57:16","endLine":339,"groupId":"6137","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"initCreateRoutineLoadStmt","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/5f/6750c93658333be1ad8061fb532f5417ed6c60.src","preCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/load/routineload/KafkaRoutineLoadJobTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":320,"status":"M"}],"commitId":"d61c10b76108fdbd04f7d86f89c646708a3934ea","commitMessage":"@@@[Delete] Support batch delete [part 1] (#4310)\n\n* Implements the grammar of the batch delete #4051 \n* Process create.  alter table when table has delete sign column\n* Support the syntax for enabling the delete column\n* Automatically filtered deleted data in the select statement.\n* Automatically add delete sign when create  rollup table\nTODO:\n * Optimize the reading and compaction logic on the be side.  so that the data marked as deleted will be completely deleted during base compaction","date":"2020-08-21 22:57:16","modifiedFileCount":"44","status":"M","submitter":"Zhengguo Yang"},{"authorTime":"2020-08-21 22:57:16","codes":[{"authorDate":"2021-03-09 09:35:39","commitOrder":3,"curCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        Separator columnSeparator = new Separator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","date":"2021-03-09 09:35:39","endLine":130,"groupId":"10147","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testAnalyzeWithDuplicateProperty","params":"(@InjectableAnalyzeranalyzer)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/8c/3a1fac86f84b41dff726f015a163bb57496e76.src","preCode":"    public void testAnalyzeWithDuplicateProperty(@Injectable Analyzer analyzer) throws UserException {\n        String jobName = \"job1\";\n        String dbName = \"db1\";\n        LabelName labelName = new LabelName(dbName, jobName);\n        String tableNameString = \"table1\";\n        String topicName = \"topic1\";\n        String serverAddress = \"http://127.0.0.1:8080\";\n        String kafkaPartitionString = \"1,2,3\";\n        List<String> partitionNameString = Lists.newArrayList();\n        partitionNameString.add(\"p1\");\n        PartitionNames partitionNames = new PartitionNames(false, partitionNameString);\n        ColumnSeparator columnSeparator = new ColumnSeparator(\",\");\n\n        \r\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(columnSeparator);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n\n        new MockUp<StatementBase>() {\n            @Mock\n            public void analyze(Analyzer analyzer1) {\n                return;\n            }\n        };\n\n        try {\n            createRoutineLoadStmt.analyze(analyzer);\n            Assert.fail();\n        } catch (AnalysisException e) {\n            LOG.info(e.getMessage());\n        }\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/analysis/CreateRoutineLoadStmtTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":86,"status":"M"},{"authorDate":"2020-08-21 22:57:16","commitOrder":3,"curCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","date":"2020-08-21 22:57:16","endLine":339,"groupId":"10147","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"initCreateRoutineLoadStmt","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-incubatordoris-10-0.7/blobInfo/CC_OUT/blobs/5f/6750c93658333be1ad8061fb532f5417ed6c60.src","preCode":"    private CreateRoutineLoadStmt initCreateRoutineLoadStmt() {\n        List<ParseNode> loadPropertyList = new ArrayList<>();\n        loadPropertyList.add(columnSeparator);\n        loadPropertyList.add(partitionNames);\n        Map<String, String> properties = Maps.newHashMap();\n        properties.put(CreateRoutineLoadStmt.DESIRED_CONCURRENT_NUMBER_PROPERTY, \"2\");\n        String typeName = LoadDataSourceType.KAFKA.name();\n        Map<String, String> customProperties = Maps.newHashMap();\n\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_TOPIC_PROPERTY, topicName);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_BROKER_LIST_PROPERTY, serverAddress);\n        customProperties.put(CreateRoutineLoadStmt.KAFKA_PARTITIONS_PROPERTY, kafkaPartitionString);\n\n        CreateRoutineLoadStmt createRoutineLoadStmt = new CreateRoutineLoadStmt(labelName, tableNameString,\n                                                                                loadPropertyList, properties,\n                                                                                typeName, customProperties,\n                                                                                LoadTask.MergeType.APPEND);\n        Deencapsulation.setField(createRoutineLoadStmt, \"name\", jobName);\n        return createRoutineLoadStmt;\n    }\n","realPath":"fe/fe-core/src/test/java/org/apache/doris/load/routineload/KafkaRoutineLoadJobTest.java","repoName":"incubatordoris","snippetEndLine":0,"snippetStartLine":0,"startLine":320,"status":"N"}],"commitId":"e023ef5404493fa0b1aece6b72d1c2202f190dc2","commitMessage":"@@@[Load] Support multi bytes LineDelimiter and ColumnSeparator (#5462)\n\n* [Internal][Support Multibytes Separator] doris-1079\nsupport multi bytes LineDelimiter and ColumnSeparator","date":"2021-03-09 09:35:39","modifiedFileCount":"15","status":"M","submitter":"Zhengguo Yang"}]
