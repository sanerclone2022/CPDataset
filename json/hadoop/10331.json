[{"authorTime":"2018-01-27 04:36:45","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","date":"2018-01-27 04:36:45","endLine":825,"groupId":"18507","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDoubleTooManyFetchFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/43/571a9b824e21a78cc9dd0cdc7d9e09f085f2d7.src","preCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":758,"status":"B"},{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"  public void testTooManyFetchFailureAfterKill() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n        splits, jobConf, taListener,\n        mock(Token.class), new Credentials(),\n        SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n      container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n      TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_KILL));\n    assertEquals(\"Task attempt is not in KILLED state\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in KILLED state, still\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n      eventHandler.internalError);\n  }\n","date":"2018-01-27 04:36:45","endLine":952,"groupId":"18507","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testTooManyFetchFailureAfterKill","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/43/571a9b824e21a78cc9dd0cdc7d9e09f085f2d7.src","preCode":"  public void testTooManyFetchFailureAfterKill() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n        splits, jobConf, taListener,\n        mock(Token.class), new Credentials(),\n        SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n      container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n      TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_KILL));\n    assertEquals(\"Task attempt is not in KILLED state\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in KILLED state, still\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n      eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":888,"status":"B"}],"commitId":"a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd","commitMessage":"@@@MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n","date":"2018-01-27 04:36:45","modifiedFileCount":"19","status":"B","submitter":"Jason Lowe"},{"authorTime":"2019-08-12 19:54:13","codes":[{"authorDate":"2019-08-12 19:54:13","commitOrder":2,"curCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in SUCCEEDED state\")\n        .isEqualTo(TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in FAILED state\")\n        .isEqualTo(TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in FAILED state, still\")\n        .isEqualTo(TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","date":"2019-08-12 19:54:28","endLine":831,"groupId":"10331","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDoubleTooManyFetchFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/d0/9531c641c0ccbfce7d83a3d258ec03fe3c7e58.src","preCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":761,"status":"M"},{"authorDate":"2019-08-12 19:54:13","commitOrder":2,"curCode":"  public void testTooManyFetchFailureAfterKill() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n        splits, jobConf, taListener,\n        mock(Token.class), new Credentials(),\n        SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n      container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in SUCCEEDED state\")\n        .isEqualTo(TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_KILL));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in KILLED state\")\n        .isEqualTo(TaskAttemptState.KILLED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in KILLED state, still\")\n        .isEqualTo(TaskAttemptState.KILLED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n      eventHandler.internalError);\n  }\n","date":"2019-08-12 19:54:28","endLine":961,"groupId":"10331","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testTooManyFetchFailureAfterKill","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/d0/9531c641c0ccbfce7d83a3d258ec03fe3c7e58.src","preCode":"  public void testTooManyFetchFailureAfterKill() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n        splits, jobConf, taListener,\n        mock(Token.class), new Credentials(),\n        SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n      container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n      TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_KILL));\n    assertEquals(\"Task attempt is not in KILLED state\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n      TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in KILLED state, still\", taImpl.getState(),\n      TaskAttemptState.KILLED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n      eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":894,"status":"M"}],"commitId":"ac6c4f0b290477017798491a4bd77fa9f107871c","commitMessage":"@@@MAPREDUCE-7197. Fix order of actual and expected expression in assert statements. Contributed by Adam Antal\n","date":"2019-08-12 19:54:28","modifiedFileCount":"75","status":"M","submitter":"Szilard Nemeth"}]
