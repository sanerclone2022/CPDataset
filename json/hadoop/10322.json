[{"authorTime":"2018-01-27 04:36:45","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"  public void testKilledDuringFailAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n    dispatcher.init(conf);\n    dispatcher.start();\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public void setupJob(JobContext jobContext) throws IOException {\n        throw new IOException(\"forced failure\");\n      }\n\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.FAIL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","date":"2018-01-27 04:36:45","endLine":493,"groupId":"25187","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testKilledDuringFailAbort","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/85/92b20dad2da58fb37a12996a1dde43be403212.src","preCode":"  public void testKilledDuringFailAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n    dispatcher.init(conf);\n    dispatcher.start();\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public void setupJob(JobContext jobContext) throws IOException {\n        throw new IOException(\"forced failure\");\n      }\n\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.FAIL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestJobImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":454,"status":"B"},{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"  public void testKilledDuringKillAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    \r\n    \r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.SETUP);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","date":"2018-01-27 04:36:45","endLine":534,"groupId":"25187","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testKilledDuringKillAbort","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/85/92b20dad2da58fb37a12996a1dde43be403212.src","preCode":"  public void testKilledDuringKillAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    \r\n    \r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.SETUP);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestJobImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":496,"status":"B"}],"commitId":"a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd","commitMessage":"@@@MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n","date":"2018-01-27 04:36:45","modifiedFileCount":"19","status":"B","submitter":"Jason Lowe"},{"authorTime":"2019-09-07 07:39:02","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":2,"curCode":"  public void testKilledDuringFailAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n    dispatcher.init(conf);\n    dispatcher.start();\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public void setupJob(JobContext jobContext) throws IOException {\n        throw new IOException(\"forced failure\");\n      }\n\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.FAIL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","date":"2018-01-27 04:36:45","endLine":493,"groupId":"10322","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testKilledDuringFailAbort","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/85/92b20dad2da58fb37a12996a1dde43be403212.src","preCode":"  public void testKilledDuringFailAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n    dispatcher.init(conf);\n    dispatcher.start();\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public void setupJob(JobContext jobContext) throws IOException {\n        throw new IOException(\"forced failure\");\n      }\n\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.FAIL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestJobImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":454,"status":"N"},{"authorDate":"2019-09-07 07:39:02","commitOrder":2,"curCode":"  public void testKilledDuringKillAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    \r\n    \r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n    dispatcher.init(conf);\n\n\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.SETUP);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","date":"2019-09-07 07:39:02","endLine":536,"groupId":"10322","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testKilledDuringKillAbort","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/94/5b2543919c005360bd867768ffae8b97e7c4e5.src","preCode":"  public void testKilledDuringKillAbort() throws Exception {\n    Configuration conf = new Configuration();\n    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);\n    \r\n    \r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n\n    OutputCommitter committer = new StubbedOutputCommitter() {\n      @Override\n      public synchronized void abortJob(JobContext jobContext, State state)\n          throws IOException {\n        while (!Thread.interrupted()) {\n          try {\n            wait();\n          } catch (InterruptedException e) {\n          }\n        }\n      }\n    };\n    CommitterEventHandler commitHandler =\n        createCommitterEventHandler(dispatcher, committer);\n    commitHandler.init(conf);\n    commitHandler.start();\n\n    JobImpl job = createStubbedJob(conf, dispatcher, 2, null);\n    JobId jobId = job.getID();\n    job.handle(new JobEvent(jobId, JobEventType.JOB_INIT));\n    assertJobState(job, JobStateInternal.INITED);\n    job.handle(new JobStartEvent(jobId));\n    assertJobState(job, JobStateInternal.SETUP);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILL_ABORT);\n\n    job.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n    assertJobState(job, JobStateInternal.KILLED);\n    dispatcher.stop();\n    commitHandler.stop();\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestJobImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":496,"status":"M"}],"commitId":"5d497abe21bc60f4a017792e5b3fd8cf9a1185be","commitMessage":"@@@YARN-9817. Fix failing testcases due to not initialized AsyncDispatcher - ArithmeticException: / by zero. Contributed by Prabhu Joseph.\n","date":"2019-09-07 07:39:02","modifiedFileCount":"3","status":"M","submitter":"Tao Yang"}]
