[{"authorTime":"2018-01-04 01:01:38","codes":[{"authorDate":"2018-01-04 01:01:38","commitOrder":1,"curCode":"  public void fatalError(TaskAttemptID taskAttemptID, String msg)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - exited : \" + msg);\n    reportDiagnosticInfo(taskAttemptID, \"Error: \" + msg);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","date":"2018-01-04 01:01:38","endLine":298,"groupId":"20208","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"fatalError","params":"(TaskAttemptIDtaskAttemptID@Stringmsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/55/6c90c4412173dbb9f9975be9ed53c29ef6dd77.src","preCode":"  public void fatalError(TaskAttemptID taskAttemptID, String msg)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - exited : \" + msg);\n    reportDiagnosticInfo(taskAttemptID, \"Error: \" + msg);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":284,"status":"B"},{"authorDate":"2018-01-04 01:01:38","commitOrder":1,"curCode":"  public void fsError(TaskAttemptID taskAttemptID, String message)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - failed due to FSError: \"\n        + message);\n    reportDiagnosticInfo(taskAttemptID, \"FSError: \" + message);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","date":"2018-01-04 01:01:38","endLine":316,"groupId":"20208","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"fsError","params":"(TaskAttemptIDtaskAttemptID@Stringmessage)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/55/6c90c4412173dbb9f9975be9ed53c29ef6dd77.src","preCode":"  public void fsError(TaskAttemptID taskAttemptID, String message)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - failed due to FSError: \"\n        + message);\n    reportDiagnosticInfo(taskAttemptID, \"FSError: \" + message);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":301,"status":"B"}],"commitId":"fe35103591ece0209f8345aba5544313e45a073c","commitMessage":"@@@MAPREDUCE-7028. Concurrent task progress updates causing NPE in Application Master. Contributed by Gergo Repas\n","date":"2018-01-04 01:01:38","modifiedFileCount":"1","status":"B","submitter":"Jason Lowe"},{"authorTime":"2018-01-27 04:36:45","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":2,"curCode":"  public void fatalError(TaskAttemptID taskAttemptID, String msg, boolean fastFail)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - exited : \" + msg);\n    reportDiagnosticInfo(taskAttemptID, \"Error: \" + msg);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptFailEvent(attemptID, fastFail));\n  }\n","date":"2018-01-27 04:36:45","endLine":299,"groupId":"10510","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"fatalError","params":"(TaskAttemptIDtaskAttemptID@Stringmsg@booleanfastFail)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/b1/55af220f1cd9b35844f593b180733f1c335445.src","preCode":"  public void fatalError(TaskAttemptID taskAttemptID, String msg)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - exited : \" + msg);\n    reportDiagnosticInfo(taskAttemptID, \"Error: \" + msg);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":285,"status":"M"},{"authorDate":"2018-01-27 04:36:45","commitOrder":2,"curCode":"  public void fsError(TaskAttemptID taskAttemptID, String message)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - failed due to FSError: \"\n        + message);\n    reportDiagnosticInfo(taskAttemptID, \"FSError: \" + message);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptFailEvent(attemptID));\n  }\n","date":"2018-01-27 04:36:45","endLine":317,"groupId":"10510","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"fsError","params":"(TaskAttemptIDtaskAttemptID@Stringmessage)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/b1/55af220f1cd9b35844f593b180733f1c335445.src","preCode":"  public void fsError(TaskAttemptID taskAttemptID, String message)\n      throws IOException {\n    \r\n    LOG.error(\"Task: \" + taskAttemptID + \" - failed due to FSError: \"\n        + message);\n    reportDiagnosticInfo(taskAttemptID, \"FSError: \" + message);\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =\n        TypeConverter.toYarn(taskAttemptID);\n\n    \r\n    preemptionPolicy.handleFailedContainer(attemptID);\n\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(attemptID, TaskAttemptEventType.TA_FAILMSG));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":302,"status":"M"}],"commitId":"a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd","commitMessage":"@@@MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n","date":"2018-01-27 04:36:45","modifiedFileCount":"19","status":"M","submitter":"Jason Lowe"}]
