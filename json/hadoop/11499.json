[{"authorTime":"2018-01-27 04:36:45","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskAttemptId taskAttemptId =\n          ((TaskTAttemptEvent) event).getTaskAttemptID();\n      task.handleTaskAttemptCompletion(taskAttemptId, taCompletionEventStatus);\n      task.finishedAttempts.add(taskAttemptId);\n      \r\n      if (task.finishedAttempts.size() == task.attempts.size()) {\n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, null,\n              finalState, null); \r\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent)); \n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n          \t\t\" generated for task: \" + task.getID());\n        }\n\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, getExternalState(finalState)));\n        return finalState;\n      }\n      return task.getInternalState();\n    }\n","date":"2018-01-27 04:36:45","endLine":1036,"groupId":"36019","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"transition","params":"(TaskImpltask@TaskEventevent)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/ce/3b3cc59639f20fcab53ad81f6d8435dc4168d3.src","preCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskAttemptId taskAttemptId =\n          ((TaskTAttemptEvent) event).getTaskAttemptID();\n      task.handleTaskAttemptCompletion(taskAttemptId, taCompletionEventStatus);\n      task.finishedAttempts.add(taskAttemptId);\n      \r\n      if (task.finishedAttempts.size() == task.attempts.size()) {\n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, null,\n              finalState, null); \r\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent)); \n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n          \t\t\" generated for task: \" + task.getID());\n        }\n\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, getExternalState(finalState)));\n        return finalState;\n      }\n      return task.getInternalState();\n    }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":1014,"status":"B"},{"authorDate":"2018-01-27 04:36:45","commitOrder":1,"curCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskTAttemptFailedEvent castEvent = (TaskTAttemptFailedEvent) event;\n      TaskAttemptId taskAttemptId = castEvent.getTaskAttemptID();\n      task.failedAttempts.add(taskAttemptId); \n      if (taskAttemptId.equals(task.commitAttempt)) {\n        task.commitAttempt = null;\n      }\n      TaskAttempt attempt = task.attempts.get(taskAttemptId);\n      if (attempt.getAssignedContainerMgrAddress() != null) {\n        \r\n        task.eventHandler.handle(new ContainerFailedEvent(attempt.getID(), \n            attempt.getAssignedContainerMgrAddress()));\n      }\n      \n      task.finishedAttempts.add(taskAttemptId);\n      if (!castEvent.isFastFail()\n          && task.failedAttempts.size() < task.maxAttempts) {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.FAILED);\n        \r\n        task.inProgressAttempts.remove(taskAttemptId);\n        if (task.successfulAttempt == null) {\n          boolean shouldAddNewAttempt = true;\n          if (task.inProgressAttempts.size() > 0) {\n            \r\n            for (TaskAttemptId attemptId : task.inProgressAttempts) {\n              if (((TaskAttemptImpl) task.getAttempt(attemptId))\n                  .isContainerAssigned()) {\n                shouldAddNewAttempt = false;\n                break;\n              }\n            }\n          }\n          if (shouldAddNewAttempt) {\n            task.addAndScheduleAttempt(Avataar.VIRGIN);\n          }\n        }\n      } else {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.TIPFAILED);\n\n        \r\n        for (TaskAttempt taskAttempt : task.attempts.values()) {\n          task.killUnfinishedAttempt\n            (taskAttempt, \"Task has failed. Killing attempt!\");\n        }\n        task.inProgressAttempts.clear();\n        \n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, attempt.getDiagnostics(),\n            TaskStateInternal.FAILED, taskAttemptId);\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent));\n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n              \" generated for task: \" + task.getID());\n        }\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, TaskState.FAILED));\n        return task.finished(TaskStateInternal.FAILED);\n      }\n      return getDefaultState(task);\n    }\n","date":"2018-01-27 04:36:45","endLine":1121,"groupId":"36017","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"transition","params":"(TaskImpltask@TaskEventevent)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/ce/3b3cc59639f20fcab53ad81f6d8435dc4168d3.src","preCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskTAttemptFailedEvent castEvent = (TaskTAttemptFailedEvent) event;\n      TaskAttemptId taskAttemptId = castEvent.getTaskAttemptID();\n      task.failedAttempts.add(taskAttemptId); \n      if (taskAttemptId.equals(task.commitAttempt)) {\n        task.commitAttempt = null;\n      }\n      TaskAttempt attempt = task.attempts.get(taskAttemptId);\n      if (attempt.getAssignedContainerMgrAddress() != null) {\n        \r\n        task.eventHandler.handle(new ContainerFailedEvent(attempt.getID(), \n            attempt.getAssignedContainerMgrAddress()));\n      }\n      \n      task.finishedAttempts.add(taskAttemptId);\n      if (!castEvent.isFastFail()\n          && task.failedAttempts.size() < task.maxAttempts) {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.FAILED);\n        \r\n        task.inProgressAttempts.remove(taskAttemptId);\n        if (task.successfulAttempt == null) {\n          boolean shouldAddNewAttempt = true;\n          if (task.inProgressAttempts.size() > 0) {\n            \r\n            for (TaskAttemptId attemptId : task.inProgressAttempts) {\n              if (((TaskAttemptImpl) task.getAttempt(attemptId))\n                  .isContainerAssigned()) {\n                shouldAddNewAttempt = false;\n                break;\n              }\n            }\n          }\n          if (shouldAddNewAttempt) {\n            task.addAndScheduleAttempt(Avataar.VIRGIN);\n          }\n        }\n      } else {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.TIPFAILED);\n\n        \r\n        for (TaskAttempt taskAttempt : task.attempts.values()) {\n          task.killUnfinishedAttempt\n            (taskAttempt, \"Task has failed. Killing attempt!\");\n        }\n        task.inProgressAttempts.clear();\n        \n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, attempt.getDiagnostics(),\n            TaskStateInternal.FAILED, taskAttemptId);\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent));\n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n              \" generated for task: \" + task.getID());\n        }\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, TaskState.FAILED));\n        return task.finished(TaskStateInternal.FAILED);\n      }\n      return getDefaultState(task);\n    }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":1057,"status":"B"}],"commitId":"a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd","commitMessage":"@@@MAPREDUCE-7022. Fast fail rogue jobs based on task scratch dir size. Contributed by Johan Gustavsson\n","date":"2018-01-27 04:36:45","modifiedFileCount":"19","status":"B","submitter":"Jason Lowe"},{"authorTime":"2020-05-28 11:23:01","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":2,"curCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskAttemptId taskAttemptId =\n          ((TaskTAttemptEvent) event).getTaskAttemptID();\n      task.handleTaskAttemptCompletion(taskAttemptId, taCompletionEventStatus);\n      task.finishedAttempts.add(taskAttemptId);\n      \r\n      if (task.finishedAttempts.size() == task.attempts.size()) {\n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, null,\n              finalState, null); \r\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent)); \n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n          \t\t\" generated for task: \" + task.getID());\n        }\n\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, getExternalState(finalState)));\n        return finalState;\n      }\n      return task.getInternalState();\n    }\n","date":"2018-01-27 04:36:45","endLine":1036,"groupId":"11499","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"transition","params":"(TaskImpltask@TaskEventevent)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/ce/3b3cc59639f20fcab53ad81f6d8435dc4168d3.src","preCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskAttemptId taskAttemptId =\n          ((TaskTAttemptEvent) event).getTaskAttemptID();\n      task.handleTaskAttemptCompletion(taskAttemptId, taCompletionEventStatus);\n      task.finishedAttempts.add(taskAttemptId);\n      \r\n      if (task.finishedAttempts.size() == task.attempts.size()) {\n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, null,\n              finalState, null); \r\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent)); \n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n          \t\t\" generated for task: \" + task.getID());\n        }\n\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, getExternalState(finalState)));\n        return finalState;\n      }\n      return task.getInternalState();\n    }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":1014,"status":"N"},{"authorDate":"2020-05-28 11:23:01","commitOrder":2,"curCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskTAttemptFailedEvent castEvent = (TaskTAttemptFailedEvent) event;\n      TaskAttemptId taskAttemptId = castEvent.getTaskAttemptID();\n      task.failedAttempts.add(taskAttemptId); \n      if (taskAttemptId.equals(task.commitAttempt)) {\n        task.commitAttempt = null;\n      }\n      TaskAttempt attempt = task.attempts.get(taskAttemptId);\n      if (attempt.getAssignedContainerMgrAddress() != null) {\n        \r\n        task.eventHandler.handle(new ContainerFailedEvent(attempt.getID(), \n            attempt.getAssignedContainerMgrAddress()));\n      }\n      \n      task.finishedAttempts.add(taskAttemptId);\n      if (!castEvent.isFastFail()\n          && task.failedAttempts.size() < task.maxAttempts) {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.FAILED);\n        \r\n        task.inProgressAttempts.remove(taskAttemptId);\n        if (task.successfulAttempt == null) {\n          boolean shouldAddNewAttempt = true;\n          if (task.inProgressAttempts.size() > 0) {\n            if(task.speculationEnabled) {\n              \r\n              for (TaskAttemptId attemptId : task.inProgressAttempts) {\n                if (((TaskAttemptImpl) task.getAttempt(attemptId))\n                    .isContainerAssigned()) {\n                  shouldAddNewAttempt = false;\n                  break;\n                }\n              }\n            } else {\n              \r\n              \r\n              shouldAddNewAttempt = false;\n            }\n          }\n          if (shouldAddNewAttempt) {\n            task.addAndScheduleAttempt(Avataar.VIRGIN);\n          }\n        }\n      } else {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.TIPFAILED);\n\n        \r\n        for (TaskAttempt taskAttempt : task.attempts.values()) {\n          task.killUnfinishedAttempt\n            (taskAttempt, \"Task has failed. Killing attempt!\");\n        }\n        task.inProgressAttempts.clear();\n        \n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, attempt.getDiagnostics(),\n            TaskStateInternal.FAILED, taskAttemptId);\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent));\n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n              \" generated for task: \" + task.getID());\n        }\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, TaskState.FAILED));\n        return task.finished(TaskStateInternal.FAILED);\n      }\n      return getDefaultState(task);\n    }\n","date":"2020-05-28 11:23:01","endLine":1132,"groupId":"11499","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"transition","params":"(TaskImpltask@TaskEventevent)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/b3/4cd7fd88d3997be0511fc7964e3c07c0fba967.src","preCode":"    public TaskStateInternal transition(TaskImpl task, TaskEvent event) {\n      TaskTAttemptFailedEvent castEvent = (TaskTAttemptFailedEvent) event;\n      TaskAttemptId taskAttemptId = castEvent.getTaskAttemptID();\n      task.failedAttempts.add(taskAttemptId); \n      if (taskAttemptId.equals(task.commitAttempt)) {\n        task.commitAttempt = null;\n      }\n      TaskAttempt attempt = task.attempts.get(taskAttemptId);\n      if (attempt.getAssignedContainerMgrAddress() != null) {\n        \r\n        task.eventHandler.handle(new ContainerFailedEvent(attempt.getID(), \n            attempt.getAssignedContainerMgrAddress()));\n      }\n      \n      task.finishedAttempts.add(taskAttemptId);\n      if (!castEvent.isFastFail()\n          && task.failedAttempts.size() < task.maxAttempts) {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.FAILED);\n        \r\n        task.inProgressAttempts.remove(taskAttemptId);\n        if (task.successfulAttempt == null) {\n          boolean shouldAddNewAttempt = true;\n          if (task.inProgressAttempts.size() > 0) {\n            \r\n            for (TaskAttemptId attemptId : task.inProgressAttempts) {\n              if (((TaskAttemptImpl) task.getAttempt(attemptId))\n                  .isContainerAssigned()) {\n                shouldAddNewAttempt = false;\n                break;\n              }\n            }\n          }\n          if (shouldAddNewAttempt) {\n            task.addAndScheduleAttempt(Avataar.VIRGIN);\n          }\n        }\n      } else {\n        task.handleTaskAttemptCompletion(\n            taskAttemptId, \n            TaskAttemptCompletionEventStatus.TIPFAILED);\n\n        \r\n        for (TaskAttempt taskAttempt : task.attempts.values()) {\n          task.killUnfinishedAttempt\n            (taskAttempt, \"Task has failed. Killing attempt!\");\n        }\n        task.inProgressAttempts.clear();\n        \n        if (task.historyTaskStartGenerated) {\n        TaskFailedEvent taskFailedEvent = createTaskFailedEvent(task, attempt.getDiagnostics(),\n            TaskStateInternal.FAILED, taskAttemptId);\n        task.eventHandler.handle(new JobHistoryEvent(task.taskId.getJobId(),\n            taskFailedEvent));\n        } else {\n          LOG.debug(\"Not generating HistoryFinish event since start event not\" +\n              \" generated for task: \" + task.getID());\n        }\n        task.eventHandler.handle(\n            new JobTaskEvent(task.taskId, TaskState.FAILED));\n        return task.finished(TaskStateInternal.FAILED);\n      }\n      return getDefaultState(task);\n    }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":1062,"status":"M"}],"commitId":"10db97df1c8562a9e29b00e60d5bde1773c09188","commitMessage":"@@@MAPREDUCE-7278. Speculative execution behavior is observed even when mapreduce.map.speculative and mapreduce.reduce.speculative are false\n\nContributed by Tarun Parimi.\n","date":"2020-05-28 11:23:01","modifiedFileCount":"2","status":"M","submitter":"Wilfred Spiegelenburg"}]
