[{"authorTime":"2018-01-31 17:42:42","codes":[{"authorDate":"2018-01-31 17:42:42","commitOrder":1,"curCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","date":"2018-01-31 17:42:42","endLine":460,"groupId":"14595","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testReducerRampdownDiagnostics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/78/75917b68eec03cc7f44ed43633ed880e626905.src","preCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":412,"status":"B"},{"authorDate":"2018-01-31 17:42:42","commitOrder":1,"curCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createReq(jobId, 1, 1024, locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    Assert.assertEquals(assignedContainer, 1);\n  }\n","date":"2018-01-31 17:42:42","endLine":670,"groupId":"24611","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testExcessReduceContainerAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/78/75917b68eec03cc7f44ed43633ed880e626905.src","preCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createReq(jobId, 1, 1024, locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    Assert.assertEquals(assignedContainer, 1);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":629,"status":"B"}],"commitId":"8d1e2c6409a44f4515a1549ae82c7e2597e96467","commitMessage":"@@@Merge branch 'YARN-6592' into trunk\n","date":"2018-01-31 17:42:42","modifiedFileCount":"83","status":"B","submitter":"Arun Suresh"},{"authorTime":"2018-05-11 00:31:59","codes":[{"authorDate":"2018-05-11 00:31:59","commitOrder":2,"curCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","date":"2018-05-11 00:31:59","endLine":469,"groupId":"14595","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testReducerRampdownDiagnostics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/42/7e6ea228f07be943dfedeb58106a10db30d900.src","preCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":417,"status":"M"},{"authorDate":"2018-05-11 00:31:59","commitOrder":2,"curCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createRequest(jobId, 1,\n            Resource.newInstance(1024, 1),\n            locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    Assert.assertEquals(assignedContainer, 1);\n  }\n","date":"2018-05-11 00:31:59","endLine":690,"groupId":"21256","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testExcessReduceContainerAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/42/7e6ea228f07be943dfedeb58106a10db30d900.src","preCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] { host };\n    allocator.sendRequest(createReq(jobId, 0, 1024, locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createReq(jobId, 1, 1024, locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    Assert.assertEquals(assignedContainer, 1);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":645,"status":"M"}],"commitId":"c8b53c43644b4ad22d5385c22cad8ed573c0b1ba","commitMessage":"@@@YARN-8202. DefaultAMSProcessor should properly check units of requested custom resource types against minimum/maximum allocation (snemeth via rkanter)\n","date":"2018-05-11 00:31:59","modifiedFileCount":"6","status":"M","submitter":"Robert Kanter"},{"authorTime":"2019-08-12 19:54:13","codes":[{"authorDate":"2018-05-11 00:31:59","commitOrder":3,"curCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","date":"2018-05-11 00:31:59","endLine":469,"groupId":"14595","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testReducerRampdownDiagnostics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/42/7e6ea228f07be943dfedeb58106a10db30d900.src","preCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":417,"status":"N"},{"authorDate":"2019-08-12 19:54:13","commitOrder":3,"curCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createRequest(jobId, 1,\n            Resource.newInstance(1024, 1),\n            locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    assertThat(assignedContainer).isEqualTo(1);\n  }\n","date":"2019-08-12 19:54:28","endLine":691,"groupId":"21256","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testExcessReduceContainerAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/4b/5fa0adee31b91151de304ba8999e54f1703ac1.src","preCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createRequest(jobId, 1,\n            Resource.newInstance(1024, 1),\n            locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    Assert.assertEquals(assignedContainer, 1);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":646,"status":"M"}],"commitId":"ac6c4f0b290477017798491a4bd77fa9f107871c","commitMessage":"@@@MAPREDUCE-7197. Fix order of actual and expected expression in assert statements. Contributed by Adam Antal\n","date":"2019-08-12 19:54:28","modifiedFileCount":"75","status":"M","submitter":"Szilard Nemeth"},{"authorTime":"2019-12-05 15:56:23","codes":[{"authorDate":"2019-12-05 15:56:23","commitOrder":4,"curCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = MockRMAppSubmitter.submitWithMemory(1024, rm);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","date":"2019-12-05 15:56:23","endLine":471,"groupId":"1091","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testReducerRampdownDiagnostics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/75/798876ddaaa7cafee2d3dfa054c4a14d743fab.src","preCode":"  public void testReducerRampdownDiagnostics() throws Exception {\n    LOG.info(\"Running tesReducerRampdownDiagnostics\");\n\n    final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager rm = new MyResourceManager(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(1024);\n    rm.drainEvents();\n\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 2048);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n        .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n        .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n    \r\n    rm.drainEvents();\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    for (int i = 0; i < 1;) {\n      rm.drainEvents();\n      i += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, true, false));\n    while (allocator.getTaskAttemptKillEvents().size() == 0) {\n      rm.drainEvents();\n      allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n    }\n    final String killEventMessage = allocator.getTaskAttemptKillEvents().get(0)\n        .getMessage();\n    Assert.assertTrue(\"No reducer rampDown preemption message\",\n        killEventMessage.contains(RMContainerAllocator.RAMPDOWN_DIAGNOSTIC));\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":419,"status":"M"},{"authorDate":"2019-12-05 15:56:23","commitOrder":4,"curCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = MockRMAppSubmitter.submitWithMemory(2048, rm);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createRequest(jobId, 1,\n            Resource.newInstance(1024, 1),\n            locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    assertThat(assignedContainer).isEqualTo(1);\n  }\n","date":"2019-12-05 15:56:23","endLine":692,"groupId":"1091","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testExcessReduceContainerAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/75/798876ddaaa7cafee2d3dfa054c4a14d743fab.src","preCode":"  public void testExcessReduceContainerAssign() throws Exception {\n  final Configuration conf = new Configuration();\n    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);\n    final MyResourceManager2 rm = new MyResourceManager2(conf);\n    rm.start();\n    final RMApp app = rm.submitApp(2048);\n    rm.drainEvents();\n    final String host = \"host1\";\n    final MockNM nm = rm.registerNode(String.format(\"%s:1234\", host), 4096);\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    final ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()\n          .getAppAttemptId();\n    rm.sendAMLaunched(appAttemptId);\n    rm.drainEvents();\n    final JobId jobId = MRBuilderUtils\n                 .newJobId(appAttemptId.getApplicationId(), 0);\n    final Job mockJob = mock(Job.class);\n    when(mockJob.getReport()).thenReturn(\n        MRBuilderUtils.newJobReport(jobId, \"job\", \"user\", JobState.RUNNING, 0,\n            0, 0, 0, 0, 0, 0, \"jobfile\", null, false, \"\"));\n    final MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,\n        appAttemptId, mockJob, SystemClock.getInstance());\n\n    \r\n    final String[] locations = new String[] {host};\n    allocator.sendRequest(createRequest(jobId, 0,\n            Resource.newInstance(1024, 1),\n            locations, false, true));\n    allocator.scheduleAllReduces();\n    allocator.makeRemoteRequest();\n    nm.nodeHeartbeat(true);\n    rm.drainEvents();\n    allocator.sendRequest(createRequest(jobId, 1,\n            Resource.newInstance(1024, 1),\n            locations, false, false));\n\n    int assignedContainer;\n    for (assignedContainer = 0; assignedContainer < 1;) {\n      assignedContainer += allocator.schedule().size();\n      nm.nodeHeartbeat(true);\n      rm.drainEvents();\n    }\n    \r\n    assertThat(assignedContainer).isEqualTo(1);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/rm/TestRMContainerAllocator.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":647,"status":"M"}],"commitId":"682e6fdeda68b7244e92d32cd35fe317c9b32ede","commitMessage":"@@@YARN-9052. Replace all MockRM submit method definitions with a builder. Contributed by Szilard Nemeth.\n","date":"2019-12-05 15:56:23","modifiedFileCount":"86","status":"M","submitter":"Sunil G"}]
