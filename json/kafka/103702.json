[{"authorTime":"2015-02-08 04:01:51","codes":[{"authorDate":"2015-02-08 04:01:51","commitOrder":1,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-01 06:11:59","endLine":86,"groupId":"17416","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/bc40648479d4c2ae4ac52f40dadc070a6bcf6f.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"B"},{"authorDate":"2015-02-08 04:01:51","commitOrder":1,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-01 06:11:59","endLine":112,"groupId":"3475","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/bc40648479d4c2ae4ac52f40dadc070a6bcf6f.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"B"}],"commitId":"0636928d961a6ceaab46d908f9372d913c3e5faf","commitMessage":"@@@KAFKA-1865 Add a flush() method to the producer.\n","date":"2015-03-01 06:11:59","modifiedFileCount":"10","status":"B","submitter":"Jay Kreps"},{"authorTime":"2015-03-11 02:19:48","codes":[{"authorDate":"2015-03-11 02:19:48","commitOrder":2,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.rewind();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-11 02:19:48","endLine":87,"groupId":"17416","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/4d27e14cadb86a796d27687e08c2289944bd65.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"},{"authorDate":"2015-03-11 02:19:48","commitOrder":2,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.rewind();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-11 02:19:48","endLine":114,"groupId":"17415","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/4d27e14cadb86a796d27687e08c2289944bd65.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"}],"commitId":"0b92cec1e07a1f2d9aa70f3ecd7d0fb12290d2e2","commitMessage":"@@@KAFKA-1910; Refactor new consumer and fixed a bunch of corner cases / unit tests; reviewed by Onur Karaman and Jay Kreps\n","date":"2015-03-11 02:19:48","modifiedFileCount":"27","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2015-03-11 07:18:00","codes":[{"authorDate":"2015-03-11 07:18:00","commitOrder":3,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-11 07:18:00","endLine":87,"groupId":"17416","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7b/3fb1de692dc270e0b94867c7b7d2eded8bf5b9.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.rewind();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"},{"authorDate":"2015-03-11 07:18:00","commitOrder":3,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-03-11 07:18:00","endLine":114,"groupId":"17415","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7b/3fb1de692dc270e0b94867c7b7d2eded8bf5b9.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.rewind();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"}],"commitId":"01d2a25235841feb01eac55f6ea5141750225a21","commitMessage":"@@@KAFKA-1910; follow-up on fixing buffer.flip on produce requests\n","date":"2015-03-11 07:18:00","modifiedFileCount":"5","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2015-04-07 04:34:31","codes":[{"authorDate":"2015-04-07 04:34:31","commitOrder":4,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-04-07 04:34:31","endLine":86,"groupId":"7810","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/05/e2929c0a9fc8cf2a8ebe0776ca62d5f3962d5c.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, CompressionType.NONE, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"M"},{"authorDate":"2015-04-07 04:34:31","commitOrder":4,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-04-07 04:34:31","endLine":113,"groupId":"17415","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/05/e2929c0a9fc8cf2a8ebe0776ca62d5f3962d5c.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, CompressionType.NONE, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"}],"commitId":"75e1cc8bc497e6aaa0dd05454d6c817ed0fb5e23","commitMessage":"@@@kafka-2043; CompressionType is passed in each RecordAccumulator append; patched by Grant Henke; reviewed by Jun Rao\n","date":"2015-04-07 04:34:31","modifiedFileCount":"4","status":"M","submitter":"Grant Henke"},{"authorTime":"2015-09-17 01:31:57","codes":[{"authorDate":"2015-09-17 01:31:57","commitOrder":5,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-17 01:31:57","endLine":92,"groupId":"7810","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/c52b6d29b0b3aa1302ea5ad6169d24278f99e4.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"},{"authorDate":"2015-09-17 01:31:57","commitOrder":5,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-17 01:31:57","endLine":119,"groupId":"17415","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/c52b6d29b0b3aa1302ea5ad6169d24278f99e4.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"M"}],"commitId":"da39931afad8008bc2b385a75a462777be051435","commitMessage":"@@@KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\n","date":"2015-09-17 01:31:57","modifiedFileCount":"24","status":"M","submitter":"Mayuresh Gharat"},{"authorTime":"2015-09-18 05:36:01","codes":[{"authorDate":"2015-09-18 05:36:01","commitOrder":6,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-18 05:36:01","endLine":89,"groupId":"7810","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5b/2e4ffaeab7127648db608c179703b27b577414.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"},{"authorDate":"2015-09-18 05:36:01","commitOrder":6,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-18 05:36:01","endLine":116,"groupId":"17415","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5b/2e4ffaeab7127648db608c179703b27b577414.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"}],"commitId":"9dbeb71ab258955e04b46991c1baf880b07633f4","commitMessage":"@@@Revert \"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\"\n\nThis reverts commit da39931afad8008bc2b385a75a462777be051435.\n","date":"2015-09-18 05:36:01","modifiedFileCount":"24","status":"M","submitter":"Joel Koshy"},{"authorTime":"2015-09-30 01:28:21","codes":[{"authorDate":"2015-09-30 01:28:21","commitOrder":7,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-30 01:30:03","endLine":92,"groupId":"7810","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/c52b6d29b0b3aa1302ea5ad6169d24278f99e4.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, false, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"},{"authorDate":"2015-09-30 01:28:21","commitOrder":7,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-09-30 01:30:03","endLine":119,"groupId":"17415","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/c52b6d29b0b3aa1302ea5ad6169d24278f99e4.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, false, metrics, time, metricTags);\n        accum.append(tp1, key, value, null);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"M"}],"commitId":"2c4e63a899c6cf832fba4be35773218a9ba5239f","commitMessage":"@@@KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\n","date":"2015-09-30 01:30:03","modifiedFileCount":"24","status":"M","submitter":"Mayuresh Gharat"},{"authorTime":"2015-10-29 01:11:05","codes":[{"authorDate":"2015-10-29 01:11:05","commitOrder":8,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-10-29 01:11:05","endLine":98,"groupId":"7810","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/13/2b83b19273397872c338b8db78563216183cb4.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":77,"status":"M"},{"authorDate":"2015-10-29 01:11:05","commitOrder":8,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-10-29 01:11:05","endLine":125,"groupId":"3475","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/13/2b83b19273397872c338b8db78563216183cb4.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n        batch.records.flip();\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"M"}],"commitId":"b6fe164dd6f9483469c0b0661c24467e33e91cd9","commitMessage":"@@@MINOR: Clean-up MemoryRecords variables and APIs\n\nAuthor: Guozhang Wang <wangguoz@gmail.com>\n\nReviewers: Jun Rao\n\nCloses #348 from guozhangwang/MemoryRecordsCapacity\n","date":"2015-10-29 01:11:05","modifiedFileCount":"8","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2015-12-09 11:43:05","codes":[{"authorDate":"2015-12-09 11:43:05","commitOrder":9,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-12-09 11:43:05","endLine":96,"groupId":"7810","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/72/3e4506607299e01bd925b3a554653c33943d78.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time,  metricTags);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"M"},{"authorDate":"2015-12-09 11:43:05","commitOrder":9,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2015-12-09 11:43:05","endLine":123,"groupId":"3475","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/72/3e4506607299e01bd925b3a554653c33943d78.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time, metricTags);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"}],"commitId":"ef92a8ae7479560b26edecfa8db79934065f13cf","commitMessage":"@@@KAFKA-2668; Add a metric that records the total number of metrics\n\nonurkaraman becketqin Do you have time to review this patch? It addresses the ticket that jjkoshy filed in KAFKA-2668.\n\nAuthor: Dong Lin <lindong28@gmail.com>\n\nReviewers: Onur Karaman <okaraman@linkedin.com>.  Joel Koshy <jjkoshy@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #328 from lindong28/KAFKA-2668\n","date":"2015-12-09 11:43:05","modifiedFileCount":"27","status":"M","submitter":"Dong Lin"},{"authorTime":"2016-02-19 23:56:40","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":10,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-02-19 23:56:40","endLine":96,"groupId":"7810","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0f/95ee5d494dbf009f7354ae8ebc46679355ff80.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"M"},{"authorDate":"2016-02-19 23:56:40","commitOrder":10,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-02-19 23:56:40","endLine":123,"groupId":"3475","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0f/95ee5d494dbf009f7354ae8ebc46679355ff80.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"}],"commitId":"45c8195fa14c766b200c720f316836dbb84e9d8b","commitMessage":"@@@KAFKA-3025; Added timetamp to Message and use relative offset.\n\nSee KIP-31 and KIP-32 for details.\n\nA few notes on the patch:\n1. This patch implements KIP-31 and KIP-32. The patch includes features in both KAFKA-3025.   KAFKA-3026 and KAFKA-3036\n2. All unit tests passed.\n3. The unit tests were run with new and old message format.\n4. When message format conversion occurs during consumption.  the consumer will not be able to detect the message size too large situation. I did not try to fix this because the situation seems rare and only happen during migration phase.\n\nAuthor: Jiangjie Qin <becket.qin@gmail.com>\nAuthor: Ismael Juma <ismael@juma.me.uk>\nAuthor: Jiangjie (Becket) Qin <becket.qin@gmail.com>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Anna Povzner <anna@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #764 from becketqin/KAFKA-3025\n","date":"2016-02-19 23:56:40","modifiedFileCount":"43","status":"M","submitter":"Jiangjie Qin"},{"authorTime":"2016-02-19 23:56:40","codes":[{"authorDate":"2016-05-24 16:13:40","commitOrder":11,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().records.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().records.isWritable());\n        assertTrue(partitionBatchesIterator.next().records.isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-05-24 16:13:40","endLine":111,"groupId":"19150","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/43/ac15a09a4a082b03a9a2425afa3ebc1e433421.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = 1024 / msgSize;\n        for (int i = 0; i < appends; i++) {\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":77,"status":"M"},{"authorDate":"2016-02-19 23:56:40","commitOrder":11,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-02-19 23:56:40","endLine":123,"groupId":"3475","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0f/95ee5d494dbf009f7354ae8ebc46679355ff80.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"N"}],"commitId":"fe27d8f787f38428e0add36edeac9d694f16af53","commitMessage":"@@@KAFKA-3747; Close `RecordBatch.records` when append to batch fails\n\nWith this change.  `test_producer_throughput` with message_size=10000.  compression_type=snappy and a snappy buffer size of 32k can be executed in a heap of 192m in a local environment (768m is needed without this change).\n\nAuthor: Ismael Juma <ismael@juma.me.uk>\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>\n\nCloses #1418 from ijuma/kafka-3747-close-record-batch-when-append-fails\n","date":"2016-05-24 16:13:40","modifiedFileCount":"3","status":"M","submitter":"Ismael Juma"},{"authorTime":"2016-12-14 02:26:25","codes":[{"authorDate":"2016-12-14 02:26:25","commitOrder":12,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepIterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-12-14 02:26:25","endLine":111,"groupId":"19150","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4f/25bdffab121f94cbec4a3d973bb277846a62d7.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().records.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().records.isWritable());\n        assertTrue(partitionBatchesIterator.next().records.isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":77,"status":"M"},{"authorDate":"2016-12-14 02:26:25","commitOrder":12,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepIterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-12-14 02:26:25","endLine":138,"groupId":"3475","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4f/25bdffab121f94cbec4a3d973bb277846a62d7.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records.iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"67f1e5b91bf073151ff57d5d656693e385726697","commitMessage":"@@@KAFKA-4390; Replace MessageSet usage with client-side alternatives\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #2140 from hachikuji/KAFKA4390\n","date":"2016-12-14 02:26:25","modifiedFileCount":"25","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-12-17 02:41:27","codes":[{"authorDate":"2016-12-17 02:41:27","commitOrder":13,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-12-17 02:41:27","endLine":111,"groupId":"19150","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/e14112d3291a193d4c2a8c20ae84c38aba370d.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepIterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":77,"status":"M"},{"authorDate":"2016-12-17 02:41:27","commitOrder":13,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-12-17 02:41:27","endLine":138,"groupId":"3475","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/e14112d3291a193d4c2a8c20ae84c38aba370d.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepIterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"b58b6a1bef0ecdc2107a415e222af099fcd9bce3","commitMessage":"@@@MINOR: Replace deepIterator/shallowIterator with deepEntries/shallowEntries\n\nThe latter return `Iterable` instead of `Iterator` so that enhanced foreach can be used\nin Java.\n\nAuthor: Ismael Juma <ismael@juma.me.uk>\n\nReviewers: Jason Gustafson <jason@confluent.io>\n\nCloses #2261 from ijuma/deepEntries-shallowEntries\n","date":"2016-12-17 02:41:27","modifiedFileCount":"11","status":"M","submitter":"Ismael Juma"},{"authorTime":"2016-12-17 02:41:27","codes":[{"authorDate":"2017-03-04 08:52:26","commitOrder":14,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10L * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-03-04 08:52:26","endLine":118,"groupId":"19150","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1c/b510e3f255564b01c6f55bae72e67d7a357c8d.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10 * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2016-12-17 02:41:27","commitOrder":14,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2016-12-17 02:41:27","endLine":138,"groupId":"3475","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/e14112d3291a193d4c2a8c20ae84c38aba370d.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"N"}],"commitId":"d9b784e1470714c8b04e7c3d74f626a96ca1591e","commitMessage":"@@@KAFKA-4796; Fix some findbugs warnings in Kafka Java client\n\nAuthor: Colin P. Mccabe <cmccabe@confluent.io>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>\n\nCloses #2593 from cmccabe/KAFKA-4796\n","date":"2017-03-04 08:52:26","modifiedFileCount":"16","status":"M","submitter":"Colin P. Mccabe"},{"authorTime":"2017-03-07 09:29:56","codes":[{"authorDate":"2017-03-07 09:29:56","commitOrder":15,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10L * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-03-07 09:30:01","endLine":118,"groupId":"19150","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/42/dc4c4a3402571158b14857227c451b60c07640.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10L * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<RecordBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<RecordBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2017-03-07 09:29:56","commitOrder":15,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-03-07 09:30:01","endLine":145,"groupId":"3475","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/42/dc4c4a3402571158b14857227c451b60c07640.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<RecordBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        RecordBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":129,"status":"M"}],"commitId":"81f9e1376cefed57022de62cd3abf5641c46e4aa","commitMessage":"@@@MINOR: Rename RecordBatch to ProducerBatch to free the name for KIP-98\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Apurva Mehta <apurva.1618@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #2646 from hachikuji/rename-record-batch\n","date":"2017-03-07 09:30:01","modifiedFileCount":"3","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-03-25 03:38:36","codes":[{"authorDate":"2017-03-25 03:38:36","commitOrder":16,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions());\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-03-25 03:38:43","endLine":126,"groupId":"13688","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9c/c863bdb337d12b4eba4da9de669aba2e4fdf27.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n        int batchSize = 1024;\n        RecordAccumulator accum = new RecordAccumulator(batchSize, 10L * batchSize, CompressionType.NONE, 10L, 100L, metrics, time);\n        int appends = batchSize / msgSize;\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n            assertTrue(partitionBatches.peekFirst().isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        for (int i = 0; i < appends; i++) {\n            LogEntry entry = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"},{"authorDate":"2017-03-25 03:38:36","commitOrder":16,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions());\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-03-25 03:38:43","endLine":155,"groupId":"3274","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9c/c863bdb337d12b4eba4da9de669aba2e4fdf27.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024, 10 * 1024, CompressionType.NONE, lingerMs, 100L, metrics, time);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<LogEntry> iter = batch.records().deepEntries().iterator();\n        LogEntry entry = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), entry.record().key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), entry.record().value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"M"}],"commitId":"5bd06f1d542e6b588a1d402d059bc24690017d32","commitMessage":"@@@KAFKA-4816; Message format changes for idempotent/transactional producer (KIP-98)\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Apurva Mehta <apurva@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #2614 from hachikuji/exactly-once-message-format\n","date":"2017-03-25 03:38:43","modifiedFileCount":"55","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-04-03 10:41:44","codes":[{"authorDate":"2017-04-03 10:41:44","commitOrder":17,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions(), null);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-04-03 10:41:44","endLine":130,"groupId":"13688","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/17e16881c32f6e5bc819d180a2a38a5d10668c.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions());\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertFalse(partitionBatchesIterator.next().isWritable());\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":90,"status":"M"},{"authorDate":"2017-04-03 10:41:44","commitOrder":17,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions(), null);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-04-03 10:41:44","endLine":159,"groupId":"3274","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/17e16881c32f6e5bc819d180a2a38a5d10668c.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions());\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"}],"commitId":"bdf4cba047334943aa8357585c4fb379b27e9ffd","commitMessage":"@@@KAFKA-4817; Add idempotent producer semantics\n\nThis is from the KIP-98 proposal.\n\nThe main points of discussion surround the correctness logic.  particularly the Log class where incoming entries are validated and duplicates are dropped.  and also the producer error handling to ensure that the semantics are sound from the users point of view.\n\nThere is some subtlety in the idempotent producer semantics. This patch only guarantees idempotent production upto the point where an error has to be returned to the user. Once we hit a such a non-recoverable error.  we can no longer guarantee message ordering nor idempotence without additional logic at the application level.\n\nIn particular.  if an application wants guaranteed message order without duplicates.  then it needs to do the following in the error callback:\n\n1. Close the producer so that no queued batches are sent. This is important for guaranteeing ordering.\n2. Read the tail of the log to inspect the last message committed. This is important for avoiding duplicates.\n\nAuthor: Apurva Mehta <apurva@confluent.io>\nAuthor: hachikuji <jason@confluent.io>\nAuthor: Apurva Mehta <apurva.1618@gmail.com>\nAuthor: Guozhang Wang <wangguoz@gmail.com>\nAuthor: fpj <fpj@apache.org>\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Jun Rao <junrao@gmail.com>\n\nCloses #2735 from apurvam/exactly-once-idempotent-producer\n","date":"2017-04-03 10:41:44","modifiedFileCount":"24","status":"M","submitter":"Apurva Mehta"},{"authorTime":"2017-04-29 10:17:57","codes":[{"authorDate":"2017-04-29 10:17:57","commitOrder":18,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions(), null);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-04-29 10:18:27","endLine":131,"groupId":"22646","id":35,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/af/599caf3893b536c58c9b429c043e2c93149725.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions(), null);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":91,"status":"M"},{"authorDate":"2017-04-29 10:17:57","commitOrder":18,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions(), null);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-04-29 10:18:27","endLine":176,"groupId":"3274","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/af/599caf3893b536c58c9b429c043e2c93149725.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions(), null);\n        accum.append(tp1, 0L, key, value, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":159,"status":"M"}],"commitId":"6185bc0276c03075022c30d3c36f7f5c09ef19c6","commitMessage":"@@@KAFKA-4208; Add Record Headers\n\nAs per KIP-82\n\nAdding record headers api to ProducerRecord.  ConsumerRecord\nSupport to convert from protocol to api added Kafka Producer.  Kafka Fetcher (Consumer)\nUpdated MirrorMaker.  ConsoleConsumer and scala BaseConsumer\nAdd RecordHeaders and RecordHeader implementation of the interfaces Headers and Header\n\nSome bits using are reverted to being Java 7 compatible.  for the moment until KIP-118 is implemented.\n\nAuthor: Michael Andre Pearce <Michael.Andre.Pearce@me.com>\n\nReviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>.  Jiangjie Qin <becket.qin@gmail.com>.  Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2772 from michaelandrepearce/KIP-82\n","date":"2017-04-29 10:18:27","modifiedFileCount":"26","status":"M","submitter":"Michael Andre Pearce"},{"authorTime":"2017-08-26 01:38:15","codes":[{"authorDate":"2017-08-26 01:38:15","commitOrder":19,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10L);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-08-26 01:42:40","endLine":140,"groupId":"22646","id":37,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d4/86c10a94e1635be653b335c043ba495940a385.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = new RecordAccumulator(batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize,\n                CompressionType.NONE, 10L, 100L, metrics, time, new ApiVersions(), null);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2017-08-26 01:38:15","commitOrder":19,"curCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2017-08-26 01:42:40","endLine":233,"groupId":"3274","id":38,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d4/86c10a94e1635be653b335c043ba495940a385.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = new RecordAccumulator(1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024,\n                CompressionType.NONE, lingerMs, 100L, metrics, time, new ApiVersions(), null);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":216,"status":"M"}],"commitId":"607c3c21f652a8f911d1efb8374d2eec313a4e2d","commitMessage":"@@@KAFKA-5755; KafkaProducer should be refactored to use LogContext\n\nWith LogContext.  each producer log item is automatically prefixed with client id and transactional id.\n\nAuthor: huxihx <huxi_2b@hotmail.com>\n\nReviewers: Jason Gustafson <jason@confluent.io>\n\nCloses #3703 from huxihx/KAFKA-5755\n","date":"2017-08-26 01:42:40","modifiedFileCount":"6","status":"M","submitter":"huxihx"},{"authorTime":"2019-04-29 23:59:18","codes":[{"authorDate":"2019-04-29 23:59:18","commitOrder":20,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-04-29 23:59:17","endLine":139,"groupId":"22646","id":39,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/50/61447b54499191beaa38458c693c1eafc2ba36.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10L);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2019-04-29 23:59:18","commitOrder":20,"curCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-04-29 23:59:17","endLine":232,"groupId":"3274","id":40,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/50/61447b54499191beaa38458c693c1eafc2ba36.src","preCode":"    public void testLinger() throws Exception {\n        long lingerMs = 10L;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":215,"status":"M"}],"commitId":"b4532a65f758448c763b65b2fdde1405db2f9d9d","commitMessage":"@@@KAFKA-8134: `linger.ms` must be a long\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Colin P. McCabe <cmccabe@apache.org>","date":"2019-04-29 23:59:17","modifiedFileCount":"6","status":"M","submitter":"Dhruvil Shah"},{"authorTime":"2019-08-02 05:36:12","codes":[{"authorDate":"2019-08-02 05:36:12","commitOrder":21,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-08-02 05:36:12","endLine":140,"groupId":"22646","id":41,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cd/b164af5b2dd161b3fef1f040dfa83272c21d6c.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2019-08-02 05:36:12","commitOrder":21,"curCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-08-02 05:36:12","endLine":233,"groupId":"3274","id":42,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cd/b164af5b2dd161b3fef1f040dfa83272c21d6c.src","preCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":216,"status":"M"}],"commitId":"717c55be971df862c55f55d245b9997f1d6f998c","commitMessage":"@@@KAFKA-8601: Implement KIP-480: Sticky Partitioning for keyless records (#6997)\n\nImplement KIP-480.  which specifies that the default partitioner should use a \"sticky\" partitioning strategy for records that have a null key.\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>.  Lucas Bradstreet <lucasbradstreet@gmail.com>.  Stanislav Kozlovski <stanislav_kozlovski@outlook.com>.  Jun Rao <junrao@gmail.com>.  Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>","date":"2019-08-02 05:36:12","modifiedFileCount":"9","status":"M","submitter":"Justine Olshan"},{"authorTime":"2019-12-03 20:56:16","codes":[{"authorDate":"2019-12-03 20:56:16","commitOrder":22,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-12-03 20:56:16","endLine":139,"groupId":"22646","id":43,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/08/b29b0996c864b1031a1b977aa53b2ec2135893.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2019-12-03 20:56:16","commitOrder":22,"curCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","date":"2019-12-03 20:56:16","endLine":231,"groupId":"3274","id":44,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/08/b29b0996c864b1031a1b977aa53b2ec2135893.src","preCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false);\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":214,"status":"M"}],"commitId":"38fde81132e0457e983eae60b3d4a9834ad84129","commitMessage":"@@@MINOR: Proactively update producer topic access time. (#7672)\n\nChanges the ProducerMetadata to longer record a sentinel TOPIC_EXPIRY_NEEDS_UPDATE upon topic map emplacement.  and instead set the expiry time directly. Previously the expiry time was being updated for all touched topics after a metadata fetch was processed.  which could be seconds/minutes in the future.\n\nAdditionally propagates the current time further in the Producer.  which should reduce the total number of current-time calls.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.   Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-12-03 20:56:16","modifiedFileCount":"9","status":"M","submitter":"Brian Byrne"},{"authorTime":"2021-01-14 08:17:45","codes":[{"authorDate":"2021-01-14 08:17:45","commitOrder":23,"curCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(0, accum.ready(cluster, now).readyNodes.size(), \"No partitions should be ready.\");\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes, \"Our partition's leader should be ready\");\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(ByteBuffer.wrap(key), record.key(), \"Keys should match\");\n            assertEquals(ByteBuffer.wrap(value), record.value(), \"Values should match\");\n        }\n        assertFalse(iter.hasNext(), \"No more records\");\n    }\n","date":"2021-01-14 08:17:45","endLine":140,"groupId":"103702","id":45,"instanceNumber":1,"isCurCommit":0,"methodName":"testFull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/08aabdebf6cda90c586957345bdf7e964fcf60.src","preCode":"    public void testFull() throws Exception {\n        long now = time.milliseconds();\n\n        \r\n        int batchSize = 1025;\n\n        RecordAccumulator accum = createTestRecordAccumulator(\n                batchSize + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10L * batchSize, CompressionType.NONE, 10);\n        int appends = expectedNumAppends(batchSize);\n        for (int i = 0; i < appends; i++) {\n            \r\n            accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n            Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n            assertEquals(1, partitionBatches.size());\n\n            ProducerBatch batch = partitionBatches.peekFirst();\n            assertTrue(batch.isWritable());\n            assertEquals(\"No partitions should be ready.\", 0, accum.ready(cluster, now).readyNodes.size());\n        }\n\n        \r\n\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        Deque<ProducerBatch> partitionBatches = accum.batches().get(tp1);\n        assertEquals(2, partitionBatches.size());\n        Iterator<ProducerBatch> partitionBatchesIterator = partitionBatches.iterator();\n        assertTrue(partitionBatchesIterator.next().isWritable());\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        for (int i = 0; i < appends; i++) {\n            Record record = iter.next();\n            assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n            assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        }\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"},{"authorDate":"2021-01-14 08:17:45","commitOrder":23,"curCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        assertEquals(0, accum.ready(cluster, time.milliseconds()).readyNodes.size(), \"No partitions should be ready\");\n        time.sleep(10);\n        assertEquals(Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes, \"Our partition's leader should be ready\");\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(ByteBuffer.wrap(key), record.key(), \"Keys should match\");\n        assertEquals(ByteBuffer.wrap(value), record.value(), \"Values should match\");\n        assertFalse(iter.hasNext(), \"No more records\");\n    }\n","date":"2021-01-14 08:17:45","endLine":232,"groupId":"103702","id":46,"instanceNumber":2,"isCurCommit":0,"methodName":"testLinger","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/08aabdebf6cda90c586957345bdf7e964fcf60.src","preCode":"    public void testLinger() throws Exception {\n        int lingerMs = 10;\n        RecordAccumulator accum = createTestRecordAccumulator(\n                1024 + DefaultRecordBatch.RECORD_BATCH_OVERHEAD, 10 * 1024, CompressionType.NONE, lingerMs);\n        accum.append(tp1, 0L, key, value, Record.EMPTY_HEADERS, null, maxBlockTimeMs, false, time.milliseconds());\n        assertEquals(\"No partitions should be ready\", 0, accum.ready(cluster, time.milliseconds()).readyNodes.size());\n        time.sleep(10);\n        assertEquals(\"Our partition's leader should be ready\", Collections.singleton(node1), accum.ready(cluster, time.milliseconds()).readyNodes);\n        List<ProducerBatch> batches = accum.drain(cluster, Collections.singleton(node1), Integer.MAX_VALUE, 0).get(node1.id());\n        assertEquals(1, batches.size());\n        ProducerBatch batch = batches.get(0);\n\n        Iterator<Record> iter = batch.records().records().iterator();\n        Record record = iter.next();\n        assertEquals(\"Keys should match\", ByteBuffer.wrap(key), record.key());\n        assertEquals(\"Values should match\", ByteBuffer.wrap(value), record.value());\n        assertFalse(\"No more records\", iter.hasNext());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":215,"status":"M"}],"commitId":"52b8aa0fdce1872b5b525b62dc3ac2241cfaa379","commitMessage":"@@@KAFKA-7340: Migrate clients module to JUnit 5 (#9874)\n\n* Use the packages/classes from JUnit 5\n* Move description in `assert` methods to last parameter\n* Convert parameterized tests so that they work with JUnit 5\n* Remove `hamcrest`.  it didn't seem to add much value\n* Fix `Utils.mkEntry` to have correct `equals` implementation\n* Add a missing `@Test` annotation in `SslSelectorTest` override\n* Adjust regex in `SaslAuthenticatorTest` due to small change in the\nassert failure string in JUnit 5\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>","date":"2021-01-14 08:17:45","modifiedFileCount":"254","status":"M","submitter":"Ismael Juma"}]
