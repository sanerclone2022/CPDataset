[{"authorTime":"2016-05-09 15:12:30","codes":[{"authorDate":"2016-05-09 15:12:30","commitOrder":1,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-05-09 15:12:30","endLine":477,"groupId":"2403","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f5/bce8f43568f16bf8d3dfce1bd442a19b536e2b.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":430,"status":"B"},{"authorDate":"2016-05-09 15:12:30","commitOrder":1,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-05-09 15:12:30","endLine":516,"groupId":"2409","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f5/bce8f43568f16bf8d3dfce1bd442a19b536e2b.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":480,"status":"B"}],"commitId":"8911660e2e7d9553502974393ad1aa04852c2da2","commitMessage":"@@@KAFKA-3674: Ensure connector target state changes propagated to worker\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1341 from hachikuji/KAFKA-3674\n","date":"2016-05-09 15:12:30","modifiedFileCount":"5","status":"B","submitter":"Jason Gustafson"},{"authorTime":"2016-11-30 07:30:40","codes":[{"authorDate":"2016-11-30 07:30:40","commitOrder":2,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-11-30 07:31:14","endLine":479,"groupId":"2403","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/101c3686a8df6e56bc075bdc17bd08e040b485.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":432,"status":"M"},{"authorDate":"2016-11-30 07:30:40","commitOrder":2,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-11-30 07:31:14","endLine":518,"groupId":"2409","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/101c3686a8df6e56bc075bdc17bd08e040b485.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":482,"status":"M"}],"commitId":"d98ca230a14b0aedae752fa97f5d55b3a0c49b9c","commitMessage":"@@@KAFKA-4397: Refactor Connect backing stores for thread safety\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Shikhar Bhushan <shikhar@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #2123 from kkonstantine/KAFKA-4397-Refactor-connect-backing-stores-for-thread-safety\n","date":"2016-11-30 07:31:14","modifiedFileCount":"6","status":"M","submitter":"Konstantine Karantasis"},{"authorTime":"2017-07-20 01:51:28","codes":[{"authorDate":"2017-07-20 01:51:28","commitOrder":3,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2017-07-20 01:51:28","endLine":485,"groupId":"8029","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/dd18e1377af4df24e89527931d38201722e7c9.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":438,"status":"M"},{"authorDate":"2017-07-20 01:51:28","commitOrder":3,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2017-07-20 01:51:28","endLine":524,"groupId":"21566","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/dd18e1377af4df24e89527931d38201722e7c9.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":488,"status":"M"}],"commitId":"f87d58b796977fdaefb089d17cb30b2071cd4485","commitMessage":"@@@MINOR: Code Cleanup\n\nClean up includes:\n\n- Switching try-catch-finally blocks to try-with-resources when possible\n- Removing some seemingly unnecessary `SuppressWarnings` annotations\n- Resolving some Java warnings\n- Closing unclosed Closable objects\n- Removing unused code\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Balint Molnar <balintmolnar91@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Matthias J. Sax <matthias@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3222 from vahidhashemian/minor/code_cleanup_1706\n","date":"2017-07-20 01:51:28","modifiedFileCount":"62","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2017-07-20 01:51:28","codes":[{"authorDate":"2020-05-21 11:15:43","commitOrder":4,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(1));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.connectorConfig(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.subList(0, 2), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(2, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n        configState = configStorage.snapshot();\n        \r\n        assertFalse(configState.contains(CONNECTOR_IDS.get(0)));\n        \r\n        assertEquals(Collections.emptyList(), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(0, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-05-21 11:15:43","endLine":585,"groupId":"8029","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/51/2dcb3d879104f010e9899bc72448b0fe098581.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":529,"status":"M"},{"authorDate":"2017-07-20 01:51:28","commitOrder":4,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2017-07-20 01:51:28","endLine":524,"groupId":"21566","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/dd18e1377af4df24e89527931d38201722e7c9.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":488,"status":"N"}],"commitId":"82f5efabc9249e0accf530a6a82afc2f32e65ec6","commitMessage":"@@@KAFKA-8869: Remove task configs for deleted connectors from config snapshot (#8444)\n\nCurrently.  if a connector is deleted.  its task configurations will remain in the config snapshot tracked by the KafkaConfigBackingStore. This causes issues with incremental cooperative rebalancing.  which utilizes that config snapshot to determine which connectors and tasks need to be assigned across the cluster. Specifically.  it first checks to see which connectors are present in the config snapshot.  and then.  for each of those connectors.  queries the snapshot for that connector's task configs.\n\nThe lifecycle of a connector is for its configuration to be written to the config topic.  that write to be picked up by the workers in the cluster and trigger a rebalance.  the connector to be assigned to and started by a worker.  task configs to be generated by the connector and then written to the config topic.  that write to be picked up by the workers in the cluster and trigger a second rebalance.  and finally.  the tasks to be assigned to and started by workers across the cluster.\n\nThere is a brief period in between the first time the connector is started and when the second rebalance has completed during which those stale task configs from a previously-deleted version of the connector will be used by the framework to start tasks for that connector. This fix aims to eliminate that window by preemptively clearing the task configs from the config snapshot for a connector whenever it has been deleted.\n\nAn existing unit test is modified to verify this behavior.  and should provide sufficient guarantees that the bug has been fixed.\n\nReviewers: Nigel Liang <nigel@nigelliang.com>.  Konstantine Karantasis <konstantine@confluent.io>","date":"2020-05-21 11:15:43","modifiedFileCount":"2","status":"M","submitter":"Chris Egerton"},{"authorTime":"2020-06-08 03:42:00","codes":[{"authorDate":"2020-06-08 03:42:00","commitOrder":5,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(1));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.connectorConfig(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.subList(0, 2), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(2, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n        configState = configStorage.snapshot();\n        \r\n        assertFalse(configState.contains(CONNECTOR_IDS.get(0)));\n        \r\n        assertEquals(Collections.emptyList(), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(0, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-06-08 03:42:00","endLine":604,"groupId":"8029","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a4/6f6fefcfe7382f99bd134a9766c152ff610998.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(1));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.connectorConfig(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.subList(0, 2), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(2, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n        configState = configStorage.snapshot();\n        \r\n        assertFalse(configState.contains(CONNECTOR_IDS.get(0)));\n        \r\n        assertEquals(Collections.emptyList(), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(0, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":547,"status":"M"},{"authorDate":"2020-06-08 03:42:00","commitOrder":5,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-06-08 03:42:00","endLine":644,"groupId":"21566","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a4/6f6fefcfe7382f99bd134a9766c152ff610998.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":607,"status":"M"}],"commitId":"9a0b694a6686d0dc165d7dab54be0f77535582fa","commitMessage":"@@@KAFKA-9216: Enforce internal config topic settings for Connect workers during startup (#8270)\n\nCurrently.  Kafka Connect creates its config backing topic with a fire and forget approach.\nThis is fine unless someone has manually created that topic already with the wrong partition count.\n\nIn such a case Kafka Connect may run for some time. Especially if it's in standalone mode and once switched to distributed mode it will almost certainly fail.\n\nThis commits adds a check when the KafkaConfigBackingStore is starting.\nThis check will throw a ConfigException if there is more than one partition in the backing store.\n\nThis exception is then caught upstream and logged by either:\n- DistributedHerder#run\n- ConnectStandalone#main\n\nA unit tests was added in KafkaConfigBackingStoreTest to verify the behaviour.\n\nAuthor: Evelyn Bayes <evelyn@confluent.io>\nCo-authored-by: Randall Hauch <rhauch@gmail.com>\n\nReviewer: Konstantine Karantasis <konstantine@confluent.io>","date":"2020-06-08 03:42:00","modifiedFileCount":"3","status":"M","submitter":"Evelyn Bayes"},{"authorTime":"2021-04-15 05:38:37","codes":[{"authorDate":"2021-04-15 05:38:37","commitOrder":6,"curCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, CONNECTOR_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(0), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(1), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(1),\n                        CONFIGS_SERIALIZED.get(2), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(3), new RecordHeaders(), Optional.empty()));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(1));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.connectorConfig(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.subList(0, 2), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(2, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n        configState = configStorage.snapshot();\n        \r\n        assertFalse(configState.contains(CONNECTOR_IDS.get(0)));\n        \r\n        assertEquals(Collections.emptyList(), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(0, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2021-04-15 05:38:37","endLine":619,"groupId":"105128","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testBackgroundConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/960e5bf46cfc52378c8a48bddd68139fff7cd7.src","preCode":"    public void testBackgroundConnectorDeletion() throws Exception {\n        \r\n\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(1));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        LinkedHashMap<String, byte[]> serializedData = new LinkedHashMap<>();\n        serializedData.put(CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0));\n        serializedData.put(TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(1));\n\n        Map<String, Struct> deserializedData = new HashMap<>();\n        deserializedData.put(CONNECTOR_CONFIG_KEYS.get(0), null);\n        deserializedData.put(TARGET_STATE_KEYS.get(0), null);\n\n        expectRead(serializedData, deserializedData);\n\n        configUpdateListener.onConnectorConfigRemove(CONNECTOR_IDS.get(0));\n        EasyMock.expectLastCall();\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.get(0), configState.connectorConfig(CONNECTOR_IDS.get(0)));\n        assertEquals(SAMPLE_CONFIGS.subList(0, 2), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(2, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.refresh(0, TimeUnit.SECONDS);\n        configState = configStorage.snapshot();\n        \r\n        assertFalse(configState.contains(CONNECTOR_IDS.get(0)));\n        \r\n        assertEquals(Collections.emptyList(), configState.allTaskConfigs(CONNECTOR_IDS.get(0)));\n        assertEquals(0, configState.taskCount(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":558,"status":"M"},{"authorDate":"2021-04-15 05:38:37","commitOrder":6,"curCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, CONNECTOR_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(0), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(1), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(1),\n                        CONFIGS_SERIALIZED.get(2), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0, 0, TARGET_STATE_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(3), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(4), new RecordHeaders(), Optional.empty()));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2021-04-15 05:38:37","endLine":664,"groupId":"105128","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreTargetStateUnexpectedDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/960e5bf46cfc52378c8a48bddd68139fff7cd7.src","preCode":"    public void testRestoreTargetStateUnexpectedDeletion() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.STARTED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":622,"status":"M"}],"commitId":"89933f21f204abf75336464d3ac24a4fdd254628","commitMessage":"@@@KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)\n\nThe methods have been deprecated since 0.11 without replacement since\nmessage format 2 moved the checksum to the record batch (instead of the\nrecord).\n\nUnfortunately.  we did not deprecate the constructors that take a checksum\n(even though we intended to) so we cannot remove them. I have deprecated\nthem for removal in 4.0 and added a single non deprecated constructor to\n`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.\n`ConsumerRecord` could do with one additional convenience constructor.  but\nthat requires a KIP and hence should be done separately.\n\nAlso:\n* Removed `ChecksumMessageFormatter`.  which is technically not public\nAPI.  but may have been used with the console consumer.\n* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructors\nto use the non deprecated ones.\n* Added tests for deprecated `ConsumerRecord/`RecordMetadata`\nconstructors.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  David Jacot <djacot@confluent.io>","date":"2021-04-15 05:38:37","modifiedFileCount":"47","status":"M","submitter":"Ismael Juma"}]
