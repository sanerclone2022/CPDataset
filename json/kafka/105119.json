[{"authorTime":"2016-05-09 15:12:30","codes":[{"authorDate":"2016-05-09 15:12:30","commitOrder":1,"curCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-05-09 15:12:30","endLine":385,"groupId":"2409","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testRestoreTargetState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f5/bce8f43568f16bf8d3dfce1bd442a19b536e2b.src","preCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":349,"status":"B"},{"authorDate":"2016-05-09 15:12:30","commitOrder":1,"curCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-05-09 15:12:30","endLine":616,"groupId":"12771","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f5/bce8f43568f16bf8d3dfce1bd442a19b536e2b.src","preCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":574,"status":"B"}],"commitId":"8911660e2e7d9553502974393ad1aa04852c2da2","commitMessage":"@@@KAFKA-3674: Ensure connector target state changes propagated to worker\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1341 from hachikuji/KAFKA-3674\n","date":"2016-05-09 15:12:30","modifiedFileCount":"5","status":"B","submitter":"Jason Gustafson"},{"authorTime":"2016-11-30 07:30:40","codes":[{"authorDate":"2016-11-30 07:30:40","commitOrder":2,"curCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-11-30 07:31:14","endLine":387,"groupId":"2409","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testRestoreTargetState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/101c3686a8df6e56bc075bdc17bd08e040b485.src","preCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":351,"status":"M"},{"authorDate":"2016-11-30 07:30:40","commitOrder":2,"curCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-11-30 07:31:14","endLine":618,"groupId":"12771","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/101c3686a8df6e56bc075bdc17bd08e040b485.src","preCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.configure(DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":576,"status":"M"}],"commitId":"d98ca230a14b0aedae752fa97f5d55b3a0c49b9c","commitMessage":"@@@KAFKA-4397: Refactor Connect backing stores for thread safety\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Shikhar Bhushan <shikhar@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #2123 from kkonstantine/KAFKA-4397-Refactor-connect-backing-stores-for-thread-safety\n","date":"2016-11-30 07:31:14","modifiedFileCount":"6","status":"M","submitter":"Konstantine Karantasis"},{"authorTime":"2017-07-20 01:51:28","codes":[{"authorDate":"2017-07-20 01:51:28","commitOrder":3,"curCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2017-07-20 01:51:28","endLine":393,"groupId":"21566","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testRestoreTargetState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/dd18e1377af4df24e89527931d38201722e7c9.src","preCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":357,"status":"M"},{"authorDate":"2017-07-20 01:51:28","commitOrder":3,"curCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2017-07-20 01:51:28","endLine":624,"groupId":"12771","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/dd18e1377af4df24e89527931d38201722e7c9.src","preCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":582,"status":"M"}],"commitId":"f87d58b796977fdaefb089d17cb30b2071cd4485","commitMessage":"@@@MINOR: Code Cleanup\n\nClean up includes:\n\n- Switching try-catch-finally blocks to try-with-resources when possible\n- Removing some seemingly unnecessary `SuppressWarnings` annotations\n- Resolving some Java warnings\n- Closing unclosed Closable objects\n- Removing unused code\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Balint Molnar <balintmolnar91@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Matthias J. Sax <matthias@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3222 from vahidhashemian/minor/code_cleanup_1706\n","date":"2017-07-20 01:51:28","modifiedFileCount":"62","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2020-06-08 03:42:00","codes":[{"authorDate":"2020-06-08 03:42:00","commitOrder":4,"curCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-06-08 03:42:00","endLine":501,"groupId":"21566","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testRestoreTargetState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a4/6f6fefcfe7382f99bd134a9766c152ff610998.src","preCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":464,"status":"M"},{"authorDate":"2020-06-08 03:42:00","commitOrder":4,"curCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-06-08 03:42:00","endLine":746,"groupId":"12771","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a4/6f6fefcfe7382f99bd134a9766c152ff610998.src","preCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":703,"status":"M"}],"commitId":"9a0b694a6686d0dc165d7dab54be0f77535582fa","commitMessage":"@@@KAFKA-9216: Enforce internal config topic settings for Connect workers during startup (#8270)\n\nCurrently.  Kafka Connect creates its config backing topic with a fire and forget approach.\nThis is fine unless someone has manually created that topic already with the wrong partition count.\n\nIn such a case Kafka Connect may run for some time. Especially if it's in standalone mode and once switched to distributed mode it will almost certainly fail.\n\nThis commits adds a check when the KafkaConfigBackingStore is starting.\nThis check will throw a ConfigException if there is more than one partition in the backing store.\n\nThis exception is then caught upstream and logged by either:\n- DistributedHerder#run\n- ConnectStandalone#main\n\nA unit tests was added in KafkaConfigBackingStoreTest to verify the behaviour.\n\nAuthor: Evelyn Bayes <evelyn@confluent.io>\nCo-authored-by: Randall Hauch <rhauch@gmail.com>\n\nReviewer: Konstantine Karantasis <konstantine@confluent.io>","date":"2020-06-08 03:42:00","modifiedFileCount":"3","status":"M","submitter":"Evelyn Bayes"},{"authorTime":"2021-04-15 05:38:37","codes":[{"authorDate":"2021-04-15 05:38:37","commitOrder":5,"curCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, CONNECTOR_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(0), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(1), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(1),\n                        CONFIGS_SERIALIZED.get(2), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0, 0, TARGET_STATE_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(3), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(4), new RecordHeaders(), Optional.empty()));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2021-04-15 05:38:37","endLine":508,"groupId":"105119","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testRestoreTargetState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/960e5bf46cfc52378c8a48bddd68139fff7cd7.src","preCode":"    public void testRestoreTargetState() throws Exception {\n        expectConfigure();\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(4)));\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), TARGET_STATE_PAUSED);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n        logOffset = 5;\n\n        expectStart(existingRecords, deserialized);\n\n        \r\n\n        expectPartitionCount(1);\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(5, configState.offset()); \r\n        assertEquals(Arrays.asList(CONNECTOR_IDS.get(0)), new ArrayList<>(configState.connectors()));\n        assertEquals(TargetState.PAUSED, configState.targetState(CONNECTOR_IDS.get(0)));\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":466,"status":"M"},{"authorDate":"2021-04-15 05:38:37","commitOrder":5,"curCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0, 0, CONNECTOR_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(0), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(1), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0, 0, TASK_CONFIG_KEYS.get(1),\n                        CONFIGS_SERIALIZED.get(2), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0, 0, CONNECTOR_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(3), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0, 0, TARGET_STATE_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(4), new RecordHeaders(), Optional.empty()),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0),\n                        CONFIGS_SERIALIZED.get(5), new RecordHeaders(), Optional.empty()));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","date":"2021-04-15 05:38:37","endLine":779,"groupId":"105119","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreConnectorDeletion","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d3/960e5bf46cfc52378c8a48bddd68139fff7cd7.src","preCode":"    public void testRestoreConnectorDeletion() throws Exception {\n        \r\n        \r\n\n        expectConfigure();\n        \r\n        List<ConsumerRecord<String, byte[]>> existingRecords = Arrays.asList(\n                new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(0)),\n                new ConsumerRecord<>(TOPIC, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(1)),\n                new ConsumerRecord<>(TOPIC, 0, 2, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TASK_CONFIG_KEYS.get(1), CONFIGS_SERIALIZED.get(2)),\n                new ConsumerRecord<>(TOPIC, 0, 3, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, CONNECTOR_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(3)),\n                new ConsumerRecord<>(TOPIC, 0, 4, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TARGET_STATE_KEYS.get(0), CONFIGS_SERIALIZED.get(4)),\n                new ConsumerRecord<>(TOPIC, 0, 5, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, COMMIT_TASKS_CONFIG_KEYS.get(0), CONFIGS_SERIALIZED.get(5)));\n\n        LinkedHashMap<byte[], Struct> deserialized = new LinkedHashMap<>();\n        deserialized.put(CONFIGS_SERIALIZED.get(0), CONNECTOR_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(1), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(2), TASK_CONFIG_STRUCTS.get(0));\n        deserialized.put(CONFIGS_SERIALIZED.get(3), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(4), null);\n        deserialized.put(CONFIGS_SERIALIZED.get(5), TASKS_COMMIT_STRUCT_TWO_TASK_CONNECTOR);\n\n        logOffset = 6;\n        expectStart(existingRecords, deserialized);\n        expectPartitionCount(1);\n\n        \r\n\n        expectStop();\n\n        PowerMock.replayAll();\n\n        configStorage.setupAndCreateKafkaBasedLog(TOPIC, DEFAULT_DISTRIBUTED_CONFIG);\n        configStorage.start();\n\n        \r\n        ClusterConfigState configState = configStorage.snapshot();\n        assertEquals(6, configState.offset()); \r\n        assertTrue(configState.connectors().isEmpty());\n\n        configStorage.stop();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaConfigBackingStoreTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":730,"status":"M"}],"commitId":"89933f21f204abf75336464d3ac24a4fdd254628","commitMessage":"@@@KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)\n\nThe methods have been deprecated since 0.11 without replacement since\nmessage format 2 moved the checksum to the record batch (instead of the\nrecord).\n\nUnfortunately.  we did not deprecate the constructors that take a checksum\n(even though we intended to) so we cannot remove them. I have deprecated\nthem for removal in 4.0 and added a single non deprecated constructor to\n`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.\n`ConsumerRecord` could do with one additional convenience constructor.  but\nthat requires a KIP and hence should be done separately.\n\nAlso:\n* Removed `ChecksumMessageFormatter`.  which is technically not public\nAPI.  but may have been used with the console consumer.\n* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructors\nto use the non deprecated ones.\n* Added tests for deprecated `ConsumerRecord/`RecordMetadata`\nconstructors.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  David Jacot <djacot@confluent.io>","date":"2021-04-15 05:38:37","modifiedFileCount":"47","status":"M","submitter":"Ismael Juma"}]
