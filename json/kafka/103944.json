[{"authorTime":"2017-06-07 23:14:09","codes":[{"authorDate":"2017-06-07 23:14:09","commitOrder":8,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2017-06-07 23:36:57","endLine":1170,"groupId":"8223","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ca/d17bced5c9ddb754d16670dd8e3698ef961dee.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1138,"status":"MB"},{"authorDate":"2017-06-07 23:14:09","commitOrder":8,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2017-06-07 23:36:57","endLine":1209,"groupId":"8223","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ca/d17bced5c9ddb754d16670dd8e3698ef961dee.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1173,"status":"B"}],"commitId":"dcbdce31ba525771016be5be4abc4a2067e0890b","commitMessage":"@@@KAFKA-5378; Return LSO in FetchResponse plus some metrics\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3248 from hachikuji/KAFKA-5378\n","date":"2017-06-07 23:36:57","modifiedFileCount":"7","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-07-21 08:31:24","codes":[{"authorDate":"2017-07-21 08:31:24","commitOrder":9,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2017-07-21 08:38:30","endLine":1171,"groupId":"3888","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1139,"status":"M"},{"authorDate":"2017-07-21 08:31:24","commitOrder":9,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2017-07-21 08:38:30","endLine":1210,"groupId":"3888","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp1 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp1, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp1, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1174,"status":"M"}],"commitId":"5bb53e034e4f8a06550dd06377fae7b3c2137ce2","commitMessage":"@@@KAFKA-5534; KafkaConsumer `offsetForTimes` result should include partitions with no offset\n\nFor topics that support timestamp search.  if no offset is found for a partition.  the partition should still be included in the result with a `null` offset value. This `KafkaConsumer` method currently excludes such partitions from the result.\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3460 from vahidhashemian/KAFKA-5534\n","date":"2017-07-21 08:38:30","modifiedFileCount":"2","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2018-01-15 08:18:39","codes":[{"authorDate":"2018-01-15 08:18:39","commitOrder":10,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-01-15 08:18:39","endLine":1204,"groupId":"3888","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/26/d7a50cf60391acf8be63d7d70dcdd445f33b20.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1169,"status":"M"},{"authorDate":"2018-01-15 08:18:39","commitOrder":10,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n        MetricName partitionLagMetricDeprecated = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        KafkaMetric partitionLagDeprecated = allMetrics.get(partitionLagMetricDeprecated);\n        assertEquals(50, partitionLagDeprecated.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n        assertFalse(allMetrics.containsKey(partitionLagMetricDeprecated));\n    }\n","date":"2018-01-15 08:18:39","endLine":1252,"groupId":"10952","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/26/d7a50cf60391acf8be63d7d70dcdd445f33b20.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        MetricName partitionLagMetric = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1207,"status":"M"}],"commitId":"5d81639907869ce7355c40d2bac176a655e52074","commitMessage":"@@@KAFKA-5890; records.lag should use tags for topic and partition rather than using metric name.\n\nThis is the implementation of KIP-225.\nIt marks the previous metrics as deprecated in the documentation and adds new metrics using tags.\n\nTesting verifies that both the new and the old metric report the same value.\n\nAuthor: cmolter <cmolter@apple.com>\n\nReviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>\n\nCloses #4362 from lahabana/kafka-5890\n","date":"2018-01-15 08:18:39","modifiedFileCount":"3","status":"M","submitter":"cmolter"},{"authorTime":"2018-06-12 14:32:30","codes":[{"authorDate":"2018-01-15 08:18:39","commitOrder":11,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-01-15 08:18:39","endLine":1204,"groupId":"3888","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/26/d7a50cf60391acf8be63d7d70dcdd445f33b20.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1169,"status":"N"},{"authorDate":"2018-06-12 14:32:30","commitOrder":11,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-06-12 14:32:30","endLine":1558,"groupId":"3888","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/46/666ca536e4e258dfdeafc383381f08f4b30049.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n        MetricName partitionLagMetricDeprecated = metrics.metricName(tp0 + \".records-lag\", metricGroup);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        KafkaMetric partitionLagDeprecated = allMetrics.get(partitionLagMetricDeprecated);\n        assertEquals(50, partitionLagDeprecated.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n        assertFalse(allMetrics.containsKey(partitionLagMetricDeprecated));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1518,"status":"M"}],"commitId":"4580d9f16aabc44f3d97931c6bfa29de1e40bf2d","commitMessage":"@@@MINOR: Remove deprecated per-partition lag metrics\n\nIt takes O(n^2) time to instantiate a mbean with n attributes which can be very slow if the number of attributes of this mbean is large. This PR removes metrics whose number of attributes can grow with the number of partitions in the cluster to fix the performance issue. These metrics have already been marked for removal in 2.0 by KIP-225.\n\nAuthor: Dong Lin <lindong28@gmail.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>\n\nCloses #5172 from lindong28/remove-deprecated-metrics\n","date":"2018-06-12 14:32:30","modifiedFileCount":"3","status":"M","submitter":"Dong Lin"},{"authorTime":"2018-09-13 02:05:19","codes":[{"authorDate":"2018-09-13 02:05:19","commitOrder":12,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-09-13 02:05:19","endLine":1623,"groupId":"17325","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/d61b9e0724bc4ed612c29434b75cfb16dd46f6.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(197, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1588,"status":"M"},{"authorDate":"2018-09-13 02:05:19","commitOrder":12,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-09-13 02:05:19","endLine":1705,"groupId":"14150","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/d61b9e0724bc4ed612c29434b75cfb16dd46f6.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, recordsFetchLagMax.value(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, recordsFetchLagMax.value(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, partitionLag.value(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, recordsFetchLagMax.value(), EPSILON);\n        assertEquals(147, partitionLag.value(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1665,"status":"M"}],"commitId":"c121f4eb82da654acbdd133a556cfe1f9197a46a","commitMessage":"@@@MINOR: Remove deprecated Metric.value() method usage (#5626)\n\nReviewers: Viktor Somogyi <viktorsomogyi@gmail.com>.  John Roesler <john@confluent.io>.  Rajini Sivaram <rajinisivaram@googlemail.com>\n","date":"2018-09-13 02:05:19","modifiedFileCount":"7","status":"M","submitter":"Manikumar Reddy O"},{"authorTime":"2018-11-21 07:54:24","codes":[{"authorDate":"2018-11-21 07:54:24","commitOrder":13,"curCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-11-21 07:54:24","endLine":1625,"groupId":"17777","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/52/b78e3de626ec00f3d3488cac6b169c5908ed53.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1590,"status":"M"},{"authorDate":"2018-11-21 07:54:24","commitOrder":13,"curCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2018-11-21 07:54:24","endLine":1707,"groupId":"17777","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/52/b78e3de626ec00f3d3488cac6b169c5908ed53.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NEGATIVE_INFINITY, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1667,"status":"M"}],"commitId":"068ab9cefae301f3187ea885d645c425955e77d2","commitMessage":"@@@KAFKA-7528: Standardize on Min/Avg/Max Kafka metrics' default value - NaN (#5908)\n\nWhile metrics like Min.  Avg and Max make sense to respective use Double.MAX_VALUE.  0.0 and Double.MIN_VALUE as default values to ease computation logic.  exposing those values makes reading them a bit misleading. For instance.  how would you differentiate whether your -avg metric has a value of 0 because it was given samples of 0 or no samples were fed to it?\n\nIt makes sense to standardize on the output of these metrics with something that clearly denotes that no values have been recorded.\n\nReviewers: Bill Bejeck <bill@confluent.io>.  John Roesler <john@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-11-21 07:54:24","modifiedFileCount":"10","status":"M","submitter":"Stanislav Kozlovski"},{"authorTime":"2019-03-08 08:29:19","codes":[{"authorDate":"2019-03-08 08:29:19","commitOrder":14,"curCode":"    public void testFetcherMetrics() {\n        buildFetcher();\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2019-03-08 08:29:19","endLine":1829,"groupId":"17777","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testFetcherMetrics() {\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1793,"status":"M"},{"authorDate":"2019-03-08 08:29:19","commitOrder":14,"curCode":"    public void testReadCommittedLagMetric() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2019-03-08 08:29:19","endLine":1912,"groupId":"17777","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testReadCommittedLagMetric() {\n        Metrics metrics = new Metrics();\n        fetcher = createFetcher(subscriptions, metrics, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        subscriptions.assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1873,"status":"M"}],"commitId":"460e46c3bb76a361d0706b263c03696005e12566","commitMessage":"@@@KAFKA-7831; Do not modify subscription state from background thread (#6221)\n\nMetadata may be updated from the background thread.  so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally.  it improves the following:\n\n1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription.  so this simplifies the logic.\n2. The metadata needs for the producer and consumer are quite different.  so it made sense to separate the custom logic into separate extensions of Metadata. For example.  only the producer requires topic expiration.\n3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.\n4. This patch removes the MetadataListener.  which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. \n\nReviewers: David Arthur <mumrah@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-03-08 08:29:19","modifiedFileCount":"30","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2019-04-12 02:55:14","codes":[{"authorDate":"2019-04-12 02:55:14","commitOrder":15,"curCode":"    public void testFetcherMetrics() {\n        buildFetcher();\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        fetcher.sendFetches();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2019-04-12 02:55:14","endLine":1830,"groupId":"103944","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetcherMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/a467f40d3e52a25b0cfa65d5c4458407be777d.src","preCode":"    public void testFetcherMetrics() {\n        buildFetcher();\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 0);\n        assertEquals(100, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(100, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 0);\n        assertEquals(197, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(197, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1793,"status":"M"},{"authorDate":"2019-04-12 02:55:14","commitOrder":15,"curCode":"    public void testReadCommittedLagMetric() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        fetcher.sendFetches();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","date":"2019-04-12 02:55:14","endLine":1915,"groupId":"103944","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testReadCommittedLagMetric","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/a467f40d3e52a25b0cfa65d5c4458407be777d.src","preCode":"    public void testReadCommittedLagMetric() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n\n        assignFromUser(singleton(tp0));\n        subscriptions.seek(tp0, 0);\n\n        MetricName maxLagMetric = metrics.metricInstance(metricsRegistry.recordsLagMax);\n\n        Map<String, String> tags = new HashMap<>();\n        tags.put(\"topic\", tp0.topic());\n        tags.put(\"partition\", String.valueOf(tp0.partition()));\n        MetricName partitionLagMetric = metrics.metricName(\"records-lag\", metricGroup, tags);\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric recordsFetchLagMax = allMetrics.get(maxLagMetric);\n\n        \r\n        assertEquals(Double.NaN, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        \r\n        fetchRecords(tp0, MemoryRecords.EMPTY, Errors.NONE, 100L, 50L, 0);\n        assertEquals(50, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n\n        KafkaMetric partitionLag = allMetrics.get(partitionLagMetric);\n        assertEquals(50, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                TimestampType.CREATE_TIME, 0L);\n        for (int v = 0; v < 3; v++)\n            builder.appendWithOffset(v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n        fetchRecords(tp0, builder.build(), Errors.NONE, 200L, 150L, 0);\n        assertEquals(147, (Double) recordsFetchLagMax.metricValue(), EPSILON);\n        assertEquals(147, (Double) partitionLag.metricValue(), EPSILON);\n\n        \r\n        subscriptions.unsubscribe();\n        assertFalse(allMetrics.containsKey(partitionLagMetric));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1875,"status":"M"}],"commitId":"02221bd907a23041c95ce6446986bff631652b3a","commitMessage":"@@@MINOR: Remove SubscriptionState.Listener and replace with assignmentId tracking (#6559)\n\nWe have not had great experience with listeners. They make the code harder to understand because they result in indirectly maintained circular dependencies. Often this leads to tricky deadlocks when we try to introduce locking. We were able to remove the Metadata listener in KAFKA-7831. Here we do the same for the listener in SubscriptionState.\n\nReviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-04-12 02:55:14","modifiedFileCount":"4","status":"M","submitter":"Jason Gustafson"}]
