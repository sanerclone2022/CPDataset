[{"authorTime":"2020-06-17 07:30:37","codes":[{"authorDate":"2020-06-17 07:30:37","commitOrder":1,"curCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":1828,"groupId":"12463","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendCreatedTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/2cf7ad49579eca5116e2c0b5cc8057c76a3bcb.src","preCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1822,"status":"B"},{"authorDate":"2020-06-17 07:30:37","commitOrder":1,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":1838,"groupId":"12463","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/2cf7ad49579eca5116e2c0b5cc8057c76a3bcb.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1831,"status":"B"}],"commitId":"2239004907b29e00811fee9ded5a790172701a03","commitMessage":"@@@KAFKA-10150: task state transitions/management and committing cleanup (#8856)\n\n* KAFKA-10150: always transition to SUSPENDED during suspend.  no matter the current state only call prepareCommit before closing if task.commitNeeded is true\n\n* Don't commit any consumed offsets during handleAssignment -- revoked active tasks (and any others that need committing) will be committed during handleRevocation so we only need to worry about cleaning them up in handleAssignment\n\n* KAFKA-10152: when recycling a task we should always commit consumed offsets (if any).  but don't need to write the checkpoint (since changelog offsets are preserved across task transitions)\n\n* Make sure we close all tasks during shutdown.  even if an exception is thrown during commit\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-06-17 07:30:37","modifiedFileCount":"7","status":"B","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-08-12 11:21:41","codes":[{"authorDate":"2020-06-17 07:30:37","commitOrder":2,"curCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":1828,"groupId":"12463","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendCreatedTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/2cf7ad49579eca5116e2c0b5cc8057c76a3bcb.src","preCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1822,"status":"N"},{"authorDate":"2020-08-12 11:21:41","commitOrder":2,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-08-12 11:21:41","endLine":1964,"groupId":"12463","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/4fa234888eda5e4dcdafaea518f24786462f03.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1956,"status":"M"}],"commitId":"7915d5e5f826a71c11e1c9183c84702410f7209a","commitMessage":"@@@KAFKA-9450: Decouple flushing state from commiting (#8964)\n\nIn Kafka Streams the source-of-truth of a state store is in its changelog.  therefore when committing a state store we only need to make sure its changelog records are all flushed and committed.  but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.\n\nOn the other hand.  flushing a state store too frequently may have side effects.  e.g. rocksDB flushing would gets the memtable into an L0 sstable.  leaving many small L0 files to be compacted later.  which introduces larger overhead.\n\nTherefore this PR decouples flushing from committing.  such that we do not always flush the state store upon committing.  but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled.  then it is fine if the local persisted state is actually ahead of the checkpoint.  b) if EOS is enabled.  then we would never write a checkpoint file until close.\n\nHere's a more detailed change list of this PR:\n\n1. Do not always flush state stores when calling pre-commit; move stateMgr.flush into post-commit to couple together with checkpointing.\n\n2. In post-commit.  we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint.  b) When the task is being closed.  in which case we enforce checkpointing.\n\n3. There are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer.  we still need to flush them in pre-commit to make sure all records sent via producers.  while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.\n\nI've also made some minor changes piggy-backed in this PR:\n\n4. Do not delete checkpoint file upon loading it.  and as a result simplify the checkpointNeeded logic.  initializing the snapshotLastFlush to the loaded offsets.\n\n5. In closing.  also follow the commit -> suspend -> close ordering as in revocation / assignment.\n\n6. If enforceCheckpoint == true during RUNNING.  still calls maybeCheckpoint even with EOS since that is the case for suspending / closing.\n\nReviewers: John Roesler <john@confluent.io>.  A. Sophie Blee-Goldman <sophie@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2020-08-12 11:21:41","modifiedFileCount":"24","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2021-01-07 06:01:02","codes":[{"authorDate":"2021-01-07 06:01:02","commitOrder":3,"curCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(\"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2021-01-07 06:01:02","endLine":2093,"groupId":"102073","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendCreatedTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/b67d9f5e37d8b8b82948e5ddba15ceacb74034.src","preCode":"    public void shouldAlwaysSuspendCreatedTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        assertThat(task.state(), equalTo(CREATED));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2087,"status":"M"},{"authorDate":"2021-01-07 06:01:02","commitOrder":3,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(\"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2021-01-07 06:01:02","endLine":2104,"groupId":"102073","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/b67d9f5e37d8b8b82948e5ddba15ceacb74034.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2096,"status":"M"}],"commitId":"22e8e71156762b40ac93e2cbd42eacba00dbfb0c","commitMessage":"@@@KAFKA-9274: Fix commit-TimeoutException handling for EOS (#9800)\n\nIf EOS is enabled and the TX commit fails with a timeout. \nwe should not process more messages (what is ok for non-EOS)\nbecause we don't really know the status of the TX.\nIf the commit was indeed successful.  we won't have an open TX\ncan calling send() would fail with an fatal error.\n\nInstead.  we should retry the (idempotent) commit of the TX. \nand start a new TX afterwards.\n\nReviewers: Boyang Chen <boyang@confluent.io>.  John Roesler <john@confluent.io>","date":"2021-01-07 06:01:02","modifiedFileCount":"2","status":"M","submitter":"Matthias J. Sax"}]
