[{"authorTime":"2019-03-01 01:33:53","codes":[{"authorDate":"2019-03-01 01:33:53","commitOrder":1,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":100,"groupId":"8233","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/46/31601b12a9f2cb85a39ee8fbce6853ddba1716.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"B"},{"authorDate":"2019-03-01 01:33:53","commitOrder":1,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":102,"groupId":"8233","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/40e672399f6c7d94c561537aa14ce403cd9684.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"B"}],"commitId":"3c46b5669de856f4510b8d291a8af7dbd809c07b","commitMessage":"@@@MINOR: Remove types from caching stores (#6331)\n\n* MINOR: remove types from caching stores\n\n* Github comments and rebased\n","date":"2019-03-01 01:33:53","modifiedFileCount":"32","status":"B","submitter":"Matthias J. Sax"},{"authorTime":"2019-03-09 01:30:00","codes":[{"authorDate":"2019-03-01 01:33:53","commitOrder":2,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":100,"groupId":"8233","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/46/31601b12a9f2cb85a39ee8fbce6853ddba1716.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"N"},{"authorDate":"2019-03-09 01:30:00","commitOrder":2,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-09 01:30:00","endLine":98,"groupId":"8233","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/1b210b4ad746e7b3e66bf7ec6f8499a5ff12fc.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"04e206154ac614b7d4d34a7a1b6ba2c882f607b9","commitMessage":"@@@KAFKA-3522: Add TimestampedWindowStore builder/runtime classes (#6173)\n\nAdd TimestampedWindowStore builder/runtime classes\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Matthias J. Sax <mjsax@apache.org>.   John Roesler <john@confluent.io>.   Bill Bejeck <bbejeck@gmail.com>","date":"2019-03-09 01:30:00","modifiedFileCount":"8","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-03-09 01:30:00","codes":[{"authorDate":"2019-04-21 02:30:20","commitOrder":3,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        final Serde<K> usedKeySerde;\n        final Serde<V> usedValueSerde;\n        final Map<String, Object> conf = context.appConfigs();\n        if (keySerde == null) {\n            usedKeySerde = (Serde<K>) context.keySerde();\n        } else {\n            usedKeySerde = keySerde;\n            usedKeySerde.configure(conf, true);\n        }\n        if (valueSerde == null) {\n            usedValueSerde = (Serde<V>) context.valueSerde();\n        } else {\n            usedValueSerde = valueSerde;\n            usedValueSerde.configure(conf, false);\n        }\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()), usedKeySerde, usedValueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-04-21 02:30:20","endLine":113,"groupId":"8233","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1a/55490d35f521d38de42e29655b31ea9bc5d5d3.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"M"},{"authorDate":"2019-03-09 01:30:00","commitOrder":3,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-09 01:30:00","endLine":98,"groupId":"8233","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/1b210b4ad746e7b3e66bf7ec6f8499a5ff12fc.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"N"}],"commitId":"e56ebbffca57741d398283e46073ed4170f8f927","commitMessage":"@@@[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>","date":"2019-04-21 02:30:20","modifiedFileCount":"11","status":"M","submitter":"Ted Yu"},{"authorTime":"2019-03-09 01:30:00","codes":[{"authorDate":"2019-05-01 15:33:53","commitOrder":4,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-05-01 15:33:53","endLine":100,"groupId":"8233","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/94/b004e330e75d310eaa3d77851b85ef47426797.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        final Serde<K> usedKeySerde;\n        final Serde<V> usedValueSerde;\n        final Map<String, Object> conf = context.appConfigs();\n        if (keySerde == null) {\n            usedKeySerde = (Serde<K>) context.keySerde();\n        } else {\n            usedKeySerde = keySerde;\n            usedKeySerde.configure(conf, true);\n        }\n        if (valueSerde == null) {\n            usedValueSerde = (Serde<V>) context.valueSerde();\n        } else {\n            usedValueSerde = valueSerde;\n            usedValueSerde.configure(conf, false);\n        }\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()), usedKeySerde, usedValueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"M"},{"authorDate":"2019-03-09 01:30:00","commitOrder":4,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-09 01:30:00","endLine":98,"groupId":"8233","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/1b210b4ad746e7b3e66bf7ec6f8499a5ff12fc.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"N"}],"commitId":"56c64803fa190814232c5f71e9a758346c474bb4","commitMessage":"@@@KAFKA-3729: Revert adding Serde auto-config (#6630)\n\n* Revert \"MINOR: Add unit test for SerDe auto-configuration (#6610)\"\n\nThis reverts commit 172fbb2dd55144e2e44777174f970b56768e1777.\n\n* Revert \"[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)\"\n\nThis reverts commit e56ebbffca57741d398283e46073ed4170f8f927.\n\nThe two merged PRs introduce a breaking change. Reverting to preserve backward compatibility. Jira ticket reopened.\n\nReviewers: Ted Yu <yuzhihong@gmail.com>.  Guozhang Wang <guozhang@confluent.io>","date":"2019-05-01 15:33:53","modifiedFileCount":"14","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-08-30 21:46:07","codes":[{"authorDate":"2019-08-30 21:46:07","commitOrder":5,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-08-30 21:46:07","endLine":101,"groupId":"11994","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/09/030c23ce4601bb3aeac3785038386204ed08b3.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":70,"status":"M"},{"authorDate":"2019-08-30 21:46:07","commitOrder":5,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-08-30 21:46:07","endLine":101,"groupId":"11994","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ac/86679169af1627af2966cab5fed8ecfd5b5201.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"M"}],"commitId":"d18d6b033e09515adff19225f8ec6845ca34c23b","commitMessage":"@@@MINOR: Refactor tag key for store level metrics (#7257)\n\nThe tag key for store level metrics specified in StreamsMetricsImpl\nis unified with the tag keys on thread and task level.\n\nReviewers: Sophie Blee-Goldman <sophie@confluent.io>.  Bill Bejeck <bbejeck@gmail.com>","date":"2019-08-30 21:46:07","modifiedFileCount":"16","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2019-10-05 08:07:30","codes":[{"authorDate":"2019-10-05 08:07:30","commitOrder":6,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"remove\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-10-05 08:07:30","endLine":155,"groupId":"4761","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/eb/d3bbe93021945ae68c09d100f6815c83b657ce.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"remove\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"M"},{"authorDate":"2019-10-05 08:07:30","commitOrder":6,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-10-05 08:07:30","endLine":145,"groupId":"4761","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/14/9f9f807819b193570f155e001796e0616daf76.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"}],"commitId":"52007e878aaac3f48d0d949dbe428a2ae5e56f57","commitMessage":"@@@KAFKA-8934: Introduce instance-level metrics for streams applications (#7416)\n\n1. Moves StreamsMetricsImpl from StreamThread to KafkaStreams\n2. Adds instance-level metrics as specified in KIP-444.  i.e.:\n-- version\n-- commit-id\n-- application-id\n-- topology-description\n-- state\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  John Roesler <john@confluent.io>.  Bill Bejeck <bbejeck@gmail.com>","date":"2019-10-05 08:07:30","modifiedFileCount":"65","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2019-10-31 00:24:59","codes":[{"authorDate":"2019-10-31 00:24:59","commitOrder":7,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2019-10-31 00:24:59","endLine":89,"groupId":"12418","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/17/8704fb5108376a23a2365a7d745e397a16f718.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        \r\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        removeTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"remove\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":70,"status":"M"},{"authorDate":"2019-10-31 00:24:59","commitOrder":7,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2019-10-31 00:24:59","endLine":86,"groupId":"12418","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/27/683f222bba731a65d3d3ab67c4bf0c71fe215f.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"fc0f82372e1e456cbd43490b9eba957c4a0d3eb5","commitMessage":"@@@KAFKA-8980: Refactor state-store-level streams metrics (#7584)\n\nRefactors metrics according to KIP-444\nIntroduces StateStoreMetrics as a central provider for state store metrics\nAdds metric scope (a.k.a. store type) to the in-memory suppression buffer\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.   Bill Bejeck <bbejeck@gmail.com>","date":"2019-10-31 00:24:59","modifiedFileCount":"26","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2019-10-31 00:24:59","codes":[{"authorDate":"2020-07-10 02:50:31","commitOrder":8,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-07-10 02:50:31","endLine":85,"groupId":"12418","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/97/6ca5ecc0fbee29edfad9ada5d2def2a7ca2db8.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":70,"status":"M"},{"authorDate":"2019-10-31 00:24:59","commitOrder":8,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2019-10-31 00:24:59","endLine":86,"groupId":"12418","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/27/683f222bba731a65d3d3ab67c4bf0c71fe215f.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"N"}],"commitId":"813f92c21ad4bd7ffdd8acc66c20d31927e7a67f","commitMessage":"@@@KAFKA-10179: Pass correct changelog topic to state serdes (#8902)\n\nUntil now we always passed the default changelog topic name\nto the state serdes. However.  for optimized source tables\nand global tables the changelog topic is the source topic.\n\nMost serdes do not use the topic name passed to them.\nHowever.  if the serdes actually use the topic name for\n(de)serialization a\norg.apache.kafka.common.errors.SerializationException is thrown.\n\nThis commits passed the correct changelog topic to the state\nserdes of the metered state stores.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  John Roesler <vvcephei@apache.org>","date":"2020-07-10 02:50:31","modifiedFileCount":"30","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-08-25 08:37:49","codes":[{"authorDate":"2020-08-25 08:37:49","commitOrder":9,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-25 08:37:49","endLine":89,"groupId":"12418","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/22/559e86437edc7871ef0cb2e7c3ab1565c3ff1a.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"M"},{"authorDate":"2020-08-25 08:37:49","commitOrder":9,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-25 08:37:49","endLine":89,"groupId":"12418","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/11/89af967dd2f086d5874a60589c58cca6e9e5ba.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"22bcd9fac3c988c15862d0b6c01930814b676253","commitMessage":"@@@KAFKA-10054: KIP-613.  add TRACE-level e2e latency metrics (#9094)\n\nAdds avg.  min.  and max e2e latency metrics at the new TRACE level. Also adds the missing avg task-level metric at the INFO level.\n\nI think where we left off with the KIP.  the TRACE-level metrics were still defined to be \"stateful-processor-level\". I realized this doesn't really make sense and would be pretty much impossible to define given the DFS processing approach of Streams.  and felt that store-level metrics made more sense to begin with. I haven't updated the KIP yet so I could get some initial feedback on this\n\nReviewers: Bruno Cadonna <bruno@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-08-25 08:37:49","modifiedFileCount":"18","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-08-28 07:04:28","codes":[{"authorDate":"2020-08-28 07:04:28","commitOrder":10,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-28 07:04:28","endLine":89,"groupId":"12418","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d8/ce02a6d18bb42a63f9a4ef868ca5f141873685.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"M"},{"authorDate":"2020-08-28 07:04:28","commitOrder":10,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-28 07:04:28","endLine":89,"groupId":"12418","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a1/b4b954a8596d5e693824c06a6a885e91e2ff6e.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"9da32b6bd014f1bdeeee5da8fcd00995a5916323","commitMessage":"@@@KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)\n\n* Add the first RocksDB metric that exposes a RocksDB property: num-entries-active-mem-table.\n* Add code StreamsMetricsImpl in support of exposing RocksDB properties\n* unit tests and intergration tests\n\nThis commit only contains one metric to keep the PR at a reasonable size.\nAll other RocksDB metrics described in KIP-607 will be added in other PRs.\n\nImplements: KIP-607\nReviewers: Guozhang Wang <guozhang@apache.org>.  John Roesler <vvcephei@apache.org>","date":"2020-08-28 07:04:28","modifiedFileCount":"22","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-10-08 12:06:53","codes":[{"authorDate":"2020-10-08 12:06:53","commitOrder":11,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-10-08 12:06:53","endLine":88,"groupId":"12417","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8b/9256dc5d91ba2a8349ce9ab4852a0579b5e9c2.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        removeSensor = StateStoreMetrics.removeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"M"},{"authorDate":"2020-10-08 12:06:53","commitOrder":11,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-10-08 12:06:53","endLine":89,"groupId":"19018","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d4/7233b3b2251bfe329887a145853ae3232ea6da.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"}],"commitId":"2804257fe221f37e5098bd3f633a5d76ca890634","commitMessage":"@@@KAFKA-10562: Properly invoke new StateStoreContext init (#9388)\n\n* all wrapping stores should pass StateStoreContext init through to the same\n  method on the wrapped store and not translate it to ProcessorContext init\n* base-level stores should handle StateStoreContext init so that callers passing\n  a non-InternalProcessorContext implementation will be able to initialize the store\n* extra tests are added to verify the desired behavior\n\nReviewers: Guozhang Wang <guozhang@apache.org>","date":"2020-10-08 12:06:53","modifiedFileCount":"71","status":"M","submitter":"John Roesler"},{"authorTime":"2021-06-01 20:05:08","codes":[{"authorDate":"2021-06-01 20:05:08","commitOrder":12,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-06-01 20:05:08","endLine":89,"groupId":"12470","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/96/448882777262efba4e33e6eaeee6612a0b1a87.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"},{"authorDate":"2021-06-01 20:05:08","commitOrder":12,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-06-01 20:05:08","endLine":95,"groupId":"14042","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0e/ecb7fa1b1dccb90f501f6b9501f500f41771a7.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"cfe642edee80977173279f4a41e23aa822b9d19f","commitMessage":"@@@KAFKA-12519: Remove built-in Streams metrics for versions 0.10.0-2.4 (#10765)\n\nAs specified in KIP-743.  this PR removes the built-in metrics\nin Streams that are superseded by the refactoring proposed in KIP-444.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Luke Chen <showuon@gmail.com>","date":"2021-06-01 20:05:08","modifiedFileCount":"73","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2021-07-29 02:18:56","codes":[{"authorDate":"2021-07-29 02:18:56","commitOrder":13,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId.toString(), metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-07-29 02:18:56","endLine":92,"groupId":"122855","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/74/6ec85fc26a04e44a7a3fa4e52ee6ca9de2414e.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        taskId = context.taskId().toString();\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredSessionStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":79,"status":"M"},{"authorDate":"2021-07-29 02:18:56","commitOrder":13,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId.toString(), metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-07-29 02:18:56","endLine":95,"groupId":"122855","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/bc/64db8214803faf6767abe026641366405e5f45.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"4710a491463a91ec12c670ea50c139fc14134e80","commitMessage":"@@@KAFKA-12648: Pt. 2 - Introduce TopologyMetadata to wrap InternalTopologyBuilders of named topologies (#10683)\n\nPt. 1: #10609\nPt. 2: #10683\nPt. 3: #10788\n\nThe TopologyMetadata is next up after Pt. 1 #10609. This PR sets up the basic architecture for running an app with multiple NamedTopologies.  though the APIs to add/remove them dynamically are not implemented until Pt. 3\n\nReviewers: Guozhang Wang <guozhang@confluent.io>.  Walker Carlson <wcarlson@confluent.io>","date":"2021-07-29 02:18:56","modifiedFileCount":"56","status":"M","submitter":"A. Sophie Blee-Goldman"}]
