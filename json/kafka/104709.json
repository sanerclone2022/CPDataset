[{"authorTime":"2018-05-31 02:39:45","codes":[{"authorDate":"2018-05-31 02:39:45","commitOrder":1,"curCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-05-31 02:39:45","endLine":105,"groupId":"19532","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDLQConfigWithValidTopicName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f6/a0507909c55fe1f040105afa72aeec94cc5588.src","preCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":92,"status":"B"},{"authorDate":"2018-05-31 02:39:45","commitOrder":1,"curCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-05-31 02:39:45","endLine":122,"groupId":"19532","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testReportDLQTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f6/a0507909c55fe1f040105afa72aeec94cc5588.src","preCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":108,"status":"B"}],"commitId":"f8dfbb067caa797c19494e12da6b4c6786980f73","commitMessage":"@@@KAFKA-6738: Implement error handling for source and sink tasks (KIP-298)\n\nThis PR implements the features described in this KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-298%3A+Error+Handling+in+Connect\n\nThis PR changes the Connect framework to allow it to automatically deal with errors encountered while processing records in a Connector. The following behavior changes are introduced here:\n\n**Retry on Failure**: Retry the failed operation a configurable number of times.  with backoff between each retry.\n**Task Tolerance Limits**: Tolerate a configurable number of failures in a task.\n\nWe also add the following ways to report errors.  along with sufficient context to simplify the debugging process:\n\n**Log Error Context**: The error information along with processing context is logged along with standard application logs.\n**Dead Letter Queue**: Produce the original message into a Kafka topic (applicable only to sink connectors).\n\nNew **metrics** which will monitor the number of failures.  and the behavior of the response handler are added.\n\nThe changes proposed here **are backward compatible**. The current behavior in Connect is to kill the task on the first error in any stage. This will remain the default behavior if the connector does not override any of the new configurations which are provided as part of this feature.\n\nTesting: added multiple unit tests to test the retry and tolerance logic.\n\nAuthor: Arjun Satish <arjun@confluent.io>\nAuthor: Ewen Cheslack-Postava <me@ewencp.org>\n\nReviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>.  Randall Hauch <rhauch@gmail.com>.  Konstantine Karantasis <konstantine@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5065 from wicknicks/KAFKA-6378\n","date":"2018-05-31 02:39:45","modifiedFileCount":"12","status":"B","submitter":"Arjun Satish"},{"authorTime":"2018-06-06 04:59:15","codes":[{"authorDate":"2018-06-06 04:59:15","commitOrder":2,"curCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-06-06 04:59:15","endLine":110,"groupId":"19532","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDLQConfigWithValidTopicName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b5/410d071d8a917c8420069b4f66f31655b2e575.src","preCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2018-06-06 04:59:15","commitOrder":2,"curCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-06-06 04:59:15","endLine":126,"groupId":"19532","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testReportDLQTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b5/410d071d8a917c8420069b4f66f31655b2e575.src","preCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer);\n        deadLetterQueueReporter.configure(config(DeadLetterQueueReporter.DLQ_TOPIC_NAME, DLQ_TOPIC));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"}],"commitId":"faa15b8b758ed4e3f93aaa4d49a941562bdc86bb","commitMessage":"@@@KAFKA-6981: Move the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes (KIP-298)\n\nMove the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes.  and refactor the tests and classes to use these new properties.\n\nTesting: Unit tests and running the connect-standalone script with a file sink connector.\n\nAuthor: Arjun Satish <arjun@confluent.io>\nAuthor: Randall Hauch <rhauch@gmail.com>\n\nReviewers: Konstantine Karantasis <konstantine@confluent.io>.  Magesh Nandakumar <magesh.n.kumar@gmail.com>.  Robert Yokota <rayokota@gmail.com>.  Randall Hauch <rhauch@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5125 from wicknicks/KAFKA-6981\n","date":"2018-06-06 04:59:15","modifiedFileCount":"17","status":"M","submitter":"Arjun Satish"},{"authorTime":"2018-06-12 06:16:46","codes":[{"authorDate":"2018-06-12 06:16:46","commitOrder":3,"curCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID);\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-06-12 06:16:46","endLine":125,"groupId":"19532","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testDLQConfigWithValidTopicName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f1/99982231fe841a87d79dc5ea9e2049f019f11e.src","preCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"},{"authorDate":"2018-06-12 06:16:46","commitOrder":3,"curCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID);\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-06-12 06:16:46","endLine":141,"groupId":"19532","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testReportDLQTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f1/99982231fe841a87d79dc5ea9e2049f019f11e.src","preCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)));\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":128,"status":"M"}],"commitId":"3face7fce2489715c040c9756ec05406aaa657d4","commitMessage":"@@@KAFKA-7003: Set error context in message headers (KIP-298)\n\nIf the property `errors.deadletterqueue.context.headers.enable` is set to true.  add a set of headers to the message describing the context under which the error took place.\n\nA unit test is added to check the correctness of header creation.\n\nSigned-off-by: Arjun Satish <arjunconfluent.io>\n\nAuthor: Arjun Satish <arjun@confluent.io>\n\nReviewers: Konstantine Karantasis <konstantine@confluent.io>.  Randall Hauch <rhauch@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5159 from wicknicks/KAFKA-7003\n","date":"2018-06-12 06:16:46","modifiedFileCount":"4","status":"M","submitter":"Arjun Satish"},{"authorTime":"2018-08-03 05:36:02","codes":[{"authorDate":"2018-08-03 05:36:02","commitOrder":4,"curCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(\n                producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID, errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-08-03 05:36:02","endLine":130,"groupId":"104709","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testDLQConfigWithValidTopicName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fa/628b0984080b2f61b1cafecacf0f57a982d891.src","preCode":"    public void testDLQConfigWithValidTopicName() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID);\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":118,"status":"M"},{"authorDate":"2018-08-03 05:36:02","commitOrder":4,"curCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(\n                producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID, errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","date":"2018-08-03 05:36:02","endLine":146,"groupId":"104709","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testReportDLQTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fa/628b0984080b2f61b1cafecacf0f57a982d891.src","preCode":"    public void testReportDLQTwice() {\n        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC)), TASK_ID);\n        deadLetterQueueReporter.metrics(errorHandlingMetrics);\n\n        ProcessingContext context = processingContext();\n\n        EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(metadata).times(2);\n        replay(producer);\n\n        deadLetterQueueReporter.report(context);\n        deadLetterQueueReporter.report(context);\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":133,"status":"M"}],"commitId":"70d882861e1bf3eb503c84a31834e8b628de2df9","commitMessage":"@@@KAFKA-7228: Set errorHandlingMetrics for dead letter queue\n\nDLQ reporter does not get a `errorHandlingMetrics` object when created by the worker. This results in an NPE.\n\nSigned-off-by: Arjun Satish <arjunconfluent.io>\n\n*More detailed description of your change. \nif necessary. The PR title and PR message become\nthe squashed commit message.  so use a separate\ncomment to ping reviewers.*\n\n*Summary of testing strategy (including rationale)\nfor the feature or bug fix. Unit and/or integration\ntests are expected for any behaviour change and\nsystem tests should be considered for larger changes.*\n\nAuthor: Arjun Satish <arjun@confluent.io>\n\nReviewers: Konstantine Karantasis <konstantine@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5440 from wicknicks/KAFKA-7228\n","date":"2018-08-03 05:36:02","modifiedFileCount":"6","status":"M","submitter":"Arjun Satish"}]
