[{"authorTime":"2019-03-01 01:33:53","codes":[{"authorDate":"2019-03-01 01:33:53","commitOrder":1,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":118,"groupId":"19764","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c2/1568b6c5fff37e7a2cd2c2836030d7f4489fc7.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"B"},{"authorDate":"2019-03-01 01:33:53","commitOrder":1,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":102,"groupId":"8233","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/40e672399f6c7d94c561537aa14ce403cd9684.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"B"}],"commitId":"3c46b5669de856f4510b8d291a8af7dbd809c07b","commitMessage":"@@@MINOR: Remove types from caching stores (#6331)\n\n* MINOR: remove types from caching stores\n\n* Github comments and rebased\n","date":"2019-03-01 01:33:53","modifiedFileCount":"32","status":"B","submitter":"Matthias J. Sax"},{"authorTime":"2019-03-01 01:33:53","codes":[{"authorDate":"2019-03-02 07:39:23","commitOrder":2,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","date":"2019-03-02 07:39:23","endLine":114,"groupId":"19764","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/51/da3ed1bf6021f44d4449dc7c9b57fdbebf7ef0.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"},{"authorDate":"2019-03-01 01:33:53","commitOrder":2,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-01 01:33:53","endLine":102,"groupId":"8233","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/40e672399f6c7d94c561537aa14ce403cd9684.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"N"}],"commitId":"33ba2820f4fbb459172022a83d761a7c674a8fdd","commitMessage":"@@@KAFKA-3522: Add TimestampedKeyValueStore builder/runtime classes (#6152)\n\nReviewers: John Roesler <john@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>","date":"2019-03-02 07:39:23","modifiedFileCount":"15","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-03-09 01:30:00","codes":[{"authorDate":"2019-03-02 07:39:23","commitOrder":3,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","date":"2019-03-02 07:39:23","endLine":114,"groupId":"19764","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/51/da3ed1bf6021f44d4449dc7c9b57fdbebf7ef0.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"N"},{"authorDate":"2019-03-09 01:30:00","commitOrder":3,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-03-09 01:30:00","endLine":98,"groupId":"8233","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/1b210b4ad746e7b3e66bf7ec6f8499a5ff12fc.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        serdes = new StateSerdes<>(\n            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),\n            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,\n            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"04e206154ac614b7d4d34a7a1b6ba2c882f607b9","commitMessage":"@@@KAFKA-3522: Add TimestampedWindowStore builder/runtime classes (#6173)\n\nAdd TimestampedWindowStore builder/runtime classes\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Matthias J. Sax <mjsax@apache.org>.   John Roesler <john@confluent.io>.   Bill Bejeck <bbejeck@gmail.com>","date":"2019-03-09 01:30:00","modifiedFileCount":"8","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-08-30 21:46:07","codes":[{"authorDate":"2019-08-30 21:46:07","commitOrder":4,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","date":"2019-08-30 21:46:07","endLine":115,"groupId":"19764","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/07/e171f9eb813f6e3adf93824117c01ff460b141.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"M"},{"authorDate":"2019-08-30 21:46:07","commitOrder":4,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-08-30 21:46:07","endLine":101,"groupId":"11994","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ac/86679169af1627af2966cab5fed8ecfd5b5201.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricScope + \"-metrics\";\n        final Map<String, String> taskTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", \"all\");\n        final Map<String, String> storeTags = metrics.tagMap(\"task-id\", taskName, metricScope + \"-id\", name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"M"}],"commitId":"d18d6b033e09515adff19225f8ec6845ca34c23b","commitMessage":"@@@MINOR: Refactor tag key for store level metrics (#7257)\n\nThe tag key for store level metrics specified in StreamsMetricsImpl\nis unified with the tag keys on thread and task level.\n\nReviewers: Sophie Blee-Goldman <sophie@confluent.io>.  Bill Bejeck <bbejeck@gmail.com>","date":"2019-08-30 21:46:07","modifiedFileCount":"16","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2019-10-05 08:07:30","codes":[{"authorDate":"2019-10-05 08:07:30","commitOrder":5,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put-if-absent\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put-all\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"get\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"all\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"range\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"delete\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","date":"2019-10-05 08:07:30","endLine":210,"groupId":"4761","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2f/50ba7a9022f49ac5068698594d96409b578569.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-if-absent\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put-all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"get\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"all\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"range\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"delete\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":86,"status":"M"},{"authorDate":"2019-10-05 08:07:30","commitOrder":5,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","date":"2019-10-05 08:07:30","endLine":145,"groupId":"4761","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/14/9f9f807819b193570f155e001796e0616daf76.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags = metrics.storeLevelTagMap(taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags = metrics.storeLevelTagMap(taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"put\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"fetch\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"flush\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, \"restore\", metrics, metricsGroup, taskName, name(), taskTags, storeTags);\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"}],"commitId":"52007e878aaac3f48d0d949dbe428a2ae5e56f57","commitMessage":"@@@KAFKA-8934: Introduce instance-level metrics for streams applications (#7416)\n\n1. Moves StreamsMetricsImpl from StreamThread to KafkaStreams\n2. Adds instance-level metrics as specified in KIP-444.  i.e.:\n-- version\n-- commit-id\n-- application-id\n-- topology-description\n-- state\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  John Roesler <john@confluent.io>.  Bill Bejeck <bbejeck@gmail.com>","date":"2019-10-05 08:07:30","modifiedFileCount":"65","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2019-10-31 00:24:59","codes":[{"authorDate":"2019-10-31 00:24:59","commitOrder":6,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2019-10-31 00:24:59","endLine":102,"groupId":"12418","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3d/f510b18ba9d88ee7198c13491cdb19d2a56f31.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = \"stream-\" + metricsScope + \"-state-metrics\";\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        initStoreSerde(context);\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put-if-absent\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        putAllTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put-all\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        getTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"get\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        allTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"all\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        rangeTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"range\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        deleteTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"delete\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        if (restoreTime.shouldRecord()) {\n            measureLatency(\n                () -> {\n                    super.init(context, root);\n                    return null;\n                },\n                restoreTime);\n        } else {\n            super.init(context, root);\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"M"},{"authorDate":"2019-10-31 00:24:59","commitOrder":6,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2019-10-31 00:24:59","endLine":86,"groupId":"12418","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/27/683f222bba731a65d3d3ab67c4bf0c71fe215f.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        metrics = (StreamsMetricsImpl) context.metrics();\n\n        taskName = context.taskId().toString();\n        final String metricsGroup = GROUP_PREFIX + metricsScope + STATE_LEVEL_GROUP_SUFFIX;\n        final Map<String, String> taskTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, ROLLUP_VALUE);\n        final Map<String, String> storeTags =\n            metrics.storeLevelTagMap(threadId, taskName, metricsScope, name());\n\n        putTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"put\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        fetchTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"fetch\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        flushTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"flush\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n        final Sensor restoreTime = createTaskAndStoreLatencyAndThroughputSensors(\n            DEBUG,\n            \"restore\",\n            metrics,\n            metricsGroup,\n            threadId,\n            taskName,\n            name(),\n            taskTags,\n            storeTags\n        );\n\n        \r\n        final long startNs = time.nanoseconds();\n        try {\n            super.init(context, root);\n        } finally {\n            metrics.recordLatency(\n                restoreTime,\n                startNs,\n                time.nanoseconds()\n            );\n        }\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":71,"status":"M"}],"commitId":"fc0f82372e1e456cbd43490b9eba957c4a0d3eb5","commitMessage":"@@@KAFKA-8980: Refactor state-store-level streams metrics (#7584)\n\nRefactors metrics according to KIP-444\nIntroduces StateStoreMetrics as a central provider for state store metrics\nAdds metric scope (a.k.a. store type) to the in-memory suppression buffer\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.   Bill Bejeck <bbejeck@gmail.com>","date":"2019-10-31 00:24:59","modifiedFileCount":"26","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-08-25 08:37:49","codes":[{"authorDate":"2020-08-25 08:37:49","commitOrder":7,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-25 08:37:49","endLine":108,"groupId":"12418","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d4/cd1f085839cd60cc8249fb1497d26569f8959e.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"M"},{"authorDate":"2020-08-25 08:37:49","commitOrder":7,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-25 08:37:49","endLine":89,"groupId":"12418","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/11/89af967dd2f086d5874a60589c58cca6e9e5ba.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"22bcd9fac3c988c15862d0b6c01930814b676253","commitMessage":"@@@KAFKA-10054: KIP-613.  add TRACE-level e2e latency metrics (#9094)\n\nAdds avg.  min.  and max e2e latency metrics at the new TRACE level. Also adds the missing avg task-level metric at the INFO level.\n\nI think where we left off with the KIP.  the TRACE-level metrics were still defined to be \"stateful-processor-level\". I realized this doesn't really make sense and would be pretty much impossible to define given the DFS processing approach of Streams.  and felt that store-level metrics made more sense to begin with. I haven't updated the KIP yet so I could get some initial feedback on this\n\nReviewers: Bruno Cadonna <bruno@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-08-25 08:37:49","modifiedFileCount":"18","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-08-28 07:04:28","codes":[{"authorDate":"2020-08-28 07:04:28","commitOrder":8,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-28 07:04:28","endLine":108,"groupId":"12418","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/31/e2eff5a4eb5ca76b549e464f1f5e6e5d574d79.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"M"},{"authorDate":"2020-08-28 07:04:28","commitOrder":8,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-08-28 07:04:28","endLine":89,"groupId":"12418","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a1/b4b954a8596d5e693824c06a6a885e91e2ff6e.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"M"}],"commitId":"9da32b6bd014f1bdeeee5da8fcd00995a5916323","commitMessage":"@@@KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)\n\n* Add the first RocksDB metric that exposes a RocksDB property: num-entries-active-mem-table.\n* Add code StreamsMetricsImpl in support of exposing RocksDB properties\n* unit tests and intergration tests\n\nThis commit only contains one metric to keep the PR at a reasonable size.\nAll other RocksDB metrics described in KIP-607 will be added in other PRs.\n\nImplements: KIP-607\nReviewers: Guozhang Wang <guozhang@apache.org>.  John Roesler <vvcephei@apache.org>","date":"2020-08-28 07:04:28","modifiedFileCount":"22","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-10-08 12:06:53","codes":[{"authorDate":"2020-10-08 12:06:53","commitOrder":9,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-10-08 12:06:53","endLine":103,"groupId":"12065","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/453585961b046f2a5f35092e427142ffe8e289.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putIfAbsentSensor = StateStoreMetrics.putIfAbsentSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        putAllSensor = StateStoreMetrics.putAllSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        getSensor = StateStoreMetrics.getSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        allSensor = StateStoreMetrics.allSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        rangeSensor = StateStoreMetrics.rangeSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        deleteSensor = StateStoreMetrics.deleteSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":90,"status":"M"},{"authorDate":"2020-10-08 12:06:53","commitOrder":9,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2020-10-08 12:06:53","endLine":89,"groupId":"19018","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d4/7233b3b2251bfe329887a145853ae3232ea6da.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        putSensor = StateStoreMetrics.putSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        fetchSensor = StateStoreMetrics.fetchSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        flushSensor = StateStoreMetrics.flushSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n        e2eLatencySensor = StateStoreMetrics.e2ELatencySensor(taskId, metricsScope, name(), streamsMetrics);\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"}],"commitId":"2804257fe221f37e5098bd3f633a5d76ca890634","commitMessage":"@@@KAFKA-10562: Properly invoke new StateStoreContext init (#9388)\n\n* all wrapping stores should pass StateStoreContext init through to the same\n  method on the wrapped store and not translate it to ProcessorContext init\n* base-level stores should handle StateStoreContext init so that callers passing\n  a non-InternalProcessorContext implementation will be able to initialize the store\n* extra tests are added to verify the desired behavior\n\nReviewers: Guozhang Wang <guozhang@apache.org>","date":"2020-10-08 12:06:53","modifiedFileCount":"71","status":"M","submitter":"John Roesler"},{"authorTime":"2021-06-01 20:05:08","codes":[{"authorDate":"2021-06-01 20:05:08","commitOrder":10,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-06-01 20:05:08","endLine":110,"groupId":"19912","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/32/dcc139256ff1e59aaa674286da9064ba19a7e6.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2021-06-01 20:05:08","commitOrder":10,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-06-01 20:05:08","endLine":95,"groupId":"14042","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0e/ecb7fa1b1dccb90f501f6b9501f500f41771a7.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(threadId, taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"cfe642edee80977173279f4a41e23aa822b9d19f","commitMessage":"@@@KAFKA-12519: Remove built-in Streams metrics for versions 0.10.0-2.4 (#10765)\n\nAs specified in KIP-743.  this PR removes the built-in metrics\nin Streams that are superseded by the refactoring proposed in KIP-444.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Luke Chen <showuon@gmail.com>","date":"2021-06-01 20:05:08","modifiedFileCount":"73","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2021-07-29 02:18:56","codes":[{"authorDate":"2021-07-29 02:18:56","commitOrder":11,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId.toString(), metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-07-29 02:18:56","endLine":110,"groupId":"122862","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ac/b41871cc4cd55f789d9a1f81c8102fb9468e26.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId().toString();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2021-07-29 02:18:56","commitOrder":11,"curCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        taskId = context.taskId();\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId.toString(), metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","date":"2021-07-29 02:18:56","endLine":95,"groupId":"122862","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"init","params":"(finalProcessorContextcontext@finalStateStoreroot)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/bc/64db8214803faf6767abe026641366405e5f45.src","preCode":"    public void init(final ProcessorContext context,\n                     final StateStore root) {\n        this.context = context instanceof InternalProcessorContext ? (InternalProcessorContext) context : null;\n        initStoreSerde(context);\n        streamsMetrics = (StreamsMetricsImpl) context.metrics();\n        taskId = context.taskId().toString();\n\n        registerMetrics();\n        final Sensor restoreSensor =\n            StateStoreMetrics.restoreSensor(taskId, metricsScope, name(), streamsMetrics);\n\n        \r\n        maybeMeasureLatency(() -> super.init(context, root), time, restoreSensor);\n    }\n","realPath":"streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredWindowStore.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"4710a491463a91ec12c670ea50c139fc14134e80","commitMessage":"@@@KAFKA-12648: Pt. 2 - Introduce TopologyMetadata to wrap InternalTopologyBuilders of named topologies (#10683)\n\nPt. 1: #10609\nPt. 2: #10683\nPt. 3: #10788\n\nThe TopologyMetadata is next up after Pt. 1 #10609. This PR sets up the basic architecture for running an app with multiple NamedTopologies.  though the APIs to add/remove them dynamically are not implemented until Pt. 3\n\nReviewers: Guozhang Wang <guozhang@confluent.io>.  Walker Carlson <wcarlson@confluent.io>","date":"2021-07-29 02:18:56","modifiedFileCount":"56","status":"M","submitter":"A. Sophie Blee-Goldman"}]
