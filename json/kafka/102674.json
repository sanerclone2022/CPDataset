[{"authorTime":"2019-04-27 00:30:20","codes":[{"authorDate":"2019-04-27 00:30:20","commitOrder":1,"curCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2019-04-27 00:30:20","endLine":150,"groupId":"2892","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldUseDefaultSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/f0a4121e35107bdcc7acc031405d544fa73159.src","preCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"B"},{"authorDate":"2019-04-27 00:30:20","commitOrder":1,"curCode":"    public void shouldInheritSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        \r\n        final KTable<String, Long> valueCounts = inputStream\n            .groupByKey()\n            .count();\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2019-04-27 00:30:20","endLine":203,"groupId":"2892","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldInheritSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/f0a4121e35107bdcc7acc031405d544fa73159.src","preCode":"    public void shouldInheritSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        \r\n        final KTable<String, Long> valueCounts = inputStream\n            .groupByKey()\n            .count();\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"B"}],"commitId":"eecb403bae80b82b6fb7a27bebb5b53d6c8f3115","commitMessage":"@@@KAFKA-8254: Pass Changelog as Topic in Suppress Serdes (#6602)\n\nReviewers:  Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-04-27 00:30:20","modifiedFileCount":"15","status":"B","submitter":"John Roesler"},{"authorTime":"2020-04-30 06:11:49","codes":[{"authorDate":"2020-04-30 06:11:49","commitOrder":2,"curCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            quietlyCleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2020-04-30 06:11:49","endLine":155,"groupId":"102674","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldUseDefaultSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9d/7c23d73c631af9ed2c964771a7b696f20942c9.src","preCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"M"},{"authorDate":"2020-04-30 06:11:49","commitOrder":2,"curCode":"    public void shouldInheritSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        \r\n        final KTable<String, Long> valueCounts = inputStream\n            .groupByKey()\n            .count();\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            quietlyCleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2020-04-30 06:11:49","endLine":208,"groupId":"102674","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldInheritSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9d/7c23d73c631af9ed2c964771a7b696f20942c9.src","preCode":"    public void shouldInheritSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        \r\n        final KTable<String, Long> valueCounts = inputStream\n            .groupByKey()\n            .count();\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":158,"status":"M"}],"commitId":"dc4d439825b2d117707b01c7c64769e700246fc6","commitMessage":"@@@KAFKA-9875: Make integration tests more resilient (#8578)\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-04-30 06:11:49","modifiedFileCount":"25","status":"M","submitter":"John Roesler"}]
