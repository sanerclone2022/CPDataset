[{"authorTime":"2018-09-26 04:41:22","codes":[{"authorDate":"2018-09-26 04:41:22","commitOrder":1,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2018-09-26 04:41:22","endLine":321,"groupId":"19367","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d9/8a15e093b9a296c120424daca5b4c35a4ac1e5.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"B"},{"authorDate":"2018-09-26 04:41:22","commitOrder":1,"curCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2018-09-26 04:41:22","endLine":161,"groupId":"3664","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/af/91abaf2b1b7deec04e845395ef22bedba78741.src","preCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"B"}],"commitId":"f712ce69fc2cb6a164b1ea8e491c9d68e6661933","commitMessage":"@@@KAFKA-7223: add tests in preparation for suppression (#5687)\n\nThis is Part 2 of suppression.\nPart 1 was #5567\n\nIn an effort to control the scope of the review.  this PR is just the tests for buffered suppression.\n\nReviewers: Bill Bejeck <bill@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-09-26 04:41:22","modifiedFileCount":"9","status":"B","submitter":"John Roesler"},{"authorTime":"2018-10-04 00:52:13","codes":[{"authorDate":"2018-09-26 04:41:22","commitOrder":2,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2018-09-26 04:41:22","endLine":321,"groupId":"19367","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d9/8a15e093b9a296c120424daca5b4c35a4ac1e5.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"N"},{"authorDate":"2018-10-04 00:52:13","commitOrder":2,"curCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2018-10-04 00:52:13","endLine":156,"groupId":"3664","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/20/8f1eb3c50bce05c86e599dd298ea59c3a8e4ce.src","preCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"M"}],"commitId":"b793eaade4fcb0705ab80c2a806331fab8c29f9f","commitMessage":"@@@KAFKA-7223: Make suppression buffer durable (#5724)\n\nThis is Part 4 of suppression (durability)\nPart 1 was #5567 (the API)\nPart 2 was #5687 (the tests)\nPart 3 was #5693 (in-memory buffering)\n\nImplement a changelog for the suppression buffer so that the buffer state may be recovered on restart or recovery.\nAs of this PR.  suppression is suitable for general usage.\n\nReviewers: Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2018-10-04 00:52:13","modifiedFileCount":"5","status":"M","submitter":"John Roesler"},{"authorTime":"2018-10-04 00:52:13","codes":[{"authorDate":"2018-10-04 09:05:41","commitOrder":3,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2018-10-04 09:05:41","endLine":296,"groupId":"19367","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/b7ab8662169779674a6b6cc31d525b00af2496.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Serialized.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":233,"status":"M"},{"authorDate":"2018-10-04 00:52:13","commitOrder":3,"curCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2018-10-04 00:52:13","endLine":156,"groupId":"3664","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/20/8f1eb3c50bce05c86e599dd298ea59c3a8e4ce.src","preCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"N"}],"commitId":"87879d51521d5574cbbf37dd97c83b7e4fc00dae","commitMessage":"@@@KAFKA-7223: Add name config to Suppressed (#5731)\n\nKIP-372 (allow naming all internal topics) was designed and developed concurrently with suppression.\n\nSince suppression introduces a new internal topic.  it also needs to be nameable.\n\nReviewers: Guozhang Wang <guozhang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2018-10-04 09:05:41","modifiedFileCount":"9","status":"M","submitter":"John Roesler"},{"authorTime":"2018-10-04 00:52:13","codes":[{"authorDate":"2018-10-28 00:22:02","commitOrder":4,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2018-10-28 00:22:02","endLine":290,"groupId":"19367","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/3bf0b83d02a6f79f02c8084ab643909498d0b8.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":231,"status":"M"},{"authorDate":"2018-10-04 00:52:13","commitOrder":4,"curCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2018-10-04 00:52:13","endLine":156,"groupId":"3664","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/20/8f1eb3c50bce05c86e599dd298ea59c3a8e4ce.src","preCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":145,"status":"N"}],"commitId":"c9d3debfe44fb09fa1740c645883717e669f0117","commitMessage":"@@@MINOR: SuppressScenarioTest should set StreamsConfig.STATE_DIR_CONFIG (#5826)\n\nSet `StreamsConfig.STATED_DIR_CONFIG` in `SuppressScenarioTest`.  as\nwith `StreamsTestUtils`. I have deliberately avoided using `StreamsTestUtils` as\nthis test sets bogus config parameters.  but still fails if the default\n`STATE_DIR_CONFIG` does not exist.\n\nReviewers: Colin Patrick McCabe <colin@cmccabe.xyz>.  John Roesler <john@confluent.io>.  Ismael Juma <ismael@juma.me.uk>","date":"2018-10-28 00:22:02","modifiedFileCount":"1","status":"M","submitter":"Lucas Bradstreet"},{"authorTime":"2019-04-27 00:30:20","codes":[{"authorDate":"2018-10-28 00:22:02","commitOrder":5,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2018-10-28 00:22:02","endLine":290,"groupId":"19367","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/3bf0b83d02a6f79f02c8084ab643909498d0b8.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":231,"status":"N"},{"authorDate":"2019-04-27 00:30:20","commitOrder":5,"curCode":"    private static KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2019-04-27 00:30:20","endLine":98,"groupId":"3664","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/f0a4121e35107bdcc7acc031405d544fa73159.src","preCode":"    private KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"M"}],"commitId":"eecb403bae80b82b6fb7a27bebb5b53d6c8f3115","commitMessage":"@@@KAFKA-8254: Pass Changelog as Topic in Suppress Serdes (#6602)\n\nReviewers:  Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-04-27 00:30:20","modifiedFileCount":"15","status":"M","submitter":"John Roesler"},{"authorTime":"2019-04-27 00:30:20","codes":[{"authorDate":"2019-10-07 16:01:58","commitOrder":6,"curCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v2\", 1L);\n            inputTopic.pipeInput(\"k2\", \"v1\", 2L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            inputTopic.pipeInput(\"x\", \"x\", 3L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","date":"2019-10-07 16:01:58","endLine":289,"groupId":"101726","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSuppressIntermediateEventsWithRecordLimit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/f8670a87bb8a49ab586fa7a089eeef465f1118.src","preCode":"    public void shouldSuppressIntermediateEventsWithRecordLimit() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<String, Long> valueCounts = builder\n            .table(\n                \"input\",\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(Long.MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v2\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 2L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"v1\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L),\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 0L, 1L),\n                    new KeyValueTimestamp<>(\"v2\", 1L, 1L)\n                    \r\n                )\n            );\n            driver.pipeInput(recordFactory.create(\"input\", \"x\", \"x\", 3L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    new KeyValueTimestamp<>(\"x\", 1L, 3L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                singletonList(\n                    \r\n                    new KeyValueTimestamp<>(\"v1\", 1L, 2L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":229,"status":"M"},{"authorDate":"2019-04-27 00:30:20","commitOrder":6,"curCode":"    private static KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","date":"2019-04-27 00:30:20","endLine":98,"groupId":"101726","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"buildCountsTable","params":"(finalStringinput@finalStreamsBuilderbuilder)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/f0a4121e35107bdcc7acc031405d544fa73159.src","preCode":"    private static KTable<String, Long> buildCountsTable(final String input, final StreamsBuilder builder) {\n        return builder\n            .table(\n                input,\n                Consumed.with(STRING_SERDE, STRING_SERDE),\n                Materialized.<String, String, KeyValueStore<Bytes, byte[]>>with(STRING_SERDE, STRING_SERDE)\n                    .withCachingDisabled()\n                    .withLoggingDisabled()\n            )\n            .groupBy((k, v) -> new KeyValue<>(v, k), Grouped.with(STRING_SERDE, STRING_SERDE))\n            .count(Materialized.<String, Long, KeyValueStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"N"}],"commitId":"a5a6938c69f4310f7ec519036f0df77d8022326a","commitMessage":"@@@KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)\n\nImplements KIP-470\n\nReviewers: Bill Bejeck <bill@confluent.io>.  John Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2019-10-07 16:01:58","modifiedFileCount":"47","status":"M","submitter":"Jukka Karvanen"}]
