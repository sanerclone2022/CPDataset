[{"authorTime":"2020-02-11 02:09:27","codes":[{"authorDate":"2020-02-11 02:09:27","commitOrder":2,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = kafkaStreams1\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = kafkaStreams2\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","date":"2020-02-11 02:09:27","endLine":134,"groupId":"3459","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ec/820f2593fd480b39c66deb9b733de12509eb88.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = kafkaStreams1\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = kafkaStreams2\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":93,"status":"B"},{"authorDate":"2020-02-11 02:09:27","commitOrder":2,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.getPartition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        } else {\n            store2 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        } else {\n            store4 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","date":"2020-02-11 02:09:27","endLine":209,"groupId":"10177","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ec/820f2593fd480b39c66deb9b733de12509eb88.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.getPartition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        } else {\n            store2 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        } else {\n            store4 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":137,"status":"MB"}],"commitId":"d76fa1b22d4b06e1f1a7700272ca963091f13931","commitMessage":"@@@KAFKA-9487: Follow-up PR of Kafka-9445 (#8033)\n\nFollows up on the original PR for KAFKA-9445 to address a final round of feedback\n\nReviewers: John Roesler <vvcephei@apache.org>.  Matthias J. Sax <matthias@confluent.io>\n","date":"2020-02-11 02:09:27","modifiedFileCount":"24","status":"M","submitter":"Navinder Pal Singh Brar"},{"authorTime":"2020-04-29 06:04:19","codes":[{"authorDate":"2020-04-29 06:04:19","commitOrder":3,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","date":"2020-04-29 06:04:19","endLine":130,"groupId":"3459","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/195b536e32bd41da49bebdaf2bb109e91361e0.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = kafkaStreams1\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = kafkaStreams2\n                .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType));\n\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2020-04-29 06:04:19","commitOrder":3,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.getPartition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n\n        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n                .withPartition(keyPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n            .withPartition(keyDontBelongPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","date":"2020-04-29 06:04:19","endLine":200,"groupId":"7228","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/195b536e32bd41da49bebdaf2bb109e91361e0.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.getPartition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive;\n        if ((keyQueryMetadata.getActiveHost().port() % 2) == 1) {\n            kafkaStreams1IsActive = true;\n        } else {\n            kafkaStreams1IsActive = false;\n        }\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        } else {\n            store2 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyPartition));\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = kafkaStreams1\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        } else {\n            store4 = kafkaStreams2\n                    .store(StoreQueryParameters.fromNameAndType(TABLE_NAME, queryableStoreType).withPartition(keyDontBelongPartition));\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":133,"status":"M"}],"commitId":"11fc953c05eb2c8db61c61bc765aa8be0598d638","commitMessage":"@@@KAFKA-9176: Retry on getting local stores from KafkaStreams (#8568)\n\nThis PR fixes and improves two major issues:\n\n1. When calling KafkaStreams#store we can always get an InvalidStateStoreException.  and even waiting for Streams state to become RUNNING is not sufficient (this is also how OptimizedKTableIntegrationTest failed). So I wrapped all the function with a Util wrapper that captures and retries on that exception.\n\n2. While trouble-shooting this issue.  I also realized a potential bug in test-util's produceKeyValuesSynchronously.  which creates a new producer for each of the record to send in that batch --- i.e. if you are sending N records with a single call.  within that call it will create N producers used to send one record each.  which is very slow and costly.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  John Roesler <john@confluent.io>","date":"2020-04-29 06:04:19","modifiedFileCount":"9","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-08-07 02:15:35","codes":[{"authorDate":"2020-08-07 02:15:35","commitOrder":4,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","date":"2020-08-07 02:15:35","endLine":131,"groupId":"3459","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9c/c519463e0f71e796bd20d77df3768df74bde08.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2020-08-07 02:15:35","commitOrder":4,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.partition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n                .withPartition(keyPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n            .withPartition(keyDontBelongPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","date":"2020-08-07 02:15:35","endLine":201,"groupId":"7228","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9c/c519463e0f71e796bd20d77df3768df74bde08.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.getPartition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.getActiveHost().port() % 2) == 1;\n\n        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n                .withPartition(keyPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n            .withPartition(keyDontBelongPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"}],"commitId":"e7316f35d933d8bf738caa1a01e8477f74021677","commitMessage":"@@@KAFKA-10316: Consider renaming getter method for Interactive Queries (#9120)\n\n - implements KIP-648\n - Deprecated the existing getters and added new getters without `get` prefix to `KeyQueryMetadata`\n\nCo-authored-by: johnthotekat <Iabon1989*>\n\nReviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>.  Matthias J. Sax <matthias@confluent.io>","date":"2020-08-07 02:15:35","modifiedFileCount":"5","status":"M","submitter":"John Thomas"},{"authorTime":"2020-10-30 00:57:31","codes":[{"authorDate":"2020-10-30 00:57:31","commitOrder":5,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2020-10-30 00:57:31","endLine":157,"groupId":"12334","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/2ae917b1859ca9e0a92d67003eb8a8a549e2b2.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = QueryableStoreTypes.keyValueStore();\n        final ReadOnlyKeyValueStore<Integer, Integer> store1 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n        final ReadOnlyKeyValueStore<Integer, Integer> store2 = IntegrationTestUtils.getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n        assertThat(kafkaStreams1IsActive ? store2.get(key) : store1.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"},{"authorDate":"2020-10-30 00:57:31","commitOrder":5,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2020-10-30 00:57:31","endLine":251,"groupId":"12335","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/2ae917b1859ca9e0a92d67003eb8a8a549e2b2.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                        Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                                .withCachingDisabled())\n                .toStream()\n                .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n        \r\n        final int keyPartition = keyQueryMetadata.partition();\n\n        \r\n        final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n        final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n        StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n            StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n                .withPartition(keyPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n        if (kafkaStreams1IsActive) {\n            store1 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store2 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        if (kafkaStreams1IsActive) {\n            assertThat(store1, is(notNullValue()));\n            assertThat(store2, is(nullValue()));\n        } else {\n            assertThat(store2, is(notNullValue()));\n            assertThat(store1, is(nullValue()));\n        }\n\n        \r\n        assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n        storeQueryParam = StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, QueryableStoreTypes.keyValueStore())\n            .withPartition(keyDontBelongPartition);\n        ReadOnlyKeyValueStore<Integer, Integer> store3 = null;\n        ReadOnlyKeyValueStore<Integer, Integer> store4 = null;\n        if (!kafkaStreams1IsActive) {\n            store3 = IntegrationTestUtils.getStore(kafkaStreams1, storeQueryParam);\n        } else {\n            store4 = IntegrationTestUtils.getStore(kafkaStreams2, storeQueryParam);\n        }\n\n        \r\n        \r\n        \r\n        assertThat(kafkaStreams1IsActive ? store4.get(key) : store3.get(key), is(nullValue()));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":160,"status":"M"}],"commitId":"933a813950b1ae06e19ead23734fa6bdf1f32e3f","commitMessage":"@@@KAFKA-10638: Fix QueryableStateIntegrationTest (#9521)\n\nThis test has been observed to have flaky failures.\nApparently.  in the failed runs.  Streams had entered a rebalance\nbefore some of the assertions were made. We recently made\nIQ a little stricter on whether it would return errors instead of\nnull responses in such cases:\nKAFKA-10598: Improve IQ name and type checks (#9408)\n\nAs a result.  we have started seeing failures now instead of\nsilently executing an invalid test (I.e..  it was asserting the\nreturn to be null.  but the result was null for the wrong\nreason).\n\nNow.  if the test discovers that Streams is no longer running. \nit will repeat the verification until it actually gets a valid\npositive or negative result.\n\nReviewers: Chia-Ping Tsai <chia7712@apache.org>","date":"2020-10-30 00:57:31","modifiedFileCount":"2","status":"M","submitter":"John Roesler"},{"authorTime":"2020-10-30 00:57:31","codes":[{"authorDate":"2020-12-04 05:59:32","commitOrder":6,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2020-12-04 05:59:32","endLine":157,"groupId":"12334","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/4231468975883332821c59f30c8416101bd786.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"},{"authorDate":"2020-10-30 00:57:31","commitOrder":6,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2020-10-30 00:57:31","endLine":251,"groupId":"12335","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/2ae917b1859ca9e0a92d67003eb8a8a549e2b2.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":160,"status":"N"}],"commitId":"7c68531a1f114e39f04532ed1c59619c25a143f3","commitMessage":"@@@MINOR: Fix flaky test shouldQueryOnlyActivePartitionStoresByDefault (#9681)\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-12-04 05:59:32","modifiedFileCount":"1","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2021-01-14 02:01:14","codes":[{"authorDate":"2020-12-04 05:59:32","commitOrder":7,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2020-12-04 05:59:32","endLine":157,"groupId":"12334","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/4231468975883332821c59f30c8416101bd786.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"N"},{"authorDate":"2021-01-14 02:01:14","commitOrder":7,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-01-14 02:01:14","endLine":248,"groupId":"12335","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/38/760694a9a5fab8ec9f44dc0b07475c8eee66c1.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            \r\n            assertThat(kafkaStreams1IsActive ? store1.get(key) : store2.get(key), is(notNullValue()));\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":160,"status":"M"}],"commitId":"ee5ef89a71c57888b24f3bd4b5b82eead631aa7c","commitMessage":"@@@MINOR: Fix flaky test shouldQuerySpecificActivePartitionStores (#9873)\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2021-01-14 02:01:14","modifiedFileCount":"1","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2021-01-14 02:01:14","codes":[{"authorDate":"2021-07-30 05:26:00","commitOrder":8,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                oneOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-07-30 05:26:00","endLine":168,"groupId":"12334","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3e/cb6a978feb0ac3d375ae8cda1aba2660439477.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2021-01-14 02:01:14","commitOrder":8,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-01-14 02:01:14","endLine":248,"groupId":"12335","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/38/760694a9a5fab8ec9f44dc0b07475c8eee66c1.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":160,"status":"N"}],"commitId":"c074b673958efe90553700a89f89e3d0c4a13c25","commitMessage":"@@@Fix for flaky test in StoreQueryIntegrationTest (#11129)\n\nFix a bug in StoreQueryIntegrationTest::shouldQueryOnlyActivePartitionStoresByDefault that causes the test to fail in the case of a client rebalancing. The changes in this PR make sure the test keeps re-trying after a rebalancing operation.  instead of failing.\n\nReviewers: Luke Chen <showuon@gmail.com>.  John Roesler <vvcephei@apache.org>","date":"2021-07-30 05:26:00","modifiedFileCount":"1","status":"M","submitter":"Patrick Stuedi"},{"authorTime":"2021-07-31 01:56:57","codes":[{"authorDate":"2021-07-31 01:56:57","commitOrder":9,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                oneOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-07-31 01:56:57","endLine":166,"groupId":"12334","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/44/3ea5fd3d2a2b01ab437cc7437595cee343710c.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                oneOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"M"},{"authorDate":"2021-07-31 01:56:57","commitOrder":9,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-07-31 01:56:57","endLine":253,"groupId":"12335","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/44/3ea5fd3d2a2b01ab437cc7437595cee343710c.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        builder.table(INPUT_TOPIC_NAME, Consumed.with(Serdes.Integer(), Serdes.Integer()),\n                      Materialized.<Integer, Integer, KeyValueStore<Bytes, byte[]>>as(TABLE_NAME)\n                          .withCachingDisabled())\n               .toStream()\n               .peek((k, v) -> semaphore.release());\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"M"}],"commitId":"5d52de2ccfaebc8d4f8d6ff247b86a2830eb1c8b","commitMessage":"@@@KAFKA-12648: minor followup from Pt. 2 and some new tests (#11146)\n\nAddresses the handful of remaining feedback from Pt. 2.  plus adds two new tests: one verifying a multi-topology application with a FKJ and its internal topics.  another to make sure IQ works with named topologies (though note that there is a bit more work left for IQ to be fully supported.  will be tackled after Pt. 3\n\nReviewers: Guozhang Wang <guozhang@confluent.io>.  Walker Carlson <wcarlson@confluent.io>","date":"2021-07-31 01:56:57","modifiedFileCount":"7","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-08-06 05:39:33","codes":[{"authorDate":"2021-08-06 05:39:33","commitOrder":10,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                anyOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-08-06 05:39:33","endLine":165,"groupId":"12334","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c4/a236b586331b118110be1595edbe344232e60c.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                oneOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"},{"authorDate":"2021-08-06 05:39:33","commitOrder":10,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    \"Unexpected exception thrown while getting the value from store.\",\n                    exception.getMessage(),\n                    is(\n                        anyOf(\n                            containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                            containsString(\"The state store, source-table, may have migrated to another instance\")\n                        )\n                    )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-08-06 05:39:33","endLine":258,"groupId":"12335","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c4/a236b586331b118110be1595edbe344232e60c.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    exception.getMessage(),\n                    containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\")\n                );\n                LOG.info(\"Streams wasn't running. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":168,"status":"M"}],"commitId":"be8820cdacb93e7b2aef5ae20ca00ad401328379","commitMessage":"@@@MINOR: Port fix to other StoreQueryIntegrationTests (#11153)\n\nPort the fix from #11129 to the other store-query tests.\n\nReviewers: John Roesler <vvcephei@apache.org>","date":"2021-08-06 05:39:33","modifiedFileCount":"1","status":"M","submitter":"Walker Carlson"},{"authorTime":"2021-08-28 11:12:12","codes":[{"authorDate":"2021-08-28 11:12:12","commitOrder":11,"curCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                verifyRetrievableException(exception);\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-08-28 11:12:12","endLine":156,"groupId":"102761","id":19,"instanceNumber":1,"isCurCommit":1,"methodName":"shouldQueryOnlyActivePartitionStoresByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/76/916c95a2ca0a500869bcf964c15d1f012d5839.src","preCode":"    public void shouldQueryOnlyActivePartitionStoresByDefault() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            final QueryableStoreType<ReadOnlyKeyValueStore<Integer, Integer>> queryableStoreType = keyValueStore();\n            final ReadOnlyKeyValueStore<Integer, Integer> store1 = getStore(TABLE_NAME, kafkaStreams1, queryableStoreType);\n            final ReadOnlyKeyValueStore<Integer, Integer> store2 = getStore(TABLE_NAME, kafkaStreams2, queryableStoreType);\n\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            try {\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(store2.get(key), is(nullValue()));\n                } else {\n                    assertThat(store1.get(key), is(nullValue()));\n                    assertThat(store2.get(key), is(notNullValue()));\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                        \"Unexpected exception thrown while getting the value from store.\",\n                        exception.getMessage(),\n                        is(\n                                anyOf(\n                                        containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                                        containsString(\"The state store, source-table, may have migrated to another instance\")\n                                )\n                        )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"},{"authorDate":"2021-08-28 11:12:12","commitOrder":11,"curCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                verifyRetrievableException(exception);\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","date":"2021-08-28 11:12:12","endLine":240,"groupId":"102761","id":20,"instanceNumber":2,"isCurCommit":1,"methodName":"shouldQuerySpecificActivePartitionStores","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/76/916c95a2ca0a500869bcf964c15d1f012d5839.src","preCode":"    public void shouldQuerySpecificActivePartitionStores() throws Exception {\n        final int batch1NumMessages = 100;\n        final int key = 1;\n        final Semaphore semaphore = new Semaphore(0);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n        getStreamsBuilderWithTopology(builder, semaphore);\n\n        final KafkaStreams kafkaStreams1 = createKafkaStreams(builder, streamsConfiguration());\n        final KafkaStreams kafkaStreams2 = createKafkaStreams(builder, streamsConfiguration());\n        final List<KafkaStreams> kafkaStreamsList = Arrays.asList(kafkaStreams1, kafkaStreams2);\n\n        startApplicationAndWaitUntilRunning(kafkaStreamsList, Duration.ofSeconds(60));\n\n        produceValueRange(key, 0, batch1NumMessages);\n\n        \r\n        assertThat(semaphore.tryAcquire(batch1NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n        until(() -> {\n            final KeyQueryMetadata keyQueryMetadata = kafkaStreams1.queryMetadataForKey(TABLE_NAME, key, (topic, somekey, value, numPartitions) -> 0);\n\n            \r\n            final int keyPartition = keyQueryMetadata.partition();\n\n            \r\n            final int keyDontBelongPartition = (keyPartition == 0) ? 1 : 0;\n            final boolean kafkaStreams1IsActive = (keyQueryMetadata.activeHost().port() % 2) == 1;\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                    .withPartition(keyPartition);\n            ReadOnlyKeyValueStore<Integer, Integer> store1 = null;\n            ReadOnlyKeyValueStore<Integer, Integer> store2 = null;\n            if (kafkaStreams1IsActive) {\n                store1 = getStore(kafkaStreams1, storeQueryParam);\n            } else {\n                store2 = getStore(kafkaStreams2, storeQueryParam);\n            }\n\n            if (kafkaStreams1IsActive) {\n                assertThat(store1, is(notNullValue()));\n                assertThat(store2, is(nullValue()));\n            } else {\n                assertThat(store2, is(notNullValue()));\n                assertThat(store1, is(nullValue()));\n            }\n\n            final StoreQueryParameters<ReadOnlyKeyValueStore<Integer, Integer>> storeQueryParam2 =\n                StoreQueryParameters.<ReadOnlyKeyValueStore<Integer, Integer>>fromNameAndType(TABLE_NAME, keyValueStore())\n                .withPartition(keyDontBelongPartition);\n\n            try {\n                \r\n                \r\n                \r\n                if (kafkaStreams1IsActive) {\n                    assertThat(store1.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams2, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams1, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                } else {\n                    assertThat(store2.get(key), is(notNullValue()));\n                    assertThat(getStore(kafkaStreams1, storeQueryParam2).get(key), is(nullValue()));\n                    final InvalidStateStoreException exception =\n                        assertThrows(InvalidStateStoreException.class, () -> getStore(kafkaStreams2, storeQueryParam2).get(key));\n                    assertThat(\n                        exception.getMessage(),\n                        containsString(\"The specified partition 1 for store source-table does not exist.\")\n                    );\n                }\n                return true;\n            } catch (final InvalidStateStoreException exception) {\n                assertThat(\n                    \"Unexpected exception thrown while getting the value from store.\",\n                    exception.getMessage(),\n                    is(\n                        anyOf(\n                            containsString(\"Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING\"),\n                            containsString(\"The state store, source-table, may have migrated to another instance\")\n                        )\n                    )\n                );\n                LOG.info(\"Either streams wasn't running or a re-balancing took place. Will try again.\");\n                return false;\n            }\n        });\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/StoreQueryIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":159,"status":"M"}],"commitId":"49aed781d8b398975e8952ef21578c05114064ed","commitMessage":"@@@KAFKA-13128: extract retry checker and update with retriable exception causing flaky StoreQueryIntegrationTest (#11275)\n\nAdd a new case to the list of possible retriable exceptions for the flaky tests to take care of threads starting up\n\nReviewers: Leah Thomas <lthomas@confluent.io>.  Anna Sophie Blee-Goldman","date":"2021-08-28 11:12:12","modifiedFileCount":"1","status":"M","submitter":"Walker Carlson"}]
