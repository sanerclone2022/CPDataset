[{"authorTime":"2021-02-05 11:02:56","codes":[{"authorDate":"2020-06-24 09:08:26","commitOrder":3,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2020-06-24 09:08:26","endLine":813,"groupId":"19922","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1e/3d232298036756562a67669bee23a699c1220d.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":788,"status":"NB"},{"authorDate":"2021-02-05 11:02:56","commitOrder":3,"curCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            \"threadId\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext\n        );\n    }\n","date":"2021-02-05 11:02:56","endLine":897,"groupId":"19915","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getExceptionalStreamsProducerOnSend","params":"(finalExceptionexception)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ee/803992550c072484a1f68b294f167d182137c3.src","preCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            \"threadId\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":877,"status":"B"}],"commitId":"470e6f2b9ac45fc32bdeb77d0bf4c72d26c6f3fd","commitMessage":"@@@KAFKA-9274: Add timeout handling for `StreamPartitioner` (#9997)\n\n Part of KIP-572: When a custom `StreamPartitioner` is used.  we need to get the number of partitions of output topics from the producer. This `partitionFor(topic)` call may through a `TimeoutException` that we now handle gracefully.\n\nReviewers: John Roesler <john@confluent.io>.  A. Sophie Blee-Goldman <sophie@confluent.io>","date":"2021-02-05 11:02:56","modifiedFileCount":"8","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2021-04-29 04:22:15","codes":[{"authorDate":"2021-04-29 04:22:15","commitOrder":4,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2021-04-29 04:22:15","endLine":870,"groupId":"8844","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5a/83c6839d3d59075fd101c9444abd0dea01649c.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":845,"status":"M"},{"authorDate":"2021-04-29 04:22:15","commitOrder":4,"curCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            processId + \"-StreamThread-1\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext\n        );\n    }\n","date":"2021-04-29 04:22:15","endLine":900,"groupId":"19915","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getExceptionalStreamsProducerOnSend","params":"(finalExceptionexception)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5a/83c6839d3d59075fd101c9444abd0dea01649c.src","preCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            \"threadId\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":880,"status":"M"}],"commitId":"3805f3706f8f3ebba81b80915c9259590525fb05","commitMessage":"@@@KAFKA-12574: KIP-732.  Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)\n\nDeprecates the following \n\n1. StreamsConfig.EXACTLY_ONCE\n2. StreamsConfig.EXACTLY_ONCE_BETA\n3. Producer#sendOffsetsToTransaction(Map offsets.  String consumerGroupId)\n\nAnd introduces a new StreamsConfig.EXACTLY_ONCE_V2 config. Additionally.  this PR replaces usages of the term \"eos-beta\" throughout the code with the term \"eos-v2\"\n\nReviewers: Matthias J. Sax <mjsax@confluent.io>","date":"2021-04-29 04:22:15","modifiedFileCount":"32","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-08-31 06:39:25","codes":[{"authorDate":"2021-08-31 06:39:25","commitOrder":5,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext,\n                Time.SYSTEM\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2021-08-31 06:39:25","endLine":875,"groupId":"102318","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/364f27db583906a2fe2bdaa385ddbaffc54f3b.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":849,"status":"M"},{"authorDate":"2021-08-31 06:39:25","commitOrder":5,"curCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            processId + \"-StreamThread-1\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext,\n            Time.SYSTEM\n        );\n    }\n","date":"2021-08-31 06:39:25","endLine":906,"groupId":"102318","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"getExceptionalStreamsProducerOnSend","params":"(finalExceptionexception)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/364f27db583906a2fe2bdaa385ddbaffc54f3b.src","preCode":"    private StreamsProducer getExceptionalStreamsProducerOnSend(final Exception exception) {\n        return new StreamsProducer(\n            config,\n            processId + \"-StreamThread-1\",\n            new MockClientSupplier() {\n                @Override\n                public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                    return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                        @Override\n                        public synchronized Future<RecordMetadata> send(final ProducerRecord<byte[], byte[]> record, final Callback callback) {\n                            callback.onCompletion(null, exception);\n                            return null;\n                        }\n                    };\n                }\n            },\n            null,\n            null,\n            logContext\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":885,"status":"M"}],"commitId":"01ab888dbd08ccd4b0de9333d21581ce24fe2c3b","commitMessage":"@@@KAFKA-13229: add total blocked time metric to streams (KIP-761) (#11149)\n\n* Add the following producer metrics:\nflush-time-total: cumulative sum of time elapsed during in flush.\ntxn-init-time-total: cumulative sum of time elapsed during in initTransactions.\ntxn-begin-time-total: cumulative sum of time elapsed during in beginTransaction.\ntxn-send-offsets-time-total: cumulative sum of time elapsed during in sendOffsetsToTransaction.\ntxn-commit-time-total: cumulative sum of time elapsed during in commitTransaction.\ntxn-abort-time-total: cumulative sum of time elapsed during in abortTransaction.\n\n* Add the following consumer metrics:\ncommited-time-total: cumulative sum of time elapsed during in committed.\ncommit-sync-time-total: cumulative sum of time elapsed during in commitSync.\n\n* Add a total-blocked-time metric to streams that is the sum of:\nconsumer?s io-waittime-total\nconsumer?s iotime-total\nconsumer?s committed-time-total\nconsumer?s commit-sync-time-total\nrestore consumer?s io-waittime-total\nrestore consumer?s iotime-total\nadmin client?s io-waittime-total\nadmin client?s iotime-total\nproducer?s bufferpool-wait-time-total\nproducer's flush-time-total\nproducer's txn-init-time-total\nproducer's txn-begin-time-total\nproducer's txn-send-offsets-time-total\nproducer's txn-commit-time-total\nproducer's txn-abort-time-total\n\nReviewers: Bruno Cadonna <cadonna@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2021-08-31 06:39:25","modifiedFileCount":"23","status":"M","submitter":"Rohan"}]
