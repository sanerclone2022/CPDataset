[{"authorTime":"2020-06-17 07:30:37","codes":[{"authorDate":"2020-06-17 07:30:37","commitOrder":1,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":1838,"groupId":"12463","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/2cf7ad49579eca5116e2c0b5cc8057c76a3bcb.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1831,"status":"B"},{"authorDate":"2020-06-17 07:30:37","commitOrder":1,"curCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":499,"groupId":"12463","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRunningTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/4b410358c07100e3f6d708e8c231c170f9dfb0.src","preCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":492,"status":"B"}],"commitId":"2239004907b29e00811fee9ded5a790172701a03","commitMessage":"@@@KAFKA-10150: task state transitions/management and committing cleanup (#8856)\n\n* KAFKA-10150: always transition to SUSPENDED during suspend.  no matter the current state only call prepareCommit before closing if task.commitNeeded is true\n\n* Don't commit any consumed offsets during handleAssignment -- revoked active tasks (and any others that need committing) will be committed during handleRevocation so we only need to worry about cleaning them up in handleAssignment\n\n* KAFKA-10152: when recycling a task we should always commit consumed offsets (if any).  but don't need to write the checkpoint (since changelog offsets are preserved across task transitions)\n\n* Make sure we close all tasks during shutdown.  even if an exception is thrown during commit\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-06-17 07:30:37","modifiedFileCount":"7","status":"B","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-06-27 06:11:56","codes":[{"authorDate":"2020-06-17 07:30:37","commitOrder":2,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-17 07:30:37","endLine":1838,"groupId":"12463","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/2cf7ad49579eca5116e2c0b5cc8057c76a3bcb.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1831,"status":"N"},{"authorDate":"2020-06-27 06:11:56","commitOrder":2,"curCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-27 06:11:56","endLine":550,"groupId":"12463","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRunningTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ba/07d55c51c6d65ff36ad2f6f609a71d704af02f.src","preCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":542,"status":"M"}],"commitId":"30df089631cf3c7667b609e2b9689cb02230c64e","commitMessage":"@@@KAFKA-10166: always write checkpoint before closing an (initialized) task (#8926)\n\nThis should address at least some of the excessive TaskCorruptedExceptions we've been seeing lately. Basically.  at the moment we only commit tasks if commitNeeded is true -- this seems obvious by definition. But the problem is we do some essential cleanup in postCommit that should always be done before a task is closed:\n\n* clear the PartitionGroup\n* write the checkpoint\n\nThe second is actually fine to skip when commitNeeded = false with ALOS.  as we will have already written a checkpoint during the last commit. But for EOS.  we only write the checkpoint before a close -- so even if there is no new pending data since the last commit.  we have to write the current offsets. If we don't.  the task will be assumed dirty and we will run into our friend the TaskCorruptedException during (re)initialization.\n\nTo fix this.  we should just always call prepareCommit and postCommit at the TaskManager level. Within the task.  it can decide whether or not to actually do something in those methods based on commitNeeded.\n\nOne subtle issue is that we still need to avoid checkpointing a task that was still in CREATED.  to avoid potentially overwriting an existing checkpoint with uninitialized empty offsets. Unfortunately we always suspend a task before closing and committing.  so we lose the information about whether the task as in CREATED or RUNNING/RESTORING by the time we get to the checkpoint. For this we introduce a special flag to keep track of whether a suspended task should actually be checkpointed or not\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-06-27 06:11:56","modifiedFileCount":"7","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-06-27 06:11:56","codes":[{"authorDate":"2020-08-12 11:21:41","commitOrder":3,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-08-12 11:21:41","endLine":1964,"groupId":"12463","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/4fa234888eda5e4dcdafaea518f24786462f03.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1956,"status":"M"},{"authorDate":"2020-06-27 06:11:56","commitOrder":3,"curCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-27 06:11:56","endLine":550,"groupId":"12463","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRunningTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ba/07d55c51c6d65ff36ad2f6f609a71d704af02f.src","preCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":542,"status":"N"}],"commitId":"7915d5e5f826a71c11e1c9183c84702410f7209a","commitMessage":"@@@KAFKA-9450: Decouple flushing state from commiting (#8964)\n\nIn Kafka Streams the source-of-truth of a state store is in its changelog.  therefore when committing a state store we only need to make sure its changelog records are all flushed and committed.  but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.\n\nOn the other hand.  flushing a state store too frequently may have side effects.  e.g. rocksDB flushing would gets the memtable into an L0 sstable.  leaving many small L0 files to be compacted later.  which introduces larger overhead.\n\nTherefore this PR decouples flushing from committing.  such that we do not always flush the state store upon committing.  but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled.  then it is fine if the local persisted state is actually ahead of the checkpoint.  b) if EOS is enabled.  then we would never write a checkpoint file until close.\n\nHere's a more detailed change list of this PR:\n\n1. Do not always flush state stores when calling pre-commit; move stateMgr.flush into post-commit to couple together with checkpointing.\n\n2. In post-commit.  we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint.  b) When the task is being closed.  in which case we enforce checkpointing.\n\n3. There are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer.  we still need to flush them in pre-commit to make sure all records sent via producers.  while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.\n\nI've also made some minor changes piggy-backed in this PR:\n\n4. Do not delete checkpoint file upon loading it.  and as a result simplify the checkpointNeeded logic.  initializing the snapshotLastFlush to the loaded offsets.\n\n5. In closing.  also follow the commit -> suspend -> close ordering as in revocation / assignment.\n\n6. If enforceCheckpoint == true during RUNNING.  still calls maybeCheckpoint even with EOS since that is the case for suspending / closing.\n\nReviewers: John Roesler <john@confluent.io>.  A. Sophie Blee-Goldman <sophie@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2020-08-12 11:21:41","modifiedFileCount":"24","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-06-27 06:11:56","codes":[{"authorDate":"2021-01-07 06:01:02","commitOrder":4,"curCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(\"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2021-01-07 06:01:02","endLine":2104,"groupId":"102077","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRestoringTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/b67d9f5e37d8b8b82948e5ddba15ceacb74034.src","preCode":"    public void shouldAlwaysSuspendRestoringTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andReturn(Collections.emptyMap()).anyTimes();\n        EasyMock.replay(stateManager);\n        task = createStatefulTask(createConfig(false, \"100\"), true);\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RESTORING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2096,"status":"M"},{"authorDate":"2020-06-27 06:11:56","commitOrder":4,"curCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","date":"2020-06-27 06:11:56","endLine":550,"groupId":"102077","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldAlwaysSuspendRunningTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ba/07d55c51c6d65ff36ad2f6f609a71d704af02f.src","preCode":"    public void shouldAlwaysSuspendRunningTasks() {\n        EasyMock.expect(stateManager.changelogOffsets()).andStubReturn(Collections.emptyMap());\n        EasyMock.replay(stateManager);\n        task = createStandbyTask();\n        task.initializeIfNeeded();\n        assertThat(task.state(), equalTo(RUNNING));\n        task.suspend();\n        assertThat(task.state(), equalTo(SUSPENDED));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":542,"status":"N"}],"commitId":"22e8e71156762b40ac93e2cbd42eacba00dbfb0c","commitMessage":"@@@KAFKA-9274: Fix commit-TimeoutException handling for EOS (#9800)\n\nIf EOS is enabled and the TX commit fails with a timeout. \nwe should not process more messages (what is ok for non-EOS)\nbecause we don't really know the status of the TX.\nIf the commit was indeed successful.  we won't have an open TX\ncan calling send() would fail with an fatal error.\n\nInstead.  we should retry the (idempotent) commit of the TX. \nand start a new TX afterwards.\n\nReviewers: Boyang Chen <boyang@confluent.io>.  John Roesler <john@confluent.io>","date":"2021-01-07 06:01:02","modifiedFileCount":"2","status":"M","submitter":"Matthias J. Sax"}]
