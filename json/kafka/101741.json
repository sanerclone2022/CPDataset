[{"authorTime":"2018-09-26 04:41:22","codes":[{"authorDate":"2018-09-26 04:41:22","commitOrder":1,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(2L))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-09-26 04:41:22","endLine":502,"groupId":"22708","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d9/8a15e093b9a296c120424daca5b4c35a4ac1e5.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(2L))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":446,"status":"B"},{"authorDate":"2018-09-26 04:41:22","commitOrder":1,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(5L))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","date":"2018-09-26 04:41:22","endLine":556,"groupId":"19490","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d9/8a15e093b9a296c120424daca5b4c35a4ac1e5.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(5L))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":505,"status":"B"}],"commitId":"f712ce69fc2cb6a164b1ea8e491c9d68e6661933","commitMessage":"@@@KAFKA-7223: add tests in preparation for suppression (#5687)\n\nThis is Part 2 of suppression.\nPart 1 was #5567\n\nIn an effort to control the scope of the review.  this PR is just the tests for buffered suppression.\n\nReviewers: Bill Bejeck <bill@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-09-26 04:41:22","modifiedFileCount":"9","status":"B","submitter":"John Roesler"},{"authorTime":"2018-10-04 09:05:41","codes":[{"authorDate":"2018-10-04 09:05:41","commitOrder":2,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(2L))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-10-04 09:05:41","endLine":476,"groupId":"22708","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/b7ab8662169779674a6b6cc31d525b00af2496.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(2L))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"M"},{"authorDate":"2018-10-04 09:05:41","commitOrder":2,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(5L))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","date":"2018-10-04 09:05:41","endLine":530,"groupId":"19490","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/b7ab8662169779674a6b6cc31d525b00af2496.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Serialized.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(5L))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":479,"status":"M"}],"commitId":"87879d51521d5574cbbf37dd97c83b7e4fc00dae","commitMessage":"@@@KAFKA-7223: Add name config to Suppressed (#5731)\n\nKIP-372 (allow naming all internal topics) was designed and developed concurrently with suppression.\n\nSince suppression introduces a new internal topic.  it also needs to be nameable.\n\nReviewers: Guozhang Wang <guozhang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2018-10-04 09:05:41","modifiedFileCount":"9","status":"M","submitter":"John Roesler"},{"authorTime":"2018-10-05 04:51:39","codes":[{"authorDate":"2018-10-05 04:51:39","commitOrder":3,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-10-05 04:51:39","endLine":476,"groupId":"22708","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/c51fc5f28434e4c13700748eb8592203534730.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(2L))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"M"},{"authorDate":"2018-10-05 04:51:39","commitOrder":3,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","date":"2018-10-05 04:51:39","endLine":530,"groupId":"19490","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/c51fc5f28434e4c13700748eb8592203534730.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(5L))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":479,"status":"M"}],"commitId":"ca641b3e2e48c14ff308181c775775408f5f35f7","commitMessage":"@@@KAFKA-7277: Migrate Streams API to Duration instead of longMs times (#5682)\n\nReviewers: Johne Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>","date":"2018-10-05 04:51:39","modifiedFileCount":"97","status":"M","submitter":"Nikolay"},{"authorTime":"2018-10-28 00:22:02","codes":[{"authorDate":"2018-10-28 00:22:02","commitOrder":4,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-10-28 00:22:02","endLine":458,"groupId":"22708","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/3bf0b83d02a6f79f02c8084ab643909498d0b8.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":406,"status":"M"},{"authorDate":"2018-10-28 00:22:02","commitOrder":4,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","date":"2018-10-28 00:22:02","endLine":508,"groupId":"22709","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/3bf0b83d02a6f79f02c8084ab643909498d0b8.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final Properties config = Utils.mkProperties(Utils.mkMap(\n            Utils.mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, getClass().getSimpleName().toLowerCase(Locale.getDefault())),\n            Utils.mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"bogus\")\n        ));\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":461,"status":"M"}],"commitId":"c9d3debfe44fb09fa1740c645883717e669f0117","commitMessage":"@@@MINOR: SuppressScenarioTest should set StreamsConfig.STATE_DIR_CONFIG (#5826)\n\nSet `StreamsConfig.STATED_DIR_CONFIG` in `SuppressScenarioTest`.  as\nwith `StreamsTestUtils`. I have deliberately avoided using `StreamsTestUtils` as\nthis test sets bogus config parameters.  but still fails if the default\n`STATE_DIR_CONFIG` does not exist.\n\nReviewers: Colin Patrick McCabe <colin@cmccabe.xyz>.  John Roesler <john@confluent.io>.  Ismael Juma <ismael@juma.me.uk>","date":"2018-10-28 00:22:02","modifiedFileCount":"1","status":"M","submitter":"Lucas Bradstreet"},{"authorTime":"2018-11-15 09:29:19","codes":[{"authorDate":"2018-11-15 09:29:19","commitOrder":5,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-11-15 09:29:19","endLine":460,"groupId":"22708","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b0/b87be51b5bf3cfefe52d9d1d5e277dc609a8b7.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(2L).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":408,"status":"M"},{"authorDate":"2018-11-15 09:29:19","commitOrder":5,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","date":"2018-11-15 09:29:19","endLine":510,"groupId":"22709","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b0/b87be51b5bf3cfefe52d9d1d5e277dc609a8b7.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(5L).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":463,"status":"M"}],"commitId":"14d3ead19d250f2f3117af473ff6244c663ef8ca","commitMessage":"@@@MINOR: Remove deprecated callers (#5911)\n\nCallers of 1) Windows#until.  2) Windows#of.  3) Serialized are replaced when possible with the new APIs.\n\nReviewers: Matthias J. Sax <mjsax@apache.org>.  Bill Bejeck <bill@confluent.io>","date":"2018-11-15 09:29:19","modifiedFileCount":"28","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2019-05-03 08:44:53","codes":[{"authorDate":"2018-11-15 09:29:19","commitOrder":6,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-11-15 09:29:19","endLine":460,"groupId":"22708","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b0/b87be51b5bf3cfefe52d9d1d5e277dc609a8b7.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":408,"status":"N"},{"authorDate":"2019-05-03 08:44:53","commitOrder":6,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","date":"2019-05-03 08:44:53","endLine":511,"groupId":"11047","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/24/f222bc1da87e910e919175ad4627d992cdb017.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(5L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 7L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/1]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@7/7]\", 1L, 7L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":460,"status":"M"}],"commitId":"eab855541a4b776b150a849cecda9c758598cdca","commitMessage":"@@@KAFKA-8289: Fix Session Expiration and Suppression (#6654)\n\nFix two problems in Streams:\n\n* Session windows expired prematurely (off-by-one error).  since the window end is inclusive.  unlike other windows\n* Suppress duration for sessions incorrectly waited only the grace period.  but session windows aren't closed until gracePeriod + sessionGap\n\nUpdate the tests accordingly\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  Boyang Chen <boyang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-05-03 08:44:53","modifiedFileCount":"5","status":"M","submitter":"John Roesler"},{"authorTime":"2019-05-13 06:31:44","codes":[{"authorDate":"2018-11-15 09:29:19","commitOrder":7,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2018-11-15 09:29:19","endLine":460,"groupId":"22708","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b0/b87be51b5bf3cfefe52d9d1d5e277dc609a8b7.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":408,"status":"N"},{"authorDate":"2019-05-13 06:31:44","commitOrder":7,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","date":"2019-05-13 06:31:44","endLine":518,"groupId":"11047","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a7/151cd686ab8785640f1f1539776e7e22e54f30.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory = new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 1L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":466,"status":"M"}],"commitId":"8a237f599afa539868a138b5a2534dbf884cb4ec","commitMessage":"@@@KAFKA-6455: Session Aggregation should use window-end-time as record timestamp (#6645)\n\nFor session-windows.  the result record should have the window-end timestamp as record timestamp.\n\nRebased to resolve merge conflicts. Removed unused classes TupleForwarder and ForwardingCacheFlushListener (replace with TimestampedTupleForwarder.  SessionTupleForwarder.  TimestampedCacheFlushListerner.  and SessionCacheFlushListener)\n\nReviewers: John Roesler <john@confluent.io>.  Bruno Cadonna <bruno@confluent.io>.  Boyang Chen <boyang@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-05-13 06:31:44","modifiedFileCount":"14","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-05-13 06:31:44","codes":[{"authorDate":"2019-05-18 07:48:07","commitOrder":8,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2019-05-18 07:48:07","endLine":463,"groupId":"22708","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/43/ad42ad013707c56fa3bb0665a4b93d911654ed.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"M"},{"authorDate":"2019-05-13 06:31:44","commitOrder":8,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","date":"2019-05-13 06:31:44","endLine":518,"groupId":"11047","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a7/151cd686ab8785640f1f1539776e7e22e54f30.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":466,"status":"N"}],"commitId":"6a2749faa63397caa93dae7bfdc3f1d0573a2ff4","commitMessage":"@@@KAFKA-6455: Improve DSL operator timestamp semantics (#6725)\n\nBasic idea:\nKTable-KTable join: set max(left-ts. right-ts) for result\n#agg(...) (stream/table windowed/non-windowed): set max(ts1.  ts2.  ts3. ...) of all input records that contribute to the aggregation result\nfor all stateless transformation: input-ts -> output-ts\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.   John Roesler <john@confluent.io>.  Andy Coates <andy@confluent.io>.   Bill Bejeck <bbejeck@gmail.com","date":"2019-05-18 07:48:07","modifiedFileCount":"61","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-10-07 16:01:58","codes":[{"authorDate":"2019-10-07 16:01:58","commitOrder":9,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 2L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 3L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 4L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2019-10-07 16:01:58","endLine":460,"groupId":"22708","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/f8670a87bb8a49ab586fa7a089eeef465f1118.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 2L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 3L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 4L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"M"},{"authorDate":"2019-10-07 16:01:58","commitOrder":9,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            \r\n            inputTopic.pipeInput(\"k2\", \"v1\", 6L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","date":"2019-10-07 16:01:58","endLine":515,"groupId":"8515","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/f8670a87bb8a49ab586fa7a089eeef465f1118.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        final ConsumerRecordFactory<String, String> recordFactory =\n            new ConsumerRecordFactory<>(STRING_SERIALIZER, STRING_SERIALIZER);\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 0L));\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 1L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k2\", \"v1\", 6L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 5L));\n            \r\n            driver.pipeInput(recordFactory.create(\"input\", \"k1\", \"v1\", 30L));\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":463,"status":"M"}],"commitId":"a5a6938c69f4310f7ec519036f0df77d8022326a","commitMessage":"@@@KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)\n\nImplements KIP-470\n\nReviewers: Bill Bejeck <bill@confluent.io>.  John Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2019-10-07 16:01:58","modifiedFileCount":"47","status":"M","submitter":"Jukka Karvanen"},{"authorTime":"2021-06-29 06:39:49","codes":[{"authorDate":"2019-10-07 16:01:58","commitOrder":10,"curCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 2L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 3L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 4L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","date":"2019-10-07 16:01:58","endLine":460,"groupId":"101741","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForTimeWindowsWithLargeJump","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/f8670a87bb8a49ab586fa7a089eeef465f1118.src","preCode":"    public void shouldSupportFinalResultsForTimeWindowsWithLargeJump() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(TimeWindows.of(ofMillis(2L)).grace(ofMillis(2L)))\n            .count(Materialized.<String, Long, WindowStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled().withKeySerde(STRING_SERDE));\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 2L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 3L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 4L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 2L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 1L, 2L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 3L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L),\n                    new KeyValueTimestamp<>(\"[k1@30/32]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/2]\", 4L, 1L),\n                    new KeyValueTimestamp<>(\"[k1@2/4]\", 2L, 3L),\n                    new KeyValueTimestamp<>(\"[k1@4/6]\", 1L, 4L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"N"},{"authorDate":"2021-06-29 06:39:49","commitOrder":10,"curCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            \r\n            inputTopic.pipeInput(\"k2\", \"v1\", 11L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@11/11]\", 1L, 11L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@11/11]\", 1L, 11L)\n                )\n            );\n        }\n    }\n","date":"2021-06-29 06:39:49","endLine":609,"groupId":"101741","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldSupportFinalResultsForSessionWindows","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e0/b7957e018a9b23062b38ba8f92d44104a78549.src","preCode":"    public void shouldSupportFinalResultsForSessionWindows() {\n        final StreamsBuilder builder = new StreamsBuilder();\n        final KTable<Windowed<String>, Long> valueCounts = builder\n            .stream(\"input\", Consumed.with(STRING_SERDE, STRING_SERDE))\n            .groupBy((String k, String v) -> k, Grouped.with(STRING_SERDE, STRING_SERDE))\n            .windowedBy(SessionWindows.with(ofMillis(5L)).grace(ofMillis(0L)))\n            .count(Materialized.<String, Long, SessionStore<Bytes, byte[]>>as(\"counts\").withCachingDisabled());\n        valueCounts\n            .suppress(untilWindowCloses(unbounded()))\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-suppressed\", Produced.with(STRING_SERDE, Serdes.Long()));\n        valueCounts\n            .toStream()\n            .map((final Windowed<String> k, final Long v) -> new KeyValue<>(k.toString(), v))\n            .to(\"output-raw\", Produced.with(STRING_SERDE, Serdes.Long()));\n        final Topology topology = builder.build();\n        System.out.println(topology.describe());\n        try (final TopologyTestDriver driver = new TopologyTestDriver(topology, config)) {\n            final TestInputTopic<String, String> inputTopic =\n                    driver.createInputTopic(\"input\", STRING_SERIALIZER, STRING_SERIALIZER);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 0L);\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 1L);\n            \r\n            inputTopic.pipeInput(\"k2\", \"v1\", 6L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 5L);\n            \r\n            inputTopic.pipeInput(\"k1\", \"v1\", 30L);\n            verify(\n                drainProducerRecords(driver, \"output-raw\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", 1L, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/0]\", null, 0L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 2L, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", null, 5L),\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L),\n                    new KeyValueTimestamp<>(\"[k1@30/30]\", 1L, 30L)\n                )\n            );\n            verify(\n                drainProducerRecords(driver, \"output-suppressed\", STRING_DESERIALIZER, LONG_DESERIALIZER),\n                asList(\n                    new KeyValueTimestamp<>(\"[k1@0/5]\", 3L, 5L),\n                    new KeyValueTimestamp<>(\"[k2@6/6]\", 1L, 6L)\n                )\n            );\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SuppressScenarioTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":557,"status":"M"}],"commitId":"cfcabc368c3f0a123c4561059b043648d79b1df8","commitMessage":"@@@KAFKA-12718: SessionWindows are closed too early (#10824)\n\nSession windows should not be close directly when \"window end\" time is reached.  but \"window close\" time should be \"window-end + gap + grace-period\".\n\nReviewer: Matthias J. Sax <matthias@confluent.io>","date":"2021-06-29 06:39:49","modifiedFileCount":"3","status":"M","submitter":"Juan Gonzalez-Zurita"}]
