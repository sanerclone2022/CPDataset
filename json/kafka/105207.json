[{"authorTime":"2016-02-24 14:47:31","codes":[{"authorDate":"2016-03-04 00:54:37","commitOrder":3,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, advertisedUrl.toString());\n        final Connect connect = new Connect(worker, herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-03-04 00:54:37","endLine":88,"groupId":"20336","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/84/9fa2f5ac1a38be525e0a4e2d935c6614e8e7f6.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, advertisedUrl.toString());\n        final Connect connect = new Connect(worker, herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"MB"},{"authorDate":"2016-02-24 14:47:31","commitOrder":3,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(worker, herder, rest);\n        connect.start();\n\n        try {\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-02-24 14:47:31","endLine":106,"groupId":"19931","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6c/4335e6b8d0e4a9752d0c8274bf8ac9fb9ab2ef.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(worker, herder, rest);\n        connect.start();\n\n        try {\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"NB"}],"commitId":"079c88178dff4b3a4c9de55629e7d15b60e5f562","commitMessage":"@@@KAFKA-2934; Offset storage file configuration in Connect standalone mode is not included in StandaloneConfig\n\nAdded offsetBackingStore config to StandaloneConfig and DistributedConfig;\nAdded config for offset.storage.topic and config.storage.topic into DistributedConfig;\n\nAuthor: jinxing <jinxing@fenbi.com>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #734 from ZoneMayor/trunk-KAFKA-2934\n","date":"2016-03-04 00:54:37","modifiedFileCount":"21","status":"M","submitter":"jinxing"},{"authorTime":"2016-04-21 05:09:59","codes":[{"authorDate":"2016-04-21 05:09:59","commitOrder":4,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-04-21 05:09:59","endLine":94,"groupId":"20336","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e7/a0c36c0c52fb8a7e6ac44a5e179b0a3619fd44.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, advertisedUrl.toString());\n        final Connect connect = new Connect(worker, herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2016-04-21 05:09:59","commitOrder":4,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        connect.start();\n\n        try {\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-04-21 05:09:59","endLine":106,"groupId":"19931","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/de18c878fc3ea1ab1d392fd926c96633b7029a.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(worker, herder, rest);\n        connect.start();\n\n        try {\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"c9485b78a6e43747daf1314ae9532839fb7bc810","commitMessage":"@@@KAFKA-2370: kafka connect pause/resume API\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Liquan Pei <liquanpei@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1087 from hachikuji/KAFKA-2370\n","date":"2016-04-21 05:09:59","modifiedFileCount":"29","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-05-09 14:52:13","codes":[{"authorDate":"2016-04-21 05:09:59","commitOrder":5,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-04-21 05:09:59","endLine":94,"groupId":"20336","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e7/a0c36c0c52fb8a7e6ac44a5e179b0a3619fd44.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"N"},{"authorDate":"2016-05-09 14:52:13","commitOrder":5,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-05-09 14:52:13","endLine":106,"groupId":"19931","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b7/5783cd2f7b1d59ba99a2f3184b8c28788820e9.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        connect.start();\n\n        try {\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"fc89083f812a513699f5f0c02648f7a7927acf64","commitMessage":"@@@MINOR: Move connect.start() to try catch block\n\nAuthor: Liquan Pei <liquanpei@gmail.com>\n\nReviewers: Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1347 from Ishiihara/connect-standalone\n","date":"2016-05-09 14:52:13","modifiedFileCount":"1","status":"M","submitter":"Liquan Pei"},{"authorTime":"2016-08-27 05:00:16","codes":[{"authorDate":"2016-08-27 05:00:16","commitOrder":6,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-08-27 05:00:42","endLine":96,"groupId":"18391","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7a/09ac3c5e78f78fb26d0c832fe6534b185ecab2.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"},{"authorDate":"2016-08-27 05:00:16","commitOrder":6,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-08-27 05:00:42","endLine":108,"groupId":"11843","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/a71af3f9834ee4c9f1fc3e2091a8fab978d88d.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"71f7e7c3a29e8f7339430837065126256907bd2a","commitMessage":"@@@KAFKA-4042: Contain connector & task start/stop failures within the Worker\n\nInvoke the statusListener.onFailure() callback on start failures so that the statusBackingStore is updated. This involved a fix to the putSafe() functionality which prevented any update that was not preceded by a (non-safe) put() from completing.  so here when a connector or task is transitioning directly to FAILED.\n\nWorker start methods can still throw if the same connector name or task ID is already registered with the worker.  as this condition should not happen.\n\nAuthor: Shikhar Bhushan <shikhar@confluent.io>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1778 from shikhar/distherder-stayup-take4\n","date":"2016-08-27 05:00:42","modifiedFileCount":"11","status":"M","submitter":"Shikhar Bhushan"},{"authorTime":"2016-08-27 05:00:16","codes":[{"authorDate":"2016-11-30 07:30:40","commitOrder":7,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-11-30 07:31:14","endLine":95,"groupId":"18391","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c3/a61b22f17ffd920070b76e93a7028576eec7fb.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter());\n        configBackingStore.configure(config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"},{"authorDate":"2016-08-27 05:00:16","commitOrder":7,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-08-27 05:00:42","endLine":108,"groupId":"11843","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/a71af3f9834ee4c9f1fc3e2091a8fab978d88d.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"N"}],"commitId":"d98ca230a14b0aedae752fa97f5d55b3a0c49b9c","commitMessage":"@@@KAFKA-4397: Refactor Connect backing stores for thread safety\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Shikhar Bhushan <shikhar@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #2123 from kkonstantine/KAFKA-4397-Refactor-connect-backing-stores-for-thread-safety\n","date":"2016-11-30 07:31:14","modifiedFileCount":"6","status":"M","submitter":"Konstantine Karantasis"},{"authorTime":"2016-12-02 22:00:58","codes":[{"authorDate":"2016-12-02 22:00:58","commitOrder":8,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-12-02 22:00:58","endLine":94,"groupId":"18391","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fc/957a73c35f8b77157d89595b6a3a25b49a3c69.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2016-12-02 22:00:58","commitOrder":8,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2016-12-02 22:00:58","endLine":107,"groupId":"11843","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c1/25a335e0f83de8fff540628a0c4a5b5d4e2b87.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = new SystemTime();\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"128d0ff91d84a3a1f5a5237133f9ec01caf18d66","commitMessage":"@@@KAFKA-2247; Merge kafka.utils.Time and kafka.common.utils.Time\n\nAlso:\n* Make all implementations of `Time` thread-safe as they are accessed from multiple threads in some cases.\n* Change default implementation of `MockTime` to use two separate variables for `nanoTime` and `currentTimeMillis` as they have different `origins`.\n\nAuthor: Ismael Juma <ismael@juma.me.uk>\n\nReviewers: Ewen Cheslack-Postava <ewen@confluent.io>.  Shikhar Bhushan <shikhar@confluent.io>.  Jason Gustafson <jason@confluent.io>.  Eno Thereska <eno.thereska@gmail.com>.  Damian Guy <damian.guy@gmail.com>\n\nCloses #2095 from ijuma/kafka-2247-consolidate-time-interfaces\n","date":"2016-12-02 22:00:58","modifiedFileCount":"26","status":"M","submitter":"Ismael Juma"},{"authorTime":"2017-02-03 06:22:31","codes":[{"authorDate":"2017-02-03 06:22:31","commitOrder":9,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-02-03 06:23:49","endLine":93,"groupId":"18391","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f9/cf2071aa516e2a1908b5a1baa55a058ed39fe9.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2017-02-03 06:22:31","commitOrder":9,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-02-03 06:23:49","endLine":106,"groupId":"11843","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6c/f04c253bc942b76d7adf092fb72674a4121919.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            System.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"}],"commitId":"cb674e5487f3f56647546b323dfe4fd45ccf0186","commitMessage":"@@@KAFKA-4039; Fix deadlock during shutdown due to log truncation not allowed\n\nAuthor: Maysam Yabandeh <myabandeh@dropbox.com>\nAuthor: Ismael Juma <ismael@juma.me.uk>\n\nReviewers: Jun Rao <junrao@gmail.com>\n\nCloses #2474 from ijuma/kafka-4039-deadlock-during-shutdown\n","date":"2017-02-03 06:23:49","modifiedFileCount":"12","status":"M","submitter":"Maysam Yabandeh"},{"authorTime":"2017-05-19 01:39:15","codes":[{"authorDate":"2017-05-19 01:39:15","commitOrder":10,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-05-19 01:39:15","endLine":93,"groupId":"0","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/71/7ccd9f8c6905ee5f5c3aeec5efa848892dc4b6.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2017-05-19 01:39:15","commitOrder":10,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-05-19 01:39:15","endLine":106,"groupId":"0","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/d0e59185e0a222708b91609560a6b07ff7c45d.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        ConnectorFactory connectorFactory = new ConnectorFactory();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, connectorFactory, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"}],"commitId":"45f2261763eac5caaebf860daab32ef5337c9293","commitMessage":"@@@KAFKA-3487: Support classloading isolation in Connect (KIP-146)\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Randall Hauch <rhauch@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #3028 from kkonstantine/KAFKA-3487-Support-classloading-isolation-in-Connect\n","date":"2017-05-19 01:39:15","modifiedFileCount":"26","status":"M","submitter":"Konstantine Karantasis"},{"authorTime":"2017-09-28 13:07:37","codes":[{"authorDate":"2017-09-28 13:07:37","commitOrder":11,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-09-28 13:07:37","endLine":101,"groupId":"0","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1b/2f94e461377f4ac977eff26a446dcdfa23f435.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2017-09-28 13:07:37","commitOrder":11,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2017-09-28 13:07:37","endLine":114,"groupId":"6695","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/1c6b51d3b0dd8cd85c4166933aae441efeaf28.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        Time time = Time.SYSTEM;\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        \n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"}],"commitId":"1444b7b594f9c0c426a3631ec43d77b19c8f4373","commitMessage":"@@@KAFKA-5867: Log Kafka Connect worker info during startup\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Randall Hauch <rhauch@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #3932 from kkonstantine/KAFKA-5867-Kafka-Connect-applications-should-log-info-message-when-starting-up\n","date":"2017-09-28 13:07:37","modifiedFileCount":"2","status":"M","submitter":"Konstantine Karantasis"},{"authorTime":"2018-01-05 23:52:50","codes":[{"authorDate":"2018-01-05 23:52:50","commitOrder":12,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-01-05 23:52:50","endLine":105,"groupId":"15878","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/a77ed06c944dd5d74d6d8ec3ad58f12a7f4104.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2018-01-05 23:52:50","commitOrder":12,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-01-05 23:52:50","endLine":117,"groupId":"6695","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/17/69905354171a33a0a21389ee28fecfabf4fb77.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"bfb272c5cdb227040d862f0ab7337df68f787764","commitMessage":"@@@KAFKA-6311: Expose Kafka cluster ID in Connect REST API (KIP-238) (#4314)\n\nReviewers: Konstantine Karantasis <konstantine@confluent.io>.  Randall Hauch <rhauch@gmail.com>.  Jason Gustafson <jason@confluent.io>","date":"2018-01-05 23:52:50","modifiedFileCount":"15","status":"M","submitter":"Ewen Cheslack-Postava"},{"authorTime":"2018-01-05 23:52:50","codes":[{"authorDate":"2018-02-14 08:39:21","commitOrder":13,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        Converter internalValueConverter = worker.getInternalValueConverter();\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-02-14 08:39:21","endLine":107,"groupId":"15878","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4a/fa47dda1ae2d594f5da4d93e82b773ac4faf96.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, worker.getInternalValueConverter());\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(worker.getInternalValueConverter(), config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"},{"authorDate":"2018-01-05 23:52:50","commitOrder":13,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-01-05 23:52:50","endLine":117,"groupId":"6695","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/17/69905354171a33a0a21389ee28fecfabf4fb77.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"2693e9be7412ec03173c8942e9ccfcc24cfbbce1","commitMessage":"@@@MINOR: Misc improvements on runtime / storage / metrics / config parts (#4525)\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2018-02-14 08:39:21","modifiedFileCount":"7","status":"M","submitter":"Benedict Jin"},{"authorTime":"2018-02-22 17:39:59","codes":[{"authorDate":"2018-02-22 17:39:59","commitOrder":14,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n        log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        Converter internalValueConverter = worker.getInternalValueConverter();\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-02-22 17:39:59","endLine":108,"groupId":"12303","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3b/7ec87f64450b792a886e610f09fd2f8a7c82d5.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        Converter internalValueConverter = worker.getInternalValueConverter();\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"},{"authorDate":"2018-02-22 17:39:59","commitOrder":14,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n        log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","date":"2018-02-22 17:39:59","endLine":118,"groupId":"6695","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/41/3cb46cf28988044d3a248abd88b6f0593dd17b.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"fc19c3e6f243a8d1b3e27cdc912dc092bbd342e0","commitMessage":"@@@KAFKA-6577: Fix Connect system tests and add debug messages\n\n**NOTE: This should be backported to the `1.1` branch.  and is currently a blocker for 1.1.**\n\nThe `connect_test.py::ConnectStandaloneFileTest.test_file_source_and_sink` system test is failing with the SASL configuration without a sufficient explanation. During the test.  the Connect worker fails to start.  but the Connect log contains no useful information. There are actual several things compounding to cause the failure and make it difficult to understand the problem.\n\nFirst.  the `tests/kafkatest/tests/connect/templates/connect_standalone.properties` is only adding in the broker's security configuration with the `producer.` and `consumer.` prefixes.  but is not adding them with no prefix. The worker uses the AdminClient to connect to the broker to get the Kafka cluster ID and to manage the three internal topics.  and the AdminClient is configured via top-level properties. Because the SASL test requires the clients all connect using SASL.  the lack of broker security configs means the AdminClient was attempting and failing to connect to the broker. This is corrected by adding the broker's security configuration to the Connect worker configuration file at the top-level. (This was already being done in the `connect_distributed.properties` file.)\n\nSecond.  the default `request.timeout.ms` for the AdminClient (and the other clients) is 120 seconds.  so the AdminClient was retrying for 120 seconds before it would give up and thrown an error. However.  the test was only waiting for 60 seconds before determining that the service failed to start. This can be corrected by setting `request.timeout.ms=10000` in the Connect distributed and standalone worker configurations.\n\nThird.  the Connect workers were recently changed to lookup the Kafka cluster ID before it started the herder. This is unlike the older uses of the AdminClient to find and manage the internal topics.  where failure to connect was not necessarily logged correctly but nevertheless still skipped over.  relying upon broker auto-topic creation to create the internal topics. (This may be why the test did not fail prior to the recent change to always require a successful AdminClient connection.) Although the worker never got this far in its startup process.  the fact that we missed such an error since the prior releases means that failure to connect with the AdminClient was not being properly reported.\n\nThe `ConnectStandaloneFileTest.test_file_source_and_sink` system tests were run locally prior to this fix.  and they failed as with the nightlies. Once these fixes were made.  the locally run system tests passed.\n\nAuthor: Randall Hauch <rhauch@gmail.com>\n\nReviewers: Konstantine Karantasis <konstantine@confluent.io>.  Ewen Cheslack-Postava <me@ewencp.org>\n\nCloses #4610 from rhauch/kafka-6577-trunk\n","date":"2018-02-22 17:39:59","modifiedFileCount":"6","status":"M","submitter":"Randall Hauch"},{"authorTime":"2018-02-23 14:29:49","codes":[{"authorDate":"2018-02-23 14:29:49","commitOrder":15,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-02-23 14:29:49","endLine":115,"groupId":"12303","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/54/854fe4b8077db30f0d11bc2e2654c5111de0e0.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect distributed worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        DistributedConfig config = new DistributedConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n        log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n        offsetBackingStore.configure(config);\n\n        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n        Converter internalValueConverter = worker.getInternalValueConverter();\n        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n        statusBackingStore.configure(config);\n\n        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n        DistributedHerder herder = new DistributedHerder(config, time, worker,\n                kafkaClusterId, statusBackingStore, configBackingStore,\n                advertisedUrl.toString());\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n        try {\n            connect.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start Connect\", e);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":55,"status":"M"},{"authorDate":"2018-02-23 14:29:49","commitOrder":15,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-02-23 14:29:49","endLine":125,"groupId":"6695","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ab/a9d9c32aa4bd707f6eedb85cfe7fc7772cb32c.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        Time time = Time.SYSTEM;\n        log.info(\"Kafka Connect standalone worker initializing ...\");\n        long initStart = time.hiResClockMs();\n        WorkerInfo initInfo = new WorkerInfo();\n        initInfo.logAll();\n\n        String workerPropsFile = args[0];\n        Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n        log.info(\"Scanning for plugin classes. This might take a moment ...\");\n        Plugins plugins = new Plugins(workerProps);\n        plugins.compareAndSwapWithDelegatingLoader();\n        StandaloneConfig config = new StandaloneConfig(workerProps);\n\n        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n        log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n        RestServer rest = new RestServer(config);\n        URI advertisedUrl = rest.advertisedUrl();\n        String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n        Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n        Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n        final Connect connect = new Connect(herder, rest);\n        log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n        try {\n            connect.start();\n            for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                    @Override\n                    public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    }\n                });\n                herder.putConnectorConfig(\n                        connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                        connectorProps, false, cb);\n                cb.get();\n            }\n        } catch (Throwable t) {\n            log.error(\"Stopping after connector error\", t);\n            connect.stop();\n        }\n\n        \r\n        connect.awaitStop();\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"0e22fd6f8d49e7884b7126d963af12ab305d5629","commitMessage":"@@@KAFKA-6578: Changed the Connect distributed and standalone main method to log all exceptions (#4609)\n\nAny exception thrown by calls within a `main()` method are not logged unless explicitly done so. This change simply adds a try-catch block around most of the content of the distributed and standalone `main()` methods.","date":"2018-02-23 14:29:49","modifiedFileCount":"2","status":"M","submitter":"Randall Hauch"},{"authorTime":"2018-02-23 14:29:49","codes":[{"authorDate":"2018-05-31 05:43:11","commitOrder":16,"curCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n            WorkerConfigTransformer configTransformer = worker.configTransformer();\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                    internalValueConverter,\n                    config,\n                    configTransformer);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-05-31 05:43:11","endLine":120,"groupId":"21821","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f8/c15de8ef4a961dae39dba8e5a47832d3b9d0db.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"},{"authorDate":"2018-02-23 14:29:49","commitOrder":16,"curCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-02-23 14:29:49","endLine":125,"groupId":"6695","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ab/a9d9c32aa4bd707f6eedb85cfe7fc7772cb32c.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"08e8facdc9fce3a9195f5f646b49f55ffa043c73","commitMessage":"@@@KAFKA-6886: Externalize secrets from Connect configs (KIP-297)\n\nThis commit allows secrets in Connect configs to be externalized and replaced with variable references of the form `${provider:[path:]key}`.  where the \"path\" is optional.\n\nThere are 2 main additions to `org.apache.kafka.common.config`: a `ConfigProvider` and a `ConfigTransformer`.  The `ConfigProvider` is an interface that allows key-value pairs to be provided by an external source for a given \"path\".  An a TTL can be associated with the key-value pairs returned from the path.  The `ConfigTransformer` will use instances of `ConfigProvider` to replace variable references in a set of configuration values.\n\nIn the Connect framework.  `ConfigProvider` classes can be specified in the worker config.  and then variable references can be used in the connector config.  In addition.  the herder can be configured to restart connectors (or not) based on the TTL returned from a `ConfigProvider`.  The main class that performs restarts and transformations is `WorkerConfigTransformer`.\n\nFinally.  a `configs()` method has been added to both `SourceTaskContext` and `SinkTaskContext`.  This allows connectors to get configs with variables replaced by the latest values from instances of `ConfigProvider`.\n\nMost of the other changes in the Connect framework are threading various objects through classes to enable the above functionality.\n\nAuthor: Robert Yokota <rayokota@gmail.com>\nAuthor: Ewen Cheslack-Postava <me@ewencp.org>\n\nReviewers: Randall Hauch <rhauch@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5068 from rayokota/KAFKA-6886-connect-secrets\n","date":"2018-05-31 05:43:11","modifiedFileCount":"30","status":"M","submitter":"Robert Yokota"},{"authorTime":"2018-11-22 19:42:34","codes":[{"authorDate":"2018-11-22 19:42:34","commitOrder":17,"curCode":"    public static void main(String[] args) {\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n            WorkerConfigTransformer configTransformer = worker.configTransformer();\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                    internalValueConverter,\n                    config,\n                    configTransformer);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-11-22 19:42:34","endLine":121,"groupId":"21821","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dd/43c37cadda5b4739f1685b7aa6e5dff2b58d2f.src","preCode":"    public static void main(String[] args) throws Exception {\n        if (args.length < 1) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n            WorkerConfigTransformer configTransformer = worker.configTransformer();\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                    internalValueConverter,\n                    config,\n                    configTransformer);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"},{"authorDate":"2018-11-22 19:42:34","commitOrder":17,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-11-22 19:42:34","endLine":125,"groupId":"6695","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/34/98ffe45c76deb565b07e0a417a1bad04bf722d.src","preCode":"    public static void main(String[] args) throws Exception {\n\n        if (args.length < 2) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"ad26914de65e2db244fbe36a2a5fd03de87dfb79","commitMessage":"@@@KAFKA-7418: Add the missing '--help' option to Kafka commands (KIP-374)\n\nChanges made as part of this [KIP-374](https://cwiki.apache.org/confluence/x/FgSQBQ) and [KAFKA-7418](https://issues.apache.org/jira/browse/KAFKA-7418)\n - Checking for empty args or help option in command file to print Usage\n - Added new class to enforce help option to all commands\n - Refactored few lines (ex `PreferredReplicaLeaderElectionCommand`) to\n   make use of `CommandDefaultOptions` attributes.\n - Made the changes in help text wordings\n\nRun the unit tests in local(Windows) few Linux friendly tests are failing but\nnot any functionality.  verified `--help` and no option response by running\nScala classes.  since those all are having `main` method.\n\nAuthor: Srinivas Reddy <srinivas96alluri@gmail.com>\nAuthor: Srinivas Reddy <mrsrinivas@users.noreply.github.com>\nAuthor: Srinivas <srinivas96alluri@gmail.com>\n\nReviewers: Colin Patrick McCabe <colin@cmccabe.xyz>.  Manikumar Reddy <manikumar.reddy@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Mickael Maison <mickael.maison@gmail.com>\n\nCloses #5910 from mrsrinivas/KIP-374\n","date":"2018-11-22 19:42:34","modifiedFileCount":"3","status":"M","submitter":"Srinivas Reddy"},{"authorTime":"2018-11-22 19:42:34","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":18,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"12329","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect distributed worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            DistributedConfig config = new DistributedConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n            offsetBackingStore.configure(config);\n\n            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);\n            WorkerConfigTransformer configTransformer = worker.configTransformer();\n\n            Converter internalValueConverter = worker.getInternalValueConverter();\n            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n            statusBackingStore.configure(config);\n\n            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                    internalValueConverter,\n                    config,\n                    configTransformer);\n\n            DistributedHerder herder = new DistributedHerder(config, time, worker,\n                    kafkaClusterId, statusBackingStore, configBackingStore,\n                    advertisedUrl.toString());\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect distributed worker initialization took {}ms\", time.hiResClockMs() - initStart);\n            try {\n                connect.start();\n            } catch (Exception e) {\n                log.error(\"Failed to start Connect\", e);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"},{"authorDate":"2018-11-22 19:42:34","commitOrder":18,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2018-11-22 19:42:34","endLine":125,"groupId":"6695","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/34/98ffe45c76deb565b07e0a417a1bad04bf722d.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"}],"commitId":"69d8d2ea11c5e08884ab4c7b8079af5fd21247be","commitMessage":"@@@KAFKA-7503: Connect integration test harness\n\nExpose a programmatic way to bring up a Kafka and Zk cluster through Java API to facilitate integration tests for framework level changes in Kafka Connect. The Kafka classes would be similar to KafkaEmbedded in streams. The new classes would reuse the kafka.server.KafkaServer classes from :core.  and provide a simple interface to bring up brokers in integration tests.\n\nSigned-off-by: Arjun Satish <arjunconfluent.io>\n\nAuthor: Arjun Satish <arjun@confluent.io>\nAuthor: Arjun Satish <wicknicks@users.noreply.github.com>\n\nReviewers: Randall Hauch <rhauch@gmail.com>.  Konstantine Karantasis <konstantine@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #5516 from wicknicks/connect-integration-test\n","date":"2019-01-15 05:50:23","modifiedFileCount":"12","status":"M","submitter":"Arjun Satish"},{"authorTime":"2019-01-17 14:58:30","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":19,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"12329","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2019-01-17 14:58:30","commitOrder":19,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            HerderProvider provider = new HerderProvider();\n            rest.start(provider, plugins);\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                \r\n                provider.setHerder(herder);\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-17 14:58:30","endLine":131,"groupId":"0","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dd/1cf0f7a307b53704c3021e5d0960ac238ca58c.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"dec68c9350dba6da9f38247db08f93dc0a798ebd","commitMessage":"@@@MINOR: Start Connect REST server in standalone mode to match distributed mode (KAFKA-7503 follow-up)\n\nStart the Rest server in the standalone mode similar to how it's done for distributed mode.\n\nAuthor: Magesh Nandakumar <magesh.n.kumar@gmail.com>\n\nReviewers: Arjun Satish <arjun@confluent.io>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #6148 from mageshn/KAFKA-7826\n","date":"2019-01-17 14:58:30","modifiedFileCount":"1","status":"M","submitter":"Magesh Nandakumar"},{"authorTime":"2019-05-08 06:20:51","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":20,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"12329","id":35,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2019-05-08 06:20:51","commitOrder":20,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-05-08 06:20:51","endLine":127,"groupId":"0","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/49/9e6dfdfe93f827ee29c9a0e9d4bf74ed690d04.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            HerderProvider provider = new HerderProvider();\n            rest.start(provider, plugins);\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                \r\n                provider.setHerder(herder);\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"}],"commitId":"cc097e909c7e5b1617565e4456f5328a826eafbc","commitMessage":"@@@KAFKA-8304: Fix registration of Connect REST extensions (#6651)\n\nFix registration of Connect REST extensions to prevent deadlocks when extensions get the list of connectors before the herder is available. Added integration test to check the behavior.\n\nAuthor: Chris Egerton <cegerton@oberlin.edu>\nReviewers: Arjun Satish <arjun@confluent.io>.  Randall Hauch <rhauch@gmail.com>","date":"2019-05-08 06:20:51","modifiedFileCount":"14","status":"M","submitter":"Chris Egerton"},{"authorTime":"2019-05-17 16:37:32","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":21,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"12329","id":37,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2019-05-17 16:37:32","commitOrder":21,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                config, ConnectorClientConfigOverridePolicy.class);\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n                                       connectorClientConfigOverridePolicy);\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId, connectorClientConfigOverridePolicy);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-05-17 16:37:32","endLine":133,"groupId":"8847","id":38,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cf/7b93bd7c838645091ece0b441cd99203f7446d.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"2e91a310d7bf9e7d4d46b0bc0ca0c11cb4531e10","commitMessage":"@@@KAFKA-8265: Initial implementation for ConnectorClientConfigPolicy to enable overrides (KIP-458) (#6624)\n\nImplementation to enable policy for Connector Client config overrides. This is\nimplemented per the KIP-458.\n\nReviewers: Randall Hauch <rhauch@gmail.com>","date":"2019-05-17 16:37:32","modifiedFileCount":"22","status":"M","submitter":"Magesh Nandakumar"},{"authorTime":"2021-02-05 01:15:49","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":22,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"12329","id":39,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2021-02-05 01:15:49","commitOrder":22,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                config, ConnectorClientConfigOverridePolicy.class);\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n                                       connectorClientConfigOverridePolicy);\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId, connectorClientConfigOverridePolicy);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>((error, info) -> {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2021-02-05 01:15:49","endLine":129,"groupId":"8847","id":40,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/15/5e6cf7dc6014b5293e512448ed01210decedee.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                config, ConnectorClientConfigOverridePolicy.class);\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n                                       connectorClientConfigOverridePolicy);\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId, connectorClientConfigOverridePolicy);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>(new Callback<Herder.Created<ConnectorInfo>>() {\n                        @Override\n                        public void onCompletion(Throwable error, Herder.Created<ConnectorInfo> info) {\n                            if (error != null)\n                                log.error(\"Failed to create job for {}\", connectorPropsFile);\n                            else\n                                log.info(\"Created connector {}\", info.result().name());\n                        }\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"c19a35d1b740c85559a7ff4e882fc95b4737808d","commitMessage":"@@@KAFKA-10835: Replace Runnable and Callable overrides with lambdas in Connect (#9867)\n\nReviewers: Konstantine Karantasis <k.karantasis@gmail.com>","date":"2021-02-05 01:15:49","modifiedFileCount":"50","status":"M","submitter":"Lev Zemlyanov"},{"authorTime":"2021-02-05 09:08:56","codes":[{"authorDate":"2019-01-15 05:50:23","commitOrder":23,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2019-01-15 05:50:23","endLine":86,"groupId":"105207","id":41,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/c6d98facacc58163a90b57acd9edabbcfe19fc.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 1 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectDistributed worker.properties\");\n            Exit.exit(1);\n        }\n\n        try {\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            ConnectDistributed connectDistributed = new ConnectDistributed();\n            Connect connect = connectDistributed.startConnect(workerProps);\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"N"},{"authorDate":"2021-02-05 09:08:56","commitOrder":23,"curCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                config, ConnectorClientConfigOverridePolicy.class);\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n                                       connectorClientConfigOverridePolicy);\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId, connectorClientConfigOverridePolicy);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>((error, info) -> {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","date":"2021-02-05 09:08:56","endLine":129,"groupId":"105207","id":42,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/19/cc115d9ddc412d1f9744b76bdc94f8a7b0a122.src","preCode":"    public static void main(String[] args) {\n\n        if (args.length < 2 || Arrays.asList(args).contains(\"--help\")) {\n            log.info(\"Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]\");\n            Exit.exit(1);\n        }\n\n        try {\n            Time time = Time.SYSTEM;\n            log.info(\"Kafka Connect standalone worker initializing ...\");\n            long initStart = time.hiResClockMs();\n            WorkerInfo initInfo = new WorkerInfo();\n            initInfo.logAll();\n\n            String workerPropsFile = args[0];\n            Map<String, String> workerProps = !workerPropsFile.isEmpty() ?\n                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.<String, String>emptyMap();\n\n            log.info(\"Scanning for plugin classes. This might take a moment ...\");\n            Plugins plugins = new Plugins(workerProps);\n            plugins.compareAndSwapWithDelegatingLoader();\n            StandaloneConfig config = new StandaloneConfig(workerProps);\n\n            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);\n            log.debug(\"Kafka cluster ID: {}\", kafkaClusterId);\n\n            RestServer rest = new RestServer(config);\n            rest.initializeServer();\n\n            URI advertisedUrl = rest.advertisedUrl();\n            String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n\n            ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                config, ConnectorClientConfigOverridePolicy.class);\n            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n                                       connectorClientConfigOverridePolicy);\n\n            Herder herder = new StandaloneHerder(worker, kafkaClusterId, connectorClientConfigOverridePolicy);\n            final Connect connect = new Connect(herder, rest);\n            log.info(\"Kafka Connect standalone worker initialization took {}ms\", time.hiResClockMs() - initStart);\n\n            try {\n                connect.start();\n                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {\n                    Map<String, String> connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));\n                    FutureCallback<Herder.Created<ConnectorInfo>> cb = new FutureCallback<>((error, info) -> {\n                        if (error != null)\n                            log.error(\"Failed to create job for {}\", connectorPropsFile);\n                        else\n                            log.info(\"Created connector {}\", info.result().name());\n                    });\n                    herder.putConnectorConfig(\n                            connectorProps.get(ConnectorConfig.NAME_CONFIG),\n                            connectorProps, false, cb);\n                    cb.get();\n                }\n            } catch (Throwable t) {\n                log.error(\"Stopping after connector error\", t);\n                connect.stop();\n                Exit.exit(3);\n            }\n\n            \r\n            connect.awaitStop();\n\n        } catch (Throwable t) {\n            log.error(\"Stopping due to error\", t);\n            Exit.exit(2);\n        }\n    }\n","realPath":"connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"07843cfbf4e3e7a2d26d63904bbf0da0fcd07ca2","commitMessage":"@@@KAFKA-10834: Remove redundant type casts in Connect (#10053)\n\nCleanup up to remove redundant type casts in Connect and use the diamond operator when needed \n\nReviewers: Konstantine Karantasis <k.karantasis@gmail.com>","date":"2021-02-05 09:08:56","modifiedFileCount":"41","status":"M","submitter":"Lev Zemlyanov"}]
