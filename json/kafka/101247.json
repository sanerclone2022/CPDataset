[{"authorTime":"2020-02-12 09:31:13","codes":[{"authorDate":"2019-10-05 08:07:30","commitOrder":3,"curCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","date":"2019-10-05 08:07:30","endLine":357,"groupId":"19178","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setUpMetricsMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/2c02ed4d4c217ac4a1cd38206c65b27bc2277b.src","preCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":328,"status":"NB"},{"authorDate":"2020-02-12 09:31:13","commitOrder":3,"curCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-02-12 09:31:13","endLine":390,"groupId":"19846","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpMetricsStubMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fc/60c2784b35a1a5eaa8ed3319e290d0b860b502.src","preCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":361,"status":"B"}],"commitId":"cde6d18983b5d58199f8857d8d61d7efcbe6e54a","commitMessage":"@@@KAFKA-9355: Fix bug that removed RocksDB metrics after failure in EOS (#7996)\n\n* Added init() method to RocksDBMetricsRecorder\n* Added call to init() of RocksDBMetricsRecorder to init() of RocksDB store\n* Added call to init() of RocksDBMetricsRecorder to openExisting() of segmented state stores\n* Adapted unit tests\n* Added integration test that reproduces the situation in which the bug occurred\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-02-12 09:31:13","modifiedFileCount":"10","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-08-14 03:40:40","codes":[{"authorDate":"2020-08-14 03:40:40","commitOrder":4,"curCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-08-14 03:40:40","endLine":475,"groupId":"19178","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setUpMetricsMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1e/cedca4482401bc356ea168d525594b8098dbc2.src","preCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":446,"status":"M"},{"authorDate":"2020-08-14 03:40:40","commitOrder":4,"curCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-08-14 03:40:40","endLine":506,"groupId":"19846","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpMetricsStubMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1e/cedca4482401bc356ea168d525594b8098dbc2.src","preCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, taskId1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":477,"status":"M"}],"commitId":"5645d906fa319206a9270c080926a21dfddc852a","commitMessage":"@@@KAFKA-9924: Prepare RocksDB and metrics for RocksDB properties recording (#9098)\n\nRefactor the RocksDB store and the metrics infrastructure in Streams\nin preparation of the recordings of the RocksDB properties specified in KIP-607.\n\nThe refactoring includes:\n* wrapper around BlockedBasedTableConfig to make the cache accessible to the\n  RocksDB metrics recorder\n* RocksDB metrics recorder now takes also the DB instance and the cache in addition\n  to the statistics\n* The value providers for the metrics are added to the RockDB metrics recorder also if\n  the recording level is INFO.\n* The creation of the RocksDB metrics recording trigger is moved to StreamsMetricsImpl\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  John Roesler <vvcephei@apache.org>\n","date":"2020-08-14 03:40:40","modifiedFileCount":"27","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-08-28 07:04:28","codes":[{"authorDate":"2020-08-28 07:04:28","commitOrder":5,"curCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-08-28 07:04:28","endLine":476,"groupId":"19178","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setUpMetricsMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/3cf97f40ebe7d91faf42313c00e81dc741f3f3.src","preCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":446,"status":"M"},{"authorDate":"2020-08-28 07:04:28","commitOrder":5,"curCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-08-28 07:04:28","endLine":508,"groupId":"19846","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpMetricsStubMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/3cf97f40ebe7d91faf42313c00e81dc741f3f3.src","preCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(THREAD_ID, TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":478,"status":"M"}],"commitId":"9da32b6bd014f1bdeeee5da8fcd00995a5916323","commitMessage":"@@@KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)\n\n* Add the first RocksDB metric that exposes a RocksDB property: num-entries-active-mem-table.\n* Add code StreamsMetricsImpl in support of exposing RocksDB properties\n* unit tests and intergration tests\n\nThis commit only contains one metric to keep the PR at a reasonable size.\nAll other RocksDB metrics described in KIP-607 will be added in other PRs.\n\nImplements: KIP-607\nReviewers: Guozhang Wang <guozhang@apache.org>.  John Roesler <vvcephei@apache.org>","date":"2020-08-28 07:04:28","modifiedFileCount":"22","status":"M","submitter":"Bruno Cadonna"},{"authorTime":"2020-09-03 06:32:17","codes":[{"authorDate":"2020-09-03 06:32:17","commitOrder":6,"curCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumImmutableMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCurSizeActiveMemTable(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCurSizeAllMemTables(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addSizeAllMemTables(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumEntriesImmMemTablesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumDeletesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumDeletesImmMemTablesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addMemTableFlushPending(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumRunningFlushesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCompactionPendingMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumRunningCompactionsMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimatePendingCompactionBytesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addTotalSstFilesSizeMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addLiveSstFilesSizeMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumLiveVersionMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCacheCapacityMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCacheUsageMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCachePinnedUsageMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimateNumKeysMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimateTableReadersMemMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBackgroundErrorsMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-09-03 06:32:17","endLine":584,"groupId":"101247","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"setUpMetricsMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/08f845fe1ab0f23d5e4562ed76a3255acb92ab.src","preCode":"    private void setUpMetricsMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(eq(streamsMetrics), eq(metricsContext)))\n            .andReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":533,"status":"M"},{"authorDate":"2020-09-03 06:32:17","commitOrder":6,"curCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumImmutableMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCurSizeActiveMemTable(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCurSizeAllMemTables(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addSizeAllMemTables(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumEntriesImmMemTablesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumDeletesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumDeletesImmMemTablesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addMemTableFlushPending(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumRunningFlushesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addCompactionPendingMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumRunningCompactionsMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimatePendingCompactionBytesMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addTotalSstFilesSizeMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addLiveSstFilesSizeMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addNumLiveVersionMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCacheCapacityMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCacheUsageMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBlockCachePinnedUsageMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimateNumKeysMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addEstimateTableReadersMemMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        RocksDBMetrics.addBackgroundErrorsMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","date":"2020-09-03 06:32:17","endLine":637,"groupId":"101247","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"setUpMetricsStubMock","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/08f845fe1ab0f23d5e4562ed76a3255acb92ab.src","preCode":"    private void setUpMetricsStubMock() {\n        mockStatic(RocksDBMetrics.class);\n        final RocksDBMetricContext metricsContext =\n            new RocksDBMetricContext(TASK_ID1.toString(), METRICS_SCOPE, STORE_NAME);\n        expect(RocksDBMetrics.bytesWrittenToDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenToDatabaseSensor);\n        expect(RocksDBMetrics.bytesReadFromDatabaseSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadFromDatabaseSensor);\n        expect(RocksDBMetrics.memtableBytesFlushedSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableBytesFlushedSensor);\n        expect(RocksDBMetrics.memtableHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(memtableHitRatioSensor);\n        expect(RocksDBMetrics.writeStallDurationSensor(streamsMetrics, metricsContext))\n            .andStubReturn(writeStallDurationSensor);\n        expect(RocksDBMetrics.blockCacheDataHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheDataHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheIndexHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheIndexHitRatioSensor);\n        expect(RocksDBMetrics.blockCacheFilterHitRatioSensor(streamsMetrics, metricsContext))\n            .andStubReturn(blockCacheFilterHitRatioSensor);\n        expect(RocksDBMetrics.bytesWrittenDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesWrittenDuringCompactionSensor);\n        expect(RocksDBMetrics.bytesReadDuringCompactionSensor(streamsMetrics, metricsContext))\n            .andStubReturn(bytesReadDuringCompactionSensor);\n        expect(RocksDBMetrics.numberOfOpenFilesSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfOpenFilesSensor);\n        expect(RocksDBMetrics.numberOfFileErrorsSensor(streamsMetrics, metricsContext))\n            .andStubReturn(numberOfFileErrorsSensor);\n        RocksDBMetrics.addNumEntriesActiveMemTableMetric(eq(streamsMetrics), eq(metricsContext), anyObject());\n        replay(RocksDBMetrics.class);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/state/internals/metrics/RocksDBMetricsRecorderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":586,"status":"M"}],"commitId":"c04000cab1e98c206c5410ef68d00df1d9129182","commitMessage":"@@@KAFKA-9924: Add remaining property-based RocksDB metrics as described in KIP-607 (#9232)\n\nThis commit adds the remaining property-based RocksDB metrics as described in KIP-607.  except for num-entries-active-mem-table.  which was added in PR #9177.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-09-03 06:32:17","modifiedFileCount":"8","status":"M","submitter":"Bruno Cadonna"}]
