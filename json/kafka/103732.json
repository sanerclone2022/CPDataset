[{"authorTime":"2020-01-23 05:48:36","codes":[{"authorDate":"2020-06-24 05:07:14","commitOrder":2,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2020-06-24 05:07:14","endLine":876,"groupId":"22421","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/68/667b9bdddbae44088a9e0108c17c0da6c00c7f.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":854,"status":"B"},{"authorDate":"2020-01-23 05:48:36","commitOrder":2,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","date":"2020-01-23 05:48:36","endLine":737,"groupId":"13757","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e5/dc27e0abc59315884f7ac82eb2a5f821479496.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":703,"status":"NB"}],"commitId":"a047a7c0ebd8401e11ac9bde69a1a2b3e1f15377","commitMessage":"@@@KAFKA-9439: add KafkaProducer API unit tests (#8174)\n\nAdd unit tests for KafkaProducer.close().  KafkaProducer.abortTransaction().  and KafkaProducer.flush() in the KafkaProducerTest.\n\nIncrease KafkaProducer test code coverage from 82% methods.  82% lines to 86% methods.  87% lines when being merged.\n\nReviewers: Boyang Chen <boyang@confluent.io>","date":"2020-06-24 05:07:14","modifiedFileCount":"1","status":"M","submitter":"Jeff Kim"},{"authorTime":"2020-12-03 10:34:27","codes":[{"authorDate":"2020-12-03 10:34:27","commitOrder":3,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2020-12-03 10:34:27","endLine":875,"groupId":"22421","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/81/53c2f7b4acfc37a7d35d784a10676b21629faa.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":853,"status":"M"},{"authorDate":"2020-12-03 10:34:27","commitOrder":3,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","date":"2020-12-03 10:34:27","endLine":912,"groupId":"13757","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/81/53c2f7b4acfc37a7d35d784a10676b21629faa.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = new KafkaProducer<>(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":878,"status":"M"}],"commitId":"e63f591ec4d4664608286072c31127323371cb96","commitMessage":"@@@KAFKA-10090 Misleading warnings: The configuration was supplied but i? (#8826)\n\nReviewers: Jun Rao <junrao@gmail.com>","date":"2020-12-03 10:34:27","modifiedFileCount":"10","status":"M","submitter":"Chia-Ping Tsai"},{"authorTime":"2020-12-10 03:15:58","codes":[{"authorDate":"2020-12-10 03:15:58","commitOrder":4,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2020-12-10 03:15:58","endLine":876,"groupId":"22421","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/ef6f688f8690f65949cd2807f1d8693abcf60c.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":854,"status":"M"},{"authorDate":"2020-12-10 03:15:58","commitOrder":4,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","date":"2020-12-10 03:15:58","endLine":913,"groupId":"13757","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/ef6f688f8690f65949cd2807f1d8693abcf60c.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = TestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":879,"status":"M"}],"commitId":"1f98112e993bc4ae098936b1b0661fdb2c4b1880","commitMessage":"@@@MINOR: Remove connection id from Send and consolidate request/message utils (#9714)\n\nConnection id is now only present in `NetworkSend`.  which is now\nthe class used by `Selector`/`NetworkClient`/`KafkaChannel` (which\nworks well since `NetworkReceive` is the class used for\nreceived data).\n\nThe previous `NetworkSend` was also responsible for adding a size\nprefix. This logic is already present in `SendBuilder`.  but for the\nminority of cases where `SendBuilder` is not used (including\na number of tests).  we now have `ByteBufferSend.sizePrefixed()`.\n\nWith regards to the request/message utilities:\n* Renamed `toByteBuffer`/`toBytes` in `MessageUtil` to\n`toVersionPrefixedByteBuffer`/`toVersionPrefixedBytes` for clarity.\n* Introduced new `MessageUtil.toByteBuffer` that does not include\nthe version as the prefix.\n* Renamed `serializeBody` in `AbstractRequest/Response` to\n`serialize` for symmetry with `parse`.\n* Introduced `RequestTestUtils` and moved relevant methods from\n`TestUtils`.\n* Moved `serializeWithHeader` methods that were only used in\ntests to `RequestTestUtils`.\n* Deleted `MessageTestUtil`.\n\nFinally.  a couple of changes to simplify coding patterns:\n* Added `flip()` and `buffer()` to `ByteBufferAccessor`.\n* Added `MessageSizeAccumulator.sizeExcludingZeroCopy`.\n* Used lambdas instead of `TestCondition`.\n* Used `Arrays.copyOf` instead of `System.arraycopy` in `MessageUtil`.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  Jason Gustafson <jason@confluent.io>","date":"2020-12-10 03:15:58","modifiedFileCount":"80","status":"M","submitter":"Ismael Juma"},{"authorTime":"2020-12-15 21:33:36","codes":[{"authorDate":"2020-12-10 03:15:58","commitOrder":5,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2020-12-10 03:15:58","endLine":876,"groupId":"22421","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/ef6f688f8690f65949cd2807f1d8693abcf60c.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":854,"status":"N"},{"authorDate":"2020-12-15 21:33:36","commitOrder":5,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data().groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","date":"2020-12-15 21:33:36","endLine":913,"groupId":"22423","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/57/c8474996dceeabf9bf68d0405c6ae215098c69.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data.groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":879,"status":"M"}],"commitId":"1a10c3445e157da1d2fd670c043f19c385465eb0","commitMessage":"@@@KAFKA-10525: Emit JSONs with new auto-generated schema (KIP-673) (#9526)\n\nThis patch updates the request logger to output request and response payloads in JSON. Payloads are converted to JSON based on their auto-generated schema.\n\nReviewers:  Lucas Bradstreet <lucas@confluent.io>.  David Mao <dmao@confluent.io>.  David Jacot <djacot@confluent.io>\n","date":"2020-12-15 21:33:36","modifiedFileCount":"124","status":"M","submitter":"Anastasia Vela"},{"authorTime":"2021-04-29 04:22:15","codes":[{"authorDate":"2020-12-10 03:15:58","commitOrder":6,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2020-12-10 03:15:58","endLine":876,"groupId":"22421","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/ef6f688f8690f65949cd2807f1d8693abcf60c.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":854,"status":"N"},{"authorDate":"2021-04-29 04:22:15","commitOrder":6,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data().groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), new ConsumerGroupMetadata(groupId));\n            producer.commitTransaction();\n        }\n    }\n","date":"2021-04-29 04:22:15","endLine":906,"groupId":"22423","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/d4e944cee784744af4eafbb85a860d51fd4b87.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data().groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), groupId);\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":872,"status":"M"}],"commitId":"3805f3706f8f3ebba81b80915c9259590525fb05","commitMessage":"@@@KAFKA-12574: KIP-732.  Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)\n\nDeprecates the following \n\n1. StreamsConfig.EXACTLY_ONCE\n2. StreamsConfig.EXACTLY_ONCE_BETA\n3. Producer#sendOffsetsToTransaction(Map offsets.  String consumerGroupId)\n\nAnd introduces a new StreamsConfig.EXACTLY_ONCE_V2 config. Additionally.  this PR replaces usages of the term \"eos-beta\" throughout the code with the term \"eos-v2\"\n\nReviewers: Matthias J. Sax <mjsax@confluent.io>","date":"2021-04-29 04:22:15","modifiedFileCount":"32","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-07-02 05:05:03","codes":[{"authorDate":"2021-07-02 05:05:03","commitOrder":7,"curCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, \"some.id\", host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","date":"2021-07-02 05:05:03","endLine":869,"groupId":"103732","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testAbortTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f0/55e12c2318167769c53e72d0c4952be7505bd0.src","preCode":"    public void testAbortTransaction() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n                new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.abortTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":847,"status":"M"},{"authorDate":"2021-07-02 05:05:03","commitOrder":7,"curCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, \"some.id\", host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, \"some.id\", host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data().groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), new ConsumerGroupMetadata(groupId));\n            producer.commitTransaction();\n        }\n    }\n","date":"2021-07-02 05:05:03","endLine":906,"groupId":"103732","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testSendTxnOffsetsWithGroupId","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f0/55e12c2318167769c53e72d0c4952be7505bd0.src","preCode":"    public void testSendTxnOffsetsWithGroupId() {\n        Map<String, Object> configs = new HashMap<>();\n        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"some.id\");\n        configs.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 10000);\n        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9000\");\n\n        Time time = new MockTime(1);\n        MetadataResponse initialUpdateResponse = RequestTestUtils.metadataUpdateWith(1, singletonMap(\"topic\", 1));\n        ProducerMetadata metadata = newMetadata(0, Long.MAX_VALUE);\n\n        MockClient client = new MockClient(time, metadata);\n        client.updateMetadata(initialUpdateResponse);\n\n        Node node = metadata.fetch().nodes().get(0);\n        client.throttle(node, 5000);\n\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        client.prepareResponse(initProducerIdResponse(1L, (short) 5, Errors.NONE));\n        client.prepareResponse(addOffsetsToTxnResponse(Errors.NONE));\n        client.prepareResponse(FindCoordinatorResponse.prepareResponse(Errors.NONE, host1));\n        String groupId = \"group\";\n        client.prepareResponse(request ->\n            ((TxnOffsetCommitRequest) request).data().groupId().equals(groupId),\n            txnOffsetsCommitResponse(Collections.singletonMap(\n                new TopicPartition(\"topic\", 0), Errors.NONE)));\n        client.prepareResponse(endTxnResponse(Errors.NONE));\n\n        try (Producer<String, String> producer = kafkaProducer(configs, new StringSerializer(),\n            new StringSerializer(), metadata, client, null, time)) {\n            producer.initTransactions();\n            producer.beginTransaction();\n            producer.sendOffsetsToTransaction(Collections.emptyMap(), new ConsumerGroupMetadata(groupId));\n            producer.commitTransaction();\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":872,"status":"M"}],"commitId":"f5d5f654db359af077088685e29fbe5ea69616cf","commitMessage":"@@@KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)\n\nThis implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+time\n\nIt updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version.  clients can revert to the previous behaviour and use a request for each coordinator.\n\nReviewers: David Jacot <djacot@confluent.io>.  Tom Bentley <tbentley@redhat.com>.  Sanjana Kaundinya <skaundinya@gmail.com>","date":"2021-07-02 05:05:03","modifiedFileCount":"33","status":"M","submitter":"Mickael Maison"}]
