[{"authorTime":"2018-10-22 16:36:24","codes":[{"authorDate":"2018-07-27 00:13:50","commitOrder":2,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.run(time.milliseconds());  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2018-07-27 00:13:50","endLine":2024,"groupId":"4636","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2f/be3df20675b6dd48ea10cf847e251030411e51.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.run(time.milliseconds());  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1996,"status":"NB"},{"authorDate":"2018-10-22 16:36:24","commitOrder":2,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.run(time.milliseconds());\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.run(time.milliseconds());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2018-10-22 16:36:24","endLine":2067,"groupId":"4637","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8a/8ddd358360f40ff8d130d72fca2661a4b8d2d1.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.run(time.milliseconds());\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.run(time.milliseconds());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2040,"status":"B"}],"commitId":"fed27fdd75e3f7994b87a035f4984d77b8f4411b","commitMessage":"@@@KAFKA-7501: Fix producer batch double deallocation when receiving message too large error on expired batch (#5807)\n\nMinor clean-ups for clarity included.\n\nReviewers: Dong Lin <lindong28@gmail.com>.  Ismael Juma <ismael@juma.me.uk>","date":"2018-10-22 16:36:24","modifiedFileCount":"3","status":"M","submitter":"Xiongqi Wu"},{"authorTime":"2019-05-03 00:29:22","codes":[{"authorDate":"2019-05-03 00:29:22","commitOrder":3,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-05-03 00:29:22","endLine":2107,"groupId":"17965","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5e/4e31e2697c8a67156cb44d31f1fcbe66de018a.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.run(time.milliseconds());  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.run(time.milliseconds()); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2079,"status":"M"},{"authorDate":"2019-05-03 00:29:22","commitOrder":3,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-05-03 00:29:22","endLine":2137,"groupId":"1522","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5e/4e31e2697c8a67156cb44d31f1fcbe66de018a.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n\n        sender.run(time.milliseconds());  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.run(time.milliseconds());\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.run(time.milliseconds());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2110,"status":"M"}],"commitId":"c34330c5481803c91705cbfcc499021360ff7fdc","commitMessage":"@@@KAFKA-8248; Ensure time updated before sending transactional request (#6613)\n\nThis patch fixes a bug in the sending of transactional requests. We need to call `KafkaClient.send` with an updated current time. Failing to do so can result in an `IllegalStateExcepton` which leaves the producer effectively dead since the in-flight correlation id has been set.  but no request has been sent. To avoid the same problem in the future.  we update the in flight correlationId only after sending the request.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Apurva Mehta <apurva@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-05-03 00:29:22","modifiedFileCount":"7","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2019-08-02 05:36:12","codes":[{"authorDate":"2019-08-02 05:36:12","commitOrder":4,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-08-02 05:36:12","endLine":2108,"groupId":"17965","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/56/308c1e38a09448816793ead3cf4f0454be3d75.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2080,"status":"M"},{"authorDate":"2019-08-02 05:36:12","commitOrder":4,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-08-02 05:36:12","endLine":2138,"groupId":"2152","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/56/308c1e38a09448816793ead3cf4f0454be3d75.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT).future;\n\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2111,"status":"M"}],"commitId":"717c55be971df862c55f55d245b9997f1d6f998c","commitMessage":"@@@KAFKA-8601: Implement KIP-480: Sticky Partitioning for keyless records (#6997)\n\nImplement KIP-480.  which specifies that the default partitioner should use a \"sticky\" partitioning strategy for records that have a null key.\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>.  Lucas Bradstreet <lucasbradstreet@gmail.com>.  Stanislav Kozlovski <stanislav_kozlovski@outlook.com>.  Jun Rao <junrao@gmail.com>.  Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>","date":"2019-08-02 05:36:12","modifiedFileCount":"9","status":"M","submitter":"Justine Olshan"},{"authorTime":"2019-12-03 20:56:16","codes":[{"authorDate":"2019-12-03 20:56:16","commitOrder":5,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-12-03 20:56:16","endLine":2089,"groupId":"17965","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/02/51f7be8548954f0d4764aa7c978d85778ed923.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key\".getBytes(), \"value\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2063,"status":"M"},{"authorDate":"2019-12-03 20:56:16","commitOrder":5,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        Future<RecordMetadata> request2 = appendToAccumulator(tp0);\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-12-03 20:56:16","endLine":2116,"groupId":"1522","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/02/51f7be8548954f0d4764aa7c978d85778ed923.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 =\n            accumulator.append(tp0, time.milliseconds(), \"key1\".getBytes(), \"value1\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n        Future<RecordMetadata> request2 =\n            accumulator.append(tp0, time.milliseconds(), \"key2\".getBytes(), \"value2\".getBytes(), null, null,\n                MAX_BLOCK_TIMEOUT, false).future;\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2092,"status":"M"}],"commitId":"38fde81132e0457e983eae60b3d4a9834ad84129","commitMessage":"@@@MINOR: Proactively update producer topic access time. (#7672)\n\nChanges the ProducerMetadata to longer record a sentinel TOPIC_EXPIRY_NEEDS_UPDATE upon topic map emplacement.  and instead set the expiry time directly. Previously the expiry time was being updated for all touched topics after a metadata fetch was processed.  which could be seconds/minutes in the future.\n\nAdditionally propagates the current time further in the Producer.  which should reduce the total number of current-time calls.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.   Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-12-03 20:56:16","modifiedFileCount":"9","status":"M","submitter":"Brian Byrne"},{"authorTime":"2019-12-03 20:56:16","codes":[{"authorDate":"2020-04-24 12:39:11","commitOrder":6,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2020-04-24 12:39:11","endLine":2164,"groupId":"17965","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5e/b2e20df89be9f53a352c8c704d4693b58260d0.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        Map<TopicPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();\n        responseMap.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE, 0L, 0L, 0L));\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2140,"status":"M"},{"authorDate":"2019-12-03 20:56:16","commitOrder":6,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        Future<RecordMetadata> request2 = appendToAccumulator(tp0);\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-12-03 20:56:16","endLine":2116,"groupId":"1522","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/02/51f7be8548954f0d4764aa7c978d85778ed923.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        Future<RecordMetadata> request2 = appendToAccumulator(tp0);\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2092,"status":"N"}],"commitId":"f3c8bff311b0e4c4d0e316ac949fe4491f9b107f","commitMessage":"@@@KAFKA-8639: Replace AddPartitionsToTxn with Automated Protocol  (#8326)\n\nPart of the protocol automation effort.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-04-24 12:39:11","modifiedFileCount":"8","status":"M","submitter":"Boyang Chen"},{"authorTime":"2019-12-03 20:56:16","codes":[{"authorDate":"2020-07-18 03:05:11","commitOrder":7,"curCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_OR_FOLLOWER, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2020-07-18 03:05:11","endLine":2166,"groupId":"103684","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotRetry","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a5/5d6d6849cbcbee39692acf28d12cc477c516b4.src","preCode":"    public void testExpiredBatchDoesNotRetry() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        setupWithTransactionState(null, false, null);\n\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        sender.runOnce();  \r\n        assertEquals(1, client.inFlightRequestCount());\n        time.sleep(deliverTimeoutMs);\n\n        client.respond(produceResponse(tp0, -1, Errors.NOT_LEADER_FOR_PARTITION, -1)); \r\n\n        sender.runOnce();  \r\n        assertTrue(request1.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        sender.runOnce(); \r\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2142,"status":"M"},{"authorDate":"2019-12-03 20:56:16","commitOrder":7,"curCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        Future<RecordMetadata> request2 = appendToAccumulator(tp0);\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","date":"2019-12-03 20:56:16","endLine":2116,"groupId":"103684","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testExpiredBatchDoesNotSplitOnMessageTooLargeError","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/02/51f7be8548954f0d4764aa7c978d85778ed923.src","preCode":"    public void testExpiredBatchDoesNotSplitOnMessageTooLargeError() throws Exception {\n        long deliverTimeoutMs = 1500L;\n        \r\n        Future<RecordMetadata> request1 = appendToAccumulator(tp0);\n        Future<RecordMetadata> request2 = appendToAccumulator(tp0);\n\n        \r\n        sender.runOnce();\n        assertEquals(1, client.inFlightRequestCount());\n        \r\n        client.respond(produceResponse(tp0, -1, Errors.MESSAGE_TOO_LARGE, -1));\n\n        time.sleep(deliverTimeoutMs);\n        \r\n        sender.runOnce();\n        assertTrue(request1.isDone());\n        assertTrue(request2.isDone());\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n\n        \r\n        sender.runOnce();\n        assertEquals(0, client.inFlightRequestCount());\n        assertEquals(0, sender.inFlightBatches(tp0).size());\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2092,"status":"N"}],"commitId":"9c8f75c4b624084c954b4da69f092211a9ac4689","commitMessage":"@@@KAFKA-10223; Use NOT_LEADER_OR_FOLLOWER instead of non-retriable REPLICA_NOT_AVAILABLE for consumers (#8979)\n\nBrokers currently return NOT_LEADER_FOR_PARTITION to producers and REPLICA_NOT_AVAILABLE to consumers if a replica is not available on the broker during reassignments. Non-Java clients treat REPLICA_NOT_AVAILABLE as a non-retriable exception.  Java consumers handle this error by explicitly matching the error code even though it is not an InvalidMetadataException. This PR renames NOT_LEADER_FOR_PARTITION to NOT_LEADER_OR_FOLLOWER and uses the same error for producers and consumers. This is compatible with both Java and non-Java clients since all clients handle this error code (6) as retriable exception. The PR also makes ReplicaNotAvailableException a subclass of InvalidMetadataException.\n    - ALTER_REPLICA_LOG_DIRS continues to return REPLICA_NOT_AVAILABLE. Retained this for compatibility since this request never returned NOT_LEADER_FOR_PARTITION earlier. \n   -  MetadataRequest version 0 also returns REPLICA_NOT_AVAILABLE as topic-level error code for compatibility. Newer versions filter these out and return Errors.NONE.  so didn't change this.\n   - Partition responses in MetadataRequest return REPLICA_NOT_AVAILABLE to indicate that one of the replicas is not available. Did not change this since NOT_LEADER_FOR_PARTITION is not suitable in this case.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>.  Bob Barrett <bob.barrett@confluent.io>\n","date":"2020-07-18 03:05:11","modifiedFileCount":"20","status":"M","submitter":"Rajini Sivaram"}]
