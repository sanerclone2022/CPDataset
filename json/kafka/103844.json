[{"authorTime":"2019-12-05 05:33:34","codes":[{"authorDate":"2019-07-26 04:02:09","commitOrder":12,"curCode":"    public void testDescribeConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(\"group-0\").get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(\"group-0\", groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","date":"2019-07-26 04:02:09","endLine":1256,"groupId":"8351","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDescribeConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/76/9f58c3caf4033bf4b19fb2bb6b6401918a4b75.src","preCode":"    public void testDescribeConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(\"group-0\").get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(\"group-0\", groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1153,"status":"NB"},{"authorDate":"2019-12-05 05:33:34","commitOrder":12,"curCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n\n            TestUtils.assertFutureError(result.describedGroups().get(\"group-0\"), IllegalArgumentException.class);\n        }\n    }\n","date":"2019-12-05 05:33:34","endLine":1550,"groupId":"20028","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testDescribeNonConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/3036c1e4bf37dbc58a8b7eb652363cd284e4c0.src","preCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n\n            TestUtils.assertFutureError(result.describedGroups().get(\"group-0\"), IllegalArgumentException.class);\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1516,"status":"B"}],"commitId":"b0d89cb6ad8e01de05d7840de754ad45c361173a","commitMessage":"@@@KAFKA-9251; Describing a non consumer group with the Admin API hangs forever (#7763)\n\nIf a non-consumer group is specified in `describeConsumerGroup`.  the future will hang indefinitely because the future callback is never completed. This patch fixes the problem by completing the future exceptionally with an `IllegalArgumentException`.\n\nReviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>.  Jason Gustafson <jason@confluent.io>","date":"2019-12-05 05:33:34","modifiedFileCount":"2","status":"M","submitter":"David Jacot"},{"authorTime":"2019-12-18 14:08:53","codes":[{"authorDate":"2019-12-18 14:08:53","commitOrder":13,"curCode":"    public void testDescribeConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(\"group-0\").get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(\"group-0\", groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","date":"2019-12-18 14:08:53","endLine":1343,"groupId":"8351","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDescribeConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e5/4c717102730e3e5f8e9150482fe11941af0b75.src","preCode":"    public void testDescribeConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(\"group-0\").get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(\"group-0\", groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1251,"status":"M"},{"authorDate":"2019-12-18 14:08:53","commitOrder":13,"curCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n\n            TestUtils.assertFutureError(result.describedGroups().get(\"group-0\"), IllegalArgumentException.class);\n        }\n    }\n","date":"2019-12-18 14:08:53","endLine":1454,"groupId":"20028","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testDescribeNonConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e5/4c717102730e3e5f8e9150482fe11941af0b75.src","preCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        final HashMap<Integer, Node> nodes = new HashMap<>();\n        nodes.put(0, new Node(0, \"localhost\", 8121));\n\n        final Cluster cluster =\n            new Cluster(\n                \"mockClusterId\",\n                nodes.values(),\n                Collections.<PartitionInfo>emptyList(),\n                Collections.<String>emptySet(),\n                Collections.<String>emptySet(), nodes.get(0));\n\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(cluster)) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n\n            TestUtils.assertFutureError(result.describedGroups().get(\"group-0\"), IllegalArgumentException.class);\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1431,"status":"M"}],"commitId":"75a68341da423d8b041ac8824fbebe99f9bd15ff","commitMessage":"@@@MINOR; Refactor KafkaAdminClientTest to reduce the boilerplate code (#7842)\n\n`KafkaAdminClientTest` contains many code repetitions which could be removed. This PR removes most of the boiler plate code.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2019-12-18 14:08:53","modifiedFileCount":"1","status":"M","submitter":"David Jacot"},{"authorTime":"2021-07-02 05:05:03","codes":[{"authorDate":"2021-07-02 05:05:03","commitOrder":14,"curCode":"    public void testDescribeConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(GROUP_ID).get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(GROUP_ID, groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","date":"2021-07-02 05:05:03","endLine":2779,"groupId":"82","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testDescribeConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/44/6e22d17ff9336e8bcef276360419e86393b15b.src","preCode":"    public void testDescribeConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    \"group-0\",\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(\"group-0\").get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(\"group-0\", groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2687,"status":"M"},{"authorDate":"2021-07-02 05:05:03","commitOrder":14,"curCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n\n            TestUtils.assertFutureError(result.describedGroups().get(GROUP_ID), IllegalArgumentException.class);\n        }\n    }\n","date":"2021-07-02 05:05:03","endLine":2890,"groupId":"20863","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testDescribeNonConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/44/6e22d17ff9336e8bcef276360419e86393b15b.src","preCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                \"group-0\",\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(\"group-0\"));\n\n            TestUtils.assertFutureError(result.describedGroups().get(\"group-0\"), IllegalArgumentException.class);\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2867,"status":"M"}],"commitId":"f5d5f654db359af077088685e29fbe5ea69616cf","commitMessage":"@@@KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)\n\nThis implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+time\n\nIt updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version.  clients can revert to the previous behaviour and use a request for each coordinator.\n\nReviewers: David Jacot <djacot@confluent.io>.  Tom Bentley <tbentley@redhat.com>.  Sanjana Kaundinya <skaundinya@gmail.com>","date":"2021-07-02 05:05:03","modifiedFileCount":"33","status":"M","submitter":"Mickael Maison"},{"authorTime":"2021-07-02 05:05:03","codes":[{"authorDate":"2021-07-15 20:25:41","commitOrder":15,"curCode":"    public void testDescribeConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(GROUP_ID).get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(GROUP_ID, groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","date":"2021-07-15 20:25:41","endLine":2782,"groupId":"103844","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testDescribeConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ab/11833e97b5105c01c5352e80e4ccdcb35d02d0.src","preCode":"    public void testDescribeConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            \r\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE,  Node.noNode()));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS,  Node.noNode()));\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            \r\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_LOAD_IN_PROGRESS,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.COORDINATOR_NOT_AVAILABLE,\n                \"\",\n                \"\",\n                \"\",\n                Collections.emptyList(),\n                Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            \r\n\r\n\r\n\r\n\n            data = new DescribeGroupsResponseData();\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NOT_COORDINATOR,\n                    \"\",\n                    \"\",\n                    \"\",\n                    Collections.emptyList(),\n                    Collections.emptySet()));\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            data = new DescribeGroupsResponseData();\n            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n\n            final List<TopicPartition> topicPartitions = new ArrayList<>();\n            topicPartitions.add(0, myTopicPartition0);\n            topicPartitions.add(1, myTopicPartition1);\n            topicPartitions.add(2, myTopicPartition2);\n\n            final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n            byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n            memberAssignment.get(memberAssignmentBytes);\n\n            DescribedGroupMember memberOne = DescribeGroupsResponse.groupMember(\"0\", \"instance1\", \"clientId0\", \"clientHost\", memberAssignmentBytes, null);\n            DescribedGroupMember memberTwo = DescribeGroupsResponse.groupMember(\"1\", \"instance2\", \"clientId1\", \"clientHost\", memberAssignmentBytes, null);\n\n            List<MemberDescription> expectedMemberDescriptions = new ArrayList<>();\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberOne,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            expectedMemberDescriptions.add(convertToMemberDescriptions(memberTwo,\n                                                                       new MemberAssignment(new HashSet<>(topicPartitions))));\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                    GROUP_ID,\n                    Errors.NONE,\n                    \"\",\n                    ConsumerProtocol.PROTOCOL_TYPE,\n                    \"\",\n                    asList(memberOne, memberTwo),\n                    Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n            final ConsumerGroupDescription groupDescription = result.describedGroups().get(GROUP_ID).get();\n\n            assertEquals(1, result.describedGroups().size());\n            assertEquals(GROUP_ID, groupDescription.groupId());\n            assertEquals(2, groupDescription.members().size());\n            assertEquals(expectedMemberDescriptions, groupDescription.members());\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2687,"status":"M"},{"authorDate":"2021-07-02 05:05:03","commitOrder":15,"curCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n\n            TestUtils.assertFutureError(result.describedGroups().get(GROUP_ID), IllegalArgumentException.class);\n        }\n    }\n","date":"2021-07-02 05:05:03","endLine":2890,"groupId":"103844","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testDescribeNonConsumerGroups","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/44/6e22d17ff9336e8bcef276360419e86393b15b.src","preCode":"    public void testDescribeNonConsumerGroups() throws Exception {\n        try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(mockCluster(1, 0))) {\n            env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n\n            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n\n            DescribeGroupsResponseData data = new DescribeGroupsResponseData();\n\n            data.groups().add(DescribeGroupsResponse.groupMetadata(\n                GROUP_ID,\n                Errors.NONE,\n                \"\",\n                \"non-consumer\",\n                \"\",\n                asList(),\n                Collections.emptySet()));\n\n            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n\n            final DescribeConsumerGroupsResult result = env.adminClient().describeConsumerGroups(singletonList(GROUP_ID));\n\n            TestUtils.assertFutureError(result.describedGroups().get(GROUP_ID), IllegalArgumentException.class);\n        }\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2867,"status":"N"}],"commitId":"df398aa71b116895ae030adb9cbb2a55d8beee7b","commitMessage":"@@@KAFKA-13063: Make DescribeConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11022)\n\nThis patch improve the error handling in `DescribeConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.\n\nReviewers: David Jacot <djacot@confluent.io>","date":"2021-07-15 20:25:41","modifiedFileCount":"3","status":"M","submitter":"Luke Chen"}]
