[{"authorTime":"2017-04-28 05:11:17","codes":[{"authorDate":"2017-04-28 05:11:17","commitOrder":1,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","date":"2017-04-28 05:11:36","endLine":1144,"groupId":"4436","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/60/59180bb416ae604560e7c3cb6772ac3ef007cf.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1113,"status":"B"},{"authorDate":"2017-04-28 05:11:17","commitOrder":1,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        currentOffset += commitTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2017-04-28 05:11:36","endLine":1299,"groupId":"11462","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/60/59180bb416ae604560e7c3cb6772ac3ef007cf.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        currentOffset += commitTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1254,"status":"B"}],"commitId":"a82f194b21a6af2f52e36e55e2c6adcdba942c08","commitMessage":"@@@KAFKA-4818; Exactly once transactional clients\n\nAuthor: Apurva Mehta <apurva@confluent.io>\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2840 from apurvam/exactly-once-transactional-clients\n","date":"2017-04-28 05:11:36","modifiedFileCount":"23","status":"B","submitter":"Apurva Mehta"},{"authorTime":"2017-05-07 02:49:35","codes":[{"authorDate":"2017-05-07 02:49:35","commitOrder":2,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","date":"2017-05-07 02:49:35","endLine":1257,"groupId":"4866","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0a/0f3d9ba8b408eea2d53a67d84d818f60cd8d52.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1226,"status":"M"},{"authorDate":"2017-05-07 02:49:35","commitOrder":2,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        currentOffset += commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2017-05-07 02:49:35","endLine":1418,"groupId":"11462","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0a/0f3d9ba8b408eea2d53a67d84d818f60cd8d52.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        currentOffset += commitTransaction(buffer, 1L, currentOffset, time.milliseconds());\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1373,"status":"M"}],"commitId":"e71dce89c0da50f3eccc47d0fc050c92d5a99b88","commitMessage":"@@@KAFKA-5121; Implement transaction index for KIP-98\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jun Rao <junrao@gmail.com>\n\nCloses #2910 from hachikuji/eos-txn-index\n","date":"2017-05-07 02:49:35","modifiedFileCount":"23","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-05-13 03:07:22","codes":[{"authorDate":"2017-05-07 02:49:35","commitOrder":3,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","date":"2017-05-07 02:49:35","endLine":1257,"groupId":"4866","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0a/0f3d9ba8b408eea2d53a67d84d818f60cd8d52.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1226,"status":"N"},{"authorDate":"2017-05-13 03:07:22","commitOrder":3,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2017-05-13 03:07:22","endLine":1452,"groupId":"3575","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4e/46d57d206ffd5a115fc5a236c5150ab9e40965.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        currentOffset += commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1407,"status":"M"}],"commitId":"7baa58d797126b6fb2b1de30e72428895d2bcb40","commitMessage":"@@@KAFKA-5196; Make LogCleaner transaction-aware\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jun Rao <junrao@gmail.com>\n\nCloses #3008 from hachikuji/KAFKA-5196\n","date":"2017-05-13 03:07:22","modifiedFileCount":"5","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-05-13 03:07:22","codes":[{"authorDate":"2017-05-31 17:23:39","commitOrder":4,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","date":"2017-05-31 17:27:16","endLine":1383,"groupId":"8227","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7d/4862372124b7a50cfa46d6724810ad3abcdefc.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1352,"status":"M"},{"authorDate":"2017-05-13 03:07:22","commitOrder":4,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2017-05-13 03:07:22","endLine":1452,"groupId":"3575","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4e/46d57d206ffd5a115fc5a236c5150ab9e40965.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1407,"status":"N"}],"commitId":"aebba89a2b9b5ea6a7cab2599555232ef3fe21ad","commitMessage":"@@@KAFKA-5349; Fix illegal state error in consumer's ListOffset handler\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Apurva Mehta <apurva@confluent.io>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3175 from hachikuji/KAFKA-5349\n","date":"2017-05-31 17:27:16","modifiedFileCount":"2","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-07-21 08:31:24","codes":[{"authorDate":"2017-07-21 08:31:24","commitOrder":5,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2017-07-21 08:38:30","endLine":1429,"groupId":"13225","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp1));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1398,"status":"M"},{"authorDate":"2017-07-21 08:31:24","commitOrder":5,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2017-07-21 08:38:30","endLine":1593,"groupId":"3575","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp1));\n\n        subscriptions.seek(tp1, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp1));\n        assertEquals(fetchedRecords.get(tp1).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp1);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1548,"status":"M"}],"commitId":"5bb53e034e4f8a06550dd06377fae7b3c2137ce2","commitMessage":"@@@KAFKA-5534; KafkaConsumer `offsetForTimes` result should include partitions with no offset\n\nFor topics that support timestamp search.  if no offset is found for a partition.  the partition should still be included in the result with a `null` offset value. This `KafkaConsumer` method currently excludes such partitions from the result.\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3460 from vahidhashemian/KAFKA-5534\n","date":"2017-07-21 08:38:30","modifiedFileCount":"2","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2018-02-06 02:09:17","codes":[{"authorDate":"2018-02-06 02:09:17","commitOrder":6,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2018-02-06 02:09:17","endLine":1512,"groupId":"13225","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a0/205e7f19ec21137a0a3ba0db83bf7bd317c538.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1481,"status":"M"},{"authorDate":"2018-02-06 02:09:17","commitOrder":6,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2018-02-06 02:09:17","endLine":1676,"groupId":"3575","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a0/205e7f19ec21137a0a3ba0db83bf7bd317c538.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1631,"status":"M"}],"commitId":"7fe1c2b3d3a78ea3ffb9e269563653626861fbd2","commitMessage":"@@@KAFKA-6254; Incremental fetch requests\n\nAuthor: Colin P. Mccabe <cmccabe@confluent.io>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Jun Rao <junrao@gmail.com>\n\nCloses #4418 from cmccabe/KAFKA-6254\n","date":"2018-02-06 02:09:17","modifiedFileCount":"8","status":"M","submitter":"Colin P. Mccabe"},{"authorTime":"2018-08-04 08:25:07","codes":[{"authorDate":"2018-08-04 08:25:07","commitOrder":7,"curCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2018-08-04 08:25:07","endLine":1890,"groupId":"13225","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1a/82faa0a3dd9620f0fe91d4802b7330247fca35.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1859,"status":"M"},{"authorDate":"2018-08-04 08:25:07","commitOrder":7,"curCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2018-08-04 08:25:07","endLine":2054,"groupId":"3575","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1a/82faa0a3dd9620f0fe91d4802b7330247fca35.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(0);\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2009,"status":"M"}],"commitId":"fc5f6b0e46ff81302b3e445fed0cdf454c942792","commitMessage":"@@@MINOR: Add Timer to simplify timeout bookkeeping and use it in the consumer (#5087)\n\nWe currently do a lot of bookkeeping for timeouts which is both error-prone and distracting. This patch adds a new `Timer` class to simplify this logic and control unnecessary calls to system time. In particular.  this helps with nested timeout operations. The consumer has been updated to use the new class.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-08-04 08:25:07","modifiedFileCount":"17","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2019-03-08 08:29:19","codes":[{"authorDate":"2019-03-08 08:29:19","commitOrder":8,"curCode":"    public void testSkippingAbortedTransactions() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2019-03-08 08:29:19","endLine":2323,"groupId":"18602","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testSkippingAbortedTransactions() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2292,"status":"M"},{"authorDate":"2019-03-08 08:29:19","commitOrder":8,"curCode":"    public void testMultipleAbortMarkers() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","date":"2019-03-08 08:29:19","endLine":2487,"groupId":"15903","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testMultipleAbortMarkers() {\n        Fetcher<byte[], byte[]> fetcher = createFetcher(subscriptions, new Metrics(), new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        subscriptions.assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetcher.fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2442,"status":"M"}],"commitId":"460e46c3bb76a361d0706b263c03696005e12566","commitMessage":"@@@KAFKA-7831; Do not modify subscription state from background thread (#6221)\n\nMetadata may be updated from the background thread.  so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally.  it improves the following:\n\n1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription.  so this simplifies the logic.\n2. The metadata needs for the producer and consumer are quite different.  so it made sense to separate the custom logic into separate extensions of Metadata. For example.  only the producer requires topic expiration.\n3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.\n4. This patch removes the MetadataListener.  which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. \n\nReviewers: David Arthur <mumrah@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-03-08 08:29:19","modifiedFileCount":"30","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2020-02-17 04:06:33","codes":[{"authorDate":"2019-03-08 08:29:19","commitOrder":9,"curCode":"    public void testSkippingAbortedTransactions() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2019-03-08 08:29:19","endLine":2323,"groupId":"18602","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testSkippingAbortedTransactions() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2292,"status":"N"},{"authorDate":"2020-02-17 04:06:33","commitOrder":9,"curCode":"    public void testMultipleAbortMarkers() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertEquals(actuallyCommittedKeys, committedKeys);\n    }\n","date":"2020-02-17 04:06:33","endLine":2842,"groupId":"15903","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b7/57e885852818034e4db1e456db581e4c3f9877.src","preCode":"    public void testMultipleAbortMarkers() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertTrue(actuallyCommittedKeys.equals(committedKeys));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2797,"status":"M"}],"commitId":"863b534f83aad50528828a30857e1ff56ac93f27","commitMessage":"@@@KAFKA-9535; Update metadata before retrying partitions when fetching offsets (#8088)\n\nToday if we attempt to list offsets with a fenced leader epoch.  consumer will retry without updating the metadata until the timeout is reached. This affects synchronous APIs such as `offsetsForTimes`.  `beginningOffsets`.  and `endOffsets`. The fix in this patch is to trigger the metadata update call whenever we see a retriable error before additional attempts.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2020-02-17 04:06:33","modifiedFileCount":"3","status":"M","submitter":"Boyang Chen"},{"authorTime":"2021-03-04 18:06:50","codes":[{"authorDate":"2021-03-04 18:06:50","commitOrder":10,"curCode":"    public void testSkippingAbortedTransactions() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n                new FetchResponseData.AbortedTransaction().setProducerId(1).setFirstOffset(0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","date":"2021-03-04 18:06:50","endLine":2833,"groupId":"103951","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testSkippingAbortedTransactions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/5d95947c23675530c9db6a31c6f3fbd2d6cecf.src","preCode":"    public void testSkippingAbortedTransactions() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"key\".getBytes(), \"value\".getBytes()));\n\n        abortTransaction(buffer, 1L, currentOffset);\n\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertFalse(fetchedRecords.containsKey(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2802,"status":"M"},{"authorDate":"2021-03-04 18:06:50","commitOrder":10,"curCode":"    public void testMultipleAbortMarkers() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n            new FetchResponseData.AbortedTransaction().setProducerId(1).setFirstOffset(0)\n        );\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertEquals(actuallyCommittedKeys, committedKeys);\n    }\n","date":"2021-03-04 18:06:50","endLine":2994,"groupId":"103951","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultipleAbortMarkers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/5d95947c23675530c9db6a31c6f3fbd2d6cecf.src","preCode":"    public void testMultipleAbortMarkers() {\n        buildFetcher(OffsetResetStrategy.EARLIEST, new ByteArrayDeserializer(),\n                new ByteArrayDeserializer(), Integer.MAX_VALUE, IsolationLevel.READ_COMMITTED);\n        ByteBuffer buffer = ByteBuffer.allocate(1024);\n        int currentOffset = 0;\n\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"abort1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"abort1-2\".getBytes(), \"value\".getBytes()));\n\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += abortTransaction(buffer, 1L, currentOffset);\n        \r\n        currentOffset += appendTransactionalRecords(buffer, 1L, currentOffset,\n                new SimpleRecord(time.milliseconds(), \"commit1-1\".getBytes(), \"value\".getBytes()),\n                new SimpleRecord(time.milliseconds(), \"commit1-2\".getBytes(), \"value\".getBytes()));\n        commitTransaction(buffer, 1L, currentOffset);\n        buffer.flip();\n\n        List<FetchResponse.AbortedTransaction> abortedTransactions = new ArrayList<>();\n        abortedTransactions.add(new FetchResponse.AbortedTransaction(1, 0));\n        MemoryRecords records = MemoryRecords.readableRecords(buffer);\n        assignFromUser(singleton(tp0));\n\n        subscriptions.seek(tp0, 0);\n\n        \r\n        assertEquals(1, fetcher.sendFetches());\n        assertFalse(fetcher.hasCompletedFetches());\n\n        client.prepareResponse(fullFetchResponseWithAbortedTransactions(records, abortedTransactions, Errors.NONE, 100L, 100L, 0));\n        consumerClient.poll(time.timer(0));\n        assertTrue(fetcher.hasCompletedFetches());\n\n        Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n        assertTrue(fetchedRecords.containsKey(tp0));\n        assertEquals(fetchedRecords.get(tp0).size(), 2);\n        List<ConsumerRecord<byte[], byte[]>> fetchedConsumerRecords = fetchedRecords.get(tp0);\n        Set<String> committedKeys = new HashSet<>(Arrays.asList(\"commit1-1\", \"commit1-2\"));\n        Set<String> actuallyCommittedKeys = new HashSet<>();\n        for (ConsumerRecord<byte[], byte[]> consumerRecord : fetchedConsumerRecords) {\n            actuallyCommittedKeys.add(new String(consumerRecord.key(), StandardCharsets.UTF_8));\n        }\n        assertEquals(actuallyCommittedKeys, committedKeys);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2948,"status":"M"}],"commitId":"8205051e90e3ea16165f8dc1f5c81af744bb1b9a","commitMessage":"@@@MINOR: remove FetchResponse.AbortedTransaction and redundant construc? (#9758)\n\n1. rename INVALID_HIGHWATERMARK to INVALID_HIGH_WATERMARK\n2. replace FetchResponse.AbortedTransaction by FetchResponseData.AbortedTransaction\n3. remove redundant constructors from FetchResponse.PartitionData\n4. rename recordSet to records\n5. add helpers \"recordsOrFail\" and \"recordsSize\" to FetchResponse to process record casting\n\nReviewers: Ismael Juma <ismael@juma.me.uk>","date":"2021-03-04 18:06:50","modifiedFileCount":"15","status":"M","submitter":"Chia-Ping Tsai"}]
