[{"authorTime":"2017-09-11 16:42:10","codes":[{"authorDate":"2018-02-02 02:27:59","commitOrder":16,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-02-02 02:27:59","endLine":102,"groupId":"15879","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a2/3e787198a62805df931cc9c3ff0648d9376e93.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"B"},{"authorDate":"2017-09-11 16:42:10","commitOrder":16,"curCode":"    public void testOuterJoin() {\n        StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        KStream<Integer, String> stream1;\n        KStream<Integer, String> stream2;\n        KStream<Integer, String> joined;\n        MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(stream2,\n                                   MockValueJoiner.TOSTRING_JOINER,\n                                   JoinWindows.of(100),\n                                   Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver.setUp(builder, stateDir);\n        driver.setTime(0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic1, expectedKeys[i], \"X\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"X\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic2, expectedKey, \"YY\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"XX\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","date":"2017-09-11 16:42:10","endLine":264,"groupId":"2460","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/57/2c0b02df546d7f8144f1b2a5320661136fe9dc.src","preCode":"    public void testOuterJoin() {\n        StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        KStream<Integer, String> stream1;\n        KStream<Integer, String> stream2;\n        KStream<Integer, String> joined;\n        MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(stream2,\n                                   MockValueJoiner.TOSTRING_JOINER,\n                                   JoinWindows.of(100),\n                                   Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver.setUp(builder, stateDir);\n        driver.setTime(0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic1, expectedKeys[i], \"X\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"X\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic2, expectedKey, \"YY\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"XX\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"NB"}],"commitId":"86de4a86b87c1b45732303c07d263e317ffd0ebf","commitMessage":"@@@KAFKA-6378: For KStream-GlobalKTable joins let null KeyValueMapper results indicate no match (#4494)\n\nReviewers: Damian Guy <damian@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-02-02 02:27:59","modifiedFileCount":"4","status":"M","submitter":"Andy Bryant"},{"authorTime":"2018-04-18 04:13:15","codes":[{"authorDate":"2018-02-02 02:27:59","commitOrder":17,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-02-02 02:27:59","endLine":102,"groupId":"15879","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a2/3e787198a62805df931cc9c3ff0648d9376e93.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2018-04-18 04:13:15","commitOrder":17,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver.setUp(builder, stateDir);\n        driver.setTime(0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic1, expectedKeys[i], \"X\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"X\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic2, expectedKey, \"YY\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"XX\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","date":"2018-04-18 04:13:15","endLine":265,"groupId":"2460","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/83/fee9b5b38b8fb5bb5b67fdcdc7486d5b6b0931.src","preCode":"    public void testOuterJoin() {\n        StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        KStream<Integer, String> stream1;\n        KStream<Integer, String> stream2;\n        KStream<Integer, String> joined;\n        MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(stream2,\n                                   MockValueJoiner.TOSTRING_JOINER,\n                                   JoinWindows.of(100),\n                                   Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver.setUp(builder, stateDir);\n        driver.setTime(0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic1, expectedKeys[i], \"X\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"X\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic2, expectedKey, \"YY\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"XX\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"M"}],"commitId":"ac9c3ed0b43ee848e6e555a01c55ea2eee78540a","commitMessage":"@@@KAFKA-6376: preliminary cleanup (#4872)\n\nGeneral cleanup of Streams code.  mostly resolving compiler warnings and re-formatting.\n\nThe regular testing suite should be sufficient.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-04-18 04:13:15","modifiedFileCount":"57","status":"M","submitter":"John Roesler"},{"authorTime":"2018-04-27 02:30:42","codes":[{"authorDate":"2018-02-02 02:27:59","commitOrder":18,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-02-02 02:27:59","endLine":102,"groupId":"15879","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a2/3e787198a62805df931cc9c3ff0648d9376e93.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2018-04-27 02:30:42","commitOrder":18,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver = new TopologyTestDriver(builder.build(), props, 0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","date":"2018-04-27 02:30:42","endLine":313,"groupId":"0","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/63/a040acd5e1b8d6ccaac40770ef95e70d1946ee.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver.setUp(builder, stateDir);\n        driver.setTime(0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic1, expectedKeys[i], \"X\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"X\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic2, expectedKey, \"YY\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (final int expectedKey : expectedKeys) {\n            driver.process(topic1, expectedKey, \"XX\" + expectedKey);\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.process(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]);\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":215,"status":"M"}],"commitId":"885abbfcd40aab57acec278d976956f07be15090","commitMessage":"@@@KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [partial] (#4832)\n\n* Remove ProcessorTopologyTestDriver from TopologyTest\n* Fix ProcessorTopologyTest\n* Remove ProcessorTopologyTestDriver and InternalTopologyAccessor\n* Partially refactored StreamsBuilderTest but missing one test\n* Refactor KStreamBuilderTest\n* Refactor AbstractStreamTest\n* Further cleanup of AbstractStreamTest\n* Refactor GlobalKTableJoinsTest\n* Refactor InternalStreamsBuilderTest\n* Fix circular dependency in build.gradle\n* Refactor KGroupedStreamImplTest\n* Partial modifications to KGroupedTableImplTest\n* Refactor KGroupedTableImplTest\n* Refactor KStreamBranchTest\n* Refactor KStreamFilterTest\n* Refactor KStreamFlatMapTest KStreamFlatMapValuesTest\n* Refactor KStreamForeachTest\n* Refactor KStreamGlobalKTableJoinTest\n* Refactor KStreamGlobalKTableLeftJoinTest\n* Refactor KStreamImplTest\n* Refactor KStreamImplTest\n* Refactor KStreamKStreamJoinTest\n* Refactor KStreamKStreamLeftJoinTest\n* Refactor KStreamKTableJoinTest\n* Refactor KStreamKTableLeftJoinTest\n* Refactor KStreamMapTest and KStreamMapValuesTest\n* Refactor KStreamPeekTest and KStreamTransformTest\n* Refactor KStreamSelectKeyTest\n* Refactor KStreamTransformValuesTest\n* Refactor KStreamWindowAggregateTest\n* Add Depercation anotation to KStreamTestDriver and rollback failing tests in StreamsBuilderTest and KTableAggregateTest\n* Refactor KTableFilterTest\n* Refactor KTableForeachTest\n* Add getter for ProcessorTopology.  and simplify tests in StreamsBuilderTest\n* Refactor KTableImplTest\n* Remove unused imports\n* Refactor KTableAggregateTest\n* Fix style errors\n* Fix gradle build\n* Address reviewer comments:\n  - Remove properties new instance\n  - Remove extraneous line\n  - Remove unnecessary TopologyTestDriver instances from StreamsBuilderTest\n  - Move props.clear() to @After\n  - Clarify use of timestamp in KStreamFlatMapValuesTest\n  - Keep test using old Punctuator in KStreamTransformTest\n  - Add comment to clarify clock advances in KStreamTransformTest\n  - Add TopologyTestDriverWrapper class to access the protected constructor of TopologyTestDriver\n  - Revert KTableImplTest.testRepartition to KStreamTestDriver to avoid exposing the TopologyTestDriver processor topology\n  - Revert partially migrated classes: KTableAggregateTest.  KTableFilterTest.  and KTableImplTest\n* Rebase on current trunk an fix conflicts\n\nReviewers: Matthias J Sax <matthias@confluentio>.  Bill Bejeck <bill@confluent.io>.  John Roesler <john@confluent.io>","date":"2018-04-27 02:30:42","modifiedFileCount":"33","status":"M","submitter":"Filipe Agapito"},{"authorTime":"2018-05-04 23:42:01","codes":[{"authorDate":"2018-02-02 02:27:59","commitOrder":19,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-02-02 02:27:59","endLine":102,"groupId":"15879","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a2/3e787198a62805df931cc9c3ff0648d9376e93.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2018-05-04 23:42:01","commitOrder":19,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver = new TopologyTestDriver(builder.build(), props, 0L);\n\n        final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","date":"2018-05-04 23:42:01","endLine":314,"groupId":"7921","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5d/849eee5d401fe7801abd6520a7f2a1b8d1d5a0.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> processor;\n\n        processor = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(processor);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver = new TopologyTestDriver(builder.build(), props, 0L);\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":216,"status":"M"}],"commitId":"af983267be7a2d0f81527f5a348af377f30caee4","commitMessage":"@@@MINOR: Removed deprecated schedule function (#4908)\n\nWhile working on this.  I also refactored the MockProcessor out of the MockProcessorSupplier to cleanup the unit test paths.\n\nReviewers: John Roesler <john@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2018-05-04 23:42:01","modifiedFileCount":"62","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2018-05-08 00:21:20","codes":[{"authorDate":"2018-02-02 02:27:59","commitOrder":20,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-02-02 02:27:59","endLine":102,"groupId":"15879","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a2/3e787198a62805df931cc9c3ff0648d9376e93.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"N"},{"authorDate":"2018-05-08 00:21:20","commitOrder":20,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","date":"2018-05-08 00:21:20","endLine":291,"groupId":"12669","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/de/3446c1a083ec482906c80f776bb4140d11865b.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(intSerde, stringSerde, stringSerde));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        driver = new TopologyTestDriver(builder.build(), props, 0L);\n\n        final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int expectedKey : expectedKeys) {\n            driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n        }\n\n        processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n        \r\n        \r\n        \r\n        \r\n        \r\n\n        for (int i = 0; i < 2; i++) {\n            driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n        }\n\n        processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"}],"commitId":"6f641fef6a88036ab4dacb59ab21bc8b21ef9bcf","commitMessage":"@@@KAFKA-6474: Rewrite tests to use new public TopologyTestDriver [cleanup] (#4939)\n\n* Add method to create test properties to StreamsTestUtils\n* Make TopologyTestDriver protected constructor package-private\n* Add comment suggesting the use of TopologyTestDriver to KStreamTestDriver\n* Cleanup:\n    - GlobalKTableJoinsTest\n    - KGroupedStreamImplTest\n    - KGroupedTableImplTest\n    - KStreamBranchTest\n    - KStreamFilterTest\n    - KStreamFlatMapTest\n    - KStreamFlatMapValuesTest\n    - KStreamForeachTest\n    - KStreamGlobalKTableJoinTest\n    - KStreamGlobalKTableLeftJoinTest\n    - KStreamImplTest\n    - KStreamKStreamJoinTest\n    - KStreamKStreamLeftJoinTest\n    - KStreamGlobalKTableLeftJoinTest\n    - KStreamKTableJoinTest\n    - KStreamKTableLeftJoinTest\n    - KStreamMapTest\n    - KStreamMapValuesTest\n    - KStreamPeekTest\n    - StreamsBuilderTest\n    - KStreamSelectKeyTest\n    - KStreamTransformTest\n    - KStreamTransformValuesTest\n    - KStreamWindowAggregateTest\n    - KTableForeachTest\n\nReviewers: John Roesler <john@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-05-08 00:21:20","modifiedFileCount":"27","status":"M","submitter":"Filipe Agapito"},{"authorTime":"2018-05-18 02:28:45","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":21,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"M"},{"authorDate":"2018-05-18 02:28:45","commitOrder":21,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","date":"2018-05-18 02:28:45","endLine":291,"groupId":"12574","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/59/f09530ca75c125804bbfcba92bdc11ce829591.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"}],"commitId":"1a324d784cfc53288730b7c1b5c1bde0685e4686","commitMessage":"@@@KAFKA-6729: Reuse source topics for source KTable's materialized store's changelog (#5017)\n\n1. In InternalTopologyBuilder#topicGroups.  which is used in StreamsPartitionAssignor.  look for book-kept storeToChangelogTopic map before creating a new internal changelog topics. In this way if the source KTable is created.  its source topic stored in storeToChangelogTopic will be used.\n\n2. Added unit test (confirmed that without 1) it will fail).\n\n3. MINOR: removed TODOs that are related to removed KStreamBuilder.\n\n4. MINOR: removed TODOs in StreamsBuilderTest util functions and replaced with TopologyWrapper.\n\n5. MINOR: removed StreamsBuilderTest#testFrom as it is already covered by TopologyTest#shouldNotAllowToAddSourcesWithSameName.  plus it requires KStreamImpl.SOURCE_NAME which should be a package private field of the KStreamImpl.\n\nReviewers: John Roesler <john@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Matthias\n J. Sax <matthias@confluent.io>","date":"2018-05-18 02:28:45","modifiedFileCount":"17","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2018-08-04 04:19:46","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":22,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2018-08-04 04:19:46","commitOrder":22,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","date":"2018-08-04 04:19:46","endLine":291,"groupId":"12574","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/96/3b681472b37d40e64fdc1107c08d435ac6c607.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"}],"commitId":"3637b2c374d48e99e0a7be37605d3c79f2661007","commitMessage":"@@@MINOR: Require final variables in Streams (#5452)\n\nReviewers: Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2018-08-04 04:19:46","modifiedFileCount":"212","status":"M","submitter":"John Roesler"},{"authorTime":"2018-10-05 04:51:39","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":23,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2018-10-05 04:51:39","commitOrder":23,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","date":"2018-10-05 04:51:39","endLine":292,"groupId":"12574","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/e3cc9b3982117450b3071fb7993b3f636c2736.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(100),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":193,"status":"M"}],"commitId":"ca641b3e2e48c14ff308181c775775408f5f35f7","commitMessage":"@@@KAFKA-7277: Migrate Streams API to Duration instead of longMs times (#5682)\n\nReviewers: Johne Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>","date":"2018-10-05 04:51:39","modifiedFileCount":"97","status":"M","submitter":"Nikolay"},{"authorTime":"2019-03-20 08:27:32","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":24,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2019-03-20 08:27:32","commitOrder":24,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+null (ts: 0)\", \"1:X1+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+Y0 (ts: 0)\", \"1:X1+Y1 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+Y0 (ts: 0)\", \"1:X1+Y1 (ts: 0)\", \"2:X2+null (ts: 0)\", \"3:X3+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+YY0 (ts: 0)\", \"0:X0+YY0 (ts: 0)\", \"1:X1+YY1 (ts: 0)\", \"1:X1+YY1 (ts: 0)\", \"2:X2+YY2 (ts: 0)\", \"3:X3+YY3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:XX0+Y0 (ts: 0)\", \"0:XX0+YY0 (ts: 0)\", \"1:XX1+Y1 (ts: 0)\", \"1:XX1+YY1 (ts: 0)\", \"2:XX2+YY2 (ts: 0)\", \"3:XX3+YY3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+YYY0 (ts: 0)\", \"0:X0+YYY0 (ts: 0)\", \"0:XX0+YYY0 (ts: 0)\", \"1:X1+YYY1 (ts: 0)\", \"1:X1+YYY1 (ts: 0)\", \"1:XX1+YYY1 (ts: 0)\");\n        }\n    }\n","date":"2019-03-20 08:27:32","endLine":263,"groupId":"16158","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ba/ac74e6c3eb767a433176a58ca51aeb3f7567e7.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props, 0L)) {\n\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+null\", \"1:X1+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+Y0\", \"1:X1+Y1\", \"2:X2+null\", \"3:X3+null\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YY0\", \"0:X0+YY0\", \"1:X1+YY1\", \"1:X1+YY1\", \"2:X2+YY2\", \"3:X3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n\n            processor.checkAndClearProcessResult(\"0:XX0+Y0\", \"0:XX0+YY0\", \"1:XX1+Y1\", \"1:XX1+YY1\", \"2:XX2+YY2\", \"3:XX3+YY3\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n\n            processor.checkAndClearProcessResult(\"0:X0+YYY0\", \"0:X0+YYY0\", \"0:XX0+YYY0\", \"1:X1+YYY1\", \"1:X1+YYY1\", \"1:XX1+YYY1\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":176,"status":"M"}],"commitId":"b5ce093a24d0fe212b5d1374330fc720b4913bee","commitMessage":"@@@MINOR: capture result timestamps in Kafka Streams DSL tests (#6447)\n\nReviewers: Bill Bejeck <bill@confluent.io>.  Guozhang Wang <guozhang@confluent.io>\n","date":"2019-03-20 08:27:32","modifiedFileCount":"29","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-04-18 00:07:25","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":25,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2019-04-18 00:07:25","commitOrder":25,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+null (ts: 0)\", \"1:A1+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+a0 (ts: 0)\", \"1:A1+a1 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:B0+a0 (ts: 0)\", \"1:B1+a1 (ts: 0)\", \"2:B2+null (ts: 0)\", \"3:B3+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+b0 (ts: 0)\", \"0:B0+b0 (ts: 0)\", \"1:A1+b1 (ts: 0)\", \"1:B1+b1 (ts: 0)\", \"2:B2+b2 (ts: 0)\", \"3:B3+b3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:C0+a0 (ts: 0)\", \"0:C0+b0 (ts: 0)\", \"1:C1+a1 (ts: 0)\", \"1:C1+b1 (ts: 0)\", \"2:C2+b2 (ts: 0)\", \"3:C3+b3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+c0 (ts: 0)\", \"0:B0+c0 (ts: 0)\", \"0:C0+c0 (ts: 0)\", \"1:A1+c1 (ts: 0)\", \"1:B1+c1 (ts: 0)\", \"1:C1+c1 (ts: 0)\");\n        }\n    }\n","date":"2019-04-18 00:07:25","endLine":263,"groupId":"5409","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fb/d27506777ee41c1b7e5e21e4a5c36bdb1bed52.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"X\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+null (ts: 0)\", \"1:X1+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"Y\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+Y0 (ts: 0)\", \"1:X1+Y1 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"X\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+Y0 (ts: 0)\", \"1:X1+Y1 (ts: 0)\", \"2:X2+null (ts: 0)\", \"3:X3+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"YY\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+YY0 (ts: 0)\", \"0:X0+YY0 (ts: 0)\", \"1:X1+YY1 (ts: 0)\", \"1:X1+YY1 (ts: 0)\", \"2:X2+YY2 (ts: 0)\", \"3:X3+YY3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"XX\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:XX0+Y0 (ts: 0)\", \"0:XX0+YY0 (ts: 0)\", \"1:XX1+Y1 (ts: 0)\", \"1:XX1+YY1 (ts: 0)\", \"2:XX2+YY2 (ts: 0)\", \"3:XX3+YY3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"YYY\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:X0+YYY0 (ts: 0)\", \"0:X0+YYY0 (ts: 0)\", \"0:XX0+YYY0 (ts: 0)\", \"1:X1+YYY1 (ts: 0)\", \"1:X1+YYY1 (ts: 0)\", \"1:XX1+YYY1 (ts: 0)\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":176,"status":"M"}],"commitId":"0e08358da4b114834140c720b98125a2a3a84caa","commitMessage":"@@@KAFKA-6455: KStream-KStream join should set max timestamp for result record (#6565)\n\nReviewers: John Roesler <john@confluent.io>.  Guozhang Wang <guozhang@confluent.io>","date":"2019-04-18 00:07:25","modifiedFileCount":"3","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2019-07-16 22:16:15","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":26,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2019-07-16 22:16:15","commitOrder":26,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","date":"2019-07-16 22:16:15","endLine":302,"groupId":"5409","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/69/25eba99144c906a7c50fa5b7e145a3e5fd09fd.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[]{0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+null (ts: 0)\", \"1:A1+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+a0 (ts: 0)\", \"1:A1+a1 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:B0+a0 (ts: 0)\", \"1:B1+a1 (ts: 0)\", \"2:B2+null (ts: 0)\", \"3:B3+null (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+b0 (ts: 0)\", \"0:B0+b0 (ts: 0)\", \"1:A1+b1 (ts: 0)\", \"1:B1+b1 (ts: 0)\", \"2:B2+b2 (ts: 0)\", \"3:B3+b3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(\"0:C0+a0 (ts: 0)\", \"0:C0+b0 (ts: 0)\", \"1:C1+a1 (ts: 0)\", \"1:C1+b1 (ts: 0)\", \"2:C2+b2 (ts: 0)\", \"3:C3+b3 (ts: 0)\");\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(\"0:A0+c0 (ts: 0)\", \"0:B0+c0 (ts: 0)\", \"0:C0+c0 (ts: 0)\", \"1:A1+c1 (ts: 0)\", \"1:B1+c1 (ts: 0)\", \"1:C1+c1 (ts: 0)\");\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":195,"status":"M"}],"commitId":"00757cd99f6d8bf2760c3708d307347f4cde65f6","commitMessage":"@@@KAFKA-8450: Using KeyValueTimeStamp in MockProcessor (#6933)\n\nThis PR is to use KeyValueTimeStamp Object in MockProcessor Test file instead of String and change all the dependency files with broken test cases.\n\nReviewers: Kamal Chandraprakash.  Matthias J. Sax <mjsax@apache.org>.   Boyang Chen <boyang@confluent.io>.  Bill Bejeck <bbejeck@gmail.com>","date":"2019-07-16 22:16:15","modifiedFileCount":"28","status":"M","submitter":"SuryaTeja Duggi"},{"authorTime":"2019-10-03 11:32:18","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":27,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2019-10-03 11:32:18","commitOrder":27,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","date":"2019-10-03 11:32:18","endLine":469,"groupId":"5409","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b6/6abd32c219ef798beb517463f728168d5dc2c8.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":362,"status":"M"}],"commitId":"6925775e63fd33e6a44bbda671b2de7db41d150e","commitMessage":"@@@KAFKA-8558:  Add StreamJoined config object to join (#7285)\n\nReviewer: John Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2019-10-03 11:32:18","modifiedFileCount":"11","status":"M","submitter":"Bill Bejeck"},{"authorTime":"2019-10-07 16:01:58","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":28,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2019-10-07 16:01:58","commitOrder":28,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<Integer, String> inputTopic1 =\n                    driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final TestInputTopic<Integer, String> inputTopic2 =\n                    driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic1.pipeInput(expectedKeys[i], \"A\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"a\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"B\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic2.pipeInput(expectedKey, \"b\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"C\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"c\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","date":"2019-10-07 16:01:58","endLine":478,"groupId":"652","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d7/ce37e8bce2934b70e0c6581ecf1d199ddf73a0.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKeys[i], \"A\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"a\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"B\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKey, \"b\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                driver.pipeInput(recordFactory.create(topic1, expectedKey, \"C\" + expectedKey));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                driver.pipeInput(recordFactory.create(topic2, expectedKeys[i], \"c\" + expectedKeys[i]));\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":367,"status":"M"}],"commitId":"a5a6938c69f4310f7ec519036f0df77d8022326a","commitMessage":"@@@KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)\n\nImplements KIP-470\n\nReviewers: Bill Bejeck <bill@confluent.io>.  John Roesler <john@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2019-10-07 16:01:58","modifiedFileCount":"47","status":"M","submitter":"Jukka Karvanen"},{"authorTime":"2021-04-29 08:57:28","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":29,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"15879","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2021-04-29 08:57:28","commitOrder":29,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<Integer, String> inputTopic1 =\n                    driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final TestInputTopic<Integer, String> inputTopic2 =\n                    driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic1.pipeInput(expectedKeys[i], \"A\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"a\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"B\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic2.pipeInput(expectedKey, \"b\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"C\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"c\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","date":"2021-04-29 08:57:28","endLine":598,"groupId":"14940","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ca/26393bb33a04bbcaa78b21d7ad3dd42da53caf.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<Integer, String> inputTopic1 =\n                    driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final TestInputTopic<Integer, String> inputTopic2 =\n                    driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic1.pipeInput(expectedKeys[i], \"A\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+null\", 0),\n                new KeyValueTimestamp<>(1, \"A1+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"a\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"B\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+null\", 0),\n                new KeyValueTimestamp<>(3, \"B3+null\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic2.pipeInput(expectedKey, \"b\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"C\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"c\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":490,"status":"M"}],"commitId":"bf359f8e2924ee03b34a6f7e7eaf80bef55f9d98","commitMessage":"@@@KAFKA-10847: Fix spurious results on left/outer stream-stream joins (#10462)\n\nFixes the issue with https://issues.apache.org/jira/browse/KAFKA-10847.\n\nTo fix the above problem.  the left/outer stream-stream join processor uses a buffer to hold non-joined records for some time until the window closes.  so they are not processed if a join is found during the join window time. If the window of a record closes and a join was not found.  then this should be emitted and processed by the consequent topology processor.\n\nA new time-ordered window store is used to temporary hold records that do not have a join and keep the records keys ordered by time. The KStreamStreamJoin has a reference to this new store . For every non-joined record seen.  the processor writes it to this new state store without processing it. When a joined record is seen.  the processor deletes the joined record from the new state store to prevent further processing.\n\nRecords that were never joined at the end of the window + grace period are emitted to the next topology processor. I use the stream time to check for the expiry time for determinism results . The KStreamStreamJoin checks for expired records and emit them every time a new record is processed in the join processor.\n\nThe new state store is shared with the left and right join nodes. The new store needs to serialize the record keys using a combined key of <joinSide-recordKey>. This key combination helps to delete the records from the other join if a joined record is found. Two new serdes are created for this.  KeyAndJoinSideSerde which serializes a boolean value that specifies the side where the key is found.  and ValueOrOtherValueSerde that serializes either V1 or V2 based on where the key was found.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2021-04-29 08:57:28","modifiedFileCount":"11","status":"M","submitter":"Sergio Pe?a"},{"authorTime":"2021-06-17 00:25:16","codes":[{"authorDate":"2018-05-18 02:28:45","commitOrder":30,"curCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","date":"2018-05-18 02:28:45","endLine":111,"groupId":"101444","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldRequireCopartitionedStreams","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/55/635fa6517c12a98035d019dba981319361a3c0.src","preCode":"    public void shouldRequireCopartitionedStreams() {\n\n        final Collection<Set<String>> copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":105,"status":"N"},{"authorDate":"2021-06-17 00:25:16","commitOrder":30,"curCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.ofTimeDifferenceAndGrace(ofMillis(100L), ofHours(24L)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String())\n        );\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<Integer, String> inputTopic1 =\n                    driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final TestInputTopic<Integer, String> inputTopic2 =\n                    driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic1.pipeInput(expectedKeys[i], \"A\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"a\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(\n                new KeyValueTimestamp<>(0, \"A0+a0\", 0L),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0L)\n            );\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"B\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(\n                new KeyValueTimestamp<>(0, \"B0+a0\", 0L),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0L)\n            );\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic2.pipeInput(expectedKey, \"b\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(\n                new KeyValueTimestamp<>(0, \"A0+b0\", 0L),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0L),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0L),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0L),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0L),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0L)\n            );\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"C\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(\n                new KeyValueTimestamp<>(0, \"C0+a0\", 0L),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0L),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0L),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0L),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0L),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0L)\n            );\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"c\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(\n                new KeyValueTimestamp<>(0, \"A0+c0\", 0L),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0L),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0L),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0L),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0L),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0L)\n            );\n        }\n    }\n","date":"2021-06-17 00:25:16","endLine":620,"groupId":"101444","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testOuterJoin","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ee/501add2512c45574539e0d0910e8c183a40b81.src","preCode":"    public void testOuterJoin() {\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final int[] expectedKeys = new int[] {0, 1, 2, 3};\n\n        final KStream<Integer, String> stream1;\n        final KStream<Integer, String> stream2;\n        final KStream<Integer, String> joined;\n        final MockProcessorSupplier<Integer, String> supplier = new MockProcessorSupplier<>();\n\n        stream1 = builder.stream(topic1, consumed);\n        stream2 = builder.stream(topic2, consumed);\n        joined = stream1.outerJoin(\n            stream2,\n            MockValueJoiner.TOSTRING_JOINER,\n            JoinWindows.of(ofMillis(100)),\n            StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));\n        joined.process(supplier);\n        final Collection<Set<String>> copartitionGroups =\n            TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();\n\n        assertEquals(1, copartitionGroups.size());\n        assertEquals(new HashSet<>(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<Integer, String> inputTopic1 =\n                    driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final TestInputTopic<Integer, String> inputTopic2 =\n                    driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n            final MockProcessor<Integer, String> processor = supplier.theCapturedProcessor();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic1.pipeInput(expectedKeys[i], \"A\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult();\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"a\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"B\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"B0+a0\", 0),\n                new KeyValueTimestamp<>(1, \"B1+a1\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic2.pipeInput(expectedKey, \"b\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+b0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+b1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"B2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"B3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (final int expectedKey : expectedKeys) {\n                inputTopic1.pipeInput(expectedKey, \"C\" + expectedKey);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"C0+a0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+b0\", 0),\n                new KeyValueTimestamp<>(1, \"C1+a1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+b1\", 0),\n                new KeyValueTimestamp<>(2, \"C2+b2\", 0),\n                new KeyValueTimestamp<>(3, \"C3+b3\", 0));\n\n            \r\n            \r\n            \r\n            \r\n            \r\n            for (int i = 0; i < 2; i++) {\n                inputTopic2.pipeInput(expectedKeys[i], \"c\" + expectedKeys[i]);\n            }\n            processor.checkAndClearProcessResult(new KeyValueTimestamp<>(0, \"A0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"B0+c0\", 0),\n                new KeyValueTimestamp<>(0, \"C0+c0\", 0),\n                new KeyValueTimestamp<>(1, \"A1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"B1+c1\", 0),\n                new KeyValueTimestamp<>(1, \"C1+c1\", 0));\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":501,"status":"M"}],"commitId":"96767a60db4117f257e911871d139572b84be65d","commitMessage":"@@@KAFKA-12909: disable spurious left/outer stream-stream join fix for old JoinWindows API (#10861)\n\nWe changed the behavior of left/outer stream-stream join via KAFKA-10847.\nTo avoid a breaking change during an upgrade.  we need to disable this\nfix by default.\n\nWe only enable the fix if users opt-in expliclity by changing their\ncode. We leverage KIP-633 (KAFKA-8613) that offers a new JoinWindows\nAPI with mandatory grace-period to enable the fix.\n\nReviewers: Sergio Pe?a <sergio@confluent.io>.  Israel Ekpo <israelekpo@gmail.com>.  Guozhang Wang <guozhang@confluent.io>","date":"2021-06-17 00:25:16","modifiedFileCount":"11","status":"M","submitter":"Matthias J. Sax"}]
