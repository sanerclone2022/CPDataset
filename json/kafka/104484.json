[{"authorTime":"2021-01-30 06:06:01","codes":[{"authorDate":"2021-01-30 06:06:01","commitOrder":1,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-01-30 06:06:01","endLine":224,"groupId":"12906","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/61/4ff327cffed3dfd8ddcf40a67459d34b05e706.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"B"},{"authorDate":"2021-01-30 06:06:01","commitOrder":1,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-01-30 06:06:01","endLine":270,"groupId":"12906","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/61/4ff327cffed3dfd8ddcf40a67459d34b05e706.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":227,"status":"B"}],"commitId":"5b3351e10b339f5ef43fa4ec9e23544acad298c3","commitMessage":"@@@KAFKA-10761; Kafka Raft update log start offset (#9816)\n\nAdds support for nonzero log start offsets.\n\nChanges to `Log`:\n1. Add a new \"reason\" for increasing the log start offset. This is used by `KafkaMetadataLog` when a snapshot is generated.\n2. `LogAppendInfo` should return if it was rolled because of an records append. A log is rolled when a new segment is created. This is used by `KafkaMetadataLog` to in some cases delete the created segment based on the log start offset.\n\nChanges to `KafkaMetadataLog`:\n1. Update both append functions to delete old segments based on the log start offset whenever the log is rolled.\n2. Update `lastFetchedEpoch` to return the epoch of the latest snapshot whenever the log is empty.\n3. Add a function that empties the log whenever the latest snapshot is greater than the replicated log. This is used when first loading the `KafkaMetadataLog` and whenever the `KafkaRaftClient` downloads a snapshot from the leader.\n\nChanges to `KafkaRaftClient`:\n1. Improve `validateFetchOffsetAndEpoch` so that it can handle fetch offset and last fetched epoch that are smaller than the log start offset. This is in addition to the existing code that check for a diverging log. This is used by the raft client to determine if the Fetch response should include a diverging epoch or a snapshot id. \n2. When a follower finishes fetching a snapshot from the leader fully truncate the local log.\n3. When polling the current state the raft client should check if the state machine has generated a new snapshot and update the log start offset accordingly.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2021-01-30 06:06:01","modifiedFileCount":"11","status":"B","submitter":"Jos? Armando Garc?a Sancio"},{"authorTime":"2021-02-19 08:44:40","codes":[{"authorDate":"2021-02-19 08:44:40","commitOrder":2,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-02-19 08:44:40","endLine":227,"groupId":"12906","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9e/bb776fe18182bae251459c2d63484b5728594d.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"M"},{"authorDate":"2021-02-19 08:44:40","commitOrder":2,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-02-19 08:44:40","endLine":274,"groupId":"12906","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9e/bb776fe18182bae251459c2d63484b5728594d.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.offset, oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.offset + 3, oldestSnapshotId.epoch + 2, Arrays.asList(\"a\", \"b\", \"c\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"}],"commitId":"e29f7a36dbbd316ae03008140a1a0d282a26b82d","commitMessage":"@@@KAFKA-12331: Use LEO for the base offset of LeaderChangeMessage batch (#10138)\n\nThe `KafkaMetadataLog` implementation of `ReplicatedLog` validates that batches appended using `appendAsLeader` and `appendAsFollower` have an offset that matches the LEO. This is enforced by `KafkaRaftClient` and `BatchAccumulator`. When creating control batches for the `LeaderChangeMessage` the default base offset of `0` was being used instead of using the LEO. This is fixed by:\n\n1. Changing the implementation for `MockLog` to validate against this and throw an `RuntimeException` if this invariant is violated.\n2. Always create a batch for `LeaderChangeMessage` with an offset equal to the LEO.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2021-02-19 08:44:40","modifiedFileCount":"9","status":"M","submitter":"Jos? Armando Garc?a Sancio"},{"authorTime":"2021-02-20 06:43:14","codes":[{"authorDate":"2021-02-20 06:43:14","commitOrder":3,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-02-20 06:43:14","endLine":227,"groupId":"12906","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2b/7cea55541516eb8b4e7497642937f875854427.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"M"},{"authorDate":"2021-02-20 06:43:14","commitOrder":3,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-02-20 06:43:14","endLine":274,"groupId":"12906","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2b/7cea55541516eb8b4e7497642937f875854427.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"}],"commitId":"bbf145b1b163bada0b20cea42b29d91443161170","commitMessage":"@@@KAFKA-10817; Add clusterId validation to raft Fetch handling (#10129)\n\nThis patch adds clusterId validation in the `Fetch` API as documented in KIP-595. A new error code `INCONSISTENT_CLUSTER_ID` is returned if the request clusterId does not match the value on the server. If no clusterId is provided.  the request is treated as valid.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2021-02-20 06:43:14","modifiedFileCount":"6","status":"M","submitter":"David Jacot"},{"authorTime":"2021-03-04 18:06:50","codes":[{"authorDate":"2021-02-20 06:43:14","commitOrder":4,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-02-20 06:43:14","endLine":227,"groupId":"12906","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2b/7cea55541516eb8b4e7497642937f875854427.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"N"},{"authorDate":"2021-03-04 18:06:50","commitOrder":4,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-03-04 18:06:50","endLine":274,"groupId":"12906","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/6b9bdf31e1898e6c8584d815bfc7ed1ecbcdfc.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.FetchablePartitionResponse partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"}],"commitId":"8205051e90e3ea16165f8dc1f5c81af744bb1b9a","commitMessage":"@@@MINOR: remove FetchResponse.AbortedTransaction and redundant construc? (#9758)\n\n1. rename INVALID_HIGHWATERMARK to INVALID_HIGH_WATERMARK\n2. replace FetchResponse.AbortedTransaction by FetchResponseData.AbortedTransaction\n3. remove redundant constructors from FetchResponse.PartitionData\n4. rename recordSet to records\n5. add helpers \"recordsOrFail\" and \"recordsSize\" to FetchResponse to process record casting\n\nReviewers: Ismael Juma <ismael@juma.me.uk>","date":"2021-03-04 18:06:50","modifiedFileCount":"15","status":"M","submitter":"Chia-Ping Tsai"},{"authorTime":"2021-06-16 01:32:01","codes":[{"authorDate":"2021-06-16 01:32:01","commitOrder":5,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-06-16 01:32:01","endLine":393,"groupId":"12597","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4f/2617ecd2a8c45b6bc6113ddd41554cab3227c0.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":353,"status":"M"},{"authorDate":"2021-06-16 01:32:01","commitOrder":5,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-06-16 01:32:01","endLine":441,"groupId":"12597","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/4f/2617ecd2a8c45b6bc6113ddd41554cab3227c0.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId)) {\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"M"}],"commitId":"b67a77d5b9ed497b5b3cf0dde95a4f3ef7f0b74f","commitMessage":"@@@KAFKA-12787; Integrate controller snapshoting with raft client (#10786)\n\nDirectly use `RaftClient.Listener`.  `SnapshotWriter` and `SnapshotReader` in the quorum controller.\n\n1. Allow `RaftClient` users to create snapshots by specifying the last committed offset and last committed epoch. These values are validated against the log and leader epoch cache.\n2. Remove duplicate classes in the metadata module for writing and reading snapshots.\n3. Changed the logic for comparing snapshots. The old logic was assuming a certain batch grouping. This didn't match the implementation of the snapshot writer. The snapshot writer is free to merge batches before writing them.\n4. Improve `LocalLogManager` to keep track of multiple snapshots.\n5. Improve the documentation and API for the snapshot classes to highlight the distinction between the offset of batches in the snapshot vs the offset of batches in the log. These two offsets are independent of one another. `SnapshotWriter` and `SnapshotReader` expose a method called `lastOffsetFromLog` which represents the last inclusive offset from the log that is represented in the snapshot.\n\nReviewers: dengziming <swzmdeng@163.com>.  Jason Gustafson <jason@confluent.io>","date":"2021-06-16 01:32:01","modifiedFileCount":"21","status":"M","submitter":"Jos? Armando Garc?a Sancio"},{"authorTime":"2021-06-30 00:37:20","codes":[{"authorDate":"2021-06-30 00:37:20","commitOrder":6,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-06-30 00:37:20","endLine":393,"groupId":"19323","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/df/9da9dfc535c9c1dcf815e1f9aaa13b2e7b2987.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":353,"status":"M"},{"authorDate":"2021-06-30 00:37:20","commitOrder":6,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-06-30 00:37:20","endLine":441,"groupId":"19323","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/df/9da9dfc535c9c1dcf815e1f9aaa13b2e7b2987.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"M"}],"commitId":"d3ec9f940cc4402270cba3ad159ec64a9676a385","commitMessage":"@@@KAFKA-12952 Add header and footer records for raft snapshots (#10899)\n\nAdd header and footer records for raft snapshots. This helps identify when the snapshot\nstarts and ends. The header also contains a time.  The time field is currently set to 0.\nKAFKA-12997 will add in the necessary wiring to use the correct timestamp.\n\nReviewers: Jose Sancio <jsancio@gmail.com>.  Colin P. McCabe <cmccabe@apache.org>","date":"2021-06-30 00:37:20","modifiedFileCount":"17","status":"M","submitter":"Niket"},{"authorTime":"2021-06-08 04:25:28","codes":[{"authorDate":"2021-06-30 00:37:20","commitOrder":7,"curCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","date":"2021-06-30 00:37:20","endLine":393,"groupId":"104484","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithValidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/df/9da9dfc535c9c1dcf815e1f9aaa13b2e7b2987.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":353,"status":"N"},{"authorDate":"2021-06-08 04:25:28","commitOrder":7,"curCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.log.deleteBeforeSnapshot(oldestSnapshotId);\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","date":"2021-07-07 05:19:44","endLine":442,"groupId":"104484","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testFetchRequestAtLogStartOffsetWithInvalidEpoch","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/04/b56760607a88a9d8af58708f83f67cf3038cea.src","preCode":"    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId = 0;\n        int otherNodeId = localId + 1;\n        int syncNodeId = otherNodeId + 1;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId = new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch, Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch = context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch + 2 + 1, epoch);\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, syncNodeId, context.log.endOffset().offset, epoch, 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong());\n\n        \r\n        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(oldestSnapshotId.offset - 1, oldestSnapshotId.epoch, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        \r\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset, oldestSnapshotId.epoch + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse = context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch, partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset, partitionResponse.snapshotId().endOffset());\n    }\n","realPath":"raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"M"}],"commitId":"284ec262c6c84063d90271c965e4cbc1eda111fe","commitMessage":"@@@KAFKA-12155: Metadata log and snapshot cleaning #10864\n\nThis PR includes changes to KafkaRaftClient and KafkaMetadataLog to support periodic\ncleaning of old log segments and snapshots.\n\nFour new public config keys are introduced: metadata.log.segment.bytes. \nmetadata.log.segment.ms.  metadata.max.retention.bytes.  and\nmetadata.max.retention.ms.\n\nThese are used to configure the log layer as well as the snapshot cleaning logic. Snapshot\nand log cleaning is performed based on two criteria: total metadata log + snapshot size\n(metadata.max.retention.bytes).  and max age of a snapshot (metadata.max.retention.ms).\nSince we have a requirement that the log start offset must always align with a snapshot. \nwe perform the cleaning on snapshots first and then clean what logs we can.\n\nThe cleaning algorithm follows:\n1. Delete the oldest snapshot.\n2. Advance the log start offset to the new oldest snapshot.\n3. Request that the log layer clean any segments prior to the new log start offset\n4. Repeat this until the retention size or time is no longer violated.  or only a single\nsnapshot remains.\n\nThe cleaning process is triggered every 60 seconds from the KafkaRaftClient polling\nthread.\n\nReviewers: Jos? Armando Garc?a Sancio <jsancio@gmail.com>.  dengziming <dengziming1993@gmail.com>.  Colin P. McCabe <cmccabe@apache.org>\n","date":"2021-07-07 05:19:44","modifiedFileCount":"5","status":"M","submitter":"David Arthur"}]
