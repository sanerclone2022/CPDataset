[{"authorTime":"2020-09-12 05:38:17","codes":[{"authorDate":"2019-12-13 02:52:24","commitOrder":2,"curCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","date":"2019-12-13 02:52:24","endLine":154,"groupId":"18762","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"timeWindowAggregateTestStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1e/9b6edda177029ce7e9f61325f749c28f9c93c0.src","preCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/TimeWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"NB"},{"authorDate":"2020-09-12 05:38:17","commitOrder":2,"curCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","date":"2020-09-12 05:38:17","endLine":202,"groupId":"18762","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"slidingWindowAggregateStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5c/9ccb251566317ecf2b4be22e24fc091c98832c.src","preCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SlidingWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":151,"status":"B"}],"commitId":"2194ccba5b95657ff7d6a4739edc98cf70f4472b","commitMessage":"@@@Adding reverse iterator usage for sliding windows processing (extending KIP-450) (#9239)\n\nAdd a backwardFetch call to the window store for sliding window\nprocessing. While the implementation works with the forward call\nto the window store.  using backwardFetch allows for the iterator\nto be closed earlier.  making implementation more efficient.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  John Roesler <vvcephei@apache.org>","date":"2020-09-12 05:38:17","modifiedFileCount":"6","status":"M","submitter":"leah"},{"authorTime":"2020-09-12 05:38:17","codes":[{"authorDate":"2021-02-02 08:20:35","commitOrder":3,"curCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","date":"2021-02-02 08:20:35","endLine":180,"groupId":"11889","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"timeWindowAggregateTestStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d0/52429767b7b9a08786b8c4f7ba9e4c460a9c43.src","preCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/TimeWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"M"},{"authorDate":"2020-09-12 05:38:17","commitOrder":3,"curCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","date":"2020-09-12 05:38:17","endLine":202,"groupId":"18762","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"slidingWindowAggregateStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5c/9ccb251566317ecf2b4be22e24fc091c98832c.src","preCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SlidingWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":151,"status":"N"}],"commitId":"f5a2fbac6d26fc1613ec34d9764a1e86732f0a45","commitMessage":"@@@KAFKA-10366 & KAFKA-9649: Implement KIP-659 to allow TimeWindowedDeserializer and TimeWindowedSerde to handle window size (#9253)\n\nSee KIP details and discussions here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-659%3A+Improve+TimeWindowedDeserializer+and+TimeWindowedSerde+to+handle+window+size\n\nDeprecates methods that allow users to skip setting a window size when one is needed. Adds a window size streams config to allow the timeWindowedDeserializer to calculate window end time.\n\nReviewers: Walker Carlson <wcarlson@confluent.io>.  John Roesler <vvcephei@apache.org>.  Guozhang Wang <wangguoz@gmail.com>","date":"2021-02-02 08:20:35","modifiedFileCount":"9","status":"M","submitter":"leah"},{"authorTime":"2021-05-23 05:22:42","codes":[{"authorDate":"2021-02-02 08:20:35","commitOrder":4,"curCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","date":"2021-02-02 08:20:35","endLine":180,"groupId":"11889","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"timeWindowAggregateTestStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d0/52429767b7b9a08786b8c4f7ba9e4c460a9c43.src","preCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/TimeWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"N"},{"authorDate":"2021-05-23 05:22:42","commitOrder":4,"curCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE_MS), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","date":"2021-05-23 05:22:42","endLine":203,"groupId":"18762","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"slidingWindowAggregateStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5a/06341eb86c5e10ffbd940737a0a00f3137fb9a.src","preCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer()), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SlidingWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"M"}],"commitId":"47796d2f8781447c8e7de716841db438cde9cc3c","commitMessage":"@@@MINOR: Fix deprecation warnings in SlidingWindowedCogroupedKStreamImplTest (#10703)\n\nReviewers: Matthias J. Sax <matthias@confluent.io>","date":"2021-05-23 05:22:42","modifiedFileCount":"1","status":"M","submitter":"Ismael Juma"},{"authorTime":"2021-05-26 14:43:33","codes":[{"authorDate":"2021-02-02 08:20:35","commitOrder":5,"curCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","date":"2021-02-02 08:20:35","endLine":180,"groupId":"101392","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"timeWindowAggregateTestStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d0/52429767b7b9a08786b8c4f7ba9e4c460a9c43.src","preCode":"    public void timeWindowAggregateTestStreamsTest() {\n\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 0);\n            testInputTopic.pipeInput(\"k2\", \"A\", 1);\n            testInputTopic.pipeInput(\"k1\", \"A\", 2);\n            testInputTopic.pipeInput(\"k1\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 3);\n            testInputTopic.pipeInput(\"k2\", \"B\", 4);\n            testInputTopic.pipeInput(\"k1\", \"B\", 4);\n\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A\", 0);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A\", 1);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A\", 2);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B\", 3);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k2\", \"0+A+A+B+B\", 4);\n            assertOutputKeyValueTimestamp(testOutputTopic, \"k1\", \"0+A+A+B+B\", 4);\n        }\n\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/TimeWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":149,"status":"N"},{"authorDate":"2021-05-26 14:43:33","commitOrder":5,"curCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE_MS), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final List<TestRecord<Windowed<String>, String>> results = testOutputTopic.readRecordsToList();\n\n            final List<TestRecord<Windowed<String>, String>> expected = new LinkedList<>();\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(0L, 500L)), \"0+A\", null, 500L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(0L, 500L)), \"0+A\", null, 500L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(501L, 1001L)), \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(1L, 501L)), \"0+A+A\", null, 501L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(501L, 1001L)), \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(2L, 502L)), \"0+A+A\", null, 502L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(501L, 1001L)), \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(503L, 1003L)), \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(3L, 503L)), \"0+A+A+B\", null, 503L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(501L, 1001L)), \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(502L, 1002)), \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(3L, 503L)), \"0+A+A+B\", null, 503L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(502L, 1002L)), \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(501L, 1001L)), \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(504L, 1004L)), \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k2\", new TimeWindow(4L, 504L)), \"0+A+A+B+B\", null, 504L));\n            \r\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(503L, 1003L)), \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(501L, 1001L)), \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(504L, 1004L)), \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(new Windowed<>(\"k1\", new TimeWindow(4L, 504L)), \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","date":"2021-05-26 14:43:33","endLine":204,"groupId":"101392","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"slidingWindowAggregateStreamsTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/96/d301decade340e60611c647bd230c8852bf643.src","preCode":"    public void slidingWindowAggregateStreamsTest() {\n        final KTable<Windowed<String>, String> customers = windowedCogroupedStream.aggregate(\n                MockInitializer.STRING_INIT, Materialized.with(Serdes.String(), Serdes.String()));\n        customers.toStream().to(OUTPUT);\n\n        try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n            final TestInputTopic<String, String> testInputTopic = driver.createInputTopic(\n                    TOPIC, new StringSerializer(), new StringSerializer());\n            final TestOutputTopic<Windowed<String>, String> testOutputTopic = driver.createOutputTopic(\n                    OUTPUT, new TimeWindowedDeserializer<>(new StringDeserializer(), WINDOW_SIZE_MS), new StringDeserializer());\n\n            testInputTopic.pipeInput(\"k1\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 500);\n            testInputTopic.pipeInput(\"k2\", \"A\", 501);\n            testInputTopic.pipeInput(\"k1\", \"A\", 502);\n            testInputTopic.pipeInput(\"k1\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 503);\n            testInputTopic.pipeInput(\"k2\", \"B\", 504);\n            testInputTopic.pipeInput(\"k1\", \"B\", 504);\n\n            final Set<TestRecord<String, String>> results = new HashSet<>();\n            while (!testOutputTopic.isEmpty()) {\n                final TestRecord<Windowed<String>, String> realRecord = testOutputTopic.readRecord();\n                final TestRecord<String, String> nonWindowedRecord = new TestRecord<>(\n                    realRecord.getKey().key(), realRecord.getValue(), null, realRecord.timestamp());\n                results.add(nonWindowedRecord);\n            }\n            final Set<TestRecord<String, String>> expected = new HashSet<>();\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 500L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A\", null, 501L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A\", null, 502L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B\", null, 503L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k2\", \"0+A+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+B\", null, 504L));\n            expected.add(new TestRecord<>(\"k1\", \"0+A+A+B+B\", null, 504L));\n\n            assertEquals(expected, results);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/kstream/internals/SlidingWindowedCogroupedKStreamImplTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"M"}],"commitId":"77573d88c819753e6409e6f346e1d72172313d7a","commitMessage":"@@@MINOR: add window verification to sliding-window co-group test (#10745)\n\nReviewers: Luke Chen <showuon@gmail.com>.  A. Sophie Blee-Goldman <sophie@confluent.io>","date":"2021-05-26 14:43:33","modifiedFileCount":"1","status":"M","submitter":"Matthias J. Sax"}]
