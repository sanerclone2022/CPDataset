[{"authorTime":"2020-03-06 04:20:46","codes":[{"authorDate":"2020-02-21 05:24:38","commitOrder":5,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2020-02-21 05:24:38","endLine":531,"groupId":"6581","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/df/d29c63fd3106b31582b07b7bfc3fd3a9e2a6ee.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":497,"status":"NB"},{"authorDate":"2020-03-06 04:20:46","commitOrder":5,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(\n            partition,\n            singletonList(new ConsumerRecord<>(partition.topic(), partition.partition(), 0L, null, null))\n        );\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(0L));\n    }\n","date":"2020-03-06 04:20:46","endLine":1155,"groupId":"6581","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/40/b8782772af8b9404edb58526a6e4cb675cade7.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(\n            partition,\n            singletonList(new ConsumerRecord<>(partition.topic(), partition.partition(), 0L, null, null))\n        );\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(0L));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1129,"status":"B"}],"commitId":"78374a15492cfb6df49353bd166d8c45ac9abdb2","commitMessage":"@@@KAFKA-9615: Clean up task/producer create and close (#8213)\n\n* Consolidate task/producer management. Now.  exactly one component manages\n  the creation and destruction of Producers.  whether they are per-thread or per-task.\n* Add missing test coverage on TaskManagerTest\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>.  Boyang Chen <boyang@confluent.io>","date":"2020-03-06 04:20:46","modifiedFileCount":"12","status":"M","submitter":"John Roesler"},{"authorTime":"2020-03-06 04:20:46","codes":[{"authorDate":"2020-03-14 11:56:59","commitOrder":6,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2020-03-14 11:56:59","endLine":1162,"groupId":"6581","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/62/043e391cd183f1929bbcf3fbb49169d473a9e2.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1128,"status":"M"},{"authorDate":"2020-03-06 04:20:46","commitOrder":6,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(\n            partition,\n            singletonList(new ConsumerRecord<>(partition.topic(), partition.partition(), 0L, null, null))\n        );\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(0L));\n    }\n","date":"2020-03-06 04:20:46","endLine":1155,"groupId":"6581","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/40/b8782772af8b9404edb58526a6e4cb675cade7.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(\n            partition,\n            singletonList(new ConsumerRecord<>(partition.topic(), partition.partition(), 0L, null, null))\n        );\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(0L));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1129,"status":"N"}],"commitId":"542853d99b9e0d660a9cf9317be8a3f8fce4c765","commitMessage":"@@@KAFKA-6145: Pt 2. Include offset sums in subscription (#8246)\n\nKIP-441 Pt. 2: Compute sum of offsets across all stores/changelogs in a task and include them in the subscription.\n\nPreviously each thread would just encode every task on disk.  but we now need to read the changelog file which is unsafe to do without a lock on the task directory. So.  each thread now encodes only its assigned active and standby tasks.  and ignores any already-locked tasks.\n\nIn some cases there may be unowned and unlocked tasks on disk that were reassigned to another instance and haven't been cleaned up yet by the background thread. Each StreamThread makes a weak effort to lock any such task directories it finds.  and if successful is then responsible for computing and reporting that task's offset sum (based on reading the checkpoint file)\n\nThis PR therefore also addresses two orthogonal issues:\n\n1. Prevent background cleaner thread from deleting unowned stores during a rebalance\n2. Deduplicate standby tasks in subscription: each thread used to include every (non-active) task found on disk in its \"standby task\" set.  which meant every active.  standby.  and unowned task was encoded by every thread.\n\nReviewers: Bruno Cadonna <bruno@confluent.io>.  John Roesler <vvcephei@apache.org>","date":"2020-03-14 11:56:59","modifiedFileCount":"10","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-03-27 13:54:08","codes":[{"authorDate":"2020-03-14 11:56:59","commitOrder":7,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2020-03-14 11:56:59","endLine":1162,"groupId":"6581","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/62/043e391cd183f1929bbcf3fbb49169d473a9e2.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1128,"status":"N"},{"authorDate":"2020-03-27 13:54:08","commitOrder":7,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, 0L));\n    }\n","date":"2020-03-27 13:54:08","endLine":1880,"groupId":"6581","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f3/b33e1fd3b6b4501d479954db76c790d6d176e1.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(\n            partition,\n            singletonList(new ConsumerRecord<>(partition.topic(), partition.partition(), 0L, null, null))\n        );\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(0L));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1857,"status":"M"}],"commitId":"9d9b59fccc1d3a71758dfb7dc6d2325d4fba9955","commitMessage":"@@@KAFKA-9756: Process more than one record of one task at a time (#8358)\n\n1. Within a single while loop.  process the tasks in AAABBBCCC instead of ABCABCABC. This also helps the follow-up PR to time the per-task processing ratio to record less time.  hence less overhead.\n\n2. Add thread-level process / punctuate / poll / commit ratio metrics.\n\n3. Fixed a few issues discovered (inline commented).\n\nReviewers: John Roesler <vvcephei@apache.org>","date":"2020-03-27 13:54:08","modifiedFileCount":"6","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-04-01 07:39:28","codes":[{"authorDate":"2020-03-14 11:56:59","commitOrder":8,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2020-03-14 11:56:59","endLine":1162,"groupId":"6581","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/62/043e391cd183f1929bbcf3fbb49169d473a9e2.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1128,"status":"N"},{"authorDate":"2020-04-01 07:39:28","commitOrder":8,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2020-04-01 07:39:28","endLine":1882,"groupId":"6581","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/95/717aa75213bc6a4d3157a53429c21fc502c636.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, 0L));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1859,"status":"M"}],"commitId":"353aa6206d43b4923d21510797709bbbb210f6b6","commitMessage":"@@@KAFKA-9753: Add active tasks process ratio (#8370)\n\nMeasure the percentage ratio the stream thread spent on processing each task among all assigned active tasks (KIP-444). Also add unit tests to cover the added metrics in this PR and the previous #8358. Also trying to fix the flaky test reported in KAFKA-5842\n\nCo-authored-by: John Roesler <vvcephei@apache.org>\n\nReviewers: Bruno Cadonna <bruno@confluent.io>.  John Roesler <vvcephei@apache.org>","date":"2020-04-01 07:39:28","modifiedFileCount":"12","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-10-20 02:07:56","codes":[{"authorDate":"2020-10-20 02:07:56","commitOrder":9,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2020-10-20 02:07:56","endLine":1959,"groupId":"6581","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/61/5e148d7adfac58b89f87a980544d1d0dd371d2.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1925,"status":"M"},{"authorDate":"2020-10-20 02:07:56","commitOrder":9,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2020-10-20 02:07:56","endLine":2167,"groupId":"6581","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/61/5e148d7adfac58b89f87a980544d1d0dd371d2.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2144,"status":"M"}],"commitId":"aef6cd6e9995b42db2cefa7d715321d0edee5628","commitMessage":"@@@KAFKA-9274: Add timeout handling for state restore and StandbyTasks (#9368)\n\n* Part of KIP-572\n* If a TimeoutException happens during restore of active tasks.  or updating standby tasks.  we need to trigger task.timeout.ms timeout.\n\nReviewers: John Roesler <john@confluent.io>","date":"2020-10-20 02:07:56","modifiedFileCount":"15","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2021-01-22 00:52:34","codes":[{"authorDate":"2021-01-22 00:52:34","commitOrder":10,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2021-01-22 00:52:34","endLine":2021,"groupId":"6581","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1b/a1151510f36176da74cab4e2af690ba566a41a.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1987,"status":"M"},{"authorDate":"2021-01-22 00:52:34","commitOrder":10,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2021-01-22 00:52:34","endLine":2229,"groupId":"6581","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1b/a1151510f36176da74cab4e2af690ba566a41a.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andReturn(singletonList(task00)).anyTimes();\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2206,"status":"M"}],"commitId":"92e72f7bf96841d7991f1d71f440c2da06dd89cf","commitMessage":"@@@KAFKA-12185: fix ConcurrentModificationException in newly added Tasks container class (#9940)\n\nReviewers: Guozhang Wang <guozhand@confluent.io>.  A. Sophie Blee-Goldman <sophie@confluent.io>","date":"2021-01-22 00:52:34","modifiedFileCount":"2","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2021-02-06 09:25:50","codes":[{"authorDate":"2021-02-06 09:25:50","commitOrder":11,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2021-02-06 09:25:50","endLine":1999,"groupId":"6581","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9a/3a8c92c30322fe86e22b4a1174900049e5d642.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1965,"status":"M"},{"authorDate":"2021-02-06 09:25:50","commitOrder":11,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2021-02-06 09:25:50","endLine":2270,"groupId":"6581","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9a/3a8c92c30322fe86e22b4a1174900049e5d642.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2247,"status":"M"}],"commitId":"0bc394cc1d19f1e41dd6646e9ac0e09b91fb1398","commitMessage":"@@@KAFKA-9274: handle TimeoutException on task reset (#10000)\n\nPart of KIP-572: We move the offset reset for the internal \"main consumer\" when we revive a corrupted task.  from the \"task cleanup\" code path.  to the \"task init\" code path. For this case.  we have already logic in place to handle TimeoutException that might be thrown by consumer#committed() method call.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>\n","date":"2021-02-06 09:25:50","modifiedFileCount":"10","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2021-02-07 05:04:30","codes":[{"authorDate":"2021-02-07 05:04:30","commitOrder":12,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2021-02-07 05:04:30","endLine":2023,"groupId":"6581","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/224e0cd5c002edd02d0ef2ee8e1586fa832b3d.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1989,"status":"M"},{"authorDate":"2021-02-07 05:04:30","commitOrder":12,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2021-02-07 05:04:30","endLine":2294,"groupId":"6581","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/224e0cd5c002edd02d0ef2ee8e1586fa832b3d.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2271,"status":"M"}],"commitId":"d2cb2dc45d536ae124e3da25d6d5a4e932a23a27","commitMessage":"@@@KAFKA-9751: Forward CreateTopicsRequest for FindCoordinator/Metadata when topic creation is needed (#9579)\n\nConsolidate auto topic creation logic to either forward a CreateTopicRequest or handling the creation directly as AutoTopicCreationManager.  when handling FindCoordinator/Metadata request.\n\nCo-authored-by: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2021-02-07 05:04:30","modifiedFileCount":"15","status":"M","submitter":"Boyang Chen"},{"authorTime":"2021-03-23 04:39:29","codes":[{"authorDate":"2021-03-23 04:39:29","commitOrder":13,"curCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","date":"2021-03-23 04:39:29","endLine":2018,"groupId":"101988","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldSendPurgeData","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/49/ee261715837dd2363bd8ef051c1d1588778d92.src","preCode":"    public void shouldSendPurgeData() {\n        resetToStrict(adminClient);\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(5L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        expect(adminClient.deleteRecords(singletonMap(t1p1, RecordsToDelete.beforeOffset(17L))))\n            .andReturn(new DeleteRecordsResult(singletonMap(t1p1, completedFuture())));\n        replay(adminClient);\n\n        final Map<TopicPartition, Long> purgableOffsets = new HashMap<>();\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public Map<TopicPartition, Long> purgeableOffsets() {\n                return purgableOffsets;\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        purgableOffsets.put(t1p1, 5L);\n        taskManager.maybePurgeCommittedRecords();\n\n        purgableOffsets.put(t1p1, 17L);\n        taskManager.maybePurgeCommittedRecords();\n\n        verify(adminClient);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1984,"status":"M"},{"authorDate":"2021-03-23 04:39:29","commitOrder":13,"curCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds(), null), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","date":"2021-03-23 04:39:29","endLine":2289,"groupId":"101988","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldPropagateTaskMigratedExceptionsInProcessActiveTasks","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/49/ee261715837dd2363bd8ef051c1d1588778d92.src","preCode":"    public void shouldPropagateTaskMigratedExceptionsInProcessActiveTasks() {\n        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true) {\n            @Override\n            public boolean process(final long wallClockTime) {\n                throw new TaskMigratedException(\"migrated\", new RuntimeException(\"cause\"));\n            }\n        };\n\n        expectRestoreToBeCompleted(consumer, changeLogReader);\n        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment)))\n            .andStubReturn(singletonList(task00));\n\n        replay(activeTaskCreator, consumer, changeLogReader);\n\n        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n        assertThat(taskManager.tryToCompleteRestoration(time.milliseconds()), is(true));\n\n        assertThat(task00.state(), is(Task.State.RUNNING));\n\n        final TopicPartition partition = taskId00Partitions.iterator().next();\n        task00.addRecords(partition, singletonList(getConsumerRecord(partition, 0L)));\n\n        assertThrows(TaskMigratedException.class, () -> taskManager.process(1, time));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2266,"status":"M"}],"commitId":"80f373d34f7716a54fa9ec1e37a27c65cbbae0f2","commitMessage":"@@@(Cherry-pick) KAFKA-9274: handle TimeoutException on task reset (#10000) (#10372)\n\nThis PR was removed by accident in trunk and 2.8.  bringing it back.\n\nCo-authored-by: Matthias J. Sax <matthias@confluent.io>\nReviewers: Matthias J. Sax <matthias@confluent.io>","date":"2021-03-23 04:39:29","modifiedFileCount":"10","status":"M","submitter":"Boyang Chen"}]
