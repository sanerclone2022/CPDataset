[{"authorTime":"2015-08-26 08:52:39","codes":[{"authorDate":"2015-08-26 08:52:39","commitOrder":1,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-08-26 09:33:10","endLine":110,"groupId":"10532","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/aa/44991777a855f4b7f4f7bf17107c69393ff8ff.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"B"},{"authorDate":"2015-08-26 08:52:39","commitOrder":1,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.subscribe(tp);\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-08-26 09:33:10","endLine":332,"groupId":"2823","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/22/712bb17a3bb6cdc5ac95788d37bcafc9388480.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.subscribe(tp);\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":312,"status":"B"}],"commitId":"436b7ddc386eb688ba0f12836710f5e4bcaa06c8","commitMessage":"@@@KAFKA-2136; Add throttle time (on quota violation) in fetch/produce\nresponses; reviewed by Joel Koshy.  Dong Lin and Jun Rao\n","date":"2015-08-26 09:33:10","modifiedFileCount":"10","status":"B","submitter":"Aditya Auradkar"},{"authorTime":"2015-08-27 08:20:51","codes":[{"authorDate":"2015-08-26 08:52:39","commitOrder":2,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-08-26 09:33:10","endLine":110,"groupId":"10532","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/aa/44991777a855f4b7f4f7bf17107c69393ff8ff.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"N"},{"authorDate":"2015-08-27 08:20:51","commitOrder":2,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-08-27 08:20:51","endLine":333,"groupId":"2823","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/a8381c11ca896d90abef2ca5a6d6700968ccc8.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.subscribe(tp);\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":313,"status":"M"}],"commitId":"35eaef7bb4ebcf6b209312db774564451b052ca9","commitMessage":"@@@KAFKA-2388: refactor KafkaConsumer subscribe API\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Edward Ribeiro.  Onur Karaman.  Ismael Juma.  Guozhang Wang\n\nCloses #139 from hachikuji/KAFKA-2388 and squashes the following commits:\n\n377c67e [Jason Gustafson] KAFKA-2388; refactor KafkaConsumer subscribe API\n","date":"2015-08-27 08:20:51","modifiedFileCount":"14","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2015-08-27 08:20:51","codes":[{"authorDate":"2015-09-17 01:31:57","commitOrder":3,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-09-17 01:31:57","endLine":111,"groupId":"10532","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/bc/f6a3a3197d8378d463fc441969a499178d28be.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2015-08-27 08:20:51","commitOrder":3,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-08-27 08:20:51","endLine":333,"groupId":"2823","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/a8381c11ca896d90abef2ca5a6d6700968ccc8.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":313,"status":"N"}],"commitId":"da39931afad8008bc2b385a75a462777be051435","commitMessage":"@@@KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\n","date":"2015-09-17 01:31:57","modifiedFileCount":"24","status":"M","submitter":"Mayuresh Gharat"},{"authorTime":"2015-08-27 08:20:51","codes":[{"authorDate":"2015-09-18 05:36:01","commitOrder":4,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-09-18 05:36:01","endLine":110,"groupId":"10532","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/aa/44991777a855f4b7f4f7bf17107c69393ff8ff.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2015-08-27 08:20:51","commitOrder":4,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-08-27 08:20:51","endLine":333,"groupId":"2823","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/a8381c11ca896d90abef2ca5a6d6700968ccc8.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":313,"status":"N"}],"commitId":"9dbeb71ab258955e04b46991c1baf880b07633f4","commitMessage":"@@@Revert \"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\"\n\nThis reverts commit da39931afad8008bc2b385a75a462777be051435.\n","date":"2015-09-18 05:36:01","modifiedFileCount":"24","status":"M","submitter":"Joel Koshy"},{"authorTime":"2015-08-27 08:20:51","codes":[{"authorDate":"2015-09-30 01:28:21","commitOrder":5,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-09-30 01:30:03","endLine":111,"groupId":"10532","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/bc/f6a3a3197d8378d463fc441969a499178d28be.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2015-08-27 08:20:51","commitOrder":5,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-08-27 08:20:51","endLine":333,"groupId":"2823","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/a8381c11ca896d90abef2ca5a6d6700968ccc8.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":313,"status":"N"}],"commitId":"2c4e63a899c6cf832fba4be35773218a9ba5239f","commitMessage":"@@@KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson.  Ismael Juma.  Joel Koshy.  Jun Rao.  and Edward Ribeiro\n","date":"2015-09-30 01:30:03","modifiedFileCount":"24","status":"M","submitter":"Mayuresh Gharat"},{"authorTime":"2015-10-23 12:06:10","codes":[{"authorDate":"2015-09-30 01:28:21","commitOrder":6,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-09-30 01:30:03","endLine":111,"groupId":"10532","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/bc/f6a3a3197d8378d463fc441969a499178d28be.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"N"},{"authorDate":"2015-10-23 12:06:10","commitOrder":6,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-10-23 12:06:10","endLine":386,"groupId":"2823","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/95/7d8f956201ae31136ddd7b25310c0bf4d48a2e.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assign(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":366,"status":"M"}],"commitId":"aa56dfb9e7cea19faa545a13d42d499a6958cbef","commitMessage":"@@@KAFKA-2686: Reset needsPartitionAssignment in SubscriptionState.assign()\n\nAuthor: Guozhang Wang <wangguoz@gmail.com>\n\nReviewers: Jason Gustafson.  Jun Rao\n\nCloses #352 from guozhangwang/K2686\n","date":"2015-10-23 12:06:10","modifiedFileCount":"9","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2015-12-09 11:43:05","codes":[{"authorDate":"2015-12-09 11:43:05","commitOrder":7,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-12-09 11:43:05","endLine":123,"groupId":"12991","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/61fc2e2c157843a5e62cf430f8942020d9d0f7.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"},{"authorDate":"2015-12-09 11:43:05","commitOrder":7,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2015-12-09 11:43:05","endLine":489,"groupId":"2823","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/7e/8bd40803f3ed551a3c17c132f5491b2128407f.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-avg\", metricGroup, \"\", metricTags));\n        KafkaMetric maxMetric = allMetrics.get(new MetricName(\"fetch-throttle-time-max\", metricGroup, \"\", metricTags));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":469,"status":"M"}],"commitId":"ef92a8ae7479560b26edecfa8db79934065f13cf","commitMessage":"@@@KAFKA-2668; Add a metric that records the total number of metrics\n\nonurkaraman becketqin Do you have time to review this patch? It addresses the ticket that jjkoshy filed in KAFKA-2668.\n\nAuthor: Dong Lin <lindong28@gmail.com>\n\nReviewers: Onur Karaman <okaraman@linkedin.com>.  Joel Koshy <jjkoshy@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #328 from lindong28/KAFKA-2668\n","date":"2015-12-09 11:43:05","modifiedFileCount":"27","status":"M","submitter":"Dong Lin"},{"authorTime":"2016-02-05 08:08:21","codes":[{"authorDate":"2015-12-09 11:43:05","commitOrder":8,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2015-12-09 11:43:05","endLine":123,"groupId":"12991","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/dc/61fc2e2c157843a5e62cf430f8942020d9d0f7.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"N"},{"authorDate":"2016-02-05 08:08:21","commitOrder":8,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.initFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-02-05 08:08:21","endLine":488,"groupId":"2823","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5e/750fdfe01407b51b2c34f4e65897aa8ae1d2d6.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            fetcher.initFetches(cluster);\n\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":460,"status":"M"}],"commitId":"db8d6f02c092c42f2402b7e2587c1b28d330bf83","commitMessage":"@@@KAFKA-3179; Fix seek on compressed messages\n\nThe fix itself is simple.\n\nSome explanation on unit tests. Currently we the vast majority of unit test is running with uncompressed messages.  I was initially thinking about run all the tests using compressed messages. But it seems uncompressed messages are necessary in a many test cases because we need the bytes sent and appended to the log to be predictable. In most of other cases.  it does not matter whether the message is compressed or not.  and compression will slow down the unit test. So I just added one method in the BaseConsumerTest to send compressed messages whenever we need it.\n\nAuthor: Jiangjie Qin <becket.qin@gmail.com>\n\nReviewers: Aditya Auradkar <aauradkar@linkedin.com>.  Ismael Juma <ismael@juma.me.uk>.  Joel Koshy <jjkoshy.w@gmail.com>\n\nCloses #842 from becketqin/KAFKA-3179\n","date":"2016-02-05 08:08:21","modifiedFileCount":"2","status":"M","submitter":"Jiangjie Qin"},{"authorTime":"2016-02-19 23:56:40","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":9,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"},{"authorDate":"2016-02-19 23:56:40","commitOrder":9,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.initFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-02-19 23:56:40","endLine":489,"groupId":"2823","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/97/c3d85a57185866fc9985f08f08f311d1466890.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.initFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":461,"status":"M"}],"commitId":"45c8195fa14c766b200c720f316836dbb84e9d8b","commitMessage":"@@@KAFKA-3025; Added timetamp to Message and use relative offset.\n\nSee KIP-31 and KIP-32 for details.\n\nA few notes on the patch:\n1. This patch implements KIP-31 and KIP-32. The patch includes features in both KAFKA-3025.   KAFKA-3026 and KAFKA-3036\n2. All unit tests passed.\n3. The unit tests were run with new and old message format.\n4. When message format conversion occurs during consumption.  the consumer will not be able to detect the message size too large situation. I did not try to fix this because the situation seems rare and only happen during migration phase.\n\nAuthor: Jiangjie Qin <becket.qin@gmail.com>\nAuthor: Ismael Juma <ismael@juma.me.uk>\nAuthor: Jiangjie (Becket) Qin <becket.qin@gmail.com>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Anna Povzner <anna@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #764 from becketqin/KAFKA-3025\n","date":"2016-02-19 23:56:40","modifiedFileCount":"43","status":"M","submitter":"Jiangjie Qin"},{"authorTime":"2016-02-24 07:46:32","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":10,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-02-24 07:46:32","commitOrder":10,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-02-24 07:46:32","endLine":541,"groupId":"2823","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/82/3d04ee6d5534d5840a7c2a0b47aebfa9d6b511.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.initFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":513,"status":"M"}],"commitId":"73ecd7a1797a023039fea365a08dbdba4171d10b","commitMessage":"@@@KAFKA-3007: implement max.poll.records (KIP-41)\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Grant Henke <granthenke@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #931 from hachikuji/KAFKA-3007\n","date":"2016-02-24 07:46:32","modifiedFileCount":"4","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-05-06 13:24:03","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":11,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-05-06 13:24:03","commitOrder":11,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches();\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-05-06 13:24:03","endLine":534,"groupId":"2823","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8f/ad30f986b7a60dd7a99b10459c4ec5949efe42.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches(cluster);\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":506,"status":"M"}],"commitId":"2ff955044aa875176aaa58a9be4a79c494a3fb27","commitMessage":"@@@KAFKA-3627: consumer fails to execute delayed tasks in poll when records are available\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Liquan Pei <liquanpei@gmail.com>.  Jiangjie Qin <becket.qin@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>.  Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #1295 from hachikuji/KAFKA-3627\n","date":"2016-05-06 13:24:03","modifiedFileCount":"8","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-08-20 12:59:55","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":12,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-08-20 12:59:55","commitOrder":12,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches();\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-08-20 12:59:55","endLine":630,"groupId":"2823","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5c/0b49c94bb3d8f12a7974b025db6633c2652723.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(Arrays.asList(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches();\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":602,"status":"M"}],"commitId":"317c4fdede41f2026b34f473af1ad69f8ee62a1d","commitMessage":"@@@KAFKA-3949: Fix race condition when metadata update arrives during rebalance\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Vahid Hashemian.  Guozhang Wang\n\nCloses #1762 from hachikuji/KAFKA-3949\n","date":"2016-08-20 12:59:55","modifiedFileCount":"11","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-12-13 01:38:25","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":13,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-12-13 01:38:25","commitOrder":13,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-12-13 01:38:25","endLine":632,"groupId":"0","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/5896f7a334e84d164df5732cdccf18f621f4e5.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            fetcher.sendFetches();\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":604,"status":"M"}],"commitId":"efeaf129890c2195b4753d5b9eece4f1b7cdf756","commitMessage":"@@@KAFKA-4405; Avoid unnecessary network poll in consumer if no fetches sent\n\nAuthor: Eno Thereska <eno.thereska@gmail.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2193 from enothereska/KAFKA-4405-prefetch\n","date":"2016-12-13 01:38:25","modifiedFileCount":"4","status":"M","submitter":"Eno Thereska"},{"authorTime":"2016-12-14 02:26:25","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":14,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-12-14 02:26:25","commitOrder":14,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n                for (int v = 0; v < 3; v++) {\n                    builder.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records = builder.build();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records, Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-12-14 02:26:25","endLine":637,"groupId":"14401","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/15/075cb31dacf12bbb33c045d829a6d277bc70b7.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                this.records = MemoryRecords.emptyRecords(ByteBuffer.allocate(1024), CompressionType.NONE);\n                for (int v = 0; v < 3; v++) {\n                    this.records.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records.close();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records.buffer(), Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":609,"status":"M"}],"commitId":"67f1e5b91bf073151ff57d5d656693e385726697","commitMessage":"@@@KAFKA-4390; Replace MessageSet usage with client-side alternatives\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>.  Jun Rao <junrao@gmail.com>\n\nCloses #2140 from hachikuji/KAFKA4390\n","date":"2016-12-14 02:26:25","modifiedFileCount":"25","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2016-12-21 08:07:10","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":15,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2016-12-21 08:07:10","commitOrder":15,"curCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n                for (int v = 0; v < 3; v++) {\n                    builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records = builder.build();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records, Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2016-12-21 08:07:10","endLine":637,"groupId":"14401","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/27/2a5ee406bd2a43285578867ac4899cc6ea1ec2.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n                for (int v = 0; v < 3; v++) {\n                    builder.append((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records = builder.build();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records, Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":609,"status":"M"}],"commitId":"0f86dbe89da19ed1cc9142a5362cfa2fe3bc48ee","commitMessage":"@@@MINOR: Support auto-incrementing offsets in MemoryRecordsBuilder\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>\n\nCloses #2282 from hachikuji/builder-autoincrement-offsets\n","date":"2016-12-21 08:07:10","modifiedFileCount":"8","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-01-04 05:54:40","codes":[{"authorDate":"2016-02-19 23:56:40","commitOrder":16,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2016-02-19 23:56:40","endLine":126,"groupId":"12991","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b9/83de51f82fcc484c137a3ea2834c150508a758.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"N"},{"authorDate":"2017-01-04 05:54:40","commitOrder":16,"curCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2017-01-04 05:54:40","endLine":629,"groupId":"20565","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/00/95697f0d643715e40fb93f85544efe8d6e62c0.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        List<ConsumerRecord<byte[], byte[]>> records;\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            if (i > 1) {\n                MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n                for (int v = 0; v < 3; v++) {\n                    builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n                }\n                this.records = builder.build();\n            }\n            assertEquals(1, fetcher.sendFetches());\n            client.prepareResponse(fetchResponse(this.records, Errors.NONE.code(), 100L, 100 * i));\n            consumerClient.poll(0);\n            records = fetcher.fetchedRecords().get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":609,"status":"M"}],"commitId":"b565dd7eb184da5ef3b08c88a8acc3df221aaa08","commitMessage":"@@@KAFKA-4429; Consumer lag metric should be zero if FetchResponse is empty\n\nAuthor: Dong Lin <lindong28@gmail.com>\n\nReviewers: Ewen Cheslack-Postava <me@ewencp.org>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2155 from lindong28/KAFKA-4429\n","date":"2017-01-04 05:54:40","modifiedFileCount":"2","status":"M","submitter":"Dong Lin"},{"authorTime":"2017-02-10 13:03:46","codes":[{"authorDate":"2017-02-10 13:03:46","commitOrder":17,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2017-02-10 13:03:46","endLine":127,"groupId":"10688","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6e/054d05fd234951516499464f90cc2a394ab690.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            Future<RecordMetadata> future = accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT).future;\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE.code(), 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"M"},{"authorDate":"2017-02-10 13:03:46","commitOrder":17,"curCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2017-02-10 13:03:46","endLine":755,"groupId":"8298","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b2/7802dc2d9a595d5b4784853ee55baaabddbae5.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":735,"status":"M"}],"commitId":"9898d665d1ab201405d66c70e3ea9710d9dcecd7","commitMessage":"@@@MINOR: Use an explicit `Errors` object when possible instead of a numeric error code\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2475 from vahidhashemian/minor/use_explicit_Errors_type_when_possible\n","date":"2017-02-10 13:03:46","modifiedFileCount":"48","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2017-03-25 03:38:36","codes":[{"authorDate":"2017-03-25 03:38:36","commitOrder":18,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2017-03-25 03:38:43","endLine":238,"groupId":"10688","id":35,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0d/ea6b60b22177a1f870a6ac10465638ad3d2274.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":225,"status":"M"},{"authorDate":"2017-03-25 03:38:36","commitOrder":18,"curCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2017-03-25 03:38:43","endLine":830,"groupId":"8298","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/92/150a6ce362be1e4dee386b6b41560d55378455.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE, TimestampType.CREATE_TIME);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, Record.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":809,"status":"M"}],"commitId":"5bd06f1d542e6b588a1d402d059bc24690017d32","commitMessage":"@@@KAFKA-4816; Message format changes for idempotent/transactional producer (KIP-98)\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Apurva Mehta <apurva@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #2614 from hachikuji/exactly-once-message-format\n","date":"2017-03-25 03:38:43","modifiedFileCount":"55","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-03-31 05:39:28","codes":[{"authorDate":"2017-03-25 03:38:36","commitOrder":19,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2017-03-25 03:38:43","endLine":238,"groupId":"10688","id":37,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0d/ea6b60b22177a1f870a6ac10465638ad3d2274.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":225,"status":"N"},{"authorDate":"2017-03-31 05:39:28","commitOrder":19,"curCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset(i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp1);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2017-03-31 05:39:28","endLine":831,"groupId":"4431","id":38,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/09/2f54944b3bf2597737d9ee6fb066189123621d.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp));\n        subscriptions.seek(tp, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset((long) i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), String.format(\"value-%d\", v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":810,"status":"M"}],"commitId":"dd71e4a8d830c9de40b5ec3f987f60a1d2f26b39","commitMessage":"@@@MINOR: Ensure streaming iterator is closed by Fetcher\n\nAuthor: Jason Gustafson <jason@confluent.io>\nAuthor: Ismael Juma <github@juma.me.uk>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>\n\nCloses #2762 from hachikuji/ensure-decompression-stream-closed\n","date":"2017-03-31 05:39:28","modifiedFileCount":"12","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-03-31 05:39:28","codes":[{"authorDate":"2017-04-29 10:17:57","commitOrder":20,"curCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","date":"2017-04-29 10:18:27","endLine":225,"groupId":"10688","id":39,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/93/4c89560cad8df1e418c2fa68bdb2b52097f8a5.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":212,"status":"M"},{"authorDate":"2017-03-31 05:39:28","commitOrder":20,"curCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset(i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp1);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","date":"2017-03-31 05:39:28","endLine":831,"groupId":"4431","id":40,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/09/2f54944b3bf2597737d9ee6fb066189123621d.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset(i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp1);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":810,"status":"N"}],"commitId":"6185bc0276c03075022c30d3c36f7f5c09ef19c6","commitMessage":"@@@KAFKA-4208; Add Record Headers\n\nAs per KIP-82\n\nAdding record headers api to ProducerRecord.  ConsumerRecord\nSupport to convert from protocol to api added Kafka Producer.  Kafka Fetcher (Consumer)\nUpdated MirrorMaker.  ConsoleConsumer and scala BaseConsumer\nAdd RecordHeaders and RecordHeader implementation of the interfaces Headers and Header\n\nSome bits using are reverted to being Java 7 compatible.  for the moment until KIP-118 is implemented.\n\nAuthor: Michael Andre Pearce <Michael.Andre.Pearce@me.com>\n\nReviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>.  Jiangjie Qin <becket.qin@gmail.com>.  Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #2772 from michaelandrepearce/KIP-82\n","date":"2017-04-29 10:18:27","modifiedFileCount":"26","status":"M","submitter":"Michael Andre Pearce"},{"authorTime":"2017-05-26 03:28:18","codes":[{"authorDate":"2017-05-26 03:28:18","commitOrder":21,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-05-26 03:28:18","endLine":258,"groupId":"10073","id":41,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/50/c4cd4468bdbf4680ba1b92c0681aa4e994249e.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        final long offset = 0;\n        for (int i = 1; i <= 3; i++) {\n            accumulator.append(tp0, 0L, \"key\".getBytes(), \"value\".getBytes(), null, null, MAX_BLOCK_TIMEOUT);\n            sender.run(time.milliseconds()); \r\n            client.respond(produceResponse(tp0, offset, Errors.NONE, 100 * i));\n            sender.run(time.milliseconds());\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        assertEquals(200, avgMetric.value(), EPS);\n        assertEquals(300, maxMetric.value(), EPS);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"M"},{"authorDate":"2017-05-26 03:28:18","commitOrder":21,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics,  \"consumer\" + groupId);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-05-26 03:28:18","endLine":1079,"groupId":"18224","id":42,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a8/1dc5817b59dfd84fd1a93b430924b22952ebb3.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        subscriptions.assignFromUser(singleton(tp1));\n        subscriptions.seek(tp1, 0);\n\n        \r\n        for (int i = 1; i < 4; i++) {\n            \r\n            \r\n            MemoryRecordsBuilder builder = MemoryRecords.builder(ByteBuffer.allocate(1024), CompressionType.NONE,\n                    TimestampType.CREATE_TIME, 0L);\n            for (int v = 0; v < 3; v++)\n                builder.appendWithOffset(i * 3 + v, RecordBatch.NO_TIMESTAMP, \"key\".getBytes(), (\"value-\" + v).getBytes());\n            List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE, 100L, 100 * i).get(tp1);\n            assertEquals(3, records.size());\n        }\n\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup));\n        assertEquals(200, avgMetric.value(), EPSILON);\n        assertEquals(300, maxMetric.value(), EPSILON);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1044,"status":"M"}],"commitId":"73ca0d215ead9574487744eb89f7ae677a9e13ea","commitMessage":"@@@KAFKA-5320: Include all request throttling in client throttle metrics\n\nAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3137 from rajinisivaram/KAFKA-5320\n","date":"2017-05-26 03:28:18","modifiedFileCount":"35","status":"M","submitter":"Rajini Sivaram"},{"authorTime":"2017-05-27 00:52:47","codes":[{"authorDate":"2017-05-27 00:52:47","commitOrder":22,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-05-27 00:52:47","endLine":258,"groupId":"10073","id":43,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/8ea57bbc56072f1c84accd8d5273e2caab69fa.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"M"},{"authorDate":"2017-05-27 00:52:47","commitOrder":22,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics,  \"consumer\" + groupId);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-05-27 00:52:47","endLine":1079,"groupId":"18224","id":44,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ba/5b7d53d7e52c17811bf85d7403685e48309f81.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics,  \"consumer\" + groupId);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1044,"status":"M"}],"commitId":"7892b4e6c7c32be09d78a8bbbeeaa823d3197aaa","commitMessage":"@@@KAFKA-5128; Check inter broker version in transactional methods\n\nAdd check in `KafkaApis` that the inter broker protocol version is at least `KAFKA_0_11_0_IV0`.  i.e..  supporting transactions\n\nAuthor: Damian Guy <damian.guy@gmail.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3103 from dguy/kafka-5128\n","date":"2017-05-27 00:52:47","modifiedFileCount":"4","status":"M","submitter":"Damian Guy"},{"authorTime":"2017-05-27 06:34:20","codes":[{"authorDate":"2017-05-27 00:52:47","commitOrder":23,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-05-27 00:52:47","endLine":258,"groupId":"10073","id":45,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/8ea57bbc56072f1c84accd8d5273e2caab69fa.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"N"},{"authorDate":"2017-05-27 06:34:20","commitOrder":23,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-05-27 06:34:20","endLine":1081,"groupId":"18224","id":46,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/72/0079cdfc034823ee5c7972a0ea6892ec656c36.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics,  \"consumer\" + groupId);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-avg\", metricGroup, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"fetch-throttle-time-max\", metricGroup, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1046,"status":"M"}],"commitId":"0bc4f75eedf14af6d0b2e3e9be62a460b1049d0b","commitMessage":"@@@KAFKA-5191: Autogenerate Consumer Fetcher metrics\n\nAutogenerate docs for the Consumer Fetcher's metrics. This is a smaller subset of the original PR https://github.com/apache/kafka/pull/1202.\n\nCC ijuma benstopford hachikuji\n\nAuthor: James Cheng <jylcheng@yahoo.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <wangguoz@gmail.com>\n\nCloses #2993 from wushujames/fetcher_metrics_docs\n","date":"2017-05-27 06:34:20","modifiedFileCount":"7","status":"M","submitter":"James Cheng"},{"authorTime":"2017-06-07 23:14:09","codes":[{"authorDate":"2017-05-27 00:52:47","commitOrder":24,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-05-27 00:52:47","endLine":258,"groupId":"10073","id":47,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/8ea57bbc56072f1c84accd8d5273e2caab69fa.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"N"},{"authorDate":"2017-06-07 23:14:09","commitOrder":24,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp1, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-06-07 23:36:57","endLine":1132,"groupId":"19981","id":48,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ca/d17bced5c9ddb754d16670dd8e3698ef961dee.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1097,"status":"M"}],"commitId":"dcbdce31ba525771016be5be4abc4a2067e0890b","commitMessage":"@@@KAFKA-5378; Return LSO in FetchResponse plus some metrics\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3248 from hachikuji/KAFKA-5378\n","date":"2017-06-07 23:36:57","modifiedFileCount":"7","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-07-21 08:31:24","codes":[{"authorDate":"2017-05-27 00:52:47","commitOrder":25,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-05-27 00:52:47","endLine":258,"groupId":"10073","id":49,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/8ea57bbc56072f1c84accd8d5273e2caab69fa.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"N"},{"authorDate":"2017-07-21 08:31:24","commitOrder":25,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-07-21 08:38:30","endLine":1133,"groupId":"19981","id":50,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp1, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1098,"status":"M"}],"commitId":"5bb53e034e4f8a06550dd06377fae7b3c2137ce2","commitMessage":"@@@KAFKA-5534; KafkaConsumer `offsetForTimes` result should include partitions with no offset\n\nFor topics that support timestamp search.  if no offset is found for a partition.  the partition should still be included in the result with a `null` offset value. This `KafkaConsumer` method currently excludes such partitions from the result.\n\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Jason Gustafson <jason@confluent.io>\n\nCloses #3460 from vahidhashemian/KAFKA-5534\n","date":"2017-07-21 08:38:30","modifiedFileCount":"2","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2017-07-21 08:31:24","codes":[{"authorDate":"2017-09-06 08:36:53","commitOrder":26,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-06 08:38:58","endLine":272,"groupId":"10073","id":51,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/09/6e7c1d7c82beb0e054b4e883ee059d822bec41.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-avg\", METRIC_GROUP, \"\"));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricName(\"produce-throttle-time-max\", METRIC_GROUP, \"\"));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":236,"status":"M"},{"authorDate":"2017-07-21 08:31:24","commitOrder":26,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-07-21 08:38:30","endLine":1133,"groupId":"19981","id":52,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c0/edcfd909b3299ef450a60742a598cc9aea1fbb.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1098,"status":"N"}],"commitId":"2fb5664bf4591f3e7bdc02894b9de392bf72913c","commitMessage":"@@@KAFKA-5597: Autogenerate producer sender metrics\n\nSubtask of https://issues.apache.org/jira/browse/KAFKA-3480\n\nThe changes are very similar to what was done for the consumer in https://issues.apache.org/jira/browse/KAFKA-5191 (pull request https://github.com/apache/kafka/pull/2993)\n\nAuthor: James Cheng <jylcheng@yahoo.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Rajini Sivaram <rajinisivaram@googlemail.com>.  Guozhang Wang <wangguoz@gmail.com>\n\nCloses #3535 from wushujames/producer_sender_metrics_docs\n\nFix one minor naming bug\n","date":"2017-09-06 08:38:58","modifiedFileCount":"4","status":"M","submitter":"James Cheng"},{"authorTime":"2017-09-11 22:37:39","codes":[{"authorDate":"2017-09-11 22:37:39","commitOrder":27,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-11 22:37:46","endLine":272,"groupId":"10073","id":53,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/85/b5ba6c9f32a045eee2a5656cacc89fd1279f00.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":236,"status":"M"},{"authorDate":"2017-09-11 22:37:39","commitOrder":27,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-09-11 22:37:46","endLine":1160,"groupId":"19981","id":54,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b2/ede15ac3b672795ba96079b983e76f41d8d1df.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1125,"status":"M"}],"commitId":"9bb06c3eef3ebdff77e5e3b98c26b86c40efc56c","commitMessage":"@@@KAFKA-5763; Use LogContext in NetworkClient.  Selector and broker\n\nAuthor: Andrey Dyachkov <andrey.dyachkov@gmail.com>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Manikumar Reddy <manikumar.reddy@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3761 from adyach/kafka-5763\n","date":"2017-09-11 22:37:46","modifiedFileCount":"16","status":"M","submitter":"Andrey Dyachkov"},{"authorTime":"2017-09-11 22:37:39","codes":[{"authorDate":"2017-09-14 18:23:53","commitOrder":28,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-14 18:24:25","endLine":272,"groupId":"10073","id":55,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6f/98e522621e29f3bada8e23618a0228734d4ba5.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":236,"status":"M"},{"authorDate":"2017-09-11 22:37:39","commitOrder":28,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-09-11 22:37:46","endLine":1160,"groupId":"19981","id":56,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b2/ede15ac3b672795ba96079b983e76f41d8d1df.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1125,"status":"N"}],"commitId":"2656659e0d7c0e427768ce216df2698acc8c9b11","commitMessage":"@@@MINOR: Update TransactionManager to use LogContext\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Manikumar Reddy <manikumar.reddy@gmail.com>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3852 from hachikuji/minor-use-log-context-txn-manager\n","date":"2017-09-14 18:24:25","modifiedFileCount":"5","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-09-11 22:37:39","codes":[{"authorDate":"2017-09-26 07:13:02","commitOrder":29,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-26 07:13:02","endLine":279,"groupId":"10073","id":57,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a4/5d9ac61f392971db6f1a51a1d04a9c275b187f.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = new ProduceRequest.Builder(RecordBatch.CURRENT_MAGIC_VALUE, (short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2017-09-11 22:37:39","commitOrder":29,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-09-11 22:37:46","endLine":1160,"groupId":"19981","id":58,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b2/ede15ac3b672795ba96079b983e76f41d8d1df.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1125,"status":"N"}],"commitId":"852297efd99af04df28710b1b5c99530ab20a072","commitMessage":"@@@KAFKA-5960; Fix regression in produce version selection on old brokers\n\nAuthor: Jason Gustafson <jason@confluent.io>\n\nReviewers: Apurva Mehta <apurva@confluent.io>.  Ismael Juma <ismael@juma.me.uk>\n\nCloses #3944 from hachikuji/KAFKA-5960\n","date":"2017-09-26 07:13:02","modifiedFileCount":"15","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2017-09-11 22:37:39","codes":[{"authorDate":"2017-09-28 00:54:29","commitOrder":30,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-28 00:54:37","endLine":279,"groupId":"10073","id":59,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/af/ccee01f67b1a16e2504eec2b1167c5920c0a2f.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metrics, this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(this.senderMetricsRegistry.produceThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2017-09-11 22:37:39","commitOrder":30,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2017-09-11 22:37:46","endLine":1160,"groupId":"19981","id":60,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/b2/ede15ac3b672795ba96079b983e76f41d8d1df.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1125,"status":"N"}],"commitId":"8e0e2a5b238092a3730d22d36046fe078a01c15b","commitMessage":"@@@KAFKA-5597; Improve Metrics docs generation\n\nInstead of having the metrics registry and the\norg.apache.kafka.common.metrics.Metrics object be separate things. \nhave the metrics registry hold a copy of the Metrics object.\nThat way.  all the metricInstance stuff is hidden.  and we don't\nhave to make sure that the metrics registry and the Metrics\nobject are configured identicailly (with the same tags).\n\nI personally think this looks a little better.\n\nAuthor: James Cheng <jylcheng@yahoo.com>\n\nReviewers: Ismael Juma <ismael@juma.me.uk>\n\nCloses #3799 from wushujames/producer_sender_metrics_docs_different\n","date":"2017-09-28 00:54:37","modifiedFileCount":"6","status":"M","submitter":"James Cheng"},{"authorTime":"2018-02-06 02:09:17","codes":[{"authorDate":"2017-09-28 00:54:29","commitOrder":31,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2017-09-28 00:54:37","endLine":279,"groupId":"10073","id":61,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/af/ccee01f67b1a16e2504eec2b1167c5920c0a2f.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"N"},{"authorDate":"2018-02-06 02:09:17","commitOrder":31,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2018-02-06 02:09:17","endLine":1170,"groupId":"19981","id":62,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a0/205e7f19ec21137a0a3ba0db83bf7bd317c538.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1135,"status":"M"}],"commitId":"7fe1c2b3d3a78ea3ffb9e269563653626861fbd2","commitMessage":"@@@KAFKA-6254; Incremental fetch requests\n\nAuthor: Colin P. Mccabe <cmccabe@confluent.io>\n\nReviewers: Jason Gustafson <jason@confluent.io>.  Ismael Juma <ismael@juma.me.uk>.  Jun Rao <junrao@gmail.com>\n\nCloses #4418 from cmccabe/KAFKA-6254\n","date":"2018-02-06 02:09:17","modifiedFileCount":"8","status":"M","submitter":"Colin P. Mccabe"},{"authorTime":"2018-04-12 08:03:20","codes":[{"authorDate":"2018-04-12 08:03:20","commitOrder":32,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2018-05-31 01:10:33","endLine":285,"groupId":"0","id":63,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/77/005b701527723f35271d2e2f52a4461f386827.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":244,"status":"M"},{"authorDate":"2018-04-12 08:03:20","commitOrder":32,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2018-05-31 01:10:33","endLine":1435,"groupId":"20932","id":64,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/76/cde8eddca733b99b2f2de88ace17775f932e64.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds()))\n            client.poll(1, time.milliseconds());\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1395,"status":"M"}],"commitId":"1facab387f8c2e513c8b7397430251dc44970e35","commitMessage":"@@@KAFKA-6028: Improve the quota throttle communication (KIP-219)\n\nThis implements KIP-219.  where a broker returns a response with throttle time on\nquota violation immediately after processing the corresponding request.  After\nthe response is sent out.  the broker will keep the channel muted until the\nthrottle time is over. Also.  on receiving a response with throttle time.  client\nwill block outgoing communication to the broker for the specified throttle time.\n\nSee PR 4830.  5064 and 5094 for all the review history\n\nAuthor: Jon Lee <jonlee@jonlee-ld1.linkedin.biz>\n\nReviewers: Jun Rao <junrao@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>.  Ismael Juma <ismael@juma.me.uk>.   Dong Lin <lindong28@gmail.com>\n\nCloses #5064 from jonlee2/kip-219\n","date":"2018-05-31 01:10:33","modifiedFileCount":"96","status":"M","submitter":"Jon Lee"},{"authorTime":"2018-06-14 07:21:30","codes":[{"authorDate":"2018-06-14 07:21:30","commitOrder":33,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","date":"2018-06-14 07:21:30","endLine":285,"groupId":"5975","id":65,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/d8/7c8f9e894c4a1078db7e235bb2fdce99188851.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.<TopicPartition, MemoryRecords>emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":244,"status":"M"},{"authorDate":"2018-06-14 07:21:30","commitOrder":33,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","date":"2018-06-14 07:21:30","endLine":1435,"groupId":"17324","id":66,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/41/69550ef11b51cc2dca085cb8b59c9d02d89c80.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<TopicPartition, PartitionData>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true, null);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1395,"status":"M"}],"commitId":"443091b844d4119637d252a5303568e22d4f1d48","commitMessage":"@@@KAFKA-7050; Decrease default consumer request timeout to 30s (#5203)\n\nThis patch changes the default `request.timeout.ms` of the consumer to 30 seconds. Additionally.  it adds logic to `NetworkClient` and related to components to support timeouts at the request level. We use this to handle the special case of the JoinGroup request.  which may block for as long as the value configured by `max.poll.interval.ms`.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Guozhang Wang <guozhang@confluent.io>","date":"2018-06-14 07:21:30","modifiedFileCount":"18","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2018-09-13 02:05:19","codes":[{"authorDate":"2018-09-13 02:05:19","commitOrder":34,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2018-09-13 02:05:19","endLine":300,"groupId":"5975","id":67,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f9/3f3432bddbc082c0ec8e1cf347058ba1a099a4.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, avgMetric.value(), EPS);\n        assertEquals(400, maxMetric.value(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"},{"authorDate":"2018-09-13 02:05:19","commitOrder":34,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2018-09-13 02:05:19","endLine":1582,"groupId":"17324","id":68,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/d61b9e0724bc4ed612c29434b75cfb16dd46f6.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, avgMetric.value(), EPSILON);\n        assertEquals(400, maxMetric.value(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1542,"status":"M"}],"commitId":"c121f4eb82da654acbdd133a556cfe1f9197a46a","commitMessage":"@@@MINOR: Remove deprecated Metric.value() method usage (#5626)\n\nReviewers: Viktor Somogyi <viktorsomogyi@gmail.com>.  John Roesler <john@confluent.io>.  Rajini Sivaram <rajinisivaram@googlemail.com>\n","date":"2018-09-13 02:05:19","modifiedFileCount":"7","status":"M","submitter":"Manikumar Reddy O"},{"authorTime":"2018-10-12 01:14:17","codes":[{"authorDate":"2018-10-12 01:14:17","commitOrder":35,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2018-10-12 01:14:17","endLine":301,"groupId":"5975","id":69,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/4d78cb70fd0eed080141716187c01a3ed9d5cf.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":260,"status":"M"},{"authorDate":"2018-10-12 01:14:17","commitOrder":35,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2018-10-12 01:14:17","endLine":1585,"groupId":"17324","id":70,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/42/deee7c204d9a9ff953a8e198258cf138cc3416.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1545,"status":"M"}],"commitId":"f393b2f7dd477c3a43e70631f7036a211bf5d740","commitMessage":"@@@KAFKA-6863 Kafka clients should try to use multiple DNS resolved IP (#4987)\n\nImplementation of KIP-302: Based on the new client configuration `client.dns.lookup`.  a NetworkClient can use InetAddress.getAllByName to find all IPs and iterate over them when they fail to connect. Only uses either IPv4 or IPv6 addresses similar to the default mode.\n\nCo-authored-by: Edoardo Comar <ecomar@uk.ibm.com>\nCo-authored-by: Mickael Maison <mickael.maison@gmail.com>\n\nReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2018-10-12 01:14:17","modifiedFileCount":"18","status":"M","submitter":"Edoardo Comar"},{"authorTime":"2019-03-08 08:29:19","codes":[{"authorDate":"2018-10-12 01:14:17","commitOrder":36,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2018-10-12 01:14:17","endLine":301,"groupId":"5975","id":71,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/4d78cb70fd0eed080141716187c01a3ed9d5cf.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":260,"status":"N"},{"authorDate":"2019-03-08 08:29:19","commitOrder":36,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2019-03-08 08:29:19","endLine":1787,"groupId":"17324","id":72,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3f/e7ca05c0c67d0b72786aad7f9bd09a11025ac3.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1745,"status":"M"}],"commitId":"460e46c3bb76a361d0706b263c03696005e12566","commitMessage":"@@@KAFKA-7831; Do not modify subscription state from background thread (#6221)\n\nMetadata may be updated from the background thread.  so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally.  it improves the following:\n\n1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription.  so this simplifies the logic.\n2. The metadata needs for the producer and consumer are quite different.  so it made sense to separate the custom logic into separate extensions of Metadata. For example.  only the producer requires topic expiration.\n3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.\n4. This patch removes the MetadataListener.  which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. \n\nReviewers: David Arthur <mumrah@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-03-08 08:29:19","modifiedFileCount":"30","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2019-05-18 13:45:46","codes":[{"authorDate":"2018-10-12 01:14:17","commitOrder":37,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2018-10-12 01:14:17","endLine":301,"groupId":"5975","id":73,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/4d78cb70fd0eed080141716187c01a3ed9d5cf.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":260,"status":"N"},{"authorDate":"2019-05-18 13:45:46","commitOrder":37,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2019-05-18 13:45:45","endLine":1791,"groupId":"20932","id":74,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1d/fdf231d764ce16817ec0dd145acac68763a329.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1748,"status":"M"}],"commitId":"e2847e8603fe19a87ff03584fb38954e4bd3a59e","commitMessage":"@@@KAFKA-8365; Consumer and protocol support for follower fetching (#6731)\n\nThis patch includes API changes for follower fetching per [KIP-392](https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica) as well as the consumer implementation. After this patch.  consumers will continue to fetch only from the leader.  since the broker implementation to select an alternate read replica is not included here.\n\nAdds new `client.rack` consumer configuration property is added which allows the consumer to indicate its rack. This is just an arbitrary string to indicate some relative location.  it doesn't have to actually represent a physical rack. We are keeping the naming consistent with the broker property (`broker.rack`).\n\nFetchRequest now includes `rack_id` which can optionally be specified by the consumer. FetchResponse includes an optional `preferred_read_replica` field for each partition in the response. OffsetForLeaderEpochRequest also adds new `replica_id` field which is similar to the same field in FetchRequest.\n\nWhen the consumer sees a `preferred_read_replica` in a fetch response.  it will use the Node with that ID for the next fetch.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2019-05-18 13:45:45","modifiedFileCount":"16","status":"M","submitter":"David Arthur"},{"authorTime":"2019-09-26 10:35:13","codes":[{"authorDate":"2019-09-26 10:35:13","commitOrder":38,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE, request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2019-09-26 10:35:13","endLine":311,"groupId":"2138","id":75,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/65/3faf21aa0a4bf77a52b318f508d04d1d40759b.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":270,"status":"M"},{"authorDate":"2019-09-26 10:35:13","commitOrder":38,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH, request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2019-09-26 10:35:13","endLine":2006,"groupId":"20634","id":76,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/f2/246d90d74b05869622eac9b000c203c4cb5f12.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        short apiVersionsResponseVersion = ApiKeys.API_VERSIONS.latestVersion();\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(apiVersionsResponseVersion, new ResponseHeader(0));\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH.latestVersion(), new ResponseHeader(request.correlationId()));\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1962,"status":"M"}],"commitId":"0566dfd3cedc13e2c0357378cc100c1ec9bd585a","commitMessage":"@@@MINOR: add versioning to request and response headers (#7372)\n\nAdd a version number to request and response headers.  The header\nversion is determined by the first two 16 bit fields read (API key and\nAPI version).  For now.  ControlledShutdown v0 has header version 0.  and\nall other requests have v1.  Once KIP-482 is implemented.  there will be\na v2 of the header which supports tagged fields.","date":"2019-09-26 10:35:13","modifiedFileCount":"21","status":"M","submitter":"Colin Patrick McCabe"},{"authorTime":"2019-10-18 00:21:34","codes":[{"authorDate":"2019-10-18 00:21:34","commitOrder":39,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2019-10-18 00:21:34","endLine":310,"groupId":"2138","id":77,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1b/35e0b43116e46a73253259d399f3020f32f599.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.PRODUCE, request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"M"},{"authorDate":"2019-10-18 00:21:34","commitOrder":39,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2019-10-18 00:21:34","endLine":2035,"groupId":"14715","id":78,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/fd/1be374b7eea2ce0fe855058032dceab9423aa7.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH, request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1989,"status":"M"}],"commitId":"3cb8ccf63a3f88b4de5a2133b39fb4bf175f3532","commitMessage":"@@@MINOR: AbstractRequestResponse should be an interface (#7513)\n\nAbstractRequestResponse should be an interface.  since it has no concrete elements or implementation.  Move AbstractRequestResponse#serialize to RequestUtils#serialize and make it package-private.  since it doesn't need to be public.\n\nReviewers: Ismael Juma <ismael@juma.me.uk>","date":"2019-10-18 00:21:34","modifiedFileCount":"8","status":"M","submitter":"Colin Patrick McCabe"},{"authorTime":"2020-02-20 22:54:37","codes":[{"authorDate":"2019-10-18 00:21:34","commitOrder":40,"curCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2019-10-18 00:21:34","endLine":310,"groupId":"2138","id":79,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1b/35e0b43116e46a73253259d399f3020f32f599.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"N"},{"authorDate":"2020-02-20 22:54:37","commitOrder":40,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-02-20 22:54:37","endLine":2030,"groupId":"14715","id":80,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/60/e95aac50fa3ddcb774a7f0237abb43cb5b76f7.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1984,"status":"M"}],"commitId":"8ab0994919752cd4870e771221ba934a6a539a67","commitMessage":"@@@MINOR: Fix a number of warnings in clients test (#8073)\n\n\nReviewers: Ismael Juma <ismael@juma.me.uk>.  Andrew Choi <li_andchoi@microsoft.com>","date":"2020-02-20 22:54:37","modifiedFileCount":"14","status":"M","submitter":"Mickael Maison"},{"authorTime":"2020-02-20 22:54:37","codes":[{"authorDate":"2020-04-24 12:39:11","commitOrder":41,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-04-24 12:39:11","endLine":301,"groupId":"2138","id":81,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5e/b2e20df89be9f53a352c8c704d4693b58260d0.src","preCode":"    public void testQuotaMetrics() throws Exception {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"},{"authorDate":"2020-02-20 22:54:37","commitOrder":41,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-02-20 22:54:37","endLine":2030,"groupId":"14715","id":82,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/60/e95aac50fa3ddcb774a7f0237abb43cb5b76f7.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1984,"status":"N"}],"commitId":"f3c8bff311b0e4c4d0e316ac949fe4491f9b107f","commitMessage":"@@@KAFKA-8639: Replace AddPartitionsToTxn with Automated Protocol  (#8326)\n\nPart of the protocol automation effort.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-04-24 12:39:11","modifiedFileCount":"8","status":"M","submitter":"Boyang Chen"},{"authorTime":"2020-06-04 21:21:52","codes":[{"authorDate":"2020-06-04 21:21:52","commitOrder":42,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-06-04 21:21:52","endLine":301,"groupId":"2138","id":83,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/3e/c8c809a1cecd7815423879479dc9e0581db917.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"},{"authorDate":"2020-06-04 21:21:52","commitOrder":42,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-06-04 21:21:52","endLine":2081,"groupId":"14715","id":84,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c3/6b8239f28c352631e3d794d2c9996b99f57ed3.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.DEFAULT,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n                serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2035,"status":"M"}],"commitId":"50c30128909a6714c64518d84642e8c45478668a","commitMessage":"@@@KAFKA-9313: Set `use_all_dns_ips` as the new default for `client.dns.lookup` (KIP-602) (#8644)\n\nThis applies to the producer.  consumer.  admin client.  connect worker\nand inter broker communication.\n\n`ClientDnsLookup.DEFAULT` has been deprecated and a warning\nwill be logged if it's explicitly set in a client config.\n\nReviewers: Mickael Maison <mickael.maison@gmail.com>.  Ismael Juma <ismael@juma.me.uk>","date":"2020-06-04 21:21:52","modifiedFileCount":"11","status":"M","submitter":"Badai Aqrandista"},{"authorTime":"2020-06-30 19:15:17","codes":[{"authorDate":"2020-06-30 19:15:17","commitOrder":43,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400,\n            RecordBatch.CURRENT_MAGIC_VALUE\n        ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-06-30 19:15:17","endLine":303,"groupId":"2138","id":85,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ca/da9655e4ebf4f2602ee595ecc564f369fa62ee.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400,\n            RecordBatch.CURRENT_MAGIC_VALUE\n        ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":259,"status":"M"},{"authorDate":"2020-06-30 19:15:17","commitOrder":43,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(\n                400,\n                RecordBatch.CURRENT_MAGIC_VALUE\n            ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-06-30 19:15:17","endLine":2091,"groupId":"14715","id":86,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ec/e5781645f81776a348c8d72024ab9c7bd2afcb.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000,  ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(\n                400,\n                RecordBatch.CURRENT_MAGIC_VALUE\n            ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2043,"status":"M"}],"commitId":"55b5b248cd0974f48e8bf261f61227722cb47570","commitMessage":"@@@KAFKA-9893: Configurable TCP connection timeout and improve the initial metadata fetch (KIP-601) (#8683)\n\nReviewers: David Jacot <djacot@confluent.io>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2020-06-30 19:15:17","modifiedFileCount":"17","status":"M","submitter":"Cheng Tan"},{"authorTime":"2020-06-30 19:15:17","codes":[{"authorDate":"2020-11-19 05:44:21","commitOrder":44,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-11-19 05:44:21","endLine":323,"groupId":"4766","id":87,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a0/c8d5639aafc2bd05f1d66d40700de2ed8d3046.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.Builder.forCurrentMagic((short) 1, 1000,\n                            Collections.emptyMap());\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2020-06-30 19:15:17","commitOrder":44,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(\n                400,\n                RecordBatch.CURRENT_MAGIC_VALUE\n            ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-06-30 19:15:17","endLine":2091,"groupId":"14715","id":88,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ec/e5781645f81776a348c8d72024ab9c7bd2afcb.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.\n            createApiVersionsResponse(\n                400,\n                RecordBatch.CURRENT_MAGIC_VALUE\n            ).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2043,"status":"N"}],"commitId":"30bc21ca35b165f04c472b4ce794893843809ccc","commitMessage":"@@@KAFKA-9628; Replace Produce request/response with automated protocol (#9401)\n\nThis patch rewrites `ProduceRequest` and `ProduceResponse` using the generated protocols. We have also added several new benchmarks to verify no regression in performance. A summary of results is included below:\n\n\n Benchmark\n\n1. loop **30** times\n1. calculate average\n\n\n# kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput\n\n> @cluster(num_nodes=5)\n> @parametrize(acks=-1.  topic=TOPIC_REP_THREE)\n\n- +0.3144915325 %\n- 28.08766667 ->  28.1715625 (mb_per_sec)\n\n> @cluster(num_nodes=5)\n> @matrix(acks=[1].  topic=[TOPIC_REP_THREE].  message_size=[100000]. compression_type=[\"none\"].  security_protocol=['PLAINTEXT'])\n\n- +4.220730323 %\n- 157.145 -> 163.7776667 (mb_per_sec)\n\n> @cluster(num_nodes=7)\n> @parametrize(acks=1.  topic=TOPIC_REP_THREE.  num_producers=3)\n\n- +5.996241145%\n- 57.64166667 -> 61.098 (mb_per_sec)\n\n> @cluster(num_nodes=5)\n> @parametrize(acks=1.  topic=TOPIC_REP_THREE)\n\n- +0.3979572536%\n- 44.05833333 -> 44.23366667 (mb_per_sec)\n\n> @cluster(num_nodes=5)\n> @parametrize(acks=1.  topic= TOPIC_REP_ONE)\n\n- +2.228235226%\n- 69.23266667 -> 70.77533333 (mb_per_sec)\n\n\n JMH results\n\nIn short.  most ops performance are regression since we have to convert data to protocol data. The cost is inevitable (like other request/response) before we use protocol data directly.\n\n\n JMH for ProduceRequest\n\n1. construction regression:\n    - 281.474 -> 454.935 ns/op\n    - 296.000 -> 1888.000 B/op\n1. toErrorResponse regression:\n    - 41.942 -> 107.528 ns/op\n    - 1216.000 -> 1616.000 B/op\n1. toStruct improvement:\n    - 255.185 -> 90.728 ns/op\n    - 864.000 -> 304.000 B/op\n\n**BEFORE**\n```\nBenchmark                                                                        Mode  Cnt     Score    Error   Units\nProducerRequestBenchmark.constructorErrorResponse                                avgt   15    41.942 ?  0.036   ns/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.alloc.rate                 avgt   15  6409.263 ?  5.478  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.alloc.rate.norm            avgt   15   296.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Eden_Space        avgt   15  6416.420 ? 76.071  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Eden_Space.norm   avgt   15   296.331 ?  3.539    B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Old_Gen           avgt   15     0.002 ?  0.002  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Old_Gen.norm      avgt   15    ? 10??             B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.count                      avgt   15   698.000           counts\nProducerRequestBenchmark.constructorErrorResponse:?gc.time                       avgt   15   378.000               ms\nProducerRequestBenchmark.constructorProduceRequest                               avgt   15   281.474 ?  3.286   ns/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.alloc.rate                avgt   15  3923.868 ? 46.303  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.alloc.rate.norm           avgt   15  1216.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Eden_Space       avgt   15  3923.375 ? 59.568  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Eden_Space.norm  avgt   15  1215.844 ? 11.184    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Old_Gen          avgt   15     0.004 ?  0.001  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Old_Gen.norm     avgt   15     0.001 ?  0.001    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.count                     avgt   15   515.000           counts\nProducerRequestBenchmark.constructorProduceRequest:?gc.time                      avgt   15   279.000               ms\nProducerRequestBenchmark.constructorStruct                                       avgt   15   255.185 ?  0.069   ns/op\nProducerRequestBenchmark.constructorStruct:?gc.alloc.rate                        avgt   15  3074.889 ?  0.823  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.alloc.rate.norm                   avgt   15   864.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Eden_Space               avgt   15  3077.737 ? 31.537  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Eden_Space.norm          avgt   15   864.800 ?  8.823    B/op\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Old_Gen                  avgt   15     0.003 ?  0.001  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Old_Gen.norm             avgt   15     0.001 ?  0.001    B/op\nProducerRequestBenchmark.constructorStruct:?gc.count                             avgt   15   404.000           counts\nProducerRequestBenchmark.constructorStruct:?gc.time                              avgt   15   214.000               ms\n```\n\n**AFTER**\n```\nBenchmark                                                                        Mode  Cnt     Score    Error   Units\nProducerRequestBenchmark.constructorErrorResponse                                avgt   15   107.528 ?  0.270   ns/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.alloc.rate                 avgt   15  4864.899 ? 12.132  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.alloc.rate.norm            avgt   15   576.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Eden_Space        avgt   15  4868.023 ? 61.943  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Eden_Space.norm   avgt   15   576.371 ?  7.331    B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Old_Gen           avgt   15     0.005 ?  0.001  MB/sec\nProducerRequestBenchmark.constructorErrorResponse:?gc.churn.G1_Old_Gen.norm      avgt   15     0.001 ?  0.001    B/op\nProducerRequestBenchmark.constructorErrorResponse:?gc.count                      avgt   15   639.000           counts\nProducerRequestBenchmark.constructorErrorResponse:?gc.time                       avgt   15   339.000               ms\nProducerRequestBenchmark.constructorProduceRequest                               avgt   15   454.935 ?  0.332   ns/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.alloc.rate                avgt   15  3769.014 ?  2.767  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.alloc.rate.norm           avgt   15  1888.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Eden_Space       avgt   15  3763.407 ? 31.530  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Eden_Space.norm  avgt   15  1885.190 ? 15.594    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Old_Gen          avgt   15     0.004 ?  0.001  MB/sec\nProducerRequestBenchmark.constructorProduceRequest:?gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ?  0.001    B/op\nProducerRequestBenchmark.constructorProduceRequest:?gc.count                     avgt   15   494.000           counts\nProducerRequestBenchmark.constructorProduceRequest:?gc.time                      avgt   15   264.000               ms\nProducerRequestBenchmark.constructorStruct                                       avgt   15    90.728 ?  0.695   ns/op\nProducerRequestBenchmark.constructorStruct:?gc.alloc.rate                        avgt   15  3043.140 ? 23.246  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.alloc.rate.norm                   avgt   15   304.000 ?  0.001    B/op\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Eden_Space               avgt   15  3047.251 ? 59.638  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Eden_Space.norm          avgt   15   304.404 ?  5.034    B/op\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Old_Gen                  avgt   15     0.003 ?  0.001  MB/sec\nProducerRequestBenchmark.constructorStruct:?gc.churn.G1_Old_Gen.norm             avgt   15    ? 10??             B/op\nProducerRequestBenchmark.constructorStruct:?gc.count                             avgt   15   400.000           counts\nProducerRequestBenchmark.constructorStruct:?gc.time                              avgt   15   205.000               ms\n```\n\n JMH for ProduceResponse\n\n1. construction regression:\n    - 3.293 -> 303.226 ns/op\n    - 24.000 -> 1848.000 B/op\n1. toStruct improvement:\n    - 825.889 -> 311.725 ns/op\n    - 2208.000 -> 896.000 B/op\n\n**BEFORE**\n\n```\nBenchmark                                                                          Mode  Cnt     Score    Error   Units\nProducerResponseBenchmark.constructorProduceResponse                               avgt   15     3.293 ?  0.004   ns/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.alloc.rate                avgt   15  6619.731 ?  9.075  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.alloc.rate.norm           avgt   15    24.000 ?  0.001    B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Eden_Space       avgt   15  6618.648 ?  0.153  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Eden_Space.norm  avgt   15    23.996 ?  0.033    B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Old_Gen          avgt   15     0.003 ?  0.002  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Old_Gen.norm     avgt   15    ? 10??             B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.count                     avgt   15   720.000           counts\nProducerResponseBenchmark.constructorProduceResponse:?gc.time                      avgt   15   383.000               ms\nProducerResponseBenchmark.constructorStruct                                        avgt   15   825.889 ?  0.638   ns/op\nProducerResponseBenchmark.constructorStruct:?gc.alloc.rate                         avgt   15  2428.000 ?  1.899  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.alloc.rate.norm                    avgt   15  2208.000 ?  0.001    B/op\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Eden_Space                avgt   15  2430.196 ? 55.894  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Eden_Space.norm           avgt   15  2210.001 ? 51.009    B/op\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Old_Gen                   avgt   15     0.003 ?  0.001  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Old_Gen.norm              avgt   15     0.002 ?  0.001    B/op\nProducerResponseBenchmark.constructorStruct:?gc.count                              avgt   15   319.000           counts\nProducerResponseBenchmark.constructorStruct:?gc.time                               avgt   15   166.000               ms\n```\n\n**AFTER**\n\n```\nBenchmark                                                                          Mode  Cnt     Score    Error   Units\nProducerResponseBenchmark.constructorProduceResponse                               avgt   15   303.226 ?  0.517   ns/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.alloc.rate                avgt   15  5534.940 ?  9.439  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.alloc.rate.norm           avgt   15  1848.000 ?  0.001    B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Eden_Space       avgt   15  5534.046 ? 51.849  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Eden_Space.norm  avgt   15  1847.710 ? 18.105    B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Old_Gen          avgt   15     0.007 ?  0.001  MB/sec\nProducerResponseBenchmark.constructorProduceResponse:?gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ?  0.001    B/op\nProducerResponseBenchmark.constructorProduceResponse:?gc.count                     avgt   15   602.000           counts\nProducerResponseBenchmark.constructorProduceResponse:?gc.time                      avgt   15   318.000               ms\nProducerResponseBenchmark.constructorStruct                                        avgt   15   311.725 ?  3.132   ns/op\nProducerResponseBenchmark.constructorStruct:?gc.alloc.rate                         avgt   15  2610.602 ? 25.964  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.alloc.rate.norm                    avgt   15   896.000 ?  0.001    B/op\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Eden_Space                avgt   15  2613.021 ? 42.965  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Eden_Space.norm           avgt   15   896.824 ? 11.331    B/op\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Old_Gen                   avgt   15     0.003 ?  0.001  MB/sec\nProducerResponseBenchmark.constructorStruct:?gc.churn.G1_Old_Gen.norm              avgt   15     0.001 ?  0.001    B/op\nProducerResponseBenchmark.constructorStruct:?gc.count                              avgt   15   343.000           counts\nProducerResponseBenchmark.constructorStruct:?gc.time                               avgt   15   194.000               ms\n```\n\nReviewers: David Jacot <djacot@confluent.io>.  Jason Gustafson <jason@confluent.io>\n","date":"2020-11-19 05:44:21","modifiedFileCount":"15","status":"M","submitter":"Chia-Ping Tsai"},{"authorTime":"2020-12-08 07:39:57","codes":[{"authorDate":"2020-12-08 07:39:57","commitOrder":45,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serializeWithHeader(ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serializeWithHeader(ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-12-08 07:39:57","endLine":323,"groupId":"4766","id":89,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/ed3f72de291c1ca8854ed38f3d76670bfeb047.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.\n                serialize(ApiKeys.PRODUCE, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":279,"status":"M"},{"authorDate":"2020-12-08 07:39:57","commitOrder":45,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serializeWithHeader(ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serializeWithHeader(ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-12-08 07:39:57","endLine":2100,"groupId":"0","id":90,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/0e/e5c76e2b22bd3cf60146d23a0cb4b38c731b2a.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serialize(ApiKeys.API_VERSIONS, ApiKeys.API_VERSIONS.latestVersion(), 0);\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serialize(ApiKeys.FETCH,\n                    ApiKeys.FETCH.latestVersion(),\n                    request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2056,"status":"M"}],"commitId":"6f27bb02da0dec63a16c0c6aa456b47ba416eb19","commitMessage":"@@@KAFKA-10818: Skip conversion to `Struct` when serializing generated requests/responses (#7409)\n\nGenerated request/response classes have code to serialize/deserialize directly to\n`ByteBuffer` so the intermediate conversion to `Struct` can be skipped for them.\nWe have recently completed the transition to generated request/response classes. \nso we can also remove the `Struct` based fallbacks.\n\nAdditional noteworthy changes:\n* `AbstractRequest.parseRequest` has a more efficient computation of request size that\nrelies on the received buffer instead of the parsed `Struct`.\n* Use `SendBuilder` for `AbstractRequest/Response` `toSend`.  made the superclass\nimplementation final and removed the overrides that are no longer necessary.\n* Removed request/response constructors that assume latest version as they are unsafe\noutside of tests.\n* Removed redundant version fields in requests/responses.\n* Removed unnecessary work in `OffsetFetchResponse`'s constructor when version >= 2.\n* Made `AbstractResponse.throttleTimeMs()` abstract.\n* Using `toSend` in `SaslClientAuthenticator` instead of `serialize`.\n* Various changes in Request/Response classes to make them more consistent and to\nrely on the Data classes as much as possible when it comes to their state.\n* Remove the version argument from `AbstractResponse.toString`.\n* Fix `getErrorResponse` for `ProduceRequest` and `DescribeClientQuotasRequest` to\nuse `ApiError` which processes the error message sent back to the clients. This was\nuncovered by an accidental fix to a `RequestResponseTest` test (it was calling\n`AbstractResponse.toString` instead of `AbstractResponse.toString(short)`).\n\nRely on existing protocol tests to ensure this refactoring does not change \nobserved behavior (aside from improved performance).\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>","date":"2020-12-08 07:39:57","modifiedFileCount":"174","status":"M","submitter":"Ismael Juma"},{"authorTime":"2020-12-10 03:15:58","codes":[{"authorDate":"2020-12-10 03:15:58","commitOrder":46,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(\n            ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE),\n            ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2020-12-10 03:15:58","endLine":325,"groupId":"4766","id":91,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/99/5dfc77d38e4f4a0b992915939a3eb6f0ab6e87.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE).\n            serializeWithHeader(ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = response.serializeWithHeader(ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":280,"status":"M"},{"authorDate":"2020-12-10 03:15:58","commitOrder":46,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE), ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2020-12-10 03:15:58","endLine":2101,"groupId":"5984","id":92,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5f/d65791927f683551833942cc928cadaad2f6b7.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE).serializeWithHeader(ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = response.serializeWithHeader(ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2057,"status":"M"}],"commitId":"1f98112e993bc4ae098936b1b0661fdb2c4b1880","commitMessage":"@@@MINOR: Remove connection id from Send and consolidate request/message utils (#9714)\n\nConnection id is now only present in `NetworkSend`.  which is now\nthe class used by `Selector`/`NetworkClient`/`KafkaChannel` (which\nworks well since `NetworkReceive` is the class used for\nreceived data).\n\nThe previous `NetworkSend` was also responsible for adding a size\nprefix. This logic is already present in `SendBuilder`.  but for the\nminority of cases where `SendBuilder` is not used (including\na number of tests).  we now have `ByteBufferSend.sizePrefixed()`.\n\nWith regards to the request/message utilities:\n* Renamed `toByteBuffer`/`toBytes` in `MessageUtil` to\n`toVersionPrefixedByteBuffer`/`toVersionPrefixedBytes` for clarity.\n* Introduced new `MessageUtil.toByteBuffer` that does not include\nthe version as the prefix.\n* Renamed `serializeBody` in `AbstractRequest/Response` to\n`serialize` for symmetry with `parse`.\n* Introduced `RequestTestUtils` and moved relevant methods from\n`TestUtils`.\n* Moved `serializeWithHeader` methods that were only used in\ntests to `RequestTestUtils`.\n* Deleted `MessageTestUtil`.\n\nFinally.  a couple of changes to simplify coding patterns:\n* Added `flip()` and `buffer()` to `ByteBufferAccessor`.\n* Added `MessageSizeAccumulator.sizeExcludingZeroCopy`.\n* Used lambdas instead of `TestCondition`.\n* Used `Arrays.copyOf` instead of `System.arraycopy` in `MessageUtil`.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  Jason Gustafson <jason@confluent.io>","date":"2020-12-10 03:15:58","modifiedFileCount":"80","status":"M","submitter":"Ismael Juma"},{"authorTime":"2021-02-05 02:04:17","codes":[{"authorDate":"2021-02-05 02:04:17","commitOrder":47,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2021-02-19 08:25:51","endLine":327,"groupId":"4766","id":93,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e1/18c1110e704556b8e4243b406cc9c519f98211.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(\n            ApiVersionsResponse.createApiVersionsResponse(400, RecordBatch.CURRENT_MAGIC_VALUE),\n            ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":282,"status":"M"},{"authorDate":"2021-02-05 02:04:17","commitOrder":47,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2021-02-19 08:25:51","endLine":2112,"groupId":"5984","id":94,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/2c/13864fb0589c14ddcab21b43647a30669fe194.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(ApiVersionsResponse.createApiVersionsResponse(\n            400, RecordBatch.CURRENT_MAGIC_VALUE), ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2067,"status":"M"}],"commitId":"698319b8e2c1f6cb574f339eede6f2a5b1919b55","commitMessage":"@@@KAFKA-12278; Ensure exposed api versions are consistent within listener (#10666)\n\nPreviously all APIs were accessible on every listener exposed by the broker.  but\nwith KIP-500.  that is no longer true.  We now have more complex requirements for\nAPI accessibility.\n\nFor example.  the KIP-500 controller exposes some APIs which are not exposed by\nbrokers.  such as BrokerHeartbeatRequest.  and does not expose most client APIs. \nsuch as JoinGroupRequest.  etc.  Similarly.  the KIP-500 broker does not implement\nsome APIs that the ZK-based broker does.  such as LeaderAndIsrRequest and\nUpdateFeaturesRequest.\n\nAll of this means that we need more sophistication in how we expose APIs and\nkeep them consistent with the ApiVersions API. Up until now.  we have been\nworking around this using the controllerOnly flag inside ApiKeys.  but this is\nnot rich enough to support all of the cases listed above.  This PR introduces a\nnew \"listeners\" field to the request schema definitions.  This field is an array\nof strings which indicate the listener types in which the API should be exposed.\nWe currently support \"zkBroker\".  \"broker\".  and \"controller\".  (\"broker\"\nindicates the KIP-500 broker.  whereas zkBroker indicates the old broker).\n\nThis PR also creates ApiVersionManager to encapsulate the creation of the\nApiVersionsResponse based on the listener type.  Additionally.  it modifies\nSocketServer to check the listener type of received requests before forwarding\nthem to the request handler.\n\nFinally.  this PR also fixes a bug in the handling of the ApiVersionsResponse\nprior to authentication. Previously a static response was sent.  which means that\nchanges to features would not get reflected. This also meant that the logic to\nensure that only the intersection of version ranges supported by the controller\nwould get exposed did not work. I think this is important because some clients\nrely on the initial pre-authenticated ApiVersions response rather than doing a\nsecond round after authentication as the Java client does.\n\nOne final cleanup note: I have removed the expectation that envelope requests\nare only allowed on \"privileged\" listeners.  This made sense initially because\nwe expected to use forwarding before the KIP-500 controller was available. That\nis not the case anymore and we expect the Envelope API to only be exposed on the\ncontroller listener. I have nevertheless preserved the existing workarounds to\nallow verification of the forwarding behavior in integration testing.\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>.  Ismael Juma <ismael@juma.me.uk>\n","date":"2021-02-19 08:25:51","modifiedFileCount":"24","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2021-03-04 18:06:50","codes":[{"authorDate":"2021-02-05 02:04:17","commitOrder":48,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2021-02-19 08:25:51","endLine":327,"groupId":"4766","id":95,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e1/18c1110e704556b8e4243b406cc9c519f98211.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":282,"status":"N"},{"authorDate":"2021-03-04 18:06:50","commitOrder":48,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2021-03-04 18:06:50","endLine":2134,"groupId":"15904","id":96,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/5d95947c23675530c9db6a31c6f3fbd2d6cecf.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse<MemoryRecords> response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2089,"status":"M"}],"commitId":"8205051e90e3ea16165f8dc1f5c81af744bb1b9a","commitMessage":"@@@MINOR: remove FetchResponse.AbortedTransaction and redundant construc? (#9758)\n\n1. rename INVALID_HIGHWATERMARK to INVALID_HIGH_WATERMARK\n2. replace FetchResponse.AbortedTransaction by FetchResponseData.AbortedTransaction\n3. remove redundant constructors from FetchResponse.PartitionData\n4. rename recordSet to records\n5. add helpers \"recordsOrFail\" and \"recordsSize\" to FetchResponse to process record casting\n\nReviewers: Ismael Juma <ismael@juma.me.uk>","date":"2021-03-04 18:06:50","modifiedFileCount":"15","status":"M","submitter":"Chia-Ping Tsai"},{"authorTime":"2021-04-01 22:59:59","codes":[{"authorDate":"2021-04-01 22:59:59","commitOrder":49,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2021-04-01 22:59:59","endLine":326,"groupId":"4766","id":97,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c9/8ac632a0f7dcb813c0cd18284c9c41821ec8d1.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":281,"status":"M"},{"authorDate":"2021-04-01 22:59:59","commitOrder":49,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2021-04-01 22:59:59","endLine":2134,"groupId":"15904","id":98,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/62/bbb7460160660e0010db64c1601bd4931f57ab.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000, ClientDnsLookup.USE_ALL_DNS_IPS,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2089,"status":"M"}],"commitId":"2342ec1d1cc03f4f244fc2921978534af63ae54f","commitMessage":"@@@KAFKA-12600: Remove deprecated config value `default` for client config `client.dns.lookup` (#10458)\n\nThe config has been deprecated since Kafka 2.6 (released ~1 year before\n3.0).  but it was the default before it got deprecated. As such.  it's\nreasonably unlikely that people would have set it explicitly.\n\nGiven the confusing `default` name even though it's _not_ the default.  I\nthink we should remove it in 3.0.\n\nAlso remove `ClientDnsLookup.DEFAULT` (not public API).  which unlocks\na number of code simplications.\n\nReviewers: David Jacot <djacot@confluent.io>","date":"2021-04-01 22:59:59","modifiedFileCount":"19","status":"M","submitter":"Ismael Juma"},{"authorTime":"2021-07-08 07:02:37","codes":[{"authorDate":"2021-04-01 22:59:59","commitOrder":50,"curCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","date":"2021-04-01 22:59:59","endLine":326,"groupId":"103677","id":99,"instanceNumber":1,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c9/8ac632a0f7dcb813c0cd18284c9c41821ec8d1.src","preCode":"    public void testQuotaMetrics() {\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(this.senderMetricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, logContext);\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            ProduceRequest.Builder builder = ProduceRequest.forCurrentMagic(new ProduceRequestData()\n                    .setTopicData(new ProduceRequestData.TopicProduceDataCollection())\n                    .setAcks((short) 1)\n                    .setTimeoutMs(1000));\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            ProduceResponse response = produceResponse(tp0, i, Errors.NONE, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.PRODUCE.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeAvg);\n        KafkaMetric maxMetric = allMetrics.get(this.senderMetricsRegistry.produceThrottleTimeMax);\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPS);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPS);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":281,"status":"N"},{"authorDate":"2021-07-08 07:02:37","commitOrder":50,"curCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(ApiKeys.FETCH.latestVersion(), 100, 100, new LinkedHashMap<>(), topicIds);\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","date":"2021-07-08 07:02:37","endLine":2219,"groupId":"103677","id":100,"instanceNumber":2,"isCurCommit":0,"methodName":"testQuotaMetrics","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ec/a8d4d0de616ad523f86ea20b0b0f6e6fc16cd5.src","preCode":"    public void testQuotaMetrics() {\n        buildFetcher();\n\n        MockSelector selector = new MockSelector(time);\n        Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry);\n        Cluster cluster = TestUtils.singletonCluster(\"test\", 1);\n        Node node = cluster.nodes().get(0);\n        NetworkClient client = new NetworkClient(selector, metadata, \"mock\", Integer.MAX_VALUE,\n                1000, 1000, 64 * 1024, 64 * 1024, 1000, 10 * 1000, 127 * 1000,\n                time, true, new ApiVersions(), throttleTimeSensor, new LogContext());\n\n        ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(\n            400, ApiMessageType.ListenerType.ZK_BROKER);\n        ByteBuffer buffer = RequestTestUtils.serializeResponseWithHeader(apiVersionsResponse, ApiKeys.API_VERSIONS.latestVersion(), 0);\n\n        selector.delayedReceive(new DelayedReceive(node.idString(), new NetworkReceive(node.idString(), buffer)));\n        while (!client.ready(node, time.milliseconds())) {\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n        }\n        selector.clear();\n\n        for (int i = 1; i <= 3; i++) {\n            int throttleTimeMs = 100 * i;\n            FetchRequest.Builder builder = FetchRequest.Builder.forConsumer(100, 100, new LinkedHashMap<>());\n            builder.rackId(\"\");\n            ClientRequest request = client.newClientRequest(node.idString(), builder, time.milliseconds(), true);\n            client.send(request, time.milliseconds());\n            client.poll(1, time.milliseconds());\n            FetchResponse response = fullFetchResponse(tp0, nextRecords, Errors.NONE, i, throttleTimeMs);\n            buffer = RequestTestUtils.serializeResponseWithHeader(response, ApiKeys.FETCH.latestVersion(), request.correlationId());\n            selector.completeReceive(new NetworkReceive(node.idString(), buffer));\n            client.poll(1, time.milliseconds());\n            \r\n            time.sleep(client.throttleDelayMs(node, time.milliseconds()));\n            selector.clear();\n        }\n        Map<MetricName, KafkaMetric> allMetrics = metrics.metrics();\n        KafkaMetric avgMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeAvg));\n        KafkaMetric maxMetric = allMetrics.get(metrics.metricInstance(metricsRegistry.fetchThrottleTimeMax));\n        \r\n        assertEquals(250, (Double) avgMetric.metricValue(), EPSILON);\n        assertEquals(400, (Double) maxMetric.metricValue(), EPSILON);\n        client.close();\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2174,"status":"M"}],"commitId":"2b8aff58b575c199ee8372e5689420c9d77357a5","commitMessage":"@@@KAFKA-10580: Add topic ID support to Fetch request (#9944)\n\nUpdated FetchRequest and FetchResponse to use topic IDs rather than topic names.\nSome of the complicated code is found in FetchSession and FetchSessionHandler.\nWe need to be able to store topic IDs and maintain a cache on the broker for IDs that may not have been resolved. On incremental fetch requests.  we will try to resolve them or remove them if in toForget.\n\nReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>.  Chia-Ping Tsai <chia7712@gmail.com>.  Jun Rao <junrao@gmail.com>","date":"2021-07-08 07:02:37","modifiedFileCount":"23","status":"M","submitter":"Justine Olshan"}]
