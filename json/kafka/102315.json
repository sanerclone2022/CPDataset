[{"authorTime":"2020-04-04 10:17:57","codes":[{"authorDate":"2020-04-04 10:17:57","commitOrder":7,"curCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(thrown.getMessage(), equalTo(\"Could not get partition information for topic topic for task 0_0. This can happen if the topic does not exist.\"));\n    }\n","date":"2020-04-04 10:17:57","endLine":687,"groupId":"19915","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowIfTopicIsUnknownOnSendWithPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/47/681afc939191ed91f8cfc1076ff4d3fc85d897.src","preCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(thrown.getMessage(), equalTo(\"Could not get partition information for topic topic for task 0_0. This can happen if the topic does not exist.\"));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":655,"status":"MB"},{"authorDate":"2020-04-04 10:17:57","commitOrder":7,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.close();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2020-04-04 10:17:57","endLine":715,"groupId":"19922","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/47/681afc939191ed91f8cfc1076ff4d3fc85d897.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.close();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":690,"status":"B"}],"commitId":"ab5e4f52ecb072df55c7f5cd8941122a135cdf79","commitMessage":"@@@MINOR: Refactor StreamsProducer (#8380)\n\nReviewers: Boyang Chen <boyang@confluent.io>.  Guozhang Wang <guozhang@confluent.io>.  Andrew Choi <a24choi@edu.uwaterloo.ca>","date":"2020-04-04 10:17:57","modifiedFileCount":"15","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2020-04-04 10:17:57","codes":[{"authorDate":"2020-04-22 00:25:45","commitOrder":8,"curCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","date":"2020-04-22 00:25:45","endLine":753,"groupId":"19915","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowIfTopicIsUnknownOnSendWithPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/31/2ba88a917eaac219a36519260395b781f4e8c0.src","preCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(thrown.getMessage(), equalTo(\"Could not get partition information for topic topic for task 0_0. This can happen if the topic does not exist.\"));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":717,"status":"M"},{"authorDate":"2020-04-04 10:17:57","commitOrder":8,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.close();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2020-04-04 10:17:57","endLine":715,"groupId":"19922","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/47/681afc939191ed91f8cfc1076ff4d3fc85d897.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.close();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":690,"status":"N"}],"commitId":"11d8ef76ff5348a48eb1c37cddf244e399666d59","commitMessage":"@@@MINOR: Improve usage of LogCaptureAppender (#8508)\n\nReviewers: Ismael Juma <ismael@confluent.io>.  John Roesler <john@confluent.io>","date":"2020-04-22 00:25:45","modifiedFileCount":"40","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2020-06-24 09:08:26","codes":[{"authorDate":"2020-04-22 00:25:45","commitOrder":9,"curCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","date":"2020-04-22 00:25:45","endLine":753,"groupId":"19915","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowIfTopicIsUnknownOnSendWithPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/31/2ba88a917eaac219a36519260395b781f4e8c0.src","preCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":717,"status":"N"},{"authorDate":"2020-06-24 09:08:26","commitOrder":9,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2020-06-24 09:08:26","endLine":813,"groupId":"19922","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1e/3d232298036756562a67669bee23a699c1220d.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.close();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":788,"status":"M"}],"commitId":"448e7d7f0f46db1eae14d4fe7a1d25b7af894b09","commitMessage":"@@@KAFKA-10169: swallow non-fatal KafkaException and don't abort transaction during clean close (#8900)\n\nIf there's any pending data and we haven't flushed the producer when we abort a transaction.  a KafkaException is returned for the previous send. This is a bit misleading.  since the situation is not an unrecoverable error and so the Kafka Exception is really non-fatal. For now.  we should just catch and swallow this in the RecordCollector (see also: KAFKA-10169)\n\nThe reason we ended up aborting an un-flushed transaction was due to the combination of\na. always aborting the ongoing transaction when any task is closed/revoked\nb. only committing (and flushing) if at least one of the revoked tasks needs to be committed (regardless of whether any non-revoked tasks have data/transaction in flight)\n\nGiven the above.  we can end up with an ongoing transaction that isn't committed since none of the revoked tasks have any data in the transaction. We then abort the transaction anyway.  when those tasks are closed. So in addition to the above (swallowing this exception).  we should avoid unnecessarily aborting data for tasks that haven't been revoked.\n\nWe can handle this by splitting the RecordCollector's close into a dirty and clean flavor: if dirty.  we need to abort the transaction since it may be dirty due to the commit attempt failing. But if clean.  we can skip aborting the transaction since we know that either we just committed and thus there is no ongoing transaction to abort.  or else the transaction in flight contains no data from the tasks being closed\n\nNote that this means we still abort the transaction any time a task is closed dirty.  so we must close/reinitialize any active task with pending data (that was aborted).\n\nIn sum:\n\n* hackily check the KafkaException message and swallow\n* only abort the transaction during a dirty close\n* refactor shutdown to make sure we don't closeClean a task whose data was actually aborted\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  Boyang Chen <boyang@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-06-24 09:08:26","modifiedFileCount":"12","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-04-29 04:22:15","codes":[{"authorDate":"2021-04-29 04:22:15","commitOrder":10,"curCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","date":"2021-04-29 04:22:15","endLine":842,"groupId":"19915","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowIfTopicIsUnknownOnSendWithPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5a/83c6839d3d59075fd101c9444abd0dea01649c.src","preCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":806,"status":"M"},{"authorDate":"2021-04-29 04:22:15","commitOrder":10,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2021-04-29 04:22:15","endLine":870,"groupId":"8844","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/5a/83c6839d3d59075fd101c9444abd0dea01649c.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                \"threadId\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":845,"status":"M"}],"commitId":"3805f3706f8f3ebba81b80915c9259590525fb05","commitMessage":"@@@KAFKA-12574: KIP-732.  Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)\n\nDeprecates the following \n\n1. StreamsConfig.EXACTLY_ONCE\n2. StreamsConfig.EXACTLY_ONCE_BETA\n3. Producer#sendOffsetsToTransaction(Map offsets.  String consumerGroupId)\n\nAnd introduces a new StreamsConfig.EXACTLY_ONCE_V2 config. Additionally.  this PR replaces usages of the term \"eos-beta\" throughout the code with the term \"eos-v2\"\n\nReviewers: Matthias J. Sax <mjsax@confluent.io>","date":"2021-04-29 04:22:15","modifiedFileCount":"32","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-08-31 06:39:25","codes":[{"authorDate":"2021-08-31 06:39:25","commitOrder":11,"curCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext,\n                Time.SYSTEM\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","date":"2021-08-31 06:39:25","endLine":846,"groupId":"102315","id":9,"instanceNumber":1,"isCurCommit":1,"methodName":"shouldThrowIfTopicIsUnknownOnSendWithPartitioner","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/364f27db583906a2fe2bdaa385ddbaffc54f3b.src","preCode":"    public void shouldThrowIfTopicIsUnknownOnSendWithPartitioner() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                config,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return new MockProducer<byte[], byte[]>(cluster, true, new DefaultPartitioner(), byteArraySerializer, byteArraySerializer) {\n                            @Override\n                            public List<PartitionInfo> partitionsFor(final String topic) {\n                                return Collections.emptyList();\n                            }\n                        };\n                    }\n                },\n                null,\n                null,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n        collector.initialize();\n\n        final StreamsException thrown = assertThrows(\n            StreamsException.class,\n            () -> collector.send(topic, \"3\", \"0\", null, null, stringSerializer, stringSerializer, streamPartitioner)\n        );\n        assertThat(\n            thrown.getMessage(),\n            equalTo(\"Could not get partition information for topic topic for task 0_0.\" +\n                \" This can happen if the topic does not exist.\")\n        );\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":809,"status":"M"},{"authorDate":"2021-08-31 06:39:25","commitOrder":11,"curCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext,\n                Time.SYSTEM\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","date":"2021-08-31 06:39:25","endLine":875,"groupId":"102315","id":10,"instanceNumber":2,"isCurCommit":1,"methodName":"shouldNotCloseInternalProducerForEOS","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/364f27db583906a2fe2bdaa385ddbaffc54f3b.src","preCode":"    public void shouldNotCloseInternalProducerForEOS() {\n        final RecordCollector collector = new RecordCollectorImpl(\n            logContext,\n            taskId,\n            new StreamsProducer(\n                eosConfig,\n                processId + \"-StreamThread-1\",\n                new MockClientSupplier() {\n                    @Override\n                    public Producer<byte[], byte[]> getProducer(final Map<String, Object> config) {\n                        return mockProducer;\n                    }\n                },\n                taskId,\n                processId,\n                logContext\n            ),\n            productionExceptionHandler,\n            streamsMetrics\n        );\n\n        collector.closeClean();\n\n        \r\n        streamsProducer.flush();\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":849,"status":"M"}],"commitId":"01ab888dbd08ccd4b0de9333d21581ce24fe2c3b","commitMessage":"@@@KAFKA-13229: add total blocked time metric to streams (KIP-761) (#11149)\n\n* Add the following producer metrics:\nflush-time-total: cumulative sum of time elapsed during in flush.\ntxn-init-time-total: cumulative sum of time elapsed during in initTransactions.\ntxn-begin-time-total: cumulative sum of time elapsed during in beginTransaction.\ntxn-send-offsets-time-total: cumulative sum of time elapsed during in sendOffsetsToTransaction.\ntxn-commit-time-total: cumulative sum of time elapsed during in commitTransaction.\ntxn-abort-time-total: cumulative sum of time elapsed during in abortTransaction.\n\n* Add the following consumer metrics:\ncommited-time-total: cumulative sum of time elapsed during in committed.\ncommit-sync-time-total: cumulative sum of time elapsed during in commitSync.\n\n* Add a total-blocked-time metric to streams that is the sum of:\nconsumer?s io-waittime-total\nconsumer?s iotime-total\nconsumer?s committed-time-total\nconsumer?s commit-sync-time-total\nrestore consumer?s io-waittime-total\nrestore consumer?s iotime-total\nadmin client?s io-waittime-total\nadmin client?s iotime-total\nproducer?s bufferpool-wait-time-total\nproducer's flush-time-total\nproducer's txn-init-time-total\nproducer's txn-begin-time-total\nproducer's txn-send-offsets-time-total\nproducer's txn-commit-time-total\nproducer's txn-abort-time-total\n\nReviewers: Bruno Cadonna <cadonna@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2021-08-31 06:39:25","modifiedFileCount":"23","status":"M","submitter":"Rohan"}]
