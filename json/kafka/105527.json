[{"authorTime":"2019-06-22 03:44:45","codes":[{"authorDate":"2017-05-31 09:20:15","commitOrder":2,"curCode":"    public void measureStreamingIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (RecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.streamingIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","date":"2017-05-31 09:22:07","endLine":143,"groupId":"15142","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"measureStreamingIteratorForVariableBatchSize","params":"(Blackholebh)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cf/b72e61c62c9bf8001007705d444fb134383c17.src","preCode":"    public void measureStreamingIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (RecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.streamingIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","realPath":"jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"NB"},{"authorDate":"2019-06-22 03:44:45","commitOrder":2,"curCode":"    public void measureSkipIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (MutableRecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.skipKeyValueIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","date":"2019-06-22 03:44:45","endLine":161,"groupId":"15142","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"measureSkipIteratorForVariableBatchSize","params":"(Blackholebh)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/73/552c2131ef00233c7445512e94c3fe5c66db17.src","preCode":"    public void measureSkipIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (MutableRecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.skipKeyValueIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","realPath":"jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"B"}],"commitId":"3e9d1c1411c5268de382f9dfcc95bdf66d0063a0","commitMessage":"@@@KAFKA-8106: Skipping ByteBuffer allocation of key / value / headers in logValidator (#6785)\n\n* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.\n\n* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.\n\n* github comments\n\n* use batch.skipKeyValueIterator\n\n* cleanups\n\n* no need to skip kv for uncompressed iterator\n\n* checkstyle fixes\n\n* fix findbugs\n\n* adding unit tests\n\n* reuse decompression buffer; and using streaming iterator\n\n* checkstyle\n\n* add unit tests\n\n* remove reusing buffer supplier\n\n* fix unit tests\n\n* add unit tests\n\n* use streaming iterator\n\n* minor refactoring\n\n* rename\n\n* github comments\n\n* github comments\n\n* reuse buffer at DefaultRecord caller\n\n* some further optimization\n\n* major refactoring\n\n* further refactoring\n\n* update comment\n\n* github comments\n\n* minor fix\n\n* add jmh benchmarks\n\n* update jmh\n\n* github comments\n\n* minor fix\n\n* github comments\n","date":"2019-06-22 03:44:45","modifiedFileCount":"12","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2021-05-31 03:16:36","codes":[{"authorDate":"2021-05-31 03:16:36","commitOrder":3,"curCode":"    public void measureStreamingIteratorForVariableBatchSize(Blackhole bh) {\n        for (int i = 0; i < batchCount; ++i) {\n            for (RecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.streamingIterator(requestLocal.bufferSupplier())) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","date":"2021-05-31 03:16:36","endLine":71,"groupId":"105527","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"measureStreamingIteratorForVariableBatchSize","params":"(Blackholebh)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c3/31cd584041c2e122bc560e020404388ff1f7a4.src","preCode":"    public void measureStreamingIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (RecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.streamingIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","realPath":"jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"M"},{"authorDate":"2021-05-31 03:16:36","commitOrder":3,"curCode":"    public void measureSkipIteratorForVariableBatchSize(Blackhole bh) {\n        for (int i = 0; i < batchCount; ++i) {\n            for (MutableRecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.skipKeyValueIterator(requestLocal.bufferSupplier())) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","date":"2021-05-31 03:16:36","endLine":85,"groupId":"105527","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"measureSkipIteratorForVariableBatchSize","params":"(Blackholebh)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c3/31cd584041c2e122bc560e020404388ff1f7a4.src","preCode":"    public void measureSkipIteratorForVariableBatchSize(Blackhole bh) throws IOException {\n        for (int i = 0; i < batchCount; ++i) {\n            for (MutableRecordBatch batch : MemoryRecords.readableRecords(batchBuffers[i].duplicate()).batches()) {\n                try (CloseableIterator<Record> iterator = batch.skipKeyValueIterator(bufferSupplier)) {\n                    while (iterator.hasNext())\n                        bh.consume(iterator.next());\n                }\n            }\n        }\n    }\n","realPath":"jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"M"}],"commitId":"6b005b2b4eece81a5500fb0080ef5354b4240681","commitMessage":"@@@MINOR: Reduce allocations in requests via buffer caching (#9229)\n\nUse a caching `BufferSupplier` per request handler thread so that\ndecompression buffers are cached if supported by the underlying\n`CompressionType`. This achieves a similar outcome as #9220.  but\nwith less contention.\n\nWe introduce a `RequestLocal` class to make it easier to introduce\nnew request scoped stateful instances (one example we discussed\npreviously was an `ActionQueue` that could be used to avoid\nsome of the complex group coordinator locking).\n\nThis is a small win for zstd (no synchronization or soft references) and\na more significant win for lz4. In particular.  it reduces allocations\nsignificantly when the number of partitions is high. The decompression\nbuffer size is typically 64 KB.  so a produce request with 1000 partitions\nresults in 64 MB of allocations even if each produce batch is small (likely. \nwhen there are so many partitions).\n\nI did a quick producer perf local test with 5000 partitions.  1 KB record\nsize. \n1 broker.  lz4 and ~0.5 for the producer compression rate metric:\n\nBefore this change:\n> 20000000 records sent.  346314.349535 records/sec (330.27 MB/sec). \n148.33 ms avg latency.  2267.00 ms max latency.  115 ms 50th.  383 ms 95th.  777 ms 99th.  1514 ms 99.9th.\n\nAfter this change:\n> 20000000 records sent.  431956.113259 records/sec (411.95 MB/sec). \n117.79 ms avg latency.  1219.00 ms max latency.  99 ms 50th.  295 ms 95th.  440 ms 99th.  662 ms 99.9th.\n\nThat's a 25% throughput improvement and p999 latency was reduced to\nunder half (in this test).\n\nDefault arguments will be removed in a subsequent PR.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>","date":"2021-05-31 03:16:36","modifiedFileCount":"4","status":"M","submitter":"Ismael Juma"}]
