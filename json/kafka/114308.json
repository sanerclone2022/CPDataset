[{"authorTime":"2019-04-22 07:24:18","codes":[{"authorDate":"2019-04-22 07:24:18","commitOrder":3,"curCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.leaderAndEpoch(partition));\n            this.subscriptions.seek(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2019-04-22 07:24:18","endLine":1527,"groupId":"14835","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@longoffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/83/9057cc8b21a09d100d7d28285533fdbc56af8d.src","preCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.leaderAndEpoch(partition));\n            this.subscriptions.seek(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1512,"status":"B"},{"authorDate":"2019-04-22 07:24:18","commitOrder":3,"curCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.leaderAndEpoch(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekAndValidate(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2019-04-22 07:24:18","endLine":1563,"groupId":"12211","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@OffsetAndMetadataoffsetAndMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/83/9057cc8b21a09d100d7d28285533fdbc56af8d.src","preCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.leaderAndEpoch(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekAndValidate(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1539,"status":"MB"}],"commitId":"409fabc5610443f36574bdea2e2994b6c20e2829","commitMessage":"@@@KAFKA-7747; Check for truncation after leader changes [KIP-320] (#6371)\n\nAfter the client detects a leader change we need to check the offset of the current leader for truncation. These changes were part of KIP-320: https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2019-04-22 07:24:18","modifiedFileCount":"14","status":"M","submitter":"David Arthur"},{"authorTime":"2019-05-30 23:50:45","codes":[{"authorDate":"2019-05-30 23:50:45","commitOrder":4,"curCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.leaderAndEpoch(partition));\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2019-05-30 23:50:45","endLine":1554,"groupId":"14835","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@longoffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/01/b8989e7c3383b7337c4c0da9cc4005ab60c0e0.src","preCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.leaderAndEpoch(partition));\n            this.subscriptions.seek(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1539,"status":"M"},{"authorDate":"2019-05-30 23:50:45","commitOrder":4,"curCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.leaderAndEpoch(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2019-05-30 23:50:45","endLine":1590,"groupId":"12211","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@OffsetAndMetadataoffsetAndMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/01/b8989e7c3383b7337c4c0da9cc4005ab60c0e0.src","preCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.leaderAndEpoch(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekAndValidate(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1566,"status":"M"}],"commitId":"fd9a20e4167c51c6645c55ed98800b768518c863","commitMessage":"@@@KAFKA-8429; Handle offset change when OffsetForLeaderEpoch inflight (#6811)\n\nIt is possible for the offset of a partition to be changed while we are in the middle of validation. If the OffsetForLeaderEpoch request is in-flight and the offset changes.  we need to redo the validation after it returns. We had a check for this situation previously.  but it was only checking if the current leader epoch had changed. This patch fixes this and moves the validation in `SubscriptionState` where it can be protected with a lock.\n\nAdditionally.  this patch adds test cases for the SubscriptionState validation API. We fix a small bug handling broker downgrades. Basically we should skip validation if the latest metadata does not include leader epoch information.\n\nReviewers: David Arthur <mumrah@gmail.com>","date":"2019-05-30 23:50:45","modifiedFileCount":"6","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2020-02-06 01:13:11","codes":[{"authorDate":"2020-02-06 01:13:11","commitOrder":5,"curCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.currentLeader(partition));\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2020-02-06 01:13:11","endLine":1612,"groupId":"114308","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@longoffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/20/da83f36f3679598193fc3b47468c5fbf69e4ba.src","preCode":"    public void seek(TopicPartition partition, long offset) {\n        if (offset < 0)\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n\n        acquireAndEnsureOpen();\n        try {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offset,\n                    Optional.empty(), \r\n                    this.metadata.leaderAndEpoch(partition));\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1597,"status":"M"},{"authorDate":"2020-02-06 01:13:11","commitOrder":5,"curCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.currentLeader(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","date":"2020-02-06 01:13:11","endLine":1648,"groupId":"114308","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"seek","params":"(TopicPartitionpartition@OffsetAndMetadataoffsetAndMetadata)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/20/da83f36f3679598193fc3b47468c5fbf69e4ba.src","preCode":"    public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n        long offset = offsetAndMetadata.offset();\n        if (offset < 0) {\n            throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n        }\n\n        acquireAndEnsureOpen();\n        try {\n            if (offsetAndMetadata.leaderEpoch().isPresent()) {\n                log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                        offset, partition, offsetAndMetadata.leaderEpoch().get());\n            } else {\n                log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n            }\n            Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.leaderAndEpoch(partition);\n            SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                    offsetAndMetadata.offset(),\n                    offsetAndMetadata.leaderEpoch(),\n                    currentLeaderAndEpoch);\n            this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n            this.subscriptions.seekUnvalidated(partition, newPosition);\n        } finally {\n            release();\n        }\n    }\n","realPath":"clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1624,"status":"M"}],"commitId":"ae0c6e58e5a2c545ba54eea5fb4d5dd103d237ff","commitMessage":"@@@KAFKA-9261; Client should handle unavailable leader metadata (#7770)\n\nThe client caches metadata fetched from Metadata requests. Previously.  each metadata response overwrote all of the metadata from the previous one.  so we could rely on the expectation that the broker only returned the leaderId for a partition if it had connection information available. This behavior changed with KIP-320 since having the leader epoch allows the client to filter out partition metadata which is known to be stale. However.  because of this.  we can no longer rely on the request-level guarantee of leader availability. There is no mechanism similar to the leader epoch to track the staleness of broker metadata.  so we still overwrite all of the broker metadata from each response.  which means that the partition metadata can get out of sync with the broker metadata in the client's cache. Hence it is no longer safe to validate inside the `Cluster` constructor that each leader has an associated `Node`\n\nFixing this issue was unfortunately not straightforward because the cache was built to maintain references to broker metadata through the `Node` object at the partition level. In order to keep the state consistent.  each `Node` reference would need to be updated based on the new broker metadata. Instead of doing that.  this patch changes the cache so that it is structured more closely with the Metadata response schema. Broker node information is maintained at the top level in a single collection and cached partition metadata only references the id of the broker. To accommodate this.  we have removed `PartitionInfoAndEpoch` and we have altered `MetadataResponse.PartitionMetadata` to eliminate its `Node` references.\n\nNote that one of the side benefits of the refactor here is that we virtually eliminate one of the hotspots in Metadata request handling in `MetadataCache.getEndpoints` (which was renamed to `maybeFilterAliveReplicas`). The only reason this was expensive was because we had to build a new collection for the `Node` representations of each of the replica lists. This information was doomed to just get discarded on serialization.  so the whole effort was wasteful. Now.  we work with the lower level id lists and no copy of the replicas is needed (at least for all versions other than 0).\n\nReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>.  Ismael Juma <ismael@juma.me.uk>","date":"2020-02-06 01:13:11","modifiedFileCount":"22","status":"M","submitter":"Jason Gustafson"}]
