[{"authorTime":"2020-02-26 03:23:25","codes":[{"authorDate":"2019-04-27 00:30:20","commitOrder":2,"curCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2019-04-27 00:30:20","endLine":150,"groupId":"2892","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldUseDefaultSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e3/f0a4121e35107bdcc7acc031405d544fa73159.src","preCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"NB"},{"authorDate":"2020-02-26 03:23:25","commitOrder":2,"curCode":"    public void shouldCreateChangelogByDefault() {\n        final String testId = \"-shouldCreateChangelogByDefault\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n        final String changeLog = \"suppressionintegrationtest-shouldCreateChangelogByDefault-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n                .emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n\n            assertThat(CLUSTER.getAllTopicsInCluster(), hasItem(changeLog));\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2020-02-26 03:23:25","endLine":435,"groupId":"2892","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldCreateChangelogByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8c/3be2f378aea6252d88e77b4bfa7e61890c0483.src","preCode":"    public void shouldCreateChangelogByDefault() {\n        final String testId = \"-shouldCreateChangelogByDefault\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n        final String changeLog = \"suppressionintegrationtest-shouldCreateChangelogByDefault-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n                .emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n\n            assertThat(CLUSTER.getAllTopicsInCluster(), hasItem(changeLog));\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":382,"status":"B"}],"commitId":"90640266393b530107db8256d38ec5aeba4805e1","commitMessage":"@@@KAFKA-8147: Add changelog topic configuration to KTable suppress (#8029)\n\nImplements: KIP-446\n\nReviewers: John Roesler <vvcephei@apache.org>","date":"2020-02-26 03:23:25","modifiedFileCount":"10","status":"M","submitter":"high.lee"},{"authorTime":"2020-04-30 06:11:49","codes":[{"authorDate":"2020-04-30 06:11:49","commitOrder":3,"curCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            quietlyCleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2020-04-30 06:11:49","endLine":155,"groupId":"102676","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldUseDefaultSerdes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9d/7c23d73c631af9ed2c964771a7b696f20942c9.src","preCode":"    public void shouldUseDefaultSerdes() {\n        final String testId = \"-shouldInheritSerdes\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L).emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":106,"status":"M"},{"authorDate":"2020-04-30 06:11:49","commitOrder":3,"curCode":"    public void shouldCreateChangelogByDefault() {\n        final String testId = \"-shouldCreateChangelogByDefault\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n        final String changeLog = \"suppressionintegrationtest-shouldCreateChangelogByDefault-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n                .emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n\n            assertThat(CLUSTER.getAllTopicsInCluster(), hasItem(changeLog));\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            quietlyCleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","date":"2020-04-30 06:11:49","endLine":435,"groupId":"102676","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldCreateChangelogByDefault","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9d/7c23d73c631af9ed2c964771a7b696f20942c9.src","preCode":"    public void shouldCreateChangelogByDefault() {\n        final String testId = \"-shouldCreateChangelogByDefault\";\n        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n        final String input = \"input\" + testId;\n        final String outputSuppressed = \"output-suppressed\" + testId;\n        final String outputRaw = \"output-raw\" + testId;\n        final String changeLog = \"suppressionintegrationtest-shouldCreateChangelogByDefault-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n\n        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n\n        final StreamsBuilder builder = new StreamsBuilder();\n\n        final KStream<String, String> inputStream = builder.stream(input);\n\n        final KTable<String, String> valueCounts = inputStream\n            .groupByKey()\n            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n\n        valueCounts\n            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n                .emitEarlyWhenFull()))\n            .toStream()\n            .to(outputSuppressed);\n\n        valueCounts\n            .toStream()\n            .to(outputRaw);\n\n        final Properties streamsConfig = getStreamsConfig(appId);\n        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n\n        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n        try {\n            produceSynchronously(\n                input,\n                asList(\n                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n                )\n            );\n            final boolean rawRecords = waitForAnyRecord(outputRaw);\n            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n\n            assertThat(CLUSTER.getAllTopicsInCluster(), hasItem(changeLog));\n            assertThat(rawRecords, Matchers.is(true));\n            assertThat(suppressedRecords, is(true));\n        } finally {\n            driver.close();\n            cleanStateAfterTest(CLUSTER, driver);\n        }\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":382,"status":"M"}],"commitId":"dc4d439825b2d117707b01c7c64769e700246fc6","commitMessage":"@@@KAFKA-9875: Make integration tests more resilient (#8578)\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2020-04-30 06:11:49","modifiedFileCount":"25","status":"M","submitter":"John Roesler"}]
