[{"authorTime":"2020-02-07 02:58:05","codes":[{"authorDate":"2020-02-07 02:58:05","commitOrder":6,"curCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 4) {\n            throw new IllegalArgumentException(\"Should accept 4 parameters: [mode], \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        String mode = args[0];\n        int numPartitions = Integer.parseInt(args[1]);\n        int numInstances = Integer.parseInt(args[2]);\n        int numRecords = Integer.parseInt(args[3]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(mode,\n                INPUT_TOPIC, OUTPUT_TOPIC, numPartitions,\n                numInstances, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-07 02:58:05","endLine":124,"groupId":"6468","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/28/8b7861801404892813f940e01906941124fb7f.src","preCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 4) {\n            throw new IllegalArgumentException(\"Should accept 4 parameters: [mode], \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        String mode = args[0];\n        int numPartitions = Integer.parseInt(args[1]);\n        int numInstances = Integer.parseInt(args[2]);\n        int numRecords = Integer.parseInt(args[3]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(mode,\n                INPUT_TOPIC, OUTPUT_TOPIC, numPartitions,\n                numInstances, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaExactlyOnceDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"MB"},{"authorDate":"2020-02-07 02:58:05","commitOrder":6,"curCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-07 02:58:05","endLine":40,"groupId":"7309","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/21/d85c31c9cdf42293f9b8632404fdf0b116b462.src","preCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaConsumerProducerDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":25,"status":"MB"}],"commitId":"f48946f572be2ff201abf69653b1eacc4436e34e","commitMessage":"@@@HOTFIX: Fix spotsbug failure in Kafka examples (#8051)\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2020-02-07 02:58:05","modifiedFileCount":"2","status":"M","submitter":"Boyang Chen"},{"authorTime":"2020-02-13 04:34:12","codes":[{"authorDate":"2020-02-13 04:34:12","commitOrder":7,"curCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 4) {\n            throw new IllegalArgumentException(\"Should accept 4 parameters: [mode], \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        String mode = args[0];\n        int numPartitions = Integer.parseInt(args[1]);\n        int numInstances = Integer.parseInt(args[2]);\n        int numRecords = Integer.parseInt(args[3]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, -1, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(mode,\n                INPUT_TOPIC, OUTPUT_TOPIC, numPartitions,\n                numInstances, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-13 04:34:12","endLine":124,"groupId":"6468","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6d/a159cf92170eb901bb1d52b30dcecb89cc9db9.src","preCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 4) {\n            throw new IllegalArgumentException(\"Should accept 4 parameters: [mode], \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        String mode = args[0];\n        int numPartitions = Integer.parseInt(args[1]);\n        int numInstances = Integer.parseInt(args[2]);\n        int numRecords = Integer.parseInt(args[3]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(mode,\n                INPUT_TOPIC, OUTPUT_TOPIC, numPartitions,\n                numInstances, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaExactlyOnceDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"M"},{"authorDate":"2020-02-13 04:34:12","commitOrder":7,"curCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, -1, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-13 04:34:12","endLine":40,"groupId":"7309","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8a/29402836ceac191c58c633fc885c02d94f09ef.src","preCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaConsumerProducerDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":25,"status":"M"}],"commitId":"07db26c20fcbccbf758591607864f7fd4bd8975f","commitMessage":"@@@KAFKA-9417: New Integration Test for KIP-447 (#8000)\n\nThis change mainly have 2 components:\n\n1. extend the existing transactions_test.py to also try out new sendTxnOffsets(groupMetadata) API to make sure we are not introducing any regression or compatibility issue\n  a. We shrink the time window to 10 seconds for the txn timeout scheduler on broker so that we could trigger expiration earlier than later\n\n2. create a completely new system test class called group_mode_transactions_test which is more complicated than the existing system test.  as we are taking rebalance into consideration and using multiple partitions instead of one. For further breakdown:\n  a. The message count was done on partition level.  instead of global as we need to visualize \nthe per partition order throughout the test. For this sake.  we extend ConsoleConsumer to print out the data partition as well to help message copier interpret the per partition data.\n  b. The progress count includes the time for completing the pending txn offset expiration\n  c. More visibility and feature improvements on TransactionMessageCopier to better work under either standalone or group mode.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-02-13 04:34:12","modifiedFileCount":"9","status":"M","submitter":"Boyang Chen"},{"authorTime":"2020-02-21 01:59:09","codes":[{"authorDate":"2020-02-21 01:59:09","commitOrder":8,"curCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 3) {\n            throw new IllegalArgumentException(\"Should accept 3 parameters: \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        int numPartitions = Integer.parseInt(args[0]);\n        int numInstances = Integer.parseInt(args[1]);\n        int numRecords = Integer.parseInt(args[2]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, -1, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(\n                INPUT_TOPIC, OUTPUT_TOPIC, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", Optional.empty(), true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-21 01:59:09","endLine":126,"groupId":"105507","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/50/a1ad14bc499222dd5cb317707a4576d87a808f.src","preCode":"    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        if (args.length != 4) {\n            throw new IllegalArgumentException(\"Should accept 4 parameters: [mode], \" +\n                \"[number of partitions], [number of instances], [number of records]\");\n        }\n\n        String mode = args[0];\n        int numPartitions = Integer.parseInt(args[1]);\n        int numInstances = Integer.parseInt(args[2]);\n        int numRecords = Integer.parseInt(args[3]);\n\n        \n        recreateTopics(numPartitions);\n\n        CountDownLatch prePopulateLatch = new CountDownLatch(1);\n\n        \n        Producer producerThread = new Producer(INPUT_TOPIC, false, null, true, numRecords, -1, prePopulateLatch);\n        producerThread.start();\n\n        if (!prePopulateLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for data pre-population\");\n        }\n\n        CountDownLatch transactionalCopyLatch = new CountDownLatch(numInstances);\n\n        \n        for (int instanceIdx = 0; instanceIdx < numInstances; instanceIdx++) {\n            ExactlyOnceMessageProcessor messageProcessor = new ExactlyOnceMessageProcessor(mode,\n                INPUT_TOPIC, OUTPUT_TOPIC, numPartitions,\n                numInstances, instanceIdx, transactionalCopyLatch);\n            messageProcessor.start();\n        }\n\n        if (!transactionalCopyLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for transactionally message copy\");\n        }\n\n        CountDownLatch consumeLatch = new CountDownLatch(1);\n\n        \n        Consumer consumerThread = new Consumer(OUTPUT_TOPIC, \"Verify-consumer\", true, numRecords, consumeLatch);\n        consumerThread.start();\n\n        if (!consumeLatch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for output data consumption\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaExactlyOnceDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":78,"status":"M"},{"authorDate":"2020-02-21 01:59:09","commitOrder":8,"curCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, -1, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", Optional.empty(), false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","date":"2020-02-21 01:59:09","endLine":41,"groupId":"105507","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/9f/c911acac02b321af17a45bf4159f15ca1139d8.src","preCode":"    public static void main(String[] args) throws InterruptedException {\n        boolean isAsync = args.length == 0 || !args[0].trim().equalsIgnoreCase(\"sync\");\n        CountDownLatch latch = new CountDownLatch(2);\n        Producer producerThread = new Producer(KafkaProperties.TOPIC, isAsync, null, false, 10000, -1, latch);\n        producerThread.start();\n\n        Consumer consumerThread = new Consumer(KafkaProperties.TOPIC, \"DemoConsumer\", false, 10000, latch);\n        consumerThread.start();\n\n        if (!latch.await(5, TimeUnit.MINUTES)) {\n            throw new TimeoutException(\"Timeout after 5 minutes waiting for demo producer and consumer to finish\");\n        }\n\n        consumerThread.shutdown();\n        System.out.println(\"All finished!\");\n    }\n","realPath":"examples/src/main/java/kafka/examples/KafkaConsumerProducerDemo.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":26,"status":"M"}],"commitId":"776565f7a8646c1920dbb303aad7fe3edb08d7ce","commitMessage":"@@@MINOR: Improve EOS example exception handling (#8052)\n\nThe current EOS example mixes fatal and non-fatal error handling. This patch fixes this problem and simplifies the example.\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2020-02-21 01:59:09","modifiedFileCount":"5","status":"M","submitter":"Boyang Chen"}]
