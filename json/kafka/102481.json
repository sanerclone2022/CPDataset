[{"authorTime":"2020-03-10 08:48:44","codes":[{"authorDate":"2020-02-07 07:28:19","commitOrder":3,"curCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore();\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","date":"2020-02-07 07:28:18","endLine":628,"groupId":"9205","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldOnlyRestoreStandbyChangelogInUpdateStandbyState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/784eaea10b016f54a00eb7c39e9048025f805a.src","preCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore();\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":595,"status":"NB"},{"authorDate":"2020-03-10 08:48:44","commitOrder":3,"curCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore();\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","date":"2020-03-10 08:48:44","endLine":680,"groupId":"7898","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotUpdateLimitForNonSourceStandbyChangelog","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e0/33535cd4d5157967c6813a146a0b16d9f47bca.src","preCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore();\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":631,"status":"B"}],"commitId":"dcfb641add650073f46fe8d8370c72f0284e62d7","commitMessage":"@@@KAFKA-9176: Do not update limit offset if we are in RESTORE_ACTIVE mode (#8235)\n\nPreviously we may be updating the standby's limit offset as committed offsets to those source changelogs.  and then inside the inner method we check if the state is in RESTORE_ACTIVE or not.  which is a bug.\n\nWe should.  instead.  just check on the caller that we can skip restoring if:\n\n1. we are in RESTORE_ACTIVE mode.\n2. there're no source changelog partitions.\n3. those partitions do not have any buffered records.\n\nAlso updated the unit test for this coverage.\n\nReviewers: Boyang Chen <boyang@confluent.io>.  A. Sophie Blee-Goldman <sophie@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2020-03-10 08:48:44","modifiedFileCount":"2","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-06-19 02:28:49","codes":[{"authorDate":"2020-02-07 07:28:19","commitOrder":4,"curCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore();\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","date":"2020-02-07 07:28:18","endLine":628,"groupId":"9205","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldOnlyRestoreStandbyChangelogInUpdateStandbyState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/e9/784eaea10b016f54a00eb7c39e9048025f805a.src","preCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore();\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":595,"status":"N"},{"authorDate":"2020-06-19 02:28:49","commitOrder":4,"curCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, adminClient, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore();\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","date":"2020-06-19 02:28:49","endLine":718,"groupId":"7898","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotUpdateLimitForNonSourceStandbyChangelog","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ad/16cff17a20591e8f46036ce58b7cb82ae5669b.src","preCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore();\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":669,"status":"M"}],"commitId":"d8cc6fe8e36329c647736773d9d66de89c447409","commitMessage":"@@@KAFKA-10167: use the admin client to read end-offset (#8876)\n\nSince admin client allows use to use flexible offset-spec.  we can always set to use read-uncommitted regardless of the EOS config.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  Bruno Cadonna <bruno@confluent.io>.  Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-06-19 02:28:49","modifiedFileCount":"11","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-10-20 02:07:56","codes":[{"authorDate":"2020-10-20 02:07:56","commitOrder":5,"curCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        final Map<TaskId, Task> mockTasks = mock(Map.class);\n        EasyMock.expect(mockTasks.get(null)).andReturn(mock(Task.class)).anyTimes();\n        EasyMock.replay(mockTasks, standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore(mockTasks);\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore(mockTasks);\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore(mockTasks);\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","date":"2020-10-20 02:07:56","endLine":786,"groupId":"102481","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldOnlyRestoreStandbyChangelogInUpdateStandbyState","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/5526d07d3d5bdddf588ebe7f5140fa5ec37688.src","preCode":"    public void shouldOnlyRestoreStandbyChangelogInUpdateStandbyState() {\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        changelogReader.restore();\n\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n\n        assertEquals(Collections.singleton(tp), consumer.paused());\n\n        changelogReader.transitToUpdateStandby();\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertEquals(5L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertTrue(changelogReader.changelogMetadata(tp).bufferedRecords().isEmpty());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":751,"status":"M"},{"authorDate":"2020-10-20 02:07:56","commitOrder":5,"curCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        final Map<TaskId, Task> mockTasks = mock(Map.class);\n        EasyMock.expect(mockTasks.get(null)).andReturn(mock(Task.class)).anyTimes();\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(mockTasks, standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, adminClient, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore(mockTasks);\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore(mockTasks);\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","date":"2020-10-20 02:07:56","endLine":840,"groupId":"102481","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotUpdateLimitForNonSourceStandbyChangelog","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/98/5526d07d3d5bdddf588ebe7f5140fa5ec37688.src","preCode":"    public void shouldNotUpdateLimitForNonSourceStandbyChangelog() {\n        EasyMock.expect(standbyStateManager.changelogAsSource(tp)).andReturn(false).anyTimes();\n        EasyMock.replay(standbyStateManager, storeMetadata, store);\n\n        final MockConsumer<byte[], byte[]> consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n            @Override\n            public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions) {\n                throw new AssertionError(\"Should not try to fetch committed offsets\");\n            }\n        };\n\n        final Properties properties = new Properties();\n        properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100L);\n        final StreamsConfig config = new StreamsConfig(StreamsTestUtils.getStreamsConfig(\"test-reader\", properties));\n        final StoreChangelogReader changelogReader = new StoreChangelogReader(time, config, logContext, adminClient, consumer, callback);\n        changelogReader.setMainConsumer(consumer);\n        changelogReader.transitToUpdateStandby();\n\n        consumer.updateBeginningOffsets(Collections.singletonMap(tp, 5L));\n        changelogReader.register(tp, standbyStateManager);\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        \r\n        changelogReader.restore();\n        assertNull(callback.restoreTopicPartition);\n        assertNull(callback.storeNameCalledStates.get(RESTORE_START));\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(0L, changelogReader.changelogMetadata(tp).totalRestored());\n\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 5L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 6L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 7L, \"key\".getBytes(), \"value\".getBytes()));\n        \r\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 8L, null, \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 9L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 10L, \"key\".getBytes(), \"value\".getBytes()));\n        consumer.addRecord(new ConsumerRecord<>(topicName, 0, 11L, \"key\".getBytes(), \"value\".getBytes()));\n\n        \r\n        changelogReader.restore();\n        assertEquals(StoreChangelogReader.ChangelogState.RESTORING, changelogReader.changelogMetadata(tp).state());\n        assertNull(changelogReader.changelogMetadata(tp).endOffset());\n        assertEquals(6L, changelogReader.changelogMetadata(tp).totalRestored());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedRecords().size());\n        assertEquals(0, changelogReader.changelogMetadata(tp).bufferedLimitIndex());\n        assertNull(callback.storeNameCalledStates.get(RESTORE_END));\n        assertNull(callback.storeNameCalledStates.get(RESTORE_BATCH));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":789,"status":"M"}],"commitId":"aef6cd6e9995b42db2cefa7d715321d0edee5628","commitMessage":"@@@KAFKA-9274: Add timeout handling for state restore and StandbyTasks (#9368)\n\n* Part of KIP-572\n* If a TimeoutException happens during restore of active tasks.  or updating standby tasks.  we need to trigger task.timeout.ms timeout.\n\nReviewers: John Roesler <john@confluent.io>","date":"2020-10-20 02:07:56","modifiedFileCount":"15","status":"M","submitter":"Matthias J. Sax"}]
