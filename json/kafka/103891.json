[{"authorTime":"2018-02-15 02:52:46","codes":[{"authorDate":"2018-02-15 02:52:46","commitOrder":1,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(0);\n    }\n","date":"2018-02-15 02:52:46","endLine":505,"groupId":"6147","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8c/147a58f770e0b6dec37c8bafd31798ab712ea3.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(0);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":483,"status":"B"},{"authorDate":"2018-02-15 02:52:46","commitOrder":1,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(0);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2018-02-15 02:52:46","endLine":531,"groupId":"6147","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8c/147a58f770e0b6dec37c8bafd31798ab712ea3.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(0);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":508,"status":"B"}],"commitId":"6d18d882b850a8d757c32bb124b1e42e60587c69","commitMessage":"@@@KAFKA-6397: Consumer should not block setting positions of unavailable partitions (#4557)\n\nPrior to this patch.  the consumer always blocks in poll() if there are any partitions which are awaiting their initial positions. This behavior was inconsistent with normal fetch behavior since we allow fetching on available partitions even if one or more of the assigned partitions becomes unavailable _after_ initial offset lookup. With this patch.  the consumer will do offset resets asynchronously.  which allows other partitions to make progress even if the initial positions for some partitions cannot be found.\n\nI have added several new unit tests in `FetcherTest` and `KafkaConsumerTest` to verify the new behavior. One minor compatibility implication worth mentioning is apparent from the change I made in `DynamicBrokerReconfigurationTest`. Previously it was possible to assume that all partitions had a fetch position after `poll()` completed with a non-empty assignment. This assumption is no longer generally true.  but you can force the positions to be updated using the `position()` API which still blocks indefinitely until a position is available.\n\nNote that this this patch also removes the logic to cache committed offsets in `SubscriptionState` since it was no longer needed (the consumer's `committed()` API always does an offset lookup anyway). In addition to avoiding the complexity of maintaining the cache.  this avoids wasteful offset lookups to refresh the cache when `commitAsync()` is used.\n\nReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2018-02-15 02:52:46","modifiedFileCount":"12","status":"B","submitter":"Jason Gustafson"},{"authorTime":"2018-05-27 02:50:51","codes":[{"authorDate":"2018-05-27 02:50:51","commitOrder":2,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2018-05-27 02:50:51","endLine":566,"groupId":"6147","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ce/722cf12e34b154b77008264048905c38c57cd4.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(0);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":544,"status":"M"},{"authorDate":"2018-05-27 02:50:51","commitOrder":2,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2018-05-27 02:50:51","endLine":592,"groupId":"6147","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ce/722cf12e34b154b77008264048905c38c57cd4.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(0);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":569,"status":"M"}],"commitId":"c470ff70d3e829c8b12f6eb6cc812c4162071a1f","commitMessage":"@@@KAFKA-5697; Implement new consumer poll API from KIP-266 (#4855)\n\nAdd the new stricter-timeout version of `poll` proposed in KIP-266.\n\nThe pre-existing variant `poll(long timeout)` would block indefinitely for metadata\nupdates if they were needed.  then it would issue a fetch and poll for `timeout` ms \nfor new records. The initial indefinite metadata block caused applications to become\nstuck when the brokers became unavailable. The existence of the timeout parameter\nmade the indefinite block especially unintuitive.\n\nThis PR adds `poll(Duration timeout)` with the semantics:\n1. iff a metadata update is needed:\n    1. send (asynchronous) metadata requests\n    2. poll for metadata responses (counts against timeout)\n        - if no response within timeout.  **return an empty collection immediately**\n2. if there is fetch data available.  **return it immediately**\n3. if there is no fetch request in flight.  send fetch requests\n4. poll for fetch responses (counts against timeout)\n    - if no response within timeout.  **return an empty collection** (leaving async fetch request for the next poll)\n    - if we get a response.  **return the response**\n\nThe old method.  `poll(long timeout)` is deprecated.  but we do not change its semantics.  so it remains:\n1. iff a metadata update is needed:\n    1. send (asynchronous) metadata requests\n    2. poll for metadata responses *indefinitely until we get it*\n2. if there is fetch data available.  **return it immediately**\n3. if there is no fetch request in flight.  send fetch requests\n4. poll for fetch responses (counts against timeout)\n    - if no response within timeout.  **return an empty collection** (leaving async fetch request for the next poll)\n    - if we get a response.  **return the response**\n\nOne notable usage is prohibited by the new `poll`: previously.  you could call `poll(0)` to block for metadata updates.  for example to initialize the client.  supposedly without fetching records. Note.  though.  that this behavior is not according to any contract.  and there is no guarantee that `poll(0)` won't return records the first time it's called. Therefore.  it has always been unsafe to ignore the response.","date":"2018-05-27 02:50:51","modifiedFileCount":"20","status":"M","submitter":"John Roesler"},{"authorTime":"2018-10-31 04:20:13","codes":[{"authorDate":"2018-10-31 04:20:13","commitOrder":3,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2018-10-31 04:20:13","endLine":566,"groupId":"6147","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/89/fca844262f31bb83375e9524beecfe8e4ab332.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":546,"status":"M"},{"authorDate":"2018-10-31 04:20:13","commitOrder":3,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2018-10-31 04:20:13","endLine":590,"groupId":"6147","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/89/fca844262f31bb83375e9524beecfe8e4ab332.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Cluster cluster = TestUtils.singletonCluster(topic, 1);\n        Node node = cluster.nodes().get(0);\n\n        Metadata metadata = createMetadata();\n        metadata.update(cluster, Collections.<String>emptySet(), time.milliseconds());\n\n        MockClient client = new MockClient(time, metadata);\n        client.setNode(node);\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":569,"status":"M"}],"commitId":"d71cb54672e63d2f0f4b999668336642a9a63a1d","commitMessage":"@@@KAFKA-7567; Clean up internal metadata usage for consistency and extensibility (#5813)\n\nThis patch makes two improvements to internal metadata handling logic and testing:\n\n1. It reduce dependence on the public object `Cluster` for internal metadata propagation since it is not easy to evolve. As an example.  we need to propagate leader epochs from the metadata response to `Metadata`.  but it is not straightforward to do this without exposing it in `PartitionInfo` since that is what `Cluster` uses internally. By doing this change.  we are able to remove some redundant `Cluster` building logic. \n2. We want to make the metadata handling in `MockClient` simpler and more consistent. Currently we have mix of metadata update mechanisms which are internally inconsistent with each other and do not match the implementation in `NetworkClient`.\n\nReviewers: Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2018-10-31 04:20:13","modifiedFileCount":"29","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2018-11-16 16:58:56","codes":[{"authorDate":"2018-11-16 16:58:56","commitOrder":4,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2018-11-16 16:58:56","endLine":579,"groupId":"19045","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/57077d0338154b9f4026a3a4373f9f034cbe96.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":559,"status":"M"},{"authorDate":"2018-11-16 16:58:56","commitOrder":4,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2018-11-16 16:58:56","endLine":603,"groupId":"19045","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/36/57077d0338154b9f4026a3a4373f9f034cbe96.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":582,"status":"M"}],"commitId":"c3e7d6252c41d48e74379810595c978efada9efb","commitMessage":"@@@KAFKA-6774; Improve the default group id behavior in KafkaConsumer (KIP-289) (#5877)\n\nImprove the default group id behavior by:\n* changing the default consumer group to null.  where no offset commit or fetch.  or group management operations are allowed\n* deprecating the use of empty (`\"\"`) consumer group on the client\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2018-11-16 16:58:56","modifiedFileCount":"5","status":"M","submitter":"Vahid Hashemian"},{"authorTime":"2019-03-08 08:29:19","codes":[{"authorDate":"2019-03-08 08:29:19","commitOrder":5,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2019-03-08 08:29:19","endLine":584,"groupId":"18862","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a5/161b44a8d2b6da5ce569e04a263ad93924c83c.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":563,"status":"M"},{"authorDate":"2019-03-08 08:29:19","commitOrder":5,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2019-03-08 08:29:19","endLine":609,"groupId":"18862","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a5/161b44a8d2b6da5ce569e04a263ad93924c83c.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        Metadata metadata = createMetadata();\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, metadata, assignor,\n                OffsetResetStrategy.NONE, true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":587,"status":"M"}],"commitId":"460e46c3bb76a361d0706b263c03696005e12566","commitMessage":"@@@KAFKA-7831; Do not modify subscription state from background thread (#6221)\n\nMetadata may be updated from the background thread.  so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally.  it improves the following:\n\n1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription.  so this simplifies the logic.\n2. The metadata needs for the producer and consumer are quite different.  so it made sense to separate the custom logic into separate extensions of Metadata. For example.  only the producer requires topic expiration.\n3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.\n4. This patch removes the MetadataListener.  which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. \n\nReviewers: David Arthur <mumrah@gmail.com>.  Rajini Sivaram <rajinisivaram@googlemail.com>","date":"2019-03-08 08:29:19","modifiedFileCount":"30","status":"M","submitter":"Jason Gustafson"},{"authorTime":"2019-04-27 02:44:38","codes":[{"authorDate":"2019-04-27 02:44:38","commitOrder":6,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2019-04-27 02:44:38","endLine":589,"groupId":"14408","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8f/23d41240f449718b28aa18823f0e9484878f26.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":568,"status":"M"},{"authorDate":"2019-04-27 02:44:38","commitOrder":6,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2019-04-27 02:44:38","endLine":614,"groupId":"14408","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8f/23d41240f449718b28aa18823f0e9484878f26.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":592,"status":"M"}],"commitId":"0f995ba6be1c0f949320b0879241d9a7c9578436","commitMessage":"@@@KAFKA-7862 & KIP-345 part-one: Add static membership logic to JoinGroup protocol (#6177)\n\nThis is the first diff for the implementation of JoinGroup logic for static membership. The goal of this diff contains:\n\n* Add group.instance.id to be unique identifier for consumer instances.  provided by end user;\nModify group coordinator to accept JoinGroupRequest with/without static membership.  refactor the logic for readability and code reusability.\n* Add client side support for incorporating static membership changes.  including new config for group.instance.id.  apply stream thread client id by default.  and new join group exception handling.\n* Increase max session timeout to 30 min for more user flexibility if they are inclined to tolerate partial unavailability than burdening rebalance.\n* Unit tests for each module changes.  especially on the group coordinator logic. Crossing the possibilities like:\n6.1 Dynamic/Static member\n6.2 Known/Unknown member id\n6.3 Group stable/unstable\n6.4 Leader/Follower\n\nThe rest of the 345 change will be broken down to 4 separate diffs:\n\n* Avoid kicking out members through rebalance.timeout.  only do the kick out through session timeout.\n* Changes around LeaveGroup logic.  including version bumping.  broker logic.  client logic.  etc.\n* Admin client changes to add ability to batch remove static members\n* Deprecate group.initial.rebalance.delay\n\nReviewers: Liquan Pei <liquanpei@gmail.com>.  Stanislav Kozlovski <familyguyuser192@windowslive.com>.  Jason Gustafson <jason@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-04-27 02:44:38","modifiedFileCount":"13","status":"M","submitter":"Boyang Chen"},{"authorTime":"2019-05-07 05:26:22","codes":[{"authorDate":"2019-05-07 05:26:22","commitOrder":7,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2019-05-07 05:26:22","endLine":589,"groupId":"14408","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cc/d9e94aba91bb754c26a6665a8c9c721959fca6.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":568,"status":"M"},{"authorDate":"2019-05-07 05:26:22","commitOrder":7,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2019-05-07 05:26:22","endLine":614,"groupId":"14408","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/cc/d9e94aba91bb754c26a6665a8c9c721959fca6.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(new FindCoordinatorResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":592,"status":"M"}],"commitId":"407bcdf78e06f83f2b358d2cbd96aed348a5c28f","commitMessage":"@@@KAFKA-8056; Use automatic RPC generation for FindCoordinator (#6408)\n\nReviewers: Jason Gustafson <jason@confluent.io>","date":"2019-05-07 05:26:22","modifiedFileCount":"16","status":"M","submitter":"Mickael Maison"},{"authorTime":"2019-07-26 04:02:09","codes":[{"authorDate":"2019-07-26 04:02:09","commitOrder":8,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2019-07-26 04:02:09","endLine":601,"groupId":"14408","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/12/27c27ad60357abfe313f941c14f0e3a8b33c26.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":580,"status":"M"},{"authorDate":"2019-07-26 04:02:09","commitOrder":8,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2019-07-26 04:02:09","endLine":626,"groupId":"14408","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/12/27c27ad60357abfe313f941c14f0e3a8b33c26.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        PartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":604,"status":"M"}],"commitId":"69d86a197f86ad4c6f1636b5ab4678907e30a4c0","commitMessage":"@@@KAFKA-8179: add public ConsumerPartitionAssignor interface (#7108)\n\nMain changes of this PR:\n\n* Deprecate old consumer.internal.PartitionAssignor and add public consumer.ConsumerPartitionAssignor with all OOTB assignors migrated to new interface\n* Refactor assignor's assignment/subscription related classes for easier to evolve API\n* Removed version number from classes as it is only needed for serialization/deserialization\n* Other previously-discussed cleanup included in this PR:\n\n* Remove Assignment.error added in pt 1\n* Remove ConsumerCoordinator#adjustAssignment added in pt 2\n\nReviewers: Boyang Chen <boyang@confluent.io>.  Jason Gustafson <jason@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2019-07-26 04:02:09","modifiedFileCount":"19","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2020-03-13 13:28:52","codes":[{"authorDate":"2020-03-13 13:28:52","commitOrder":9,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","date":"2020-03-13 13:28:52","endLine":612,"groupId":"14408","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/41/0eec37570edf80f1394a8b230857fd68f4a836.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":591,"status":"M"},{"authorDate":"2020-03-13 13:28:52","commitOrder":9,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2020-03-13 13:28:52","endLine":637,"groupId":"14408","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/41/0eec37570edf80f1394a8b230857fd68f4a836.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":615,"status":"M"}],"commitId":"2d2311d75c081745c7a24f7da7c8ec14feddd259","commitMessage":"@@@KAFKA-9657: Throw upon offset fetch unsupported stable flag protocol  (#8265)\n\nThis PR tries to add an internal flag to throw if we hit an unexpected protocol version for offset fetch. It could be used together with EOS_BETA flag so that if server side downgrades unexpectedly.  we shall fail the application ASAP.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-03-13 13:28:52","modifiedFileCount":"10","status":"M","submitter":"Boyang Chen"},{"authorTime":"2020-03-13 13:28:52","codes":[{"authorDate":"2021-01-10 20:20:13","commitOrder":10,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        assertThrows(NoOffsetForPartitionException.class, () -> consumer.poll(Duration.ZERO));\n    }\n","date":"2021-01-10 20:20:13","endLine":666,"groupId":"14408","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a6/d06fa6d349e132f9c22ae247ad0507e1b758f1.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":645,"status":"M"},{"authorDate":"2020-03-13 13:28:52","commitOrder":10,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2020-03-13 13:28:52","endLine":637,"groupId":"14408","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/41/0eec37570edf80f1394a8b230857fd68f4a836.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":615,"status":"N"}],"commitId":"913a019d6c9b03eb44706deb7fb164f79c1f601f","commitMessage":"@@@MINOR: replace test \"expected\" parameter by assertThrows (#9520)\n\nThis PR includes following changes.\n\n1. @Test(expected = Exception.class) is replaced by assertThrows\n2. remove reference to org.scalatest.Assertions\n3. change the magic code from 1 to 2 for testAppendAtInvalidOffset to test ZSTD\n4. rename testMaybeAddPartitionToTransactionXXXX to testNotReadyForSendXXX\n5. increase maxBlockMs from 1s to 3s to avoid unexpected timeout from TransactionsTest#testTimeout\n\nReviewers: Ismael Juma <ismael@confluent.io>","date":"2021-01-10 20:20:13","modifiedFileCount":"166","status":"M","submitter":"Chia-Ping Tsai"},{"authorTime":"2021-07-02 05:05:03","codes":[{"authorDate":"2021-07-02 05:05:03","commitOrder":11,"curCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, groupId, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        assertThrows(NoOffsetForPartitionException.class, () -> consumer.poll(Duration.ZERO));\n    }\n","date":"2021-07-02 05:05:03","endLine":740,"groupId":"103891","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testMissingOffsetNoResetPolicy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ab/8a9503b39de9c4b863c95cf7f92946c5bf9e24.src","preCode":"    public void testMissingOffsetNoResetPolicy() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        \r\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);\n        assertThrows(NoOffsetForPartitionException.class, () -> consumer.poll(Duration.ZERO));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":719,"status":"M"},{"authorDate":"2021-07-02 05:05:03","commitOrder":11,"curCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, groupId, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","date":"2021-07-02 05:05:03","endLine":765,"groupId":"103891","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetToCommittedOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ab/8a9503b39de9c4b863c95cf7f92946c5bf9e24.src","preCode":"    public void testResetToCommittedOffset() {\n        Time time = new MockTime();\n        SubscriptionState subscription = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        ConsumerMetadata metadata = createMetadata(subscription);\n        MockClient client = new MockClient(time, metadata);\n\n        initMetadata(client, Collections.singletonMap(topic, 1));\n        Node node = metadata.fetch().nodes().get(0);\n\n        ConsumerPartitionAssignor assignor = new RoundRobinAssignor();\n\n        KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor,\n                true, groupId, groupInstanceId, false);\n        consumer.assign(singletonList(tp0));\n\n        client.prepareResponseFrom(FindCoordinatorResponse.prepareResponse(Errors.NONE, node), node);\n        Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());\n\n        client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);\n        consumer.poll(Duration.ZERO);\n\n        assertEquals(539L, consumer.position(tp0));\n    }\n","realPath":"clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":743,"status":"M"}],"commitId":"f5d5f654db359af077088685e29fbe5ea69616cf","commitMessage":"@@@KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)\n\nThis implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+time\n\nIt updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version.  clients can revert to the previous behaviour and use a request for each coordinator.\n\nReviewers: David Jacot <djacot@confluent.io>.  Tom Bentley <tbentley@redhat.com>.  Sanjana Kaundinya <skaundinya@gmail.com>","date":"2021-07-02 05:05:03","modifiedFileCount":"33","status":"M","submitter":"Mickael Maison"}]
