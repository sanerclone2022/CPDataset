[{"authorTime":"2020-02-05 13:06:39","codes":[{"authorDate":"2020-02-05 13:06:39","commitOrder":10,"curCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","date":"2020-02-05 13:06:39","endLine":1444,"groupId":"9532","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createFaultyStatefulTask","params":"(finalStreamsConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/2b75df9bcf88fa0bbfd86a18affe4ad2137dc7.src","preCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1425,"status":"B"},{"authorDate":"2020-02-05 13:06:39","commitOrder":10,"curCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","date":"2020-02-05 13:06:39","endLine":1467,"groupId":"12467","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createStatefulTask","params":"(finalStreamsConfigconfig@finalbooleanlogged)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/2b75df9bcf88fa0bbfd86a18affe4ad2137dc7.src","preCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1446,"status":"MB"}],"commitId":"4090f9a2b0a95e4da127e4786007542276d97520","commitMessage":"@@@KAFKA-9113: Clean up task management and state management (#7997)\n\nThis PR is collaborated by Guozhang Wang and John Roesler. It is a significant tech debt cleanup on task management and state management.  and is broken down by several sub-tasks listed below:\n\nExtract embedded clients (producer and consumer) into RecordCollector from StreamTask.\nguozhangwang#2\nguozhangwang#5\n\nConsolidate the standby updating and active restoring logic into ChangelogReader and extract out of StreamThread.\nguozhangwang#3\nguozhangwang#4\n\nIntroduce Task state life cycle (created.  restoring.  running.  suspended.  closing).  and refactor the task operations based on the current state.\nguozhangwang#6\nguozhangwang#7\n\nConsolidate AssignedTasks into TaskManager and simplify the logic of changelog management and task management (since they are already moved in step 2) and 3)).\nguozhangwang#8\nguozhangwang#9\n\nAlso simplified the StreamThread logic a bit as the embedded clients / changelog restoration logic has been moved into step 1) and 2).\nguozhangwang#10\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  Bruno Cadonna <bruno@confluent.io>.  Boyang Chen <boyang@confluent.io>","date":"2020-02-05 13:06:39","modifiedFileCount":"76","status":"M","submitter":"Guozhang Wang"},{"authorTime":"2020-03-04 13:45:11","codes":[{"authorDate":"2020-02-05 13:06:39","commitOrder":11,"curCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","date":"2020-02-05 13:06:39","endLine":1444,"groupId":"9532","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"createFaultyStatefulTask","params":"(finalStreamsConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/2b75df9bcf88fa0bbfd86a18affe4ad2137dc7.src","preCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1425,"status":"N"},{"authorDate":"2020-03-04 13:45:11","commitOrder":11,"curCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged, final ProcessorStateManager stateManager) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","date":"2020-03-04 13:45:11","endLine":1640,"groupId":"12467","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createStatefulTask","params":"(finalStreamsConfigconfig@finalbooleanlogged@finalProcessorStateManagerstateManager)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/58/5952cd800bdd6565fa8d7ee277451f89ef95fe.src","preCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1619,"status":"M"}],"commitId":"c2ec974e81f1c65aa2f2e43f7f4dc820b1957bca","commitMessage":"@@@KAFKA-9618: Directory deletion failure leading to error task RocksDB open (#8186)\n\nWe should have the following order:\n\n1) close state stores\n2) wipe out local directory\n3) release directory lock\n\nto avoid the issue. There's an known problem that with some FS one cannot delete the lock file while the calling thread still grabs the file lock.  and this would be fixed in another ticket.\n\nReviewers: A. Sophie Blee-Goldman <sophie@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>\n","date":"2020-03-04 13:45:11","modifiedFileCount":"5","status":"M","submitter":"Boyang Chen"},{"authorTime":"2020-05-30 01:48:03","codes":[{"authorDate":"2020-05-30 01:48:03","commitOrder":12,"curCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context);\n    }\n","date":"2020-05-30 01:48:03","endLine":1908,"groupId":"5302","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"createFaultyStatefulTask","params":"(finalStreamsConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/13/d039b40823cc5b2b545fbe5a18c901e7d1b6ff.src","preCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1880,"status":"M"},{"authorDate":"2020-05-30 01:48:03","commitOrder":12,"curCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged, final ProcessorStateManager stateManager) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context);\n    }\n","date":"2020-05-30 01:48:03","endLine":1944,"groupId":"12467","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"createStatefulTask","params":"(finalStreamsConfigconfig@finalbooleanlogged@finalProcessorStateManagerstateManager)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/13/d039b40823cc5b2b545fbe5a18c901e7d1b6ff.src","preCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged, final ProcessorStateManager stateManager) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            null,\n            time,\n            stateManager,\n            recordCollector);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":1914,"status":"M"}],"commitId":"9d52deca247d9e16cf530d655891b2bbe474ffae","commitMessage":"@@@KAFKA-9501: convert between active and standby without closing stores (#8248)\n\nThis PR has gone through several significant transitions of its own.  but here's the latest:\n\n* TaskManager just collects the tasks to transition and refers to the active/standby task creator to handle closing & recycling the old task and creating the new one. If we ever hit an exception during the close.  we bail and close all the remaining tasks as dirty.\n\n* The task creators tell the task to \"close but recycle state\". If this is successful.  it tells the recycled processor context and state manager that they should transition to the new type.\n\n* During \"close and recycle\" the task just does a normal clean close.  but instead of closing the state manager it informs it to recycle itself: maintain all of its store information (most importantly the current store offsets) but unregister the changelogs from the changelog reader\n\n* The new task will (re-)register its changelogs during initialization.  but skip re-registering any stores. It will still read the checkpoint file.  but only use the written offsets if the store offsets are not already initialized from pre-transition\n\n* To ensure we don't end up with manual compaction disabled for standbys.  we have to call the state restore listener's onRestoreEnd for any active restoring stores that are switching to standbys\n\nReviewers: John Roesler <vvcephei@apache.org>.  Guozhang Wang <wangguoz@gmail.com>","date":"2020-05-30 01:48:03","modifiedFileCount":"41","status":"M","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-01-28 11:57:20","codes":[{"authorDate":"2021-01-28 11:57:20","commitOrder":13,"curCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context, logContext);\n    }\n","date":"2021-01-28 11:57:20","endLine":2211,"groupId":"102087","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"createFaultyStatefulTask","params":"(finalStreamsConfigconfig)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/07/d0bdc3e8b56c31b405cebd384297e58af121c3.src","preCode":"    private StreamTask createFaultyStatefulTask(final StreamsConfig config) {\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source3),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source3)),\n            singletonList(stateStore),\n            Collections.emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2183,"status":"M"},{"authorDate":"2021-01-28 11:57:20","commitOrder":13,"curCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged, final ProcessorStateManager stateManager) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context, logContext);\n    }\n","date":"2021-01-28 11:57:20","endLine":2247,"groupId":"102087","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"createStatefulTask","params":"(finalStreamsConfigconfig@finalbooleanlogged@finalProcessorStateManagerstateManager)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/07/d0bdc3e8b56c31b405cebd384297e58af121c3.src","preCode":"    private StreamTask createStatefulTask(final StreamsConfig config, final boolean logged, final ProcessorStateManager stateManager) {\n        final MockKeyValueStore stateStore = new MockKeyValueStore(storeName, logged);\n\n        final ProcessorTopology topology = ProcessorTopologyFactories.with(\n            asList(source1, source2),\n            mkMap(mkEntry(topic1, source1), mkEntry(topic2, source2)),\n            singletonList(stateStore),\n            logged ? Collections.singletonMap(storeName, storeName + \"-changelog\") : Collections.emptyMap());\n\n        final InternalProcessorContext context = new ProcessorContextImpl(\n            taskId,\n            config,\n            stateManager,\n            streamsMetrics,\n            null\n        );\n\n        return new StreamTask(\n            taskId,\n            partitions,\n            topology,\n            consumer,\n            config,\n            streamsMetrics,\n            stateDirectory,\n            cache,\n            time,\n            stateManager,\n            recordCollector,\n            context);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":2217,"status":"M"}],"commitId":"4d28391480fd8c547a63af119bba67fceb5d2ede","commitMessage":"@@@KAFKA-10867: Improved task idling (#9840)\n\nUse the new ConsumerRecords.metadata() API to implement\nimproved task idling as described in KIP-695\n\nReviewers: Guozhang Wang <guozhang@apache.org>","date":"2021-01-28 11:57:20","modifiedFileCount":"18","status":"M","submitter":"John Roesler"}]
