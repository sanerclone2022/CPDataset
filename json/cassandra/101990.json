[{"authorTime":"2014-11-04 00:02:10","codes":[{"authorDate":"2014-11-04 00:02:10","commitOrder":1,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2014-11-04 00:02:10","endLine":253,"groupId":"24992","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/58/803c3c22484df19c8075efd228f5c23e2d148e.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":218,"status":"B"},{"authorDate":"2014-11-04 00:02:10","commitOrder":1,"curCode":"    public void testNumberOfFiles_truncate() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","date":"2014-11-04 00:02:10","endLine":417,"groupId":"29140","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/58/803c3c22484df19c8075efd228f5c23e2d148e.src","preCode":"    public void testNumberOfFiles_truncate() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":384,"status":"B"}],"commitId":"0f59629ce280ba2a74d65a7719dde7cf79923f05","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n\nConflicts:\n\tsrc/java/org/apache/cassandra/db/compaction/CompactionManager.java\n\tsrc/java/org/apache/cassandra/db/compaction/Upgrader.java\n\tsrc/java/org/apache/cassandra/io/sstable/SSTableRewriter.java\n\ttest/unit/org/apache/cassandra/db/compaction/AntiCompactionTest.java\n","date":"2014-11-04 00:02:10","modifiedFileCount":"11","status":"B","submitter":"Marcus Eriksson"},{"authorTime":"2014-11-14 02:01:19","codes":[{"authorDate":"2014-11-14 02:01:19","commitOrder":2,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ICompactionScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2014-11-14 02:01:19","endLine":259,"groupId":"31647","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/8d/31b0416be7caf80125cd17ad1caba37430f4d9.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":222,"status":"M"},{"authorDate":"2014-11-14 02:01:19","commitOrder":2,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ICompactionScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","date":"2014-11-14 02:01:19","endLine":431,"groupId":"29140","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/8d/31b0416be7caf80125cd17ad1caba37430f4d9.src","preCode":"    public void testNumberOfFiles_truncate() throws InterruptedException\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        ICompactionScanner scanner = s.getScanner();\n        CompactionController controller = new CompactionController(cfs, compacting, 0);\n        int files = 1;\n        while(scanner.hasNext())\n        {\n            rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n            if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n            {\n                rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                files++;\n                assertEquals(cfs.getSSTables().size(), files); \r\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"M"}],"commitId":"9c66482e16b2fe45605dae8132fec8aff5eda470","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n","date":"2014-11-14 02:01:19","modifiedFileCount":"2","status":"M","submitter":"Joshua McKenzie"},{"authorTime":"2014-12-17 05:03:05","codes":[{"authorDate":"2014-12-17 05:03:05","commitOrder":3,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2014-12-17 05:03:05","endLine":267,"groupId":"31647","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/24/a0091f3f26f985304cb122482636a93fd1c013.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ICompactionScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"},{"authorDate":"2014-12-17 05:03:05","commitOrder":3,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","date":"2014-12-17 05:03:05","endLine":439,"groupId":"29140","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/24/a0091f3f26f985304cb122482636a93fd1c013.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ICompactionScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":404,"status":"M"}],"commitId":"bee53d72a530aab2949d12bd9d2320b76811c85a","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n\nConflicts:\n\tsrc/java/org/apache/cassandra/db/compaction/AbstractCompactionStrategy.java\n\tsrc/java/org/apache/cassandra/db/compaction/CompactionIterable.java\n\tsrc/java/org/apache/cassandra/db/compaction/CompactionManager.java\n\tsrc/java/org/apache/cassandra/db/compaction/LeveledCompactionStrategy.java\n\tsrc/java/org/apache/cassandra/db/compaction/WrappingCompactionStrategy.java\n\tsrc/java/org/apache/cassandra/io/sstable/format/SSTableReader.java\n\tsrc/java/org/apache/cassandra/io/sstable/format/big/BigTableScanner.java\n\tsrc/java/org/apache/cassandra/tools/SSTableExport.java\n\ttest/unit/org/apache/cassandra/db/compaction/AntiCompactionTest.java\n\ttest/unit/org/apache/cassandra/db/compaction/CompactionsTest.java\n\ttest/unit/org/apache/cassandra/db/compaction/LeveledCompactionStrategyTest.java\n\ttest/unit/org/apache/cassandra/db/compaction/TTLExpiryTest.java\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableScannerTest.java\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableUtils.java\n","date":"2014-12-17 05:03:05","modifiedFileCount":"18","status":"M","submitter":"Joshua McKenzie"},{"authorTime":"2015-01-15 01:08:51","codes":[{"authorDate":"2014-12-17 05:03:05","commitOrder":4,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2014-12-17 05:03:05","endLine":267,"groupId":"31647","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/24/a0091f3f26f985304cb122482636a93fd1c013.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"N"},{"authorDate":"2015-01-15 01:08:51","commitOrder":4,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        Thread.sleep(1000); \r\n        validateCFS(cfs);\n    }\n","date":"2015-01-15 01:08:51","endLine":498,"groupId":"29140","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/af/ad97953fcfe729e6a905c00802615f0b8a5439.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"M"}],"commitId":"30a5597ca2eb5b13330cb5843a9ee036beac63de","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n","date":"2015-01-15 01:08:51","modifiedFileCount":"1","status":"M","submitter":"Marcus Eriksson"},{"authorTime":"2015-01-15 01:08:51","codes":[{"authorDate":"2015-02-11 23:31:01","commitOrder":5,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-02-11 23:31:01","endLine":327,"groupId":"31647","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/8e/3efd78144d2967605cdb5037160a32c3722577.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files + 1, cfs.getSSTables().size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":288,"status":"M"},{"authorDate":"2015-01-15 01:08:51","commitOrder":5,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        Thread.sleep(1000); \r\n        validateCFS(cfs);\n    }\n","date":"2015-01-15 01:08:51","endLine":498,"groupId":"29140","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/af/ad97953fcfe729e6a905c00802615f0b8a5439.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        Thread.sleep(1000); \r\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"N"}],"commitId":"96866ce53fb2750217305e881b284851958f4728","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n\nConflicts:\n\tsrc/java/org/apache/cassandra/io/sstable/format/SSTableReader.java\n","date":"2015-02-11 23:31:01","modifiedFileCount":"4","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-03-05 00:31:59","codes":[{"authorDate":"2015-03-05 00:31:59","commitOrder":6,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            List<SSTableReader> sstables = rewriter.finish();\n            assertEquals(files, sstables.size());\n            assertEquals(files, cfs.getSSTables().size());\n            assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n            assertEquals(files, cfs.getSSTables().size());\n            assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n            Thread.sleep(1000);\n            assertFileCounts(s.descriptor.directory.list(), 0, 0);\n            validateCFS(cfs);\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n    }\n","date":"2015-03-05 00:31:59","endLine":341,"groupId":"31647","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/77/c6df97a224829b9d81c075de445f1e92d4cb7f.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":296,"status":"M"},{"authorDate":"2015-03-05 00:31:59","commitOrder":6,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            List<SSTableReader> sstables = rewriter.finish();\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n            Thread.sleep(1000);\n            assertFileCounts(s.descriptor.directory.list(), 0, 0);\n            cfs.truncateBlocking();\n            Thread.sleep(1000); \r\n            validateCFS(cfs);\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n    }\n","date":"2015-03-05 00:31:59","endLine":552,"groupId":"29140","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/77/c6df97a224829b9d81c075de445f1e92d4cb7f.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        Thread.sleep(1000);\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        Thread.sleep(1000); \r\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":510,"status":"M"}],"commitId":"36bd31d0578fedbcc1bfa2ca9b0dbccc4d9284d6","commitMessage":"@@@Merge branch 'cassandra-2.1' into trunk\n\nConflicts:\n\tsrc/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java\n","date":"2015-03-05 00:31:59","modifiedFileCount":"4","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-04-10 04:05:45","codes":[{"authorDate":"2015-04-10 04:05:45","commitOrder":7,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-04-10 04:05:45","endLine":351,"groupId":"29140","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/17/f33926d1d38ee8ff51d4d8571b61331a702ed4.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            List<SSTableReader> sstables = rewriter.finish();\n            assertEquals(files, sstables.size());\n            assertEquals(files, cfs.getSSTables().size());\n            assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n            assertEquals(files, cfs.getSSTables().size());\n            assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n            Thread.sleep(1000);\n            assertFileCounts(s.descriptor.directory.list(), 0, 0);\n            validateCFS(cfs);\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":305,"status":"M"},{"authorDate":"2015-04-10 04:05:45","commitOrder":7,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","date":"2015-04-10 04:05:45","endLine":564,"groupId":"29140","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/17/f33926d1d38ee8ff51d4d8571b61331a702ed4.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            List<SSTableReader> sstables = rewriter.finish();\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n            Thread.sleep(1000);\n            assertFileCounts(s.descriptor.directory.list(), 0, 0);\n            cfs.truncateBlocking();\n            Thread.sleep(1000); \r\n            validateCFS(cfs);\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":522,"status":"M"}],"commitId":"d908bf431af7abe68aa69e6fd0ab50e30f01e607","commitMessage":"@@@Fix SSTableRewriter test on Windows\n\nPatch by stefania; reviewed by jmckenzie for CASSANDRA-8962\n","date":"2015-04-10 04:05:45","modifiedFileCount":"2","status":"M","submitter":"Stefania Alborghetti"},{"authorTime":"2015-05-17 20:50:44","codes":[{"authorDate":"2015-05-17 20:50:44","commitOrder":8,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n             ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-05-17 20:50:44","endLine":346,"groupId":"22830","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/d3/9da611e93a6284cc24af66de42d9b4b1a2c539.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n\n        List<SSTableReader> sstables = rewriter.finish();\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"M"},{"authorDate":"2015-05-17 20:50:44","commitOrder":8,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n             ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","date":"2015-05-17 20:50:44","endLine":546,"groupId":"22837","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/d3/9da611e93a6284cc24af66de42d9b4b1a2c539.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n        SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n        rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n        }\n        catch (Throwable t)\n        {\n            rewriter.abort();\n            throw t;\n        }\n\n        List<SSTableReader> sstables = rewriter.finish();\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":507,"status":"M"}],"commitId":"75a34879bb4aa01a6a65858c303f2a058af512a4","commitMessage":"@@@Merge branch 'cassandra-2.2' into trunk\n\nConflicts:\n\tCHANGES.txt\n","date":"2015-05-17 20:50:44","modifiedFileCount":"52","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-05-22 16:44:46","codes":[{"authorDate":"2015-05-22 16:44:46","commitOrder":9,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false);)\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-05-22 16:44:46","endLine":346,"groupId":"13409","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/fa/91d00527f3607435c9967b40b65baf4b544403.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n             ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(1, cfs.getDataTracker().getView().shadowed.size());\n        cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        assertEquals(files, cfs.getSSTables().size());\n        assertEquals(0, cfs.getDataTracker().getView().shadowed.size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":307,"status":"M"},{"authorDate":"2015-05-22 16:44:46","commitOrder":9,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false);)\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","date":"2015-05-22 16:44:46","endLine":547,"groupId":"13409","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/fa/91d00527f3607435c9967b40b65baf4b544403.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        cfs.truncateBlocking();\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (SSTableRewriter rewriter = new SSTableRewriter(cfs, compacting, 1000, false);\n             ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n            cfs.getDataTracker().markCompactedSSTablesReplaced(compacting, sstables, OperationType.COMPACTION);\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":508,"status":"M"}],"commitId":"d96a02a12e20bc2e0b096904ebe7a1d68532d2f3","commitMessage":"@@@Merge branch 'cassandra-2.2' into trunk\n","date":"2015-05-22 16:44:46","modifiedFileCount":"48","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-05-29 15:58:49","codes":[{"authorDate":"2015-05-29 15:58:49","commitOrder":10,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-05-29 15:58:49","endLine":346,"groupId":"5132","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/9e/1cb91d579923f2a39acc23d7e542e27af8aca4.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false);)\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":308,"status":"M"},{"authorDate":"2015-05-29 15:58:49","commitOrder":10,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","date":"2015-05-29 15:58:49","endLine":544,"groupId":"5132","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/9e/1cb91d579923f2a39acc23d7e542e27af8aca4.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n        SSTableRewriter.overrideOpenInterval(10000000);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false);)\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":506,"status":"M"}],"commitId":"601944569cbe8f8aed5f1e3448828586ba3bc936","commitMessage":"@@@Merge branch 'cassandra-2.2' into trunk\n","date":"2015-05-29 15:58:49","modifiedFileCount":"4","status":"M","submitter":"Marcus Eriksson"},{"authorTime":"2014-09-02 00:54:46","codes":[{"authorDate":"2014-09-02 00:54:46","commitOrder":11,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-06-30 18:47:01","endLine":387,"groupId":"13197","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/9e/4c93910c03a2c8d186a765ff8a9c72c3705cc3.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":347,"status":"M"},{"authorDate":"2014-09-02 00:54:46","commitOrder":11,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","date":"2015-06-30 18:47:01","endLine":596,"groupId":"13197","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/9e/4c93910c03a2c8d186a765ff8a9c72c3705cc3.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(scanner.hasNext())\n            {\n                rewriter.append(new LazilyCompactedRow(controller, Arrays.asList(scanner.next())));\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":557,"status":"M"}],"commitId":"a991b64811f4d6adb6c7b31c0df52288eb06cf19","commitMessage":"@@@Storage engine refactor.  a.k.a CASSANDRA-8099\n\nInitial patch.  see ticket for details\n","date":"2015-06-30 18:47:01","modifiedFileCount":"374","status":"M","submitter":"Sylvain Lebresne"},{"authorTime":"2015-07-06 19:14:50","codes":[{"authorDate":"2014-09-02 00:54:46","commitOrder":12,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-06-30 18:47:01","endLine":387,"groupId":"13197","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/9e/4c93910c03a2c8d186a765ff8a9c72c3705cc3.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":347,"status":"N"},{"authorDate":"2015-07-06 19:14:50","commitOrder":12,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","date":"2015-07-06 19:14:50","endLine":604,"groupId":"13197","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/84/568c32a4fa0d3d8b4ff28f81d552154ce84388.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        cfs.truncateBlocking();\n        SSTableDeletingTask.waitForDeletions();\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":567,"status":"M"}],"commitId":"2d7fec94f13dd8a7d2b14179fc89202413bdcbf7","commitMessage":"@@@Merge branch 'cassandra-2.2' into trunk\n\nConflicts:\n\ttest/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java\n","date":"2015-07-06 19:14:50","modifiedFileCount":"6","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-04-27 14:38:53","codes":[{"authorDate":"2015-04-27 14:38:53","commitOrder":13,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        TransactionLogs.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-07-24 21:41:51","endLine":387,"groupId":"25776","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/0e/533c27e3a8602e74cbd3971eba0ec2dda0ca4b.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        SSTableDeletingTask.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":347,"status":"M"},{"authorDate":"2015-04-27 14:38:53","commitOrder":13,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLogs.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-07-24 21:41:51","endLine":613,"groupId":"25776","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/0e/533c27e3a8602e74cbd3971eba0ec2dda0ca4b.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        SSTableDeletingTask.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list(), 0, 0);\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":576,"status":"M"}],"commitId":"b09e60f72bb2f37235d9e9190c25db36371b3c18","commitMessage":"@@@Introduce safer durable sstable membership management\n(and simplify cleanup of compaction leftovers)\n\nInstead of using temporary files and system tables. \nthis patch introduces a simple transaction log for sstable\nmembership edits that can be committed/aborted atomically\nand simply replayed on startup.\n\npatch by stefania; reviewed by benedict for CASSANDRA-7066\n","date":"2015-07-24 21:41:51","modifiedFileCount":"75","status":"M","submitter":"Stefania Alborghetti"},{"authorTime":"2015-06-28 21:49:09","codes":[{"authorDate":"2015-06-28 21:49:09","commitOrder":14,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        TransactionLogs.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-07-28 17:28:31","endLine":389,"groupId":"25776","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/cb/07d371630737e3fcf4c107b1e03696316428c5.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getSSTables().size());\n        TransactionLogs.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":349,"status":"M"},{"authorDate":"2015-06-28 21:49:09","commitOrder":14,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLogs.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-07-28 17:28:31","endLine":615,"groupId":"25776","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/cb/07d371630737e3fcf4c107b1e03696316428c5.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLogs.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":578,"status":"M"}],"commitId":"ad8cad7c4d05fd5dea68fb274c81a102533ebe36","commitMessage":"@@@Make choice of SSTableReader types explicit\n\nAll accessors of a collection of SSTableReader must now\nspecify whether they desire the LIVE or CANONICAL set.  so\nthat no internal clients are accidentally exposed to a partial\nsstable they are not capable of safely handling.\n\npatch by benedict; reviewed by marcus for CASSANDRA-9699\n","date":"2015-07-28 17:28:31","modifiedFileCount":"60","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-08-17 17:20:15","codes":[{"authorDate":"2015-08-17 17:20:15","commitOrder":15,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        TransactionLog.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-08-17 17:20:15","endLine":389,"groupId":"25776","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/d9/516cb1f5c26f7cf4e9f37240eb4cc347f5d060.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        TransactionLogs.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":349,"status":"M"},{"authorDate":"2015-08-17 17:20:15","commitOrder":15,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLog.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-08-17 17:20:15","endLine":615,"groupId":"25776","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/d9/516cb1f5c26f7cf4e9f37240eb4cc347f5d060.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLogs.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":578,"status":"M"}],"commitId":"13ec86ce9e4fe6616bff85aa4730686212a347c1","commitMessage":"@@@Merge branch 'cassandra-3.0' into trunk\n","date":"2015-08-17 17:20:15","modifiedFileCount":"41","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-09-08 18:53:45","codes":[{"authorDate":"2015-09-08 18:53:45","commitOrder":16,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-09-08 18:53:45","endLine":388,"groupId":"25776","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/94/2c7f95e50ab58a780dbe175044c7cd93923d63.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        TransactionLog.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":348,"status":"M"},{"authorDate":"2015-09-08 18:53:45","commitOrder":16,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-09-08 18:53:45","endLine":614,"groupId":"25776","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/94/2c7f95e50ab58a780dbe175044c7cd93923d63.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        TransactionLog.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"M"}],"commitId":"322e21ec4ec4200d155ea5eb8e7545c446c3c726","commitMessage":"@@@Merge branch 'cassandra-3.0' into trunk\n","date":"2015-09-08 18:53:45","modifiedFileCount":"22","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2015-09-30 17:41:30","codes":[{"authorDate":"2015-09-30 17:41:30","commitOrder":17,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, false, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-10-08 02:04:02","endLine":388,"groupId":"22111","id":33,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/09/3bffd5ec59a3ca2ceae6bf5cb877cda1275117.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":348,"status":"M"},{"authorDate":"2015-09-30 17:41:30","commitOrder":17,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, false, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2015-10-08 02:04:02","endLine":614,"groupId":"22111","id":34,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/09/3bffd5ec59a3ca2ceae6bf5cb877cda1275117.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(cfs, txn, 1000, false, 10000000);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"M"}],"commitId":"127f7c5844f938649de0f3a5dec630b3c5cda256","commitMessage":"@@@Clean resource usage warnings.\n\nPatch by Branimir Lambov; reviewed by tjake for CASSANDRA-10385\n","date":"2015-10-08 02:04:02","modifiedFileCount":"40","status":"M","submitter":"Branimir Lambov"},{"authorTime":"2016-02-10 20:47:00","codes":[{"authorDate":"2016-02-10 20:47:00","commitOrder":18,"curCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2016-02-16 14:22:40","endLine":298,"groupId":"22111","id":35,"instanceNumber":1,"isCurCommit":0,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/7d/bc45e6f9db88ae99f92eba335cb6ef1857887d.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, false, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2016-02-10 20:47:00","commitOrder":18,"curCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2016-02-16 14:22:40","endLine":524,"groupId":"22111","id":36,"instanceNumber":2,"isCurCommit":0,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/7d/bc45e6f9db88ae99f92eba335cb6ef1857887d.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, false, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":487,"status":"M"}],"commitId":"f9a1a80af181e568240bb8a005cd53af8de00648","commitMessage":"@@@Remove duplicate offline compaction tracking\n\nPatch by marcuse; reviewed by Stefania for CASSANDRA-11148\n","date":"2016-02-16 14:22:40","modifiedFileCount":"12","status":"M","submitter":"Marcus Eriksson"},{"authorTime":"2020-12-15 04:42:50","codes":[{"authorDate":"2020-12-15 04:42:50","commitOrder":19,"curCode":"    public void testNumberOfFiles_dont_clean_readers()\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false, true);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2021-01-21 06:22:42","endLine":292,"groupId":"101990","id":37,"instanceNumber":1,"isCurCommit":1,"methodName":"testNumberOfFiles_dont_clean_readers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/18/95653ccd0b34f97ab70c32bc8d83728b4ddc54.src","preCode":"    public void testNumberOfFiles_dont_clean_readers() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n            sstables = rewriter.finish();\n        }\n\n        assertEquals(files, sstables.size());\n        assertEquals(files, cfs.getLiveSSTables().size());\n        LifecycleTransaction.waitForDeletions();\n\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":252,"status":"M"},{"authorDate":"2020-12-15 04:42:50","commitOrder":19,"curCode":"    public void testNumberOfFiles_truncate()\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false, true);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","date":"2021-01-21 06:22:42","endLine":518,"groupId":"101990","id":38,"instanceNumber":2,"isCurCommit":1,"methodName":"testNumberOfFiles_truncate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/18/95653ccd0b34f97ab70c32bc8d83728b4ddc54.src","preCode":"    public void testNumberOfFiles_truncate() throws Exception\n    {\n        Keyspace keyspace = Keyspace.open(KEYSPACE);\n        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);\n        truncate(cfs);\n        cfs.disableAutoCompaction();\n\n        SSTableReader s = writeFile(cfs, 1000);\n        cfs.addSSTable(s);\n        Set<SSTableReader> compacting = Sets.newHashSet(s);\n\n        List<SSTableReader> sstables;\n        int files = 1;\n        try (ISSTableScanner scanner = s.getScanner();\n             CompactionController controller = new CompactionController(cfs, compacting, 0);\n             LifecycleTransaction txn = cfs.getTracker().tryModify(compacting, OperationType.UNKNOWN);\n             SSTableRewriter rewriter = new SSTableRewriter(txn, 1000, 10000000, false);\n             CompactionIterator ci = new CompactionIterator(OperationType.COMPACTION, Collections.singletonList(scanner), controller, FBUtilities.nowInSeconds(), UUIDGen.getTimeUUID()))\n        {\n            rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n            while(ci.hasNext())\n            {\n                rewriter.append(ci.next());\n                if (rewriter.currentWriter().getOnDiskFilePointer() > 25000000)\n                {\n                    rewriter.switchWriter(getWriter(cfs, s.descriptor.directory, txn));\n                    files++;\n                    assertEquals(cfs.getLiveSSTables().size(), files); \r\n                }\n            }\n\n            sstables = rewriter.finish();\n        }\n\n        LifecycleTransaction.waitForDeletions();\n        assertFileCounts(s.descriptor.directory.list());\n        validateCFS(cfs);\n    }\n","realPath":"test/unit/org/apache/cassandra/io/sstable/SSTableRewriterTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":481,"status":"M"}],"commitId":"5e8f7f591dfec5a61d8eb2e9e977ec29f3a2bbe4","commitMessage":"@@@Release StreamingTombstoneHistogramBuilder spool when switching writers\n\n patch by Adam Holmberg; reviewed by Berenguer Blasi.  Mick Semb Wever for CASSANDRA-14834\n","date":"2021-01-21 06:22:42","modifiedFileCount":"10","status":"M","submitter":"Adam Holmberg"}]
