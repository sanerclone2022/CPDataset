[{"authorTime":"2019-08-27 02:21:42","codes":[{"authorDate":"2019-08-27 02:21:42","commitOrder":3,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2019-08-27 02:21:42","endLine":260,"groupId":"65636","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/4e/ba98dd49b9d8dea544775cf1e520575222b1ff.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"MB"},{"authorDate":"2019-08-27 02:21:42","commitOrder":3,"curCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","date":"2019-08-27 02:21:42","endLine":776,"groupId":"65636","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNanosIntervalSecond","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/4e/ba98dd49b9d8dea544775cf1e520575222b1ff.src","preCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":721,"status":"B"}],"commitId":"1a0dddf4ad24b3f2c751a1fe0e024fdbf8754f94","commitMessage":"@@@Range Field support for Histogram and Date Histogram aggregations(#45395)\n\n * Add support for a Range field ValuesSource.  including decode logic for range doc values and exposing RangeType as a first class enum\n * Provide hooks in ValuesSourceConfig for aggregations to control ValuesSource class selection on missing & script values\n * Branch aggregator creation in Histogram and DateHistogram based on ValuesSource class.  to enable specialization based on type.  This is similar to how Terms aggregator works.\n * Prioritize field type when available for selecting the ValuesSource class type to use for an aggregation\n\n","date":"2019-08-27 02:21:42","modifiedFileCount":"44","status":"M","submitter":"Mark Tozzi"},{"authorTime":"2020-05-07 19:22:32","codes":[{"authorDate":"2020-05-07 19:22:32","commitOrder":4,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":270,"groupId":"65636","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"},{"authorDate":"2020-05-07 19:22:32","commitOrder":4,"curCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":786,"groupId":"65636","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNanosIntervalSecond","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":731,"status":"M"}],"commitId":"0097a86d5389d990387005d64a908777dcf61ff6","commitMessage":"@@@Optimize date_histograms across daylight savings time (#55559)\n\nRounding dates on a shard that contains a daylight savings time transition\nis currently something like 1400% slower than when a shard contains dates\nonly on one side of the DST transition. And it makes a ton of short lived\ngarbage. This replaces that implementation with one that benchmarks to\nhaving around 30% overhead instead of the 1400%. And it doesn't generate\nany garbage per search hit.\n\nSome background:\nThere are two ways to round in ES:\n* Round to the nearest time unit (Day/Hour/Week/Month/etc)\n* Round to the nearest time *interval* (3 days/2 weeks/etc)\n\nI'm only optimizing the first one in this change and plan to do the second\nin a follow up. It turns out that rounding to the nearest unit really *is*\ntwo problems: when the unit rounds to midnight (day/week/month/year) and\nwhen it doesn't (hour/minute/second). Rounding to midnight is consistently\nabout 25% faster and rounding to individual hour or minutes.\n\nThis optimization relies on being able to *usually* figure out what the\nminimum and maximum dates are on the shard. This is similar to an existing\noptimization where we rewrite time zones that aren't fixed\n(think America/New_York and its daylight savings time transitions) into\nfixed time zones so long as there isn't a daylight savings time transition\non the shard (UTC-5 or UTC-4 for America/New_York). Once I implement\ntime interval rounding the time zone rewriting optimization *should* no\nlonger be needed.\n\nThis optimization doesn't come into play for `composite` or\n`auto_date_histogram` aggs because neither have been migrated to the new\n`DATE` `ValuesSourceType` which is where that range lookup happens. When\nthey are they will be able to pick up the optimization without much work.\nI expect this to be substantial for `auto_date_histogram` but less so for\n`composite` because it deals with fewer values.\n\nNote: My 30% overhead figure comes from small numbers of daylight savings\ntime transitions. That overhead gets higher when there are more\ntransitions in logarithmic fashion. When there are two thousand years\nworth of transitions my algorithm ends up being 250% slower than rounding\nwithout a time zone.  but java time is 47000% slower at that point. \nallocating memory as fast as it possibly can.\n","date":"2020-05-07 19:22:32","modifiedFileCount":"19","status":"M","submitter":"Nik Everett"},{"authorTime":"2020-05-07 19:22:32","codes":[{"authorDate":"2020-05-20 01:48:25","commitOrder":5,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-20 01:48:25","endLine":353,"groupId":"65636","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/3d/ba9219ab182e44d9bfe6c1f1f0e90a511b07c5.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":333,"status":"M"},{"authorDate":"2020-05-07 19:22:32","commitOrder":5,"curCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":786,"groupId":"65636","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNanosIntervalSecond","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":731,"status":"N"}],"commitId":"bea2341c9e12a2d28e7efa1b0cd35f6ebfedc0db","commitMessage":"@@@Save memory when date_histogram is not on top (#56921)\n\nWhen `date_histogram` is a sub-aggregator it used to allocate a bunch of\nobjects for every one of it's parent's buckets. This uses the data\nstructures that we built in #55873 rework the `date_histogram`\naggregator instead of all of the allocation.\n\nPart of #56487","date":"2020-05-20 01:48:25","modifiedFileCount":"7","status":"M","submitter":"Nik Everett"},{"authorTime":"2020-08-07 05:14:20","codes":[{"authorDate":"2020-08-07 05:14:20","commitOrder":6,"curCode":"    public void testIntervalYear() throws IOException {\n        testSearchCase(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-08-07 05:14:20","endLine":288,"groupId":"105058","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/d2/97d9fabc6139339ee1186ab355b5d85c4dbf7f.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"M"},{"authorDate":"2020-08-07 05:14:20","commitOrder":6,"curCode":"    public void testNanosIntervalSecond() throws IOException {\n        testSearchCase(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testSearchCase(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","date":"2020-08-07 05:14:20","endLine":804,"groupId":"105058","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testNanosIntervalSecond","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/d2/97d9fabc6139339ee1186ab355b5d85c4dbf7f.src","preCode":"    public void testNanosIntervalSecond() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.SECOND).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T00:00:05.015298384Z\",\n                \"2017-02-01T00:00:11.299954583Z\",\n                \"2017-02-01T00:00:11.074986434Z\",\n                \"2017-02-01T00:00:37.688314602Z\",\n                \"2017-02-01T00:00:37.210328172Z\",\n                \"2017-02-01T00:00:37.380889483Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"1000ms\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T00:00:05.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T00:00:11.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T00:00:37.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, true\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":749,"status":"M"}],"commitId":"5e3ea6eb11c68bdcc9adda51715a6e1fea9186d6","commitMessage":"@@@Merge branch 'master' into feature/runtime_fields\n","date":"2020-08-07 05:14:20","modifiedFileCount":"73","status":"M","submitter":"Nik Everett"}]
