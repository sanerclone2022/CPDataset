[{"authorTime":"2018-04-26 03:22:53","codes":[{"authorDate":"2018-04-26 03:22:53","commitOrder":1,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeRequest request = new AnalyzeRequest();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, null, registry, environment, maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","date":"2018-04-26 03:22:53","endLine":176,"groupId":"52870","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/51/5606dd10bfa1b23f01f9f15547609b5093761d.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeRequest request = new AnalyzeRequest();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, null, registry, environment, maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":129,"status":"B"},{"authorDate":"2018-04-26 03:22:53","commitOrder":1,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeRequest request = new AnalyzeRequest(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, indexAnalyzers, registry, environment, maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","date":"2018-04-26 03:22:53","endLine":345,"groupId":"10891","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/51/5606dd10bfa1b23f01f9f15547609b5093761d.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeRequest request = new AnalyzeRequest(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, indexAnalyzers, registry, environment, maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":336,"status":"B"}],"commitId":"d74fb9eb4559077e2d20b19a9ed62d9ff825027a","commitMessage":"@@@Opened x-pack ILM code\n","date":"2018-04-26 03:22:53","modifiedFileCount":"0","status":"B","submitter":"Tal Levy"},{"authorTime":"2019-06-03 16:16:54","codes":[{"authorDate":"2019-06-03 16:16:54","commitOrder":2,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze = TransportAnalyzeAction.analyze(request, \"text\", null, null, registry, environment, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","date":"2019-06-03 16:16:54","endLine":186,"groupId":"52870","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/c4/d7834f5a888b6357c8dde9adf6ccc6b6d85645.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeRequest request = new AnalyzeRequest();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, null, registry, environment, maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeRequest();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":136,"status":"M"},{"authorDate":"2019-06-03 16:16:54","commitOrder":2,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze = TransportAnalyzeAction.analyze(request, \"text\", null, indexAnalyzers, registry, environment,\n            maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","date":"2019-06-03 16:16:54","endLine":358,"groupId":"52873","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/c4/d7834f5a888b6357c8dde9adf6ccc6b6d85645.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeRequest request = new AnalyzeRequest(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeResponse analyze = TransportAnalyzeAction.analyze(request, \"text\", null, indexAnalyzers, registry, environment,\n            maxTokenCount);\n        List<AnalyzeResponse.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":348,"status":"M"}],"commitId":"17581f2f6f52369b93d15fa534ce9c1fa6d0846a","commitMessage":"@@@Create client-only AnalyzeRequest/AnalyzeResponse classes (#42197)\n\nThis commit clones the existing AnalyzeRequest/AnalyzeResponse classes\nto the high-level rest client.  and adjusts request converters to use these new\nclasses.\n\nThis is a prerequisite to removing the Streamable interface from the internal\nserver version of these classes.","date":"2019-06-03 16:16:54","modifiedFileCount":"21","status":"M","submitter":"Alan Woodward"},{"authorTime":"2019-06-04 21:32:43","codes":[{"authorDate":"2019-06-04 21:32:43","commitOrder":3,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","date":"2019-06-04 21:32:43","endLine":197,"groupId":"52870","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/1b/ef91623e885e2b51b672be22c367af123da6a4.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze = TransportAnalyzeAction.analyze(request, \"text\", null, null, registry, environment, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze = TransportAnalyzeAction.analyze(request, \"text\", null, randomBoolean() ? indexAnalyzers : null, registry, environment,\n            maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":146,"status":"M"},{"authorDate":"2019-06-04 21:32:43","commitOrder":3,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","date":"2019-06-04 21:32:43","endLine":377,"groupId":"52873","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/1b/ef91623e885e2b51b672be22c367af123da6a4.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze = TransportAnalyzeAction.analyze(request, \"text\", null, indexAnalyzers, registry, environment,\n            maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":367,"status":"M"}],"commitId":"92bbcd8c2d36932451bd488875c142a0b4a950af","commitMessage":"@@@Refactor control flow in TransportAnalyzeAction (#42801)\n\nThe control flow in TransportAnalyzeAction is currently spread across two large\nmethods.  and is quite difficult to follow. This commit tidies things up a bit.  to make\nit clearer when we use pre-defined analyzers and when we use custom built ones.","date":"2019-06-04 21:32:43","modifiedFileCount":"4","status":"M","submitter":"Alan Woodward"},{"authorTime":"2019-06-10 17:26:15","codes":[{"authorDate":"2019-06-10 17:26:15","commitOrder":4,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbar\", tokens.get(2).getTerm());\n    }\n","date":"2019-06-10 17:26:15","endLine":228,"groupId":"52870","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/aa/f97d46cd8c3b524191d70e917693f07a6ba9eb.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, randomBoolean() ? mockIndexService() : null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":162,"status":"M"},{"authorDate":"2019-06-10 17:26:15","commitOrder":4,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","date":"2019-06-10 17:26:15","endLine":439,"groupId":"52873","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/aa/f97d46cd8c3b524191d70e917693f07a6ba9eb.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, environment, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":429,"status":"M"}],"commitId":"af5e6cad821aef53d5db9bc2646173c68428a5f1","commitMessage":"@@@Move construction of custom analyzers into AnalysisRegistry (#42940)\n\nBoth TransportAnalyzeAction and CategorizationAnalyzer have logic to build\ncustom analyzers for index-independent analysis. A lot of this code is duplicated. \nand it requires the AnalysisRegistry to expose a number of internal provider\nclasses.  as well as making some assumptions about when analysis components are\nconstructed.\n\nThis commit moves the build logic directly into AnalysisRegistry.  reducing the\nregistry's API surface considerably.","date":"2019-06-10 17:26:15","modifiedFileCount":"14","status":"M","submitter":"Alan Woodward"},{"authorTime":"2019-06-10 17:26:15","codes":[{"authorDate":"2019-06-27 16:01:53","commitOrder":5,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");        \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");     \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\"));    \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbar\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\", \"suffix\", \"baz\"));\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbaz\", tokens.get(2).getTerm());\n    }\n","date":"2019-06-27 16:01:53","endLine":227,"groupId":"52870","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/72/830f79889c0da26d401c96ab983962a053cdc6.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append_foo\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxbar\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(\"append\");\n        request.text(\"the qu1ck brown fox\");\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbar\", tokens.get(2).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"M"},{"authorDate":"2019-06-10 17:26:15","commitOrder":5,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","date":"2019-06-10 17:26:15","endLine":439,"groupId":"52873","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/aa/f97d46cd8c3b524191d70e917693f07a6ba9eb.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":429,"status":"N"}],"commitId":"fbefb4690ef804596d965959d6aa50c16aea7dc3","commitMessage":"@@@Use preconfigured filters correctly in Analyze API (#43568)\n\nWhen a named token filter or char filter is passed as part of an Analyze API\nrequest with no index.  we currently try and build the relevant filter using no\nindex settings. However.  this can miss cases where there is a pre-configured\nfilter defined in the analysis registry. One example here is the elision filter.  which\nhas a pre-configured version built with the french elision set; when used as part\nof normal analysis.  this preconfigured set is used.  but when used as part of the\nAnalyze API we end up with NPEs because it tries to instantiate the filter with\nno index settings.\n\nThis commit changes the Analyze API to check for pre-configured filters in the case\nthat the request has no index defined.  and is using a name rather than a custom\ndefinition for a filter.\n\nIt also changes the pre-configured `word_delimiter_graph` filter and `edge_ngram`\ntokenizer to make their settings consistent with the defaults used when creating\nthem with no settings\n\nCloses #43002\nCloses #43621 \nCloses #43582 ","date":"2019-06-27 16:01:53","modifiedFileCount":"4","status":"M","submitter":"Alan Woodward"},{"authorTime":"2019-11-15 02:50:46","codes":[{"authorDate":"2019-06-27 16:01:53","commitOrder":6,"curCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");        \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");     \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\"));    \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbar\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\", \"suffix\", \"baz\"));\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbaz\", tokens.get(2).getTerm());\n    }\n","date":"2019-06-27 16:01:53","endLine":227,"groupId":"105961","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testNoIndexAnalyzers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/72/830f79889c0da26d401c96ab983962a053cdc6.src","preCode":"    public void testNoIndexAnalyzers() throws IOException {\n        \r\n        AnalyzeAction.Request request = new AnalyzeAction.Request();\n        request.text(\"the quick brown fox\");\n        request.analyzer(\"standard\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addCharFilter(\"append\");        \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(4, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"brown\", tokens.get(2).getTerm());\n        assertEquals(\"foxfoo\", tokens.get(3).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(\"mock\");     \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"qu1ck\", tokens.get(0).getTerm());\n        assertEquals(\"brown\", tokens.get(1).getTerm());\n        assertEquals(\"fox\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\"));    \r\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbar\", tokens.get(2).getTerm());\n\n        \r\n        request = new AnalyzeAction.Request();\n        request.text(\"the qu1ck brown fox\");\n        request.tokenizer(\"standard\");\n        request.addTokenFilter(Map.of(\"type\", \"mock\", \"stopword\", \"brown\"));\n        request.addCharFilter(Map.of(\"type\", \"append\", \"suffix\", \"baz\"));\n        analyze\n            = TransportAnalyzeAction.analyze(request, registry, null, maxTokenCount);\n        tokens = analyze.getTokens();\n        assertEquals(3, tokens.size());\n        assertEquals(\"the\", tokens.get(0).getTerm());\n        assertEquals(\"qu1ck\", tokens.get(1).getTerm());\n        assertEquals(\"foxbaz\", tokens.get(2).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"N"},{"authorDate":"2019-11-15 02:50:46","commitOrder":6,"curCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        \r\n        request.text(\"Wi-fi\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"wi-fi\", tokens.get(0).getTerm());\n    }\n","date":"2019-11-15 02:50:46","endLine":439,"groupId":"105961","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalizerWithIndex","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/23/129ae546fe6abdcdd8806d7686696cb2f6a0fe.src","preCode":"    public void testNormalizerWithIndex() throws IOException {\n        AnalyzeAction.Request request = new AnalyzeAction.Request(\"index\");\n        request.normalizer(\"my_normalizer\");\n        request.text(\"ABc\");\n        AnalyzeAction.Response analyze\n            = TransportAnalyzeAction.analyze(request, registry, mockIndexService(), maxTokenCount);\n        List<AnalyzeAction.AnalyzeToken> tokens = analyze.getTokens();\n\n        assertEquals(1, tokens.size());\n        assertEquals(\"abc\", tokens.get(0).getTerm());\n    }\n","realPath":"server/src/test/java/org/elasticsearch/action/admin/indices/TransportAnalyzeActionTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":428,"status":"M"}],"commitId":"a666fb22664284d8e2114841ebb58ea4e1924691","commitMessage":"@@@Fix `_analyze` API to correctly use normalizers when specified (#48866)\n\nCurrently the `_analyze` endpoint doesn't correctly use normalizers specified\nin the request. This change fixes that by returning the resolved normalizer from\nTransportAnalyzeAction#getAnalyzer and updates test to be able to catch this\nin the future.\n\nCloses #48650","date":"2019-11-15 02:50:46","modifiedFileCount":"2","status":"M","submitter":"bellengao"}]
