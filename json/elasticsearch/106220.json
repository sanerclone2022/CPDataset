[{"authorTime":"2020-10-06 23:29:42","codes":[{"authorDate":"2020-10-06 23:29:42","commitOrder":3,"curCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","date":"2020-10-06 23:29:42","endLine":170,"groupId":"12401","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testHighWatermarkNotExceeded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9e/84a7343e5d8161b3f4c76b1373275d45313903.src","preCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":140,"status":"MB"},{"authorDate":"2020-10-06 23:29:42","commitOrder":3,"curCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","date":"2020-10-06 23:29:42","endLine":235,"groupId":"12403","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreSnapshotAllocationDoesNotExceedWatermark","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9e/84a7343e5d8161b3f4c76b1373275d45313903.src","preCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"B"}],"commitId":"2afec0d916c7de33c9a6c3cbe30a8a2ee61be765","commitMessage":"@@@Determine shard size before allocating shards recovering from snapshots (#61906)\n\nDetermines the shard size of shards before allocating shards that are \nrecovering from snapshots. It ensures during shard allocation that the \ntarget node that is selected as recovery target will have enough free \ndisk space for the recovery event. This applies to regular restores.  \nCCR bootstrap from remote.  as well as mounting searchable snapshots.\n\nThe InternalSnapshotInfoService is responsible for fetching snapshot \nshard sizes from repositories. It provides a getShardSize() method \nto other components of the system that can be used to retrieve the \nlatest known shard size. If the latest snapshot shard size retrieval \nfailed.  the getShardSize() returns \nShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE. While \nwe'd like a better way to handle such failures.  returning this value \nallows to keep the existing behavior for now.\n\nNote that this PR does not address an issues (we already have today) \nwhere a replica is being allocated without knowing how much disk \nspace is being used by the primary. ","date":"2020-10-06 23:29:42","modifiedFileCount":"49","status":"M","submitter":"Yannick Welsch"},{"authorTime":"2020-10-06 23:29:42","codes":[{"authorDate":"2020-10-07 15:25:07","commitOrder":4,"curCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","date":"2020-10-07 15:25:07","endLine":170,"groupId":"12401","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testHighWatermarkNotExceeded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9c/4dfcad2875a0e0a69559232c0d6e9da7b11335.src","preCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"M"},{"authorDate":"2020-10-06 23:29:42","commitOrder":4,"curCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","date":"2020-10-06 23:29:42","endLine":235,"groupId":"12403","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreSnapshotAllocationDoesNotExceedWatermark","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9e/84a7343e5d8161b3f4c76b1373275d45313903.src","preCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"N"}],"commitId":"47eb590fe4fd4b6ef5d793b0c71a1af24fd06ca3","commitMessage":"@@@Fix DiskThresholdDeciderIT.testHighWatermarkNotExceeded (#63112)\n\nThe first refreshDiskUsage() refreshes the ClusterInfo update which in turn \ncalls listeners like DiskThreshMonitor. This one triggers a reroute as \nexpected and turns an internal checkInProgress flag before submitting \na cluster state update to relocate shards (the internal flag is toggled \nagain once the cluster state update is processed).\n\nIn the test I suspect that the second refreshDiskUsage() may complete \nbefore DiskThreshMonitor's internal flag is set back to its initial state.  \nresulting in the second ClusterInfo update to be ignored and message \nlike \"[node_t0] skipping monitor as a check is already in progress\" to \nbe logged. Adding another wait for languid events to be processed \nbefore executing the second refreshDiskUsage() should help here.\n\nCloses #62326","date":"2020-10-07 15:25:07","modifiedFileCount":"1","status":"M","submitter":"Tanguy Leroux"},{"authorTime":"2020-10-14 21:26:52","codes":[{"authorDate":"2020-10-14 21:26:52","commitOrder":5,"curCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, empty());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2020-10-14 21:26:52","endLine":170,"groupId":"12401","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testHighWatermarkNotExceeded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/fb/9de0ce124be1d5a2a7a3ee6ecd8ee5a3b0f697.src","preCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":141,"status":"M"},{"authorDate":"2020-10-14 21:26:52","commitOrder":5,"curCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2020-10-14 21:26:52","endLine":234,"groupId":"12403","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreSnapshotAllocationDoesNotExceedWatermark","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/fb/9de0ce124be1d5a2a7a3ee6ecd8ee5a3b0f697.src","preCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        refreshDiskUsage();\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), hasSize(1)));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"M"}],"commitId":"65c983a745afc0cfe57e30b979122848d09b82e0","commitMessage":"@@@Try to fix DiskThresholdDeciderIT (#63614)\n\nThis is another attempt to fix #62326 as my previous \nattempts failed (#63112.  #63385).","date":"2020-10-14 21:26:52","modifiedFileCount":"2","status":"M","submitter":"Tanguy Leroux"},{"authorTime":"2020-12-04 14:43:43","codes":[{"authorDate":"2020-12-04 14:43:43","commitOrder":6,"curCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, empty());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2020-12-04 14:43:43","endLine":106,"groupId":"16972","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testHighWatermarkNotExceeded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/84/1a094f88c90c2f20dea81e741a540cc1a67cd7.src","preCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, empty());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":78,"status":"M"},{"authorDate":"2020-12-04 14:43:43","commitOrder":6,"curCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2020-12-04 14:43:43","endLine":169,"groupId":"16972","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreSnapshotAllocationDoesNotExceedWatermark","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/84/1a094f88c90c2f20dea81e741a540cc1a67cd7.src","preCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n        final Path dataNode0Path = internalCluster().getInstance(Environment.class, dataNodeName).dataFiles()[0];\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        fileSystemProvider.getTestFileStore(dataNode0Path).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":108,"status":"M"}],"commitId":"7f61898276e778d677f39e26eaffe0d05ba6431d","commitMessage":"@@@Extract DiskUsageIntegTestCase (#65540)\n\nExtracted DiskUsageIntegTestCase from DiskThresholdDeciderIT to allow\nother tests to easily test functionality relying on disk usage.\n\nRelates #65520","date":"2020-12-04 14:43:43","modifiedFileCount":"1","status":"M","submitter":"Henning Andersen"},{"authorTime":"2021-01-06 01:58:30","codes":[{"authorDate":"2021-01-06 01:58:30","commitOrder":7,"curCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(\n                event -> ClusterInfoServiceUtils.refresh(clusterInfoService));\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, empty());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2021-01-06 01:58:30","endLine":108,"groupId":"106220","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testHighWatermarkNotExceeded","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/14/4a95b8ca06f55a515d2538745166110e6945bd.src","preCode":"    public void testHighWatermarkNotExceeded() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        final InternalClusterInfoService clusterInfoService\n                = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n                .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n                .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        \r\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, empty());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":79,"status":"M"},{"authorDate":"2021-01-06 01:58:30","commitOrder":7,"curCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(\n                event -> ClusterInfoServiceUtils.refresh(clusterInfoService));\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","date":"2021-01-06 01:58:30","endLine":172,"groupId":"106220","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testRestoreSnapshotAllocationDoesNotExceedWatermark","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/14/4a95b8ca06f55a515d2538745166110e6945bd.src","preCode":"    public void testRestoreSnapshotAllocationDoesNotExceedWatermark() throws Exception {\n        internalCluster().startMasterOnlyNode();\n        internalCluster().startDataOnlyNode();\n        final String dataNodeName = internalCluster().startDataOnlyNode();\n        ensureStableCluster(3);\n\n        assertAcked(client().admin().cluster().preparePutRepository(\"repo\")\n            .setType(FsRepository.TYPE)\n            .setSettings(Settings.builder()\n                .put(\"location\", randomRepoPath())\n                .put(\"compress\", randomBoolean())));\n\n        final InternalClusterInfoService clusterInfoService\n            = (InternalClusterInfoService) internalCluster().getCurrentMasterNodeInstance(ClusterInfoService.class);\n        internalCluster().getCurrentMasterNodeInstance(ClusterService.class).addListener(event -> clusterInfoService.refresh());\n\n        final String dataNode0Id = internalCluster().getInstance(NodeEnvironment.class, dataNodeName).nodeId();\n\n        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n        createIndex(indexName, Settings.builder()\n            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 6)\n            .put(INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), \"0ms\")\n            .build());\n        final long minShardSize = createReasonableSizedShards(indexName);\n\n        final CreateSnapshotResponse createSnapshotResponse = client().admin().cluster().prepareCreateSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n        assertThat(snapshotInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(snapshotInfo.state(), is(SnapshotState.SUCCESS));\n\n        assertAcked(client().admin().indices().prepareDelete(indexName).get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES - 1L);\n        refreshDiskUsage();\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())\n                .build())\n            .get());\n\n        final RestoreSnapshotResponse restoreSnapshotResponse = client().admin().cluster().prepareRestoreSnapshot(\"repo\", \"snap\")\n            .setWaitForCompletion(true).get();\n        final RestoreInfo restoreInfo = restoreSnapshotResponse.getRestoreInfo();\n        assertThat(restoreInfo.successfulShards(), is(snapshotInfo.totalShards()));\n        assertThat(restoreInfo.failedShards(), is(0));\n\n        assertBusy(() -> assertThat(getShardRoutings(dataNode0Id, indexName), empty()));\n\n        assertAcked(client().admin().cluster().prepareUpdateSettings()\n            .setTransientSettings(Settings.builder()\n                .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())\n                .build())\n            .get());\n\n        \r\n        getTestFileStore(dataNodeName).setTotalSpace(minShardSize + WATERMARK_BYTES + 1L);\n        assertBusyWithDiskUsageRefresh(dataNode0Id, indexName, hasSize(1));\n    }\n","realPath":"server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"}],"commitId":"b3e550c28929489c58e7e1026a2096cb1eb5d102","commitMessage":"@@@Make InternalClusterInfoService async (#66993)\n\nThis commit reworks the InternalClusterInfoService to run\nasynchronously.  using timeouts on the stats requests instead of\nimplementing its own blocking timeouts. It also improves the logging of\nfailures by identifying the nodes that failed or timed out. Finally it\nensures that only a single refresh is running at once.  enqueueing later\nrefresh requests to run immediately after the current refresh is\nfinished rather than racing them against each other.","date":"2021-01-06 01:58:30","modifiedFileCount":"15","status":"M","submitter":"David Turner"}]
