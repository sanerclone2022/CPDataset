[{"authorTime":"2018-05-14 17:10:33","codes":[{"authorDate":"2018-04-26 03:22:53","commitOrder":2,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-04-26 03:22:53","endLine":156,"groupId":"32409","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/a0/1eb52fdd498d0c8c0ecc6f0f5e3e40725fdab3.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"NB"},{"authorDate":"2018-05-14 17:10:33","commitOrder":2,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-14 17:10:33","endLine":196,"groupId":"37521","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/c9/b48f0c8650d415198b229af0107500da6aa9a1.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"B"}],"commitId":"b08d7c872b45a88ee1d093487d9213462b95033f","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-05-14 17:10:33","modifiedFileCount":"43","status":"M","submitter":"Colin Goodheart-Smithe"},{"authorTime":"2018-05-24 01:29:52","codes":[{"authorDate":"2018-04-26 03:22:53","commitOrder":3,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-04-26 03:22:53","endLine":156,"groupId":"32409","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/a0/1eb52fdd498d0c8c0ecc6f0f5e3e40725fdab3.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"N"},{"authorDate":"2018-05-24 01:29:52","commitOrder":3,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-24 01:29:52","endLine":197,"groupId":"50095","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/02/a4197fba94a7bba5ec71166b5710b19e708895.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"M"}],"commitId":"d1479dbaedeb6dd049c7a9b0fe58223cef32d0f1","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-05-24 01:29:52","modifiedFileCount":"119","status":"M","submitter":"Tal Levy"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-04-26 03:22:53","commitOrder":4,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-04-26 03:22:53","endLine":156,"groupId":"32409","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/a0/1eb52fdd498d0c8c0ecc6f0f5e3e40725fdab3.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"N"},{"authorDate":"2018-05-30 03:29:53","commitOrder":4,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"M"}],"commitId":"bdf70e4f2fdbfe73c7fd7eb7a8b8aaf87e3eb80b","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-05-30 03:29:53","modifiedFileCount":"70","status":"M","submitter":"Tal Levy"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-06-19 01:06:47","commitOrder":5,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-06-19 01:06:47","endLine":252,"groupId":"32409","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/cd/d8101a73c706b1213be04d535a6464097d299c.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":5,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"5d52f297cc570a2432b038832133f9ffb56d3bab","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-06-19 01:06:47","modifiedFileCount":"129","status":"M","submitter":"Tal Levy"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-06-20 17:31:45","commitOrder":6,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-06-20 17:31:45","endLine":253,"groupId":"19046","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/ca/2f74b5efee037a31d266f64b2409a3b3be83ba.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":6,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"c5b69c87c6926e04e0a778c413ac4693c19b9d8b","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-06-20 17:31:45","modifiedFileCount":"161","status":"M","submitter":"Colin Goodheart-Smithe"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-07-16 16:30:07","commitOrder":7,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-07-16 16:30:07","endLine":253,"groupId":"19046","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/d9/5af920a307b16862bfaf17922d1745c17c20ac.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requriesAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requriesAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requriesAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requriesAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requriesAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requriesAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requriesAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requriesAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requriesAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requriesAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":7,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"5d3a53843a21098de3d1a342482db555eb660976","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-07-16 16:30:07","modifiedFileCount":"183","status":"M","submitter":"Colin Goodheart-Smithe"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-09-06 03:56:58","commitOrder":8,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-09-06 03:56:58","endLine":286,"groupId":"19046","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/bb/d721169c6c7d779ec5e5f6a0ba449d0def636a.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":223,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":8,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"b5f7fb688251d198525a0dd75852a2e91aee46fb","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-09-06 03:56:58","modifiedFileCount":"114","status":"M","submitter":"Tal Levy"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-09-13 16:46:14","commitOrder":9,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-09-13 16:46:14","endLine":286,"groupId":"19046","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/17/5935258ad6e7687d318eefb6c931eebe997df1.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":221,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":9,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"8e59de3eb2df9915e4878702fbd3edd55d019ffa","commitMessage":"@@@Merge branch 'master' into index-lifecycle\n","date":"2018-09-13 16:46:14","modifiedFileCount":"189","status":"M","submitter":"Colin Goodheart-Smithe"},{"authorTime":"2018-05-30 03:29:53","codes":[{"authorDate":"2018-09-29 05:40:12","commitOrder":10,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-09-29 05:40:12","endLine":287,"groupId":"19046","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/59/ecde8cf37cebf6b2ac12a4eb53167ce528f5eb.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":220,"status":"M"},{"authorDate":"2018-05-30 03:29:53","commitOrder":10,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-05-30 03:29:53","endLine":198,"groupId":"50095","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/69/c8afb3e2fc69ff30f08ea93b5048b359c2054c.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"N"}],"commitId":"6ea396a476ada0c6d5ff0f27a3e5526b42ff1502","commitMessage":"@@@Merge remote-tracking branch 'origin/master' into index-lifecycle\n","date":"2018-09-29 05:40:12","modifiedFileCount":"333","status":"M","submitter":"Lee Hinman"},{"authorTime":"2018-11-06 18:55:23","codes":[{"authorDate":"2018-09-29 05:40:12","commitOrder":11,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2018-09-29 05:40:12","endLine":287,"groupId":"19046","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/59/ecde8cf37cebf6b2ac12a4eb53167ce528f5eb.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":220,"status":"N"},{"authorDate":"2018-11-06 18:55:23","commitOrder":11,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-11-06 18:55:23","endLine":319,"groupId":"50095","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/75/e0087831a62bef76822879b0900016ab31b713.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":298,"status":"M"}],"commitId":"a5e1f4d3a2b6f03f5b6268555ebb4271ea3c153b","commitMessage":"@@@Upgrade to lucene-8.0.0-snapshot-31d7dfe6b1 (#35224)\n\n\n","date":"2018-11-06 18:55:23","modifiedFileCount":"30","status":"M","submitter":"Nick Knize"},{"authorTime":"2018-11-06 18:55:23","codes":[{"authorDate":"2019-05-08 05:40:32","commitOrder":12,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2019-05-08 07:06:08","endLine":285,"groupId":"19046","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/f0/95b766ee1d52a1e1faa8721ddac084e1f3657c.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload_filter\", LegacyDelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":219,"status":"M"},{"authorDate":"2018-11-06 18:55:23","commitOrder":12,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-11-06 18:55:23","endLine":319,"groupId":"50095","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/75/e0087831a62bef76822879b0900016ab31b713.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":298,"status":"N"}],"commitId":"8af01dfa3cff896a4c90490d8aabf0945677395b","commitMessage":"@@@Cleanup versioned deprecations in analysis (#41560)\n\nThis commit removes versioned logic in analyzer creation that is no\nlonger relevant for 8.0.","date":"2019-05-08 07:06:08","modifiedFileCount":"15","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2018-11-06 18:55:23","codes":[{"authorDate":"2019-06-27 15:56:26","commitOrder":13,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2019-06-27 15:56:26","endLine":285,"groupId":"7470","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/ca/53cb8bf3953cbac603119c315d6642cef433b7.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", ElisionTokenFilterFactory::new);\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":219,"status":"M"},{"authorDate":"2018-11-06 18:55:23","commitOrder":13,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-11-06 18:55:23","endLine":319,"groupId":"50095","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/75/e0087831a62bef76822879b0900016ab31b713.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":298,"status":"N"}],"commitId":"d2c696d54b44ab66b850d30b0f68ad8e725dbbcc","commitMessage":"@@@Require [articles] setting in elision filter (#43083)\n\nWe should throw an exception at construction time if a list of\narticles is not provided.  otherwise we can get random NPEs during\nindexing.\n\nRelates to #43002","date":"2019-06-27 15:56:26","modifiedFileCount":"2","status":"M","submitter":"Alan Woodward"},{"authorTime":"2018-11-06 18:55:23","codes":[{"authorDate":"2019-12-21 01:01:05","commitOrder":14,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_deprecation\",\n                                \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"nGram_deprecation\",\n                                \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2019-12-21 01:01:05","endLine":323,"groupId":"19736","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/b9/de97952eb4bcbce44637da7702acb85c09950e.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", NGramTokenFilterFactory::new);\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":223,"status":"M"},{"authorDate":"2018-11-06 18:55:23","commitOrder":14,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2018-11-06 18:55:23","endLine":319,"groupId":"50095","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/75/e0087831a62bef76822879b0900016ab31b713.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":298,"status":"N"}],"commitId":"c6f7166145412a3a1a9c639cc07a2329e879a575","commitMessage":"@@@Throw Error on deprecated nGram and edgeNGram custom filters (#50376)\n\nThe camel-case `nGram` and `edgeNGram` filter names were deprecated in 6. We\ncurrently throw errors on new indices when they are used. However these errors\nare currently only thrown for pre-configured filters.  adding them as custom\nfilters doesn't trigger the warning and error. This change adds the appropriate\nexceptions for `nGram` and `edgeNGram` respectively.\n\nCloses #50360","date":"2019-12-21 01:01:05","modifiedFileCount":"1","status":"M","submitter":"Christoph B?scher"},{"authorTime":"2020-01-15 00:18:47","codes":[{"authorDate":"2019-12-21 01:01:05","commitOrder":15,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_deprecation\",\n                                \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"nGram_deprecation\",\n                                \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2019-12-21 01:01:05","endLine":323,"groupId":"19736","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/b9/de97952eb4bcbce44637da7702acb85c09950e.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_deprecation\",\n                                \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"nGram_deprecation\",\n                                \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":223,"status":"N"},{"authorDate":"2020-01-15 00:18:47","commitOrder":15,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecatedAndMaybeLog(\"nGram_tokenizer_deprecation\",\n                        \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                                + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_tokenizer_deprecation\",\n                        \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                                + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2020-01-15 00:18:47","endLine":376,"groupId":"19739","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/3c/614f84d4e231a024ec5670b57828a88e3d87fc.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":335,"status":"M"}],"commitId":"9a4357ae04687e1b62b5b72eb74ec4350cb301d6","commitMessage":"@@@Deprecate and remove camel-case nGram and edgeNGram tokenizers (#50862)\n\nWe already deprecated and removed the camel-case versions of the nGram and edgeNGram \nfilters a while ago and we should do the same with the nGram and edgeNGram tokenizers.\nThis PR deprecates the use of these names in favour of ngram and edge_ngram in 7\nand disallows usage in new indices starting with 8.\n\nCloses #50561","date":"2020-01-15 00:18:47","modifiedFileCount":"3","status":"M","submitter":"Christoph B?scher"},{"authorTime":"2020-06-01 21:44:01","codes":[{"authorDate":"2020-06-01 21:44:01","commitOrder":16,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(\"edgeNGram_deprecation\",\n                            \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                             + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(\"nGram_deprecation\",\n                            \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                            + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2020-06-01 21:44:01","endLine":328,"groupId":"19736","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/be/c6b9502f2b99c803508900cea6414d82ffd376.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_deprecation\",\n                                \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecatedAndMaybeLog(\"nGram_deprecation\",\n                                \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":228,"status":"M"},{"authorDate":"2020-06-01 21:44:01","commitOrder":16,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(\"nGram_tokenizer_deprecation\",\n                    \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(\"edgeNGram_tokenizer_deprecation\",\n                    \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2020-06-01 21:44:01","endLine":381,"groupId":"19739","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/be/c6b9502f2b99c803508900cea6414d82ffd376.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecatedAndMaybeLog(\"nGram_tokenizer_deprecation\",\n                        \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                                + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecatedAndMaybeLog(\"edgeNGram_tokenizer_deprecation\",\n                        \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                                + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":340,"status":"M"}],"commitId":"4d6dc51c72941f6184f34787b5b1b1398297a38d","commitMessage":"@@@Header warning logging refactoring (#55941)\n\nSplitting DeprecationLogger into two. HeaderWarningLogger - responsible for adding a response warning headers and ThrottlingLogger - responsible for limiting the duplicated log entries for the same key (previously deprecateAndMaybeLog).\nIntroducing A ThrottlingAndHeaderWarningLogger which is a base for other common logging usages where both response warning header and logging throttling was needed.\n\nrelates #55699\nrelates #52369","date":"2020-06-01 21:44:01","modifiedFileCount":"81","status":"M","submitter":"Przemyslaw Gomulka"},{"authorTime":"2021-01-19 00:16:54","codes":[{"authorDate":"2021-01-19 00:16:54","commitOrder":17,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"edgeNGram_deprecation\",\n                            \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                             + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"nGram_deprecation\",\n                            \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                            + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2021-01-19 00:16:54","endLine":328,"groupId":"19736","id":31,"instanceNumber":1,"isCurCommit":0,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/b2/ed5de8f06960bc0dc168ccf6628d39cea40e96.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(\"edgeNGram_deprecation\",\n                            \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                             + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(\"nGram_deprecation\",\n                            \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                            + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":228,"status":"M"},{"authorDate":"2021-01-19 00:16:54","commitOrder":17,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"nGram_tokenizer_deprecation\",\n                    \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"edgeNGram_tokenizer_deprecation\",\n                    \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2021-01-19 00:16:54","endLine":381,"groupId":"19739","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/b2/ed5de8f06960bc0dc168ccf6628d39cea40e96.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(\"nGram_tokenizer_deprecation\",\n                    \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(\"edgeNGram_tokenizer_deprecation\",\n                    \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":340,"status":"M"}],"commitId":"1a05a5ac24222d3e00a7f1679b12e700004af534","commitMessage":"@@@Introduce deprecation categories (#67443)\n\nCloses #64824. Introduce the concept of categories to deprecation\nlogging. Every location where we log a deprecation message must now\ninclude a deprecation category.\n","date":"2021-01-19 00:16:54","modifiedFileCount":"81","status":"M","submitter":"Rory Hunter"},{"authorTime":"2021-09-09 18:23:52","codes":[{"authorDate":"2021-09-09 18:23:52","commitOrder":18,"curCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.critical(DeprecationCategory.ANALYSIS, \"edgeNGram_deprecation\",\n                            \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                             + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.critical(DeprecationCategory.ANALYSIS, \"nGram_deprecation\",\n                            \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                            + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","date":"2021-09-09 18:23:52","endLine":317,"groupId":"10769","id":33,"instanceNumber":1,"isCurCommit":1,"methodName":"getTokenFilters","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/7e/dee0d149a67f8a5debaeaa2e7b78b4d2d13aef.src","preCode":"    public Map<String, AnalysisProvider<TokenFilterFactory>> getTokenFilters() {\n        Map<String, AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>();\n        filters.put(\"apostrophe\", ApostropheFilterFactory::new);\n        filters.put(\"arabic_normalization\", ArabicNormalizationFilterFactory::new);\n        filters.put(\"arabic_stem\", ArabicStemTokenFilterFactory::new);\n        filters.put(\"asciifolding\", ASCIIFoldingTokenFilterFactory::new);\n        filters.put(\"bengali_normalization\", BengaliNormalizationFilterFactory::new);\n        filters.put(\"brazilian_stem\", BrazilianStemTokenFilterFactory::new);\n        filters.put(\"cjk_bigram\", CJKBigramFilterFactory::new);\n        filters.put(\"cjk_width\", CJKWidthFilterFactory::new);\n        filters.put(\"classic\", ClassicFilterFactory::new);\n        filters.put(\"czech_stem\", CzechStemTokenFilterFactory::new);\n        filters.put(\"common_grams\", requiresAnalysisSettings(CommonGramsTokenFilterFactory::new));\n        filters.put(\"condition\",\n            requiresAnalysisSettings((i, e, n, s) -> new ScriptedConditionTokenFilterFactory(i, n, s, scriptService.get())));\n        filters.put(\"decimal_digit\", DecimalDigitFilterFactory::new);\n        filters.put(\"delimited_payload\", DelimitedPayloadTokenFilterFactory::new);\n        filters.put(\"dictionary_decompounder\", requiresAnalysisSettings(DictionaryCompoundWordTokenFilterFactory::new));\n        filters.put(\"dutch_stem\", DutchStemTokenFilterFactory::new);\n        filters.put(\"edge_ngram\", EdgeNGramTokenFilterFactory::new);\n        filters.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new EdgeNGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [edgeNGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [edge_ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"edgeNGram_deprecation\",\n                            \"The [edgeNGram] token filter name is deprecated and will be removed in a future version. \"\n                             + \"Please change the filter name to [edge_ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"elision\", requiresAnalysisSettings(ElisionTokenFilterFactory::new));\n        filters.put(\"fingerprint\", FingerprintTokenFilterFactory::new);\n        filters.put(\"flatten_graph\", FlattenGraphTokenFilterFactory::new);\n        filters.put(\"french_stem\", FrenchStemTokenFilterFactory::new);\n        filters.put(\"german_normalization\", GermanNormalizationFilterFactory::new);\n        filters.put(\"german_stem\", GermanStemTokenFilterFactory::new);\n        filters.put(\"hindi_normalization\", HindiNormalizationFilterFactory::new);\n        filters.put(\"hyphenation_decompounder\", requiresAnalysisSettings(HyphenationCompoundWordTokenFilterFactory::new));\n        filters.put(\"indic_normalization\", IndicNormalizationFilterFactory::new);\n        filters.put(\"keep\", requiresAnalysisSettings(KeepWordFilterFactory::new));\n        filters.put(\"keep_types\", requiresAnalysisSettings(KeepTypesFilterFactory::new));\n        filters.put(\"keyword_marker\", requiresAnalysisSettings(KeywordMarkerTokenFilterFactory::new));\n        filters.put(\"kstem\", KStemTokenFilterFactory::new);\n        filters.put(\"length\", LengthTokenFilterFactory::new);\n        filters.put(\"limit\", LimitTokenCountFilterFactory::new);\n        filters.put(\"lowercase\", LowerCaseTokenFilterFactory::new);\n        filters.put(\"min_hash\", MinHashTokenFilterFactory::new);\n        filters.put(\"multiplexer\", MultiplexerTokenFilterFactory::new);\n        filters.put(\"ngram\", NGramTokenFilterFactory::new);\n        filters.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            return new NGramTokenFilterFactory(indexSettings, environment, name, settings) {\n                @Override\n                public TokenStream create(TokenStream tokenStream) {\n                    if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                        throw new IllegalArgumentException(\n                                \"The [nGram] token filter name was deprecated in 6.4 and cannot be used in new indices. \"\n                                        + \"Please change the filter name to [ngram] instead.\");\n                    } else {\n                        deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"nGram_deprecation\",\n                            \"The [nGram] token filter name is deprecated and will be removed in a future version. \"\n                            + \"Please change the filter name to [ngram] instead.\");\n                    }\n                    return super.create(tokenStream);\n                }\n\n            };\n        });\n        filters.put(\"pattern_capture\", requiresAnalysisSettings(PatternCaptureGroupTokenFilterFactory::new));\n        filters.put(\"pattern_replace\", requiresAnalysisSettings(PatternReplaceTokenFilterFactory::new));\n        filters.put(\"persian_normalization\", PersianNormalizationFilterFactory::new);\n        filters.put(\"porter_stem\", PorterStemTokenFilterFactory::new);\n        filters.put(\"predicate_token_filter\",\n            requiresAnalysisSettings((i, e, n, s) -> new PredicateTokenFilterScriptFactory(i, n, s, scriptService.get())));\n        filters.put(\"remove_duplicates\", RemoveDuplicatesTokenFilterFactory::new);\n        filters.put(\"reverse\", ReverseTokenFilterFactory::new);\n        filters.put(\"russian_stem\", RussianStemTokenFilterFactory::new);\n        filters.put(\"scandinavian_folding\", ScandinavianFoldingFilterFactory::new);\n        filters.put(\"scandinavian_normalization\", ScandinavianNormalizationFilterFactory::new);\n        filters.put(\"serbian_normalization\", SerbianNormalizationFilterFactory::new);\n        filters.put(\"snowball\", SnowballTokenFilterFactory::new);\n        filters.put(\"sorani_normalization\", SoraniNormalizationFilterFactory::new);\n        filters.put(\"stemmer_override\", requiresAnalysisSettings(StemmerOverrideTokenFilterFactory::new));\n        filters.put(\"stemmer\", StemmerTokenFilterFactory::new);\n        filters.put(\"synonym\", requiresAnalysisSettings(SynonymTokenFilterFactory::new));\n        filters.put(\"synonym_graph\", requiresAnalysisSettings(SynonymGraphTokenFilterFactory::new));\n        filters.put(\"trim\", TrimTokenFilterFactory::new);\n        filters.put(\"truncate\", requiresAnalysisSettings(TruncateTokenFilterFactory::new));\n        filters.put(\"unique\", UniqueTokenFilterFactory::new);\n        filters.put(\"uppercase\", UpperCaseTokenFilterFactory::new);\n        filters.put(\"word_delimiter_graph\", WordDelimiterGraphTokenFilterFactory::new);\n        filters.put(\"word_delimiter\", WordDelimiterTokenFilterFactory::new);\n        return filters;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":217,"status":"M"},{"authorDate":"2021-09-09 18:23:52","commitOrder":18,"curCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.critical(DeprecationCategory.ANALYSIS, \"nGram_tokenizer_deprecation\",\n                    \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.critical(DeprecationCategory.ANALYSIS, \"edgeNGram_tokenizer_deprecation\",\n                    \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","date":"2021-09-09 18:23:52","endLine":370,"groupId":"10769","id":34,"instanceNumber":2,"isCurCommit":1,"methodName":"getTokenizers","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/7e/dee0d149a67f8a5debaeaa2e7b78b4d2d13aef.src","preCode":"    public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {\n        Map<String, AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>();\n        tokenizers.put(\"simple_pattern\", SimplePatternTokenizerFactory::new);\n        tokenizers.put(\"simple_pattern_split\", SimplePatternSplitTokenizerFactory::new);\n        tokenizers.put(\"thai\", ThaiTokenizerFactory::new);\n        tokenizers.put(\"nGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [nGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [ngram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"nGram_tokenizer_deprecation\",\n                    \"The [nGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [ngram] instead.\");\n            }\n            return new NGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"ngram\", NGramTokenizerFactory::new);\n        tokenizers.put(\"edgeNGram\", (IndexSettings indexSettings, Environment environment, String name, Settings settings) -> {\n            if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_8_0_0)) {\n                throw new IllegalArgumentException(\"The [edgeNGram] tokenizer name was deprecated in 7.6. \"\n                        + \"Please use the tokenizer name to [edge_nGram] for indices created in versions 8 or higher instead.\");\n            } else if (indexSettings.getIndexVersionCreated().onOrAfter(org.elasticsearch.Version.V_7_6_0)) {\n                deprecationLogger.deprecate(DeprecationCategory.ANALYSIS, \"edgeNGram_tokenizer_deprecation\",\n                    \"The [edgeNGram] tokenizer name is deprecated and will be removed in a future version. \"\n                        + \"Please change the tokenizer name to [edge_ngram] instead.\");\n            }\n            return new EdgeNGramTokenizerFactory(indexSettings, environment, name, settings);\n        });\n        tokenizers.put(\"edge_ngram\", EdgeNGramTokenizerFactory::new);\n        tokenizers.put(\"char_group\", CharGroupTokenizerFactory::new);\n        tokenizers.put(\"classic\", ClassicTokenizerFactory::new);\n        tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n        \r\n        tokenizers.put(\"lowercase\", XLowerCaseTokenizerFactory::new);\n        tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n        tokenizers.put(\"pattern\", PatternTokenizerFactory::new);\n        tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n        tokenizers.put(\"whitespace\", WhitespaceTokenizerFactory::new);\n        tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n        return tokenizers;\n    }\n","realPath":"modules/analysis-common/src/main/java/org/elasticsearch/analysis/common/CommonAnalysisPlugin.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":329,"status":"M"}],"commitId":"0d3cebe812080ea153d124b313fb2c184c7df75b","commitMessage":"@@@Change default deprecation logger level to CRITICAL (#77030)\n\nThis commit changes default deprecation logger level to CRITICAL.  where default means deprecations emitted by DeprecationLogger#critical method.\nIt also introduces WARN deprecations which are emitted by DeprecationLogger#warn Those log lines emitted at WARN are meant to indicate that a functionality is deprecated but will not break at next major version.\nrelates #76754","date":"2021-09-09 18:23:52","modifiedFileCount":"122","status":"M","submitter":"Przemyslaw Gomulka"}]
