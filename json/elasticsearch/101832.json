[{"authorTime":"2020-09-09 00:33:23","codes":[{"authorDate":"2020-09-09 00:33:23","commitOrder":3,"curCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages) throws Exception {\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : inputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            analyzer,\n            null,\n            new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(snippets.length, expectedPassages.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(snippets[i].getText(), expectedPassages[i]);\n        }\n        reader.close();\n        dir.close();\n    }\n","date":"2020-09-09 00:33:23","endLine":104,"groupId":"48347","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]inputs@Analyzeranalyzer@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/aa/a6d4829a7cc99a6d2e0448dfdc9e7047ce09f6.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages) throws Exception {\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : inputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            analyzer,\n            null,\n            new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(snippets.length, expectedPassages.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(snippets[i].getText(), expectedPassages[i]);\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"server/src/test/java/org/apache/lucene/search/uhighlight/CustomUnifiedHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"MB"},{"authorDate":"2020-09-09 00:33:23","commitOrder":3,"curCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages) throws Exception {\n\n\n        \r\n        Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        if (randomBoolean()) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n        }\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : markedUpInputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n\n        AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n        for (int i = 0; i < markedUpInputs.length; i++) {\n            annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n        }\n        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n        hiliteAnalyzer.setAnnotations(annotations);\n        AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n        passageFormatter.setAnnotations(annotations);\n\n        ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n        for (int i = 0; i < annotations.length; i++) {\n            plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n        }\n\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            hiliteAnalyzer,\n            null,\n            passageFormatter,\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(expectedPassages.length, snippets.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(expectedPassages[i], snippets[i].getText());\n        }\n        reader.close();\n        dir.close();\n    }\n","date":"2020-09-09 00:33:23","endLine":132,"groupId":"60192","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]markedUpInputs@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/ee/eb79aca3770540c74d6c2cd6b36a4e2a341662.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages) throws Exception {\n\n\n        \r\n        Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        if (randomBoolean()) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n        }\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : markedUpInputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n\n        AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n        for (int i = 0; i < markedUpInputs.length; i++) {\n            annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n        }\n        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n        hiliteAnalyzer.setAnnotations(annotations);\n        AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n        passageFormatter.setAnnotations(annotations);\n\n        ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n        for (int i = 0; i < annotations.length; i++) {\n            plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n        }\n\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            hiliteAnalyzer,\n            null,\n            passageFormatter,\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(expectedPassages.length, snippets.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(expectedPassages[i], snippets[i].getText());\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"B"}],"commitId":"ba39f46e8bc5f404b96ad6df04c0ca564d4c50ec","commitMessage":"@@@Speed up empty highlighting many fields (#61860)\n\nKibana often highlights *everything* like this:\n```\nPOST /_search\n{\n  \"query\": .... \n  \"size\": 500. \n  \"highlight\": {\n    \"fields\": {\n      \"*\": { ... }\n    }\n  }\n}\n```\n\nThis can get slow when there are hundreds of mapped fields. I tested\nthis locally and unscientifically and it took a request from 20ms to\n150ms when there are 100 fields. I've seen clusters with 2000 fields\nwhere simple search go from 500ms to 1500ms just by turning on this sort\nof highlighting. Even when the query is just a `range` that and the\nfields are all numbers and stuff so it won't highlight anything.\n\nThis speeds up the `unified` highlighter in this case in a few ways:\n1. Build the highlighting infrastructure once field rather than once pre\n   document per field. This cuts out a *ton* of work analyzing the query\n   over and over and over again.\n2. Bail out of the highlighter before loading values if we can't produce\n   any results.\n\nCombined these take that local 150ms case down to 65ms. This is unlikely\nto be really useful when there are only a few fetched docs and only a\nfew fields.  but we often end up having many fields with many fetched\ndocs.\n","date":"2020-09-09 00:33:23","modifiedFileCount":"7","status":"M","submitter":"Nik Everett"},{"authorTime":"2020-11-25 00:09:37","codes":[{"authorDate":"2020-11-25 00:09:37","commitOrder":4,"curCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages) throws Exception {\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : inputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            analyzer,\n            null,\n            new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE\n        );\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(snippets.length, expectedPassages.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(snippets[i].getText(), expectedPassages[i]);\n        }\n        reader.close();\n        dir.close();\n    }\n","date":"2020-11-25 00:09:37","endLine":103,"groupId":"48347","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]inputs@Analyzeranalyzer@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/33/1d1b38a0ece0196c90ad67b11a3b93bd531885.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages) throws Exception {\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : inputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            analyzer,\n            null,\n            new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(snippets.length, expectedPassages.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(snippets[i].getText(), expectedPassages[i]);\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"server/src/test/java/org/apache/lucene/search/uhighlight/CustomUnifiedHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"},{"authorDate":"2020-11-25 00:09:37","commitOrder":4,"curCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages) throws Exception {\n\n\n        \r\n        Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        if (randomBoolean()) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n        }\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : markedUpInputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n\n        AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n        for (int i = 0; i < markedUpInputs.length; i++) {\n            annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n        }\n        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n        hiliteAnalyzer.setAnnotations(annotations);\n        AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n        passageFormatter.setAnnotations(annotations);\n\n        ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n        for (int i = 0; i < annotations.length; i++) {\n            plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n        }\n\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            hiliteAnalyzer,\n            null,\n            passageFormatter,\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE\n        );\n        highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(expectedPassages.length, snippets.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(expectedPassages[i], snippets[i].getText());\n        }\n        reader.close();\n        dir.close();\n    }\n","date":"2020-11-25 00:09:37","endLine":131,"groupId":"60192","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]markedUpInputs@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/6b/0851c7ad3f405c673d19db2dc9912c3e5da0f8.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages) throws Exception {\n\n\n        \r\n        Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        if (randomBoolean()) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n        }\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : markedUpInputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n\n        AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n        for (int i = 0; i < markedUpInputs.length; i++) {\n            annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n        }\n        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n        hiliteAnalyzer.setAnnotations(annotations);\n        AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n        passageFormatter.setAnnotations(annotations);\n\n        ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n        for (int i = 0; i < annotations.length; i++) {\n            plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n        }\n\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            hiliteAnalyzer,\n            null,\n            passageFormatter,\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE,\n            Integer.MAX_VALUE\n        );\n        highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(expectedPassages.length, snippets.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(expectedPassages[i], snippets[i].getText());\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"M"}],"commitId":"d088171a872d90e16b65a31754c39f13f908097e","commitMessage":"@@@Use ValueFetcher when loading text snippets to highlight (#63572)\n\nHighlighterUtils.loadFieldValues() loads values directly from the source.  and\nthen callers have to deal with filtering out values that would have been removed\nby an ignore_above filter on keyword fields. Instead.  we can use the\nValueFetcher for the relevant field.  which handles all this logic for us.\n\nCloses #59931.","date":"2020-11-25 00:09:37","modifiedFileCount":"8","status":"M","submitter":"Alan Woodward"},{"authorTime":"2021-02-16 16:25:45","codes":[{"authorDate":"2021-02-16 16:25:45","commitOrder":5,"curCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages,\n                                       int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n        try (Directory dir = newDirectory()){\n            IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : inputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        analyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(snippets.length, expectedPassages.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(snippets[i].getText(), expectedPassages[i]);\n                }\n            }\n        }\n    }\n","date":"2021-02-16 16:25:45","endLine":103,"groupId":"0","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]inputs@Analyzeranalyzer@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages@intmaxAnalyzedOffset@IntegerqueryMaxAnalyzedOffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/16/bc9792ffe485c496793db5784a7dfa5c944277.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages) throws Exception {\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : inputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            analyzer,\n            null,\n            new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE\n        );\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(snippets.length, expectedPassages.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(snippets[i].getText(), expectedPassages[i]);\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"server/src/test/java/org/apache/lucene/search/uhighlight/CustomUnifiedHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"},{"authorDate":"2021-02-16 16:25:45","commitOrder":5,"curCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages,\n            int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n\n        try (Directory dir = newDirectory()) {\n            \r\n            Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n            IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            if (randomBoolean()) {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            } else {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n            }\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : markedUpInputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n\n                AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n                for (int i = 0; i < markedUpInputs.length; i++) {\n                    annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n                }\n                AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n                hiliteAnalyzer.setAnnotations(annotations);\n                AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n                passageFormatter.setAnnotations(annotations);\n\n                ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n                for (int i = 0; i < annotations.length; i++) {\n                    plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n                }\n\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        hiliteAnalyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        passageFormatter,\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(expectedPassages.length, snippets.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(expectedPassages[i], snippets[i].getText());\n                }\n            }\n        }\n    }\n","date":"2021-02-16 16:25:45","endLine":130,"groupId":"59385","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]markedUpInputs@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages@intmaxAnalyzedOffset@IntegerqueryMaxAnalyzedOffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/45/1e9a436041ee9d70d8a08c302458e60c7661c6.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages) throws Exception {\n\n\n        \r\n        Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n        Directory dir = newDirectory();\n        IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n        iwc.setMergePolicy(newTieredMergePolicy(random()));\n        RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n        FieldType ft = new FieldType(TextField.TYPE_STORED);\n        if (randomBoolean()) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n        } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n        }\n        ft.freeze();\n        Document doc = new Document();\n        for (String input : markedUpInputs) {\n            Field field = new Field(fieldName, \"\", ft);\n            field.setStringValue(input);\n            doc.add(field);\n        }\n        iw.addDocument(doc);\n        DirectoryReader reader = iw.getReader();\n        IndexSearcher searcher = newSearcher(reader);\n        iw.close();\n\n        AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n        for (int i = 0; i < markedUpInputs.length; i++) {\n            annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n        }\n        AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n        hiliteAnalyzer.setAnnotations(annotations);\n        AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n        passageFormatter.setAnnotations(annotations);\n\n        ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n        for (int i = 0; i < annotations.length; i++) {\n            plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n        }\n\n        TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n        assertThat(topDocs.totalHits.value, equalTo(1L));\n        String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n        CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n            searcher,\n            hiliteAnalyzer,\n            null,\n            passageFormatter,\n            locale,\n            breakIterator,\n            \"index\",\n            \"text\",\n            query,\n            noMatchSize,\n            expectedPassages.length,\n            name -> \"text\".equals(name),\n            Integer.MAX_VALUE\n        );\n        highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n        final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n        assertEquals(expectedPassages.length, snippets.length);\n        for (int i = 0; i < snippets.length; i++) {\n            assertEquals(expectedPassages[i], snippets[i].getText());\n        }\n        reader.close();\n        dir.close();\n    }\n","realPath":"plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"f9af60bf692c1f1bc562a69e1c0e62d9819460a8","commitMessage":"@@@Add query param to limit highlighting to specified length (#67325)\n\nAdd a `max_analyzed_offset` query parameter to allow users\nto limit the highlighting of text fields to a value less than or equal to the\n`index.highlight.max_analyzed_offset`.  thus avoiding an exception when\nthe length of the text field exceeds the limit. The highlighting still takes place. \nbut stops at the length defined by the new parameter.\n\nCloses: #52155\n","date":"2021-02-16 16:25:45","modifiedFileCount":"10","status":"M","submitter":"Marios Trivyzas"},{"authorTime":"2021-02-17 00:08:07","codes":[{"authorDate":"2021-02-16 16:25:45","commitOrder":6,"curCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages,\n                                       int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n        try (Directory dir = newDirectory()){\n            IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : inputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        analyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(snippets.length, expectedPassages.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(snippets[i].getText(), expectedPassages[i]);\n                }\n            }\n        }\n    }\n","date":"2021-02-16 16:25:45","endLine":103,"groupId":"101832","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]inputs@Analyzeranalyzer@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages@intmaxAnalyzedOffset@IntegerqueryMaxAnalyzedOffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/16/bc9792ffe485c496793db5784a7dfa5c944277.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String[] inputs, Analyzer analyzer, Query query,\n                                       Locale locale, BreakIterator breakIterator,\n                                       int noMatchSize, String[] expectedPassages,\n                                       int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n        try (Directory dir = newDirectory()){\n            IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : inputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.arrayToDelimitedString(inputs, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        analyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        new CustomPassageFormatter(\"<b>\", \"</b>\", new DefaultEncoder()),\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(snippets.length, expectedPassages.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(snippets[i].getText(), expectedPassages[i]);\n                }\n            }\n        }\n    }\n","realPath":"server/src/test/java/org/apache/lucene/search/uhighlight/CustomUnifiedHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"N"},{"authorDate":"2021-02-17 00:08:07","commitOrder":6,"curCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages,\n            int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n\n        try (Directory dir = newDirectory()) {\n            \r\n            Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n            IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            if (randomBoolean()) {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            } else {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n            }\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : markedUpInputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n\n                AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n                for (int i = 0; i < markedUpInputs.length; i++) {\n                    annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n                }\n                if (queryMaxAnalyzedOffset != null) {\n                    wrapperAnalyzer = new LimitTokenOffsetAnalyzer(wrapperAnalyzer, queryMaxAnalyzedOffset);\n                }\n                AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n                hiliteAnalyzer.setAnnotations(annotations);\n                AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n                passageFormatter.setAnnotations(annotations);\n\n                ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n                for (int i = 0; i < annotations.length; i++) {\n                    plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n                }\n\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        hiliteAnalyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        passageFormatter,\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(expectedPassages.length, snippets.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(expectedPassages[i], snippets[i].getText());\n                }\n            }\n        }\n    }\n","date":"2021-02-17 00:08:07","endLine":133,"groupId":"101832","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"assertHighlightOneDoc","params":"(StringfieldName@String[]markedUpInputs@Queryquery@Localelocale@BreakIteratorbreakIterator@intnoMatchSize@String[]expectedPassages@intmaxAnalyzedOffset@IntegerqueryMaxAnalyzedOffset)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/a5/dd4a29d044bb0ad27734217ee1681f6e814205.src","preCode":"    private void assertHighlightOneDoc(String fieldName, String []markedUpInputs,\n            Query query, Locale locale, BreakIterator breakIterator,\n            int noMatchSize, String[] expectedPassages,\n            int maxAnalyzedOffset, Integer queryMaxAnalyzedOffset) throws Exception {\n\n        try (Directory dir = newDirectory()) {\n            \r\n            Analyzer wrapperAnalyzer = new AnnotationAnalyzerWrapper(new StandardAnalyzer());\n            IndexWriterConfig iwc = newIndexWriterConfig(wrapperAnalyzer);\n            iwc.setMergePolicy(newTieredMergePolicy(random()));\n            RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n            FieldType ft = new FieldType(TextField.TYPE_STORED);\n            if (randomBoolean()) {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n            } else {\n                ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n            }\n            ft.freeze();\n            Document doc = new Document();\n            for (String input : markedUpInputs) {\n                Field field = new Field(fieldName, \"\", ft);\n                field.setStringValue(input);\n                doc.add(field);\n            }\n            iw.addDocument(doc);\n            try (DirectoryReader reader = iw.getReader()) {\n                IndexSearcher searcher = newSearcher(reader);\n                iw.close();\n\n                AnnotatedText[] annotations = new AnnotatedText[markedUpInputs.length];\n                for (int i = 0; i < markedUpInputs.length; i++) {\n                    annotations[i] = AnnotatedText.parse(markedUpInputs[i]);\n                }\n                AnnotatedHighlighterAnalyzer hiliteAnalyzer = new AnnotatedHighlighterAnalyzer(wrapperAnalyzer);\n                hiliteAnalyzer.setAnnotations(annotations);\n                AnnotatedPassageFormatter passageFormatter = new AnnotatedPassageFormatter(new DefaultEncoder());\n                passageFormatter.setAnnotations(annotations);\n\n                ArrayList<Object> plainTextForHighlighter = new ArrayList<>(annotations.length);\n                for (int i = 0; i < annotations.length; i++) {\n                    plainTextForHighlighter.add(annotations[i].textMinusMarkup);\n                }\n\n                TopDocs topDocs = searcher.search(new MatchAllDocsQuery(), 1, Sort.INDEXORDER);\n                assertThat(topDocs.totalHits.value, equalTo(1L));\n                String rawValue = Strings.collectionToDelimitedString(plainTextForHighlighter, String.valueOf(MULTIVAL_SEP_CHAR));\n                CustomUnifiedHighlighter highlighter = new CustomUnifiedHighlighter(\n                        searcher,\n                        hiliteAnalyzer,\n                        UnifiedHighlighter.OffsetSource.ANALYSIS,\n                        passageFormatter,\n                        locale,\n                        breakIterator,\n                        \"index\",\n                        \"text\",\n                        query,\n                        noMatchSize,\n                        expectedPassages.length,\n                        name -> \"text\".equals(name),\n                        maxAnalyzedOffset,\n                        queryMaxAnalyzedOffset\n                );\n                highlighter.setFieldMatcher((name) -> \"text\".equals(name));\n                final Snippet[] snippets = highlighter.highlightField(getOnlyLeafReader(reader), topDocs.scoreDocs[0].doc, () -> rawValue);\n                assertEquals(expectedPassages.length, snippets.length);\n                for (int i = 0; i < snippets.length; i++) {\n                    assertEquals(expectedPassages[i], snippets[i].getText());\n                }\n            }\n        }\n    }\n","realPath":"plugins/mapper-annotated-text/src/test/java/org/elasticsearch/search/fetch/subphase/highlight/AnnotatedTextHighlighterTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"1e12c93a31d3a91eee6ae7d7fb9ec14bed3cfaed","commitMessage":"@@@Fix issue with AnnotatedTextHighlighter and max_analyzed_offset (#69028)\n\nWith the newly introduced `max_analyzed_offset` the analyzer of\n`AnnotatedTextHighlighter` was wrapped twice with the\n`LimitTokenOffsetAnalyzer` by mistake.\n\nFollows: #67325","date":"2021-02-17 00:08:07","modifiedFileCount":"2","status":"M","submitter":"Marios Trivyzas"}]
