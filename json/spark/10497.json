[{"authorTime":"2015-11-21 07:18:41","codes":[{"authorDate":"2015-11-21 07:18:41","commitOrder":1,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.toArray());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2015-11-21 07:18:41","endLine":112,"groupId":"2536","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/98/0a9108af53f139d8bd84381f45b50c521c0826.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.toArray());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"B"},{"authorDate":"2015-11-21 07:18:41","commitOrder":1,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2015-11-21 07:18:41","endLine":96,"groupId":"2863","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/f628fb51b6ee874fb941de89cf5feed4fa35bc.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"B"}],"commitId":"ed47b1e660b830e2d4fac8d6df93f634b260393c","commitMessage":"@@@[SPARK-11549][DOCS] Replace example code in mllib-evaluation-metrics.md using include_example\n\nAuthor: Vikas Nelamangala <vikasnelamangala@Vikass-MacBook-Pro.local>\n\nCloses #9689 from vikasnp/master.\n","date":"2015-11-21 07:18:41","modifiedFileCount":"0","status":"B","submitter":"Vikas Nelamangala"},{"authorTime":"2015-11-21 07:18:41","codes":[{"authorDate":"2016-01-06 03:10:14","commitOrder":2,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2016-01-06 03:10:14","endLine":112,"groupId":"2536","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/77/9fac01c4be0d8d9a65517500da9352fe803b91.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.toArray());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"},{"authorDate":"2015-11-21 07:18:41","commitOrder":2,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2015-11-21 07:18:41","endLine":96,"groupId":"2863","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/f628fb51b6ee874fb941de89cf5feed4fa35bc.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"N"}],"commitId":"8ce645d4eeda203cf5e100c4bdba2d71edd44e6a","commitMessage":"@@@[SPARK-12615] Remove some deprecated APIs in RDD/SparkContext\n\nI looked at each case individually and it looks like they can all be removed. The only one that I had to think twice was toArray (I even thought about un-deprecating it.  until I realized it was a problem in Java to have toArray returning java.util.List).\n\nAuthor: Reynold Xin <rxin@databricks.com>\n\nCloses #10569 from rxin/SPARK-12615.\n","date":"2016-01-06 03:10:14","modifiedFileCount":"2","status":"M","submitter":"Reynold Xin"},{"authorTime":"2015-11-21 07:18:41","codes":[{"authorDate":"2016-01-09 01:47:44","commitOrder":3,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2016-01-09 01:47:44","endLine":113,"groupId":"26","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/8babba04a5398036b0a26545bc3009068e283c.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"},{"authorDate":"2015-11-21 07:18:41","commitOrder":3,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2015-11-21 07:18:41","endLine":96,"groupId":"2863","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/f628fb51b6ee874fb941de89cf5feed4fa35bc.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"N"}],"commitId":"b9c835337880f57fe8b953962913bcc524162348","commitMessage":"@@@[SPARK-12618][CORE][STREAMING][SQL] Clean up build warnings: 2.0.0 edition\n\nFix most build warnings: mostly deprecated API usages. I'll annotate some of the changes below. CC rxin who is leading the charge to remove the deprecated APIs.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #10570 from srowen/SPARK-12618.\n","date":"2016-01-09 01:47:44","modifiedFileCount":"13","status":"M","submitter":"Sean Owen"},{"authorTime":"2016-05-27 05:25:28","codes":[{"authorDate":"2016-01-09 01:47:44","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2016-01-09 01:47:44","endLine":113,"groupId":"26","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/8babba04a5398036b0a26545bc3009068e283c.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"N"},{"authorDate":"2016-05-27 05:25:28","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2016-05-27 05:25:28","endLine":94,"groupId":"2863","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e8/4a3a712df14f783a92bc47581d573f39a7dff8.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"b0a03feef2cf4daa7642ec7f4dc479dbd473b581","commitMessage":"@@@[SPARK-15457][MLLIB][ML] Eliminate some warnings from MLlib about deprecations\n\n## What changes were proposed in this pull request?\n\nSeveral classes and methods have been deprecated and are creating lots of build warnings in branch-2.0. This issue is to identify and fix those items:\n* WithSGD classes: Change to make class not deprecated.  object deprecated.  and public class constructor deprecated. Any public use will require a deprecated API. We need to keep a non-deprecated private API since we cannot eliminate certain uses: Python API.  streaming algs.  and examples.\n  * Use in PythonMLlibAPI: Change to using private constructors\n  * Streaming algs: No warnings after we un-deprecate the classes\n  * Examples: Deprecate or change ones which use deprecated APIs\n* MulticlassMetrics fields (precision.  etc.)\n* LinearRegressionSummary.model field\n\n## How was this patch tested?\n\nExisting tests.  Checked for warnings manually.\n\nAuthor: Sean Owen <sowen@cloudera.com>\nAuthor: Joseph K. Bradley <joseph@databricks.com>\n\nCloses #13314 from jkbradley/warning-cleanups.\n","date":"2016-05-27 05:25:28","modifiedFileCount":"2","status":"M","submitter":"Sean Owen"},{"authorTime":"2017-01-03 17:56:42","codes":[{"authorDate":"2017-01-03 17:56:42","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics =\n      new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-01-03 17:56:42","endLine":116,"groupId":"26","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/12/aa14f7107f73c132c28134c24c452b0426f6cd.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics =\n      new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"},{"authorDate":"2017-01-03 17:56:42","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-01-03 17:56:42","endLine":96,"groupId":"2863","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/12bdd2a64403e192d1c89f79ca5c5e9c428638.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"e5c307c50a660f706799f1f7f6890bcec888d96b","commitMessage":"@@@[MINOR] Add missing sc.stop() to end of examples\n\n## What changes were proposed in this pull request?\n\nAdd `finally` clause for `sc.stop()` in the `test(\"register and deregister Spark listener from SparkContext\")`.\n\n## How was this patch tested?\nPass the build and unit tests.\n\nAuthor: Weiqing Yang <yangweiqing001@gmail.com>\n\nCloses #16426 from weiqingy/testIssue.\n","date":"2017-01-03 17:56:42","modifiedFileCount":"4","status":"M","submitter":"Weiqing Yang"},{"authorTime":"2017-02-20 01:37:56","codes":[{"authorDate":"2017-02-20 01:37:56","commitOrder":6,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaPairRDD<Object, Object> predictionAndLabels = test.mapToPair(p ->\n      new Tuple2<>(model.predict(p.features()), p.label()));\n\n    \r\n    BinaryClassificationMetrics metrics =\n      new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<?> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<?> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<?> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<?> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(t -> Double.parseDouble(t._1().toString()));\n\n    \r\n    JavaRDD<?> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":101,"groupId":"10497","id":11,"instanceNumber":1,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b9/d0313c6bb560b1bfcccd0396cf3334f82ac593.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Java Binary Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_binary_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits =\n      data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(2)\n      .run(training.rdd());\n\n    \r\n    model.clearThreshold();\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        @Override\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    BinaryClassificationMetrics metrics =\n      new BinaryClassificationMetrics(predictionAndLabels.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n    System.out.println(\"Precision by threshold: \" + precision.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n    System.out.println(\"Recall by threshold: \" + recall.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n    System.out.println(\"F1 Score by threshold: \" + f1Score.collect());\n\n    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n    System.out.println(\"F2 Score by threshold: \" + f2Score.collect());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n    System.out.println(\"Precision-recall curve: \" + prc.collect());\n\n    \r\n    JavaRDD<Double> thresholds = precision.map(\n      new Function<Tuple2<Object, Object>, Double>() {\n        @Override\n        public Double call(Tuple2<Object, Object> t) {\n          return new Double(t._1().toString());\n        }\n      }\n    );\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n    System.out.println(\"ROC curve: \" + roc.collect());\n\n    \r\n    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n\n    \r\n    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel.load(sc, \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"M"},{"authorDate":"2017-02-20 01:37:56","commitOrder":6,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaPairRDD<Object, Object> predictionAndLabels = test.mapToPair(p ->\n      new Tuple2<>(model.predict(p.features()), p.label()));\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":89,"groupId":"10497","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/03/670383b794f20a01b00490898c5177250c8143.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"}],"commitId":"de14d35f77071932963a994fac5aec0e5df838a1","commitMessage":"@@@[SPARK-19533][EXAMPLES] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert Java tests to use lambdas.  Java 8 features.\n\n## How was this patch tested?\n\nJenkins tests.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16961 from srowen/SPARK-19533.\n","date":"2017-02-20 01:37:56","modifiedFileCount":"52","status":"M","submitter":"Sean Owen"}]
