[{"authorTime":"2015-11-21 07:18:41","codes":[{"authorDate":"2016-02-27 00:31:55","commitOrder":2,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double precision = metrics.precision();\n    System.out.println(\"Precision = \" + precision);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2016-02-27 00:31:55","endLine":78,"groupId":"2863","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/9d/8e4a90dbc99497921be3142c6fdbac911a683f.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double precision = metrics.precision();\n    System.out.println(\"Precision = \" + precision);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"B"},{"authorDate":"2015-11-21 07:18:41","commitOrder":2,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2015-11-21 07:18:41","endLine":96,"groupId":"2863","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/f628fb51b6ee874fb941de89cf5feed4fa35bc.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision\n        (metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(metrics\n        .labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure\n        (metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"NB"}],"commitId":"7af0de076f74e975c9235c88b0f11b22fcbae060","commitMessage":"@@@[SPARK-11381][DOCS] Replace example code in mllib-linear-methods.md using include_example\n\n## What changes were proposed in this pull request?\n\nThis PR replaces example codes in `mllib-linear-methods.md` using `include_example`\nby doing the followings:\n  * Extracts the example codes(Scala. Java. Python) as files in `example` module.\n  * Merges some dialog-style examples into a single file.\n  * Hide redundant codes in HTML for the consistency with other docs.\n\n## How was the this patch tested?\n\nmanual test.\nThis PR can be tested by document generations.  `SKIP_API=1 jekyll build`.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #11320 from dongjoon-hyun/SPARK-11381.\n","date":"2016-02-27 00:31:55","modifiedFileCount":"0","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-05-27 05:25:28","codes":[{"authorDate":"2016-05-27 05:25:28","commitOrder":3,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double accuracy = metrics.accuracy();\n    System.out.println(\"Accuracy = \" + accuracy);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2016-05-27 05:25:28","endLine":78,"groupId":"2863","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/7f/c371ec0f990f867979f0f8784d7b8acd99a0b2.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double precision = metrics.precision();\n    System.out.println(\"Precision = \" + precision);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"},{"authorDate":"2016-05-27 05:25:28","commitOrder":3,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","date":"2016-05-27 05:25:28","endLine":94,"groupId":"2863","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e8/4a3a712df14f783a92bc47581d573f39a7dff8.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Precision = \" + metrics.precision());\n    System.out.println(\"Recall = \" + metrics.recall());\n    System.out.println(\"F1 Score = \" + metrics.fMeasure());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"b0a03feef2cf4daa7642ec7f4dc479dbd473b581","commitMessage":"@@@[SPARK-15457][MLLIB][ML] Eliminate some warnings from MLlib about deprecations\n\n## What changes were proposed in this pull request?\n\nSeveral classes and methods have been deprecated and are creating lots of build warnings in branch-2.0. This issue is to identify and fix those items:\n* WithSGD classes: Change to make class not deprecated.  object deprecated.  and public class constructor deprecated. Any public use will require a deprecated API. We need to keep a non-deprecated private API since we cannot eliminate certain uses: Python API.  streaming algs.  and examples.\n  * Use in PythonMLlibAPI: Change to using private constructors\n  * Streaming algs: No warnings after we un-deprecate the classes\n  * Examples: Deprecate or change ones which use deprecated APIs\n* MulticlassMetrics fields (precision.  etc.)\n* LinearRegressionSummary.model field\n\n## How was this patch tested?\n\nExisting tests.  Checked for warnings manually.\n\nAuthor: Sean Owen <sowen@cloudera.com>\nAuthor: Joseph K. Bradley <joseph@databricks.com>\n\nCloses #13314 from jkbradley/warning-cleanups.\n","date":"2016-05-27 05:25:28","modifiedFileCount":"2","status":"M","submitter":"Sean Owen"},{"authorTime":"2017-01-03 17:56:42","codes":[{"authorDate":"2016-05-27 05:25:28","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double accuracy = metrics.accuracy();\n    System.out.println(\"Accuracy = \" + accuracy);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2016-05-27 05:25:28","endLine":78,"groupId":"2863","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/7f/c371ec0f990f867979f0f8784d7b8acd99a0b2.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double accuracy = metrics.accuracy();\n    System.out.println(\"Accuracy = \" + accuracy);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"N"},{"authorDate":"2017-01-03 17:56:42","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-01-03 17:56:42","endLine":96,"groupId":"2863","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/12bdd2a64403e192d1c89f79ca5c5e9c428638.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"e5c307c50a660f706799f1f7f6890bcec888d96b","commitMessage":"@@@[MINOR] Add missing sc.stop() to end of examples\n\n## What changes were proposed in this pull request?\n\nAdd `finally` clause for `sc.stop()` in the `test(\"register and deregister Spark listener from SparkContext\")`.\n\n## How was this patch tested?\nPass the build and unit tests.\n\nAuthor: Weiqing Yang <yangweiqing001@gmail.com>\n\nCloses #16426 from weiqingy/testIssue.\n","date":"2017-01-03 17:56:42","modifiedFileCount":"4","status":"M","submitter":"Weiqing Yang"},{"authorTime":"2017-02-20 01:37:56","codes":[{"authorDate":"2017-02-20 01:37:56","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaPairRDD<Object, Object> predictionAndLabels = test.mapToPair(p ->\n      new Tuple2<>(model.predict(p.features()), p.label()));\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double accuracy = metrics.accuracy();\n    System.out.println(\"Accuracy = \" + accuracy);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":72,"groupId":"10496","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/26/b8a6e9fa3ad6353791ae96c6e60a37b73bd573.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaLogisticRegressionWithLBFGSExample\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[] {0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(10)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n    double accuracy = metrics.accuracy();\n    System.out.println(\"Accuracy = \" + accuracy);\n\n    \r\n    model.save(sc, \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/javaLogisticRegressionWithLBFGSModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"},{"authorDate":"2017-02-20 01:37:56","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaPairRDD<Object, Object> predictionAndLabels = test.mapToPair(p ->\n      new Tuple2<>(model.predict(p.features()), p.label()));\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":89,"groupId":"10496","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/03/670383b794f20a01b00490898c5177250c8143.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n    SparkContext sc = new SparkContext(conf);\n    \r\n    String path = \"data/mllib/sample_multiclass_classification_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n    JavaRDD<LabeledPoint> training = splits[0].cache();\n    JavaRDD<LabeledPoint> test = splits[1];\n\n    \r\n    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n      .setNumClasses(3)\n      .run(training.rdd());\n\n    \r\n    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n        public Tuple2<Object, Object> call(LabeledPoint p) {\n          Double prediction = model.predict(p.features());\n          return new Tuple2<Object, Object>(prediction, p.label());\n        }\n      }\n    );\n\n    \r\n    MulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\n\n    \r\n    Matrix confusion = metrics.confusionMatrix();\n    System.out.println(\"Confusion matrix: \\n\" + confusion);\n\n    \r\n    System.out.println(\"Accuracy = \" + metrics.accuracy());\n\n    \r\n    for (int i = 0; i < metrics.labels().length; i++) {\n      System.out.format(\"Class %f precision = %f\\n\", metrics.labels()[i],metrics.precision(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f recall = %f\\n\", metrics.labels()[i], metrics.recall(\n        metrics.labels()[i]));\n      System.out.format(\"Class %f F1 score = %f\\n\", metrics.labels()[i], metrics.fMeasure(\n        metrics.labels()[i]));\n    }\n\n    \r\n    System.out.format(\"Weighted precision = %f\\n\", metrics.weightedPrecision());\n    System.out.format(\"Weighted recall = %f\\n\", metrics.weightedRecall());\n    System.out.format(\"Weighted F1 score = %f\\n\", metrics.weightedFMeasure());\n    System.out.format(\"Weighted false positive rate = %f\\n\", metrics.weightedFalsePositiveRate());\n\n    \r\n    model.save(sc, \"target/tmp/LogisticRegressionModel\");\n    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc,\n      \"target/tmp/LogisticRegressionModel\");\n    \r\n\n    sc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"}],"commitId":"de14d35f77071932963a994fac5aec0e5df838a1","commitMessage":"@@@[SPARK-19533][EXAMPLES] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert Java tests to use lambdas.  Java 8 features.\n\n## How was this patch tested?\n\nJenkins tests.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16961 from srowen/SPARK-19533.\n","date":"2017-02-20 01:37:56","modifiedFileCount":"52","status":"M","submitter":"Sean Owen"}]
