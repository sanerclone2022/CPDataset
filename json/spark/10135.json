[{"authorTime":"2020-11-10 01:00:52","codes":[{"authorDate":"2020-11-10 01:00:52","commitOrder":2,"curCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2020-11-10 01:00:52","endLine":77,"groupId":"746","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPushThree","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/46/a0f6cf420ebd0b3493d28838bfdebca0f92625.src","preCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"MB"},{"authorDate":"2020-11-10 01:00:52","commitOrder":2,"curCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockFetchSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockFetchFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockFetchFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2020-11-10 01:00:52","endLine":119,"groupId":"983","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testHandlingRetriableFailures","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/46/a0f6cf420ebd0b3493d28838bfdebca0f92625.src","preCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockFetchSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockFetchFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockFetchFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"MB"}],"commitId":"8113c88542ee282b510c7e046d64df1761a85d14","commitMessage":"@@@[SPARK-32916][SHUFFLE] Implementation of shuffle service that leverages push-based shuffle in YARN deployment mode\n\n\n What changes were proposed in this pull request?\nThis is one of the patches for SPIP [SPARK-30602](https://issues.apache.org/jira/browse/SPARK-30602) which is needed for push-based shuffle.\nSummary of changes:\n- Adds an implementation of `MergedShuffleFileManager` which was introduced with [Spark 32915](https://issues.apache.org/jira/browse/SPARK-32915).\n- Integrated the push-based shuffle service with `YarnShuffleService`.\n\n\n Why are the changes needed?\nRefer to the SPIP in  [SPARK-30602](https://issues.apache.org/jira/browse/SPARK-30602).\n\n\n Does this PR introduce _any_ user-facing change?\nNo\n\n\n How was this patch tested?\nAdded unit tests.\nThe reference PR with the consolidated changes covering the complete implementation is also provided in [SPARK-30602](https://issues.apache.org/jira/browse/SPARK-30602).\nWe have already verified the functionality and the improved performance as documented in the SPIP doc.\n\nLead-authored-by: Min Shen mshenlinkedin.com\nCo-authored-by: Chandni Singh chsinghlinkedin.com\nCo-authored-by: Ye Zhou yezhoulinkedin.com\n\nCloses #30062 from otterc/SPARK-32916.\n\nLead-authored-by: Chandni Singh <singh.chandni@gmail.com>\nCo-authored-by: Chandni Singh <chsingh@linkedin.com>\nCo-authored-by: Ye Zhou <yezhou@linkedin.com>\nCo-authored-by: Min Shen <mshen@linkedin.com>\nSigned-off-by: Mridul Muralidharan <mridul<at>gmail.com>\n","date":"2020-11-10 01:00:52","modifiedFileCount":"13","status":"M","submitter":"Chandni Singh"},{"authorTime":"2021-07-20 13:03:30","codes":[{"authorDate":"2021-07-20 13:03:30","commitOrder":3,"curCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\",0,  0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2021-07-20 13:03:30","endLine":77,"groupId":"746","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPushThree","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e4/1198f8ae309b5ea489f1fb4cb3c43dddce3400.src","preCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"},{"authorDate":"2021-07-20 13:03:30","commitOrder":3,"curCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockFetchSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockFetchFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockFetchFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2021-07-20 13:03:30","endLine":119,"groupId":"3287","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testHandlingRetriableFailures","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e4/1198f8ae309b5ea489f1fb4cb3c43dddce3400.src","preCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockFetchSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockFetchFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockFetchFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"}],"commitId":"c77acf0bbc25341de2636649fdd76f9bb4bdf4ed","commitMessage":"@@@[SPARK-35546][SHUFFLE] Enable push-based shuffle when multiple app attempts are enabled and manage concurrent access to the state in a better way\n\n\n What changes were proposed in this pull request?\nThis is one of the patches for SPIP SPARK-30602 which is needed for push-based shuffle.\n\n\n Summary of the change:\nWhen Executor registers with Shuffle Service.  it will encode the merged shuffle dir created and also the application attemptId into the ShuffleManagerMeta into Json. Then in Shuffle Service.  it will decode the Json string and get the correct merged shuffle dir and also the attemptId. If the registration comes from a newer attempt.  the merged shuffle information will be updated to store the information from the newer attempt.\n\nThis PR also refactored the management of the merged shuffle information to avoid concurrency issues.\n\n Why are the changes needed?\nRefer to the SPIP in SPARK-30602.\n\n\n Does this PR introduce _any_ user-facing change?\nNo.\n\n\n How was this patch tested?\nAdded unit tests.\nThe reference PR with the consolidated changes covering the complete implementation is also provided in SPARK-30602.\nWe have already verified the functionality and the improved performance as documented in the SPIP doc.\n\nCloses #33078 from zhouyejoe/SPARK-35546.\n\nAuthored-by: Ye Zhou <yezhou@linkedin.com>\nSigned-off-by: Mridul Muralidharan <mridul<at>gmail.com>\n","date":"2021-07-20 13:03:30","modifiedFileCount":"10","status":"M","submitter":"Ye Zhou"},{"authorTime":"2021-07-27 06:39:19","codes":[{"authorDate":"2021-07-27 06:39:19","commitOrder":4,"curCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\",0,  0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2021-07-27 06:39:19","endLine":77,"groupId":"746","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testPushThree","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f7/09a565c0dd587a237ab0876b424591607ac096.src","preCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\",0,  0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"},{"authorDate":"2021-07-27 06:39:19","commitOrder":4,"curCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockPushSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockPushFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockPushFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","date":"2021-07-27 06:39:19","endLine":119,"groupId":"3287","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testHandlingRetriableFailures","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f7/09a565c0dd587a237ab0876b424591607ac096.src","preCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockFetchingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockFetchSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockFetchSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockFetchFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockFetchFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockFetchFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"}],"commitId":"c4aa54ed4e8cf7942335bfafdeacf57b5d148f2a","commitMessage":"@@@[SPARK-36266][SHUFFLE] Rename classes in shuffle RPC used for block push operations\n\n\n What changes were proposed in this pull request?\nThis is a follow-up to #29855 according to the [comments](https://github.com/apache/spark/pull/29855/files#r505536514)\nIn this PR.  the following changes are made:\n\n1. A new `BlockPushingListener` interface is created specifically for block push. The existing `BlockFetchingListener` interface is left as is.  since it might be used by external shuffle solutions. These 2 interfaces are unified under `BlockTransferListener` to enable code reuse.\n2. `RetryingBlockFetcher`.  `BlockFetchStarter`.  and `RetryingBlockFetchListener` are renamed to `RetryingBlockTransferor`.  `BlockTransferStarter`.  and `RetryingBlockTransferListener` respectively. This makes their names more generic to be reused across both block fetch and push.\n3. Comments in `OneForOneBlockPusher` are further clarified to better explain how we handle retries for block push.\n\n\n Why are the changes needed?\nTo make code cleaner without sacrificing backward compatibility.\n\n\n Does this PR introduce _any_ user-facing change?\nNo\n\n\n How was this patch tested?\nExisting unit tests.\n\nCloses #33340 from Victsm/SPARK-32915-followup.\n\nLead-authored-by: Min Shen <mshen@linkedin.com>\nCo-authored-by: Min Shen <victor.nju@gmail.com>\nSigned-off-by: Mridul Muralidharan <mridul<at>gmail.com>\n","date":"2021-07-27 06:39:19","modifiedFileCount":"6","status":"M","submitter":"Min Shen"},{"authorTime":"2021-08-02 12:16:33","codes":[{"authorDate":"2021-08-02 12:16:33","commitOrder":5,"curCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_0_2_0\",\n      new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\",0,  0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_1_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_2_0\"), any());\n  }\n","date":"2021-08-02 12:16:33","endLine":78,"groupId":"10135","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"testPushThree","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d2/fd5d9be687aef1b8b063f8c4d8e0ca26beda91.src","preCode":"  public void testPushThree() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[23])));\n    blocks.put(\"shufflePush_0_2_0\", new NettyManagedBuffer(Unpooled.wrappedBuffer(new byte[23])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\",0,  0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"},{"authorDate":"2021-08-02 12:16:33","commitOrder":5,"curCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_0_1_0\", null);\n    blocks.put(\"shufflePush_0_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0_0\"), any());\n    verify(listener, times(0)).onBlockPushSuccess(not(eq(\"shufflePush_0_0_0_0\")), any());\n    verify(listener, times(0)).onBlockPushFailure(eq(\"shufflePush_0_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushFailure(eq(\"shufflePush_0_0_1_0\"), any());\n    verify(listener, times(2)).onBlockPushFailure(eq(\"shufflePush_0_0_2_0\"), any());\n  }\n","date":"2021-08-02 12:16:33","endLine":120,"groupId":"10135","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"testHandlingRetriableFailures","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d2/fd5d9be687aef1b8b063f8c4d8e0ca26beda91.src","preCode":"  public void testHandlingRetriableFailures() {\n    LinkedHashMap<String, ManagedBuffer> blocks = Maps.newLinkedHashMap();\n    blocks.put(\"shufflePush_0_0_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[12])));\n    blocks.put(\"shufflePush_0_1_0\", null);\n    blocks.put(\"shufflePush_0_2_0\", new NioManagedBuffer(ByteBuffer.wrap(new byte[0])));\n    String[] blockIds = blocks.keySet().toArray(new String[blocks.size()]);\n\n    BlockPushingListener listener = pushBlocks(\n      blocks,\n      blockIds,\n      Arrays.asList(new PushBlockStream(\"app-id\", 0, 0, 0, 0, 0),\n        new PushBlockStream(\"app-id\", 0, 0, 1, 0, 1),\n        new PushBlockStream(\"app-id\", 0, 0, 2, 0, 2)));\n\n    verify(listener, times(1)).onBlockPushSuccess(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(0)).onBlockPushSuccess(not(eq(\"shufflePush_0_0_0\")), any());\n    verify(listener, times(0)).onBlockPushFailure(eq(\"shufflePush_0_0_0\"), any());\n    verify(listener, times(1)).onBlockPushFailure(eq(\"shufflePush_0_1_0\"), any());\n    verify(listener, times(2)).onBlockPushFailure(eq(\"shufflePush_0_2_0\"), any());\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/OneForOneBlockPusherSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"M"}],"commitId":"c039d998128dd0dab27f43e7de083a71b9d1cfcf","commitMessage":"@@@[SPARK-32923][CORE][SHUFFLE] Handle indeterminate stage retries for push-based shuffle\n\n\n What changes were proposed in this pull request?\n[[SPARK-23243](https://issues.apache.org/jira/browse/SPARK-23243)] and [[SPARK-25341](https://issues.apache.org/jira/browse/SPARK-25341)] addressed cases of stage retries for indeterminate stage involving operations like repartition. This PR addresses the same issues in the context of push-based shuffle. Currently there is no way to distinguish the current execution of a stage for a shuffle ID. Therefore the changes explained below are necessary.\n\nCore changes are summarized as follows:\n\n1. Introduce a new variable `shuffleMergeId` in `ShuffleDependency` which is monotonically increasing value tracking the temporal ordering of execution of <stage-id.  stage-attempt-id> for a shuffle ID.\n2. Correspondingly make changes in the push-based shuffle protocol layer in `MergedShuffleFileManager`.  `BlockStoreClient` passing the `shuffleMergeId` in order to keep track of the shuffle output in separate files on the shuffle service side.\n3. `DAGScheduler` increments the `shuffleMergeId` tracked in `ShuffleDependency` in the cases of a indeterministic stage execution\n4. Deterministic stage will have `shuffleMergeId` set to 0 as no special handling is needed in this case and indeterminate stage will have `shuffleMergeId` starting from 1.\n\n\n Why are the changes needed?\n\nNew protocol changes are needed due to the reasons explained above.\n\n\n Does this PR introduce _any_ user-facing change?\n\nNo\n\n\n How was this patch tested?\nAdded new unit tests in `RemoteBlockPushResolverSuite.  DAGSchedulerSuite.  BlockIdSuite.  ErrorHandlerSuite`\n\nCloses #33034 from venkata91/SPARK-32923.\n\nAuthored-by: Venkata krishnan Sowrirajan <vsowrirajan@linkedin.com>\nSigned-off-by: Mridul Muralidharan <mridul<at>gmail.com>\n","date":"2021-08-02 12:16:33","modifiedFileCount":"22","status":"M","submitter":"Venkata krishnan Sowrirajan"}]
