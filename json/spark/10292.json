[{"authorTime":"2016-04-30 00:32:42","codes":[{"authorDate":"2016-04-30 00:32:42","commitOrder":1,"curCode":"  protected GetColumnsOperation(HiveSession parentSession, String catalogName, String schemaName,\n      String tableName, String columnName) {\n    super(parentSession, OperationType.GET_COLUMNS);\n    this.catalogName = catalogName;\n    this.schemaName = schemaName;\n    this.tableName = tableName;\n    this.columnName = columnName;\n    this.rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","date":"2016-04-30 00:32:42","endLine":124,"groupId":"2890","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"GetColumnsOperation","params":"(HiveSessionparentSession@StringcatalogName@StringschemaName@StringtableName@StringcolumnName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/30/9f10f640f962865233203d469f311b9c877a1b.src","preCode":"  protected GetColumnsOperation(HiveSession parentSession, String catalogName, String schemaName,\n      String tableName, String columnName) {\n    super(parentSession, OperationType.GET_COLUMNS);\n    this.catalogName = catalogName;\n    this.schemaName = schemaName;\n    this.tableName = tableName;\n    this.columnName = columnName;\n    this.rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","realPath":"sql/hive-thriftserver/src/main/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":116,"status":"B"},{"authorDate":"2016-04-30 00:32:42","commitOrder":1,"curCode":"  protected GetTableTypesOperation(HiveSession parentSession) {\n    super(parentSession, OperationType.GET_TABLE_TYPES);\n    String tableMappingStr = getParentSession().getHiveConf().\n        getVar(HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING);\n    tableTypeMapping =\n      TableTypeMappingFactory.getTableTypeMapping(tableMappingStr);\n    rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","date":"2016-04-30 00:32:42","endLine":52,"groupId":"515","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"GetTableTypesOperation","params":"(HiveSessionparentSession)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a0/9b39a4e0855152925085e46b2e0a703b32de7f.src","preCode":"  protected GetTableTypesOperation(HiveSession parentSession) {\n    super(parentSession, OperationType.GET_TABLE_TYPES);\n    String tableMappingStr = getParentSession().getHiveConf().\n        getVar(HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING);\n    tableTypeMapping =\n      TableTypeMappingFactory.getTableTypeMapping(tableMappingStr);\n    rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","realPath":"sql/hive-thriftserver/src/main/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"B"}],"commitId":"7feeb82cb7f462e44f7e698c7c3b6ac3a77aade4","commitMessage":"@@@[SPARK-14987][SQL] inline hive-service (cli) into sql/hive-thriftserver\n\n## What changes were proposed in this pull request?\n\nThis PR copy the thrift-server from hive-service-1.2 (including  TCLIService.thrift and generated Java source code) into sql/hive-thriftserver.  so we can do further cleanup and improvements.\n\n## How was this patch tested?\n\nExisting tests.\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #12764 from davies/thrift_server.\n","date":"2016-04-30 00:32:42","modifiedFileCount":"0","status":"B","submitter":"Davies Liu"},{"authorTime":"2020-10-06 06:29:56","codes":[{"authorDate":"2020-10-06 06:29:56","commitOrder":2,"curCode":"  protected GetColumnsOperation(HiveSession parentSession, String catalogName, String schemaName,\n      String tableName, String columnName) {\n    super(parentSession, OperationType.GET_COLUMNS);\n    this.catalogName = catalogName;\n    this.schemaName = schemaName;\n    this.tableName = tableName;\n    this.columnName = columnName;\n    this.rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion(), false);\n  }\n","date":"2020-10-06 06:29:56","endLine":129,"groupId":"10292","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"GetColumnsOperation","params":"(HiveSessionparentSession@StringcatalogName@StringschemaName@StringtableName@StringcolumnName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c2/5c742d392b3b299c0f12ce5276e82c0e4ee222.src","preCode":"  protected GetColumnsOperation(HiveSession parentSession, String catalogName, String schemaName,\n      String tableName, String columnName) {\n    super(parentSession, OperationType.GET_COLUMNS);\n    this.catalogName = catalogName;\n    this.schemaName = schemaName;\n    this.tableName = tableName;\n    this.columnName = columnName;\n    this.rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","realPath":"sql/hive-thriftserver/src/main/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":121,"status":"M"},{"authorDate":"2020-10-06 06:29:56","commitOrder":2,"curCode":"  protected GetTableTypesOperation(HiveSession parentSession) {\n    super(parentSession, OperationType.GET_TABLE_TYPES);\n    String tableMappingStr = getParentSession().getHiveConf()\n      .getVar(HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING);\n    tableTypeMapping =\n      TableTypeMappingFactory.getTableTypeMapping(tableMappingStr);\n    rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion(), false);\n  }\n","date":"2020-10-06 06:29:56","endLine":52,"groupId":"10292","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"GetTableTypesOperation","params":"(HiveSessionparentSession)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/cf/330cbf4100bd9e62d9a30b97baaee342887af1.src","preCode":"  protected GetTableTypesOperation(HiveSession parentSession) {\n    super(parentSession, OperationType.GET_TABLE_TYPES);\n    String tableMappingStr = getParentSession().getHiveConf()\n      .getVar(HiveConf.ConfVars.HIVE_SERVER2_TABLE_TYPE_MAPPING);\n    tableTypeMapping =\n      TableTypeMappingFactory.getTableTypeMapping(tableMappingStr);\n    rowSet = RowSetFactory.create(RESULT_SET_SCHEMA, getProtocolVersion());\n  }\n","realPath":"sql/hive-thriftserver/src/main/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"008a2ad1f836ff04fafd51a9c94c355ef35f1692","commitMessage":"@@@[SPARK-20202][BUILD][SQL] Remove references to org.spark-project.hive (Hive 1.2.1)\n\n\n What changes were proposed in this pull request?\n\nAs of today. \n- SPARK-30034 Apache Spark 3.0.0 switched its default Hive execution engine from Hive 1.2 to Hive 2.3. This removes the direct dependency to the forked Hive 1.2.1 in maven repository.\n- SPARK-32981 Apache Spark 3.1.0(`master` branch) removed Hive 1.2 related artifacts from Apache Spark binary distributions.\n\nThis PR(SPARK-20202) aims to remove the following usage of unofficial Apache Hive fork completely from Apache Spark master for Apache Spark 3.1.0.\n```\n<hive.group>org.spark-project.hive</hive.group>\n<hive.version>1.2.1.spark2</hive.version>\n```\n\nFor the forked Hive 1.2.1.spark2 users.  Apache Spark 2.4(LTS) and 3.0 (~ 2021.12) will provide it.\n\n\n Why are the changes needed?\n\n- First.  Apache Spark community should not use the unofficial forked release of another Apache project.\n- Second.  Apache Hive 1.2.1 was released at 2015-06-26 and the forked Hive `1.2.1.spark2` exposed many unfixable bugs in Apache because the forked `1.2.1.spark2` is not maintained at all. Apache Hive 2.3.0 was released at 2017-07-19 and it has been used with less number of bugs compared with `1.2.1.spark2`. Many bugs still exist in `hive-1.2` profile and new Apache Spark unit tests are added with `HiveUtils.isHive23` condition so far.\n\n\n Does this PR introduce _any_ user-facing change?\n\nNo. This is a dev-only change. PRBuilder will not accept `[test-hive1.2]` on master and `branch-3.1`.\n\n\n How was this patch tested?\n\n1. SBT/Hadoop 3.2/Hive 2.3 (https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/129366)\n2. SBT/Hadoop 2.7/Hive 2.3 (https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/129382)\n3. SBT/Hadoop 3.2/Hive 1.2 (This has not been supported already due to Hive 1.2 doesn't work with Hadoop 3.2.)\n4. SBT/Hadoop 2.7/Hive 1.2 (https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/129383.  This is rejected)\n\nCloses #29936 from dongjoon-hyun/SPARK-REMOVE-HIVE1.\n\nAuthored-by: Dongjoon Hyun <dhyun@apple.com>\nSigned-off-by: Dongjoon Hyun <dhyun@apple.com>\n","date":"2020-10-06 06:29:56","modifiedFileCount":"0","status":"M","submitter":"Dongjoon Hyun"}]
