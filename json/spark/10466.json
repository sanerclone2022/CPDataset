[{"authorTime":"2013-09-02 05:57:27","codes":[{"authorDate":"2013-09-02 05:57:27","commitOrder":1,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 10;\n    int products = 10;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","date":"2013-09-02 05:57:27","endLine":92,"groupId":"383","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/23f6cee2b910d7e6f4fcf6d531b443a98e8b89.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 10;\n    int products = 10;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"B"},{"authorDate":"2013-09-02 05:57:27","commitOrder":1,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 20;\n    int products = 30;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","date":"2013-09-02 05:57:27","endLine":109,"groupId":"383","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/23f6cee2b910d7e6f4fcf6d531b443a98e8b89.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 20;\n    int products = 30;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":95,"status":"B"}],"commitId":"2ce200bf7f7a38afbcacf3303ca2418e49bdbe2a","commitMessage":"@@@Merge remote-tracking branch 'old/master'\n","date":"2013-09-02 05:57:27","modifiedFileCount":"0","status":"B","submitter":"Matei Zaharia"},{"authorTime":"2013-10-09 14:44:55","codes":[{"authorDate":"2013-10-09 14:44:55","commitOrder":2,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2013-10-09 14:44:55","endLine":113,"groupId":"1653","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ea/fee060cda06d35da19de2abe86e475ba89b8f0.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 10;\n    int products = 10;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"M"},{"authorDate":"2013-10-09 14:44:55","commitOrder":2,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2013-10-09 14:44:55","endLine":130,"groupId":"1655","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ea/fee060cda06d35da19de2abe86e475ba89b8f0.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 20;\n    int products = 30;\n    scala.Tuple2<List<Rating>, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":116,"status":"M"}],"commitId":"3218fa795ff3ddee855772184aebe99098701d4f","commitMessage":"@@@Merge pull request #4 from MLnick/implicit-als\n\nAdding algorithm for implicit feedback data to ALS\n\nThis PR adds the commonly used \"implicit feedack\" variant to ALS.\n\nThe implementation is based in part on Mahout's implementation.  which is in turn based on [Collaborative Filtering for Implicit Feedback Datasets](http://research.yahoo.com/pub/2433). It has been adapted for the blocked approach used in MLlib.\n\nI have tested this implementation against the MovieLens 100k.  1m and 10m datasets.  and confirmed that it produces the same RMSE score as Mahout.  as well as my own port of Mahout's implicit ALS implementation to Spark (not that RMSE is necessarily the best metric to judge by for implicit feedback.  but it provides a consistent metric for comparison).\n\nIt turned out to be more straightforward than I had thought to add this. The main additions are:\n1. Adding `implicitPrefs` boolean flag and `alpha` parameter\n2. Added the `computeYtY` method. In each least-squares step.  the algorithm requires the computation of `YtY`.  where `Y` is the {user.  item} factor matrix. Since the factors are already block-distributed in an `RDD`.  this is quite straightforward to compute but does add an extra operation over the explicit version (but only twice per iteration)\n3. Finally the actual solve step in `updateBlock` boils down to:\n    * a multiplication of the `XtX` matrix by `alpha * rating`\n    * a multiplication of the `Xty` vector by `1 + alpha * rating`\n    * when solving for the factor vector.  the implicit variant adds the `YtY` matrix to the LHS\n4. Added `trainImplicit` methods in the `ALS` object\n5. Added test cases for both Scala and Java - based on achieving a confidence-weighted RMSE score < 0.4 (this is taken from Mahout's test cases)\n\nIt would be great to get some feedback on this and have people test things out against some datasets (MovieLens and others and perhaps proprietary datasets) both locally and on a cluster if possible. I have not yet tested on a cluster but will try to do that soon.\n\nI have tried to make things as efficient as possible but if there are potential improvements let me know.\n\nThe results of a run against ml-1m are below (note the vanilla RMSE scores will be very different from the explicit variant):\n\n**INPUTS**\n```\niterations=10\nfactors=10\nlambda=0.01\nalpha=1\nimplicitPrefs=true\n```\n\n**RESULTS**\n\n```\nSpark MLlib 0.8.0-SNAPSHOT\n\nRMSE = 3.1544\nTime: 24.834 sec\n```\n```\nMy own port of Mahout's ALS to Spark (updated to 0.8.0-SNAPSHOT)\n\nRMSE = 3.1543\nTime: 58.708 sec\n```\n```\nMahout 0.8\n\ntime ./factorize-movielens-1M.sh /path/to/ratings/ml-1m/ratings.dat\n\nreal\t3m48.648s\nuser\t6m39.254s\nsys\t0m14.505s\n\nRMSE = 3.1539\n```\n\nResults of a run against ml-10m\n\n```\nSpark MLlib\n\nRMSE = 3.1200\nTime: 162.348 sec\n```\n```\nMahout 0.8\n\nreal\t23m2.220s\nuser\t43m39.185s\nsys\t0m25.316s\n\nRMSE = 3.1187\n```\n","date":"2013-10-09 14:44:55","modifiedFileCount":"1","status":"M","submitter":"Matei Zaharia"},{"authorTime":"2014-02-20 15:44:53","codes":[{"authorDate":"2014-02-20 15:44:53","commitOrder":3,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-02-20 15:44:53","endLine":110,"groupId":"2232","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b1/50334deb06cbff9cbd8f780e5dfb7cba309d53.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2014-02-20 15:44:53","commitOrder":3,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-02-20 15:44:53","endLine":127,"groupId":"2232","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b1/50334deb06cbff9cbd8f780e5dfb7cba309d53.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":113,"status":"M"}],"commitId":"9e63f80e75bb6d9bbe6df268908c3219de6852d9","commitMessage":"@@@MLLIB-22. Support negative implicit input in ALS\n\nI'm back with another less trivial suggestion for ALS:\n\nIn ALS for implicit feedback.  input values are treated as weights on squared-errors in a loss function (or rather.  the weight is a simple function of the input r.  like c = 1 + alpha*r). The paper on which it's based assumes that the input is positive. Indeed.  if the input is negative.  it will create a negative weight on squared-errors.  which causes things to go haywire. The optimization will try to make the error in a cell as large possible.  and the result is silently bogus.\n\nThere is a good use case for negative input values though. Implicit feedback is usually collected from signals of positive interaction like a view or like or buy.  but equally.  can come from \"not interested\" signals. The natural representation is negative values.\n\nThe algorithm can be extended quite simply to provide a sound interpretation of these values: negative values should encourage the factorization to come up with 0 for cells with large negative input values.  just as much as positive values encourage it to come up with 1.\n\nThe implications for the algorithm are simple:\n* the confidence function value must not be negative.  and so can become 1 + alpha*|r|\n* the matrix P should have a value 1 where the input R is _positive_.  not merely where it is non-zero. Actually.  that's what the paper already says.  it's just that we can't assume P = 1 when a cell in R is specified anymore.  since it may be negative\n\nThis in turn entails just a few lines of code change in `ALS.scala`:\n* `rs(i)` becomes `abs(rs(i))`\n* When constructing `userXy(us(i))`.  it's implicitly only adding where P is 1. That had been true for any us(i) that is iterated over.  before.  since these are exactly the ones for which P is 1. But now P is zero where rs(i) <= 0.  and should not be added\n\nI think it's a safe change because:\n* It doesn't change any existing behavior (unless you're using negative values.  in which case results are already borked)\n* It's the simplest direct extension of the paper's algorithm\n* (I've used it to good effect in production FWIW)\n\nTests included.\n\nI tweaked minor things en route:\n* `ALS.scala` javadoc writes \"R = Xt*Y\" when the paper and rest of code defines it as \"R = X*Yt\"\n* RMSE in the ALS tests uses a confidence-weighted mean.  but the denominator is not actually sum of weights\n\nExcuse my Scala style; I'm sure it needs tweaks.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #500 from srowen/ALSNegativeImplicitInput and squashes the following commits:\n\ncf902a9 [Sean Owen] Support negative implicit input in ALS\n953be1c [Sean Owen] Make weighted RMSE in ALS test actually weighted; adjust comment about R = X*Yt\n","date":"2014-02-20 15:44:53","modifiedFileCount":"1","status":"M","submitter":"Sean Owen"},{"authorTime":"2014-08-01 22:32:53","codes":[{"authorDate":"2014-08-01 22:32:53","commitOrder":4,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-08-01 22:32:53","endLine":120,"groupId":"2232","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f6/ca9643227f8ea838f9596f82fe1e4e4a58c6a7.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"M"},{"authorDate":"2014-08-01 22:32:53","commitOrder":4,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-08-01 22:32:53","endLine":137,"groupId":"2232","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f6/ca9643227f8ea838f9596f82fe1e4e4a58c6a7.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    scala.Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n                                              .setIterations(iterations)\n                                              .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"M"}],"commitId":"82d209d43fb543c174e640667de15b00c7fb5d35","commitMessage":"@@@SPARK-2768 [MLLIB] Add product.  user recommend method to MatrixFactorizationModel\n\nRight now.  `MatrixFactorizationModel` can only predict a score for one or more `(user. product)` tuples. As a comment in the file notes.  it would be more useful to expose a recommend method.  that computes top N scoring products for a user (or vice versa ? users for a product).\n\n(This also corrects some long lines in the Java ALS test suite.)\n\nAs you can see.  it's a little messy to access the class from Java. Should there be a Java-friendly wrapper for it? with a pointer about where that should go.  I could add that.\n\nAuthor: Sean Owen <srowen@gmail.com>\n\nCloses #1687 from srowen/SPARK-2768 and squashes the following commits:\n\nb349675 [Sean Owen] Additional review changes\nc9edb04 [Sean Owen] Updates from code review\n7bc35f9 [Sean Owen] Add recommend methods to MatrixFactorizationModel\n","date":"2014-08-01 22:32:53","modifiedFileCount":"1","status":"M","submitter":"Sean Owen"},{"authorTime":"2014-11-14 03:42:27","codes":[{"authorDate":"2014-11-14 03:42:27","commitOrder":5,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-11-14 03:42:27","endLine":108,"groupId":"2232","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/af/688c504cf1e352d6b32e8a3e15cadc80dbe17b.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"M"},{"authorDate":"2014-11-14 03:42:27","commitOrder":5,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2014-11-14 03:42:27","endLine":125,"groupId":"2232","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/af/688c504cf1e352d6b32e8a3e15cadc80dbe17b.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data.rdd());\n    validatePrediction(model, users, products, features, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":111,"status":"M"}],"commitId":"ca26a212fda39a15fde09dfdb2fbe69580a717f6","commitMessage":"@@@[SPARK-4378][MLLIB] make ALS more Java-friendly\n\nAdd Java-friendly version of `run` and `predict`.  and use bulk prediction in Java unit tests. The user guide update will come later (though we may not save many lines of code there). srowen\n\nAuthor: Xiangrui Meng <meng@databricks.com>\n\nCloses #3240 from mengxr/SPARK-4378 and squashes the following commits:\n\n6581503 [Xiangrui Meng] check number of predictions\n6c8bbd1 [Xiangrui Meng] make ALS more Java-friendly\n","date":"2014-11-14 03:42:27","modifiedFileCount":"1","status":"M","submitter":"Xiangrui Meng"},{"authorTime":"2016-03-09 01:47:55","codes":[{"authorDate":"2016-03-09 01:47:55","commitOrder":6,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, double[], double[]> testData =\n        ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2016-03-09 01:47:55","endLine":106,"groupId":"1721","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d0/bf7f556dcc0b6ad41e74692f32114c7655eedc.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":95,"status":"M"},{"authorDate":"2016-03-09 01:47:55","commitOrder":6,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, double[], double[]> testData =\n        ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2016-03-09 01:47:55","endLine":123,"groupId":"1721","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d0/bf7f556dcc0b6ad41e74692f32114c7655eedc.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, DoubleMatrix, DoubleMatrix> testData = ALSSuite.generateRatingsAsJavaList(\n        users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":109,"status":"M"}],"commitId":"54040f8d350d2aad3078dcffef808c62b7c0b73d","commitMessage":"@@@[SPARK-13715][MLLIB] Remove last usages of jblas in tests\n\n## What changes were proposed in this pull request?\n\nRemove last usage of jblas.  in tests\n\n## How was this patch tested?\n\nJenkins tests -- the same ones that are being modified.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #11560 from srowen/SPARK-13715.\n","date":"2016-03-09 01:47:55","modifiedFileCount":"2","status":"M","submitter":"Sean Owen"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":7,"curCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, double[], double[]> testData =\n      ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = jsc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2016-05-11 02:17:47","endLine":112,"groupId":"10466","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"runALSUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/aa/784054d551eb33b83ff38f668d9a7cbe06a3fe.src","preCode":"  public void runALSUsingStaticMethods() {\n    int features = 1;\n    int iterations = 15;\n    int users = 50;\n    int products = 100;\n    Tuple3<List<Rating>, double[], double[]> testData =\n        ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n    MatrixFactorizationModel model = ALS.train(data.rdd(), features, iterations);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":101,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":7,"curCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, double[], double[]> testData =\n      ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = jsc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","date":"2016-05-11 02:17:47","endLine":129,"groupId":"10466","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"runALSUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/aa/784054d551eb33b83ff38f668d9a7cbe06a3fe.src","preCode":"  public void runALSUsingConstructor() {\n    int features = 2;\n    int iterations = 15;\n    int users = 100;\n    int products = 200;\n    Tuple3<List<Rating>, double[], double[]> testData =\n        ALSSuite.generateRatingsAsJava(users, products, features, 0.7, false, false);\n\n    JavaRDD<Rating> data = sc.parallelize(testData._1());\n\n    MatrixFactorizationModel model = new ALS().setRank(features)\n      .setIterations(iterations)\n      .run(data);\n    validatePrediction(model, users, products, testData._2(), 0.3, false, testData._3());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/recommendation/JavaALSSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"}]
