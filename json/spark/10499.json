[{"authorTime":"2015-11-14 00:36:46","codes":[{"authorDate":"2015-11-11 02:05:53","commitOrder":2,"curCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","date":"2015-11-11 02:05:53","endLine":90,"groupId":"1785","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/58/39b0cf8a8f8c388c52ec65fac6469b90906135.src","preCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"NB"},{"authorDate":"2015-11-14 00:36:46","commitOrder":2,"curCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n  }\n","date":"2015-11-14 00:36:46","endLine":95,"groupId":"1530","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/6895b36820288214c4c606509ff4bfd814c904.src","preCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"B"}],"commitId":"61a28486ccbcdd37461419df958aea222c8b9f09","commitMessage":"@@@[SPARK-11445][DOCS] Replaced example code in mllib-ensembles.md using include_example\n\nI have made the required changes and tested.\nKindly review the changes.\n\nAuthor: Rishabh Bhardwaj <rbnext29@gmail.com>\n\nCloses #9407 from rishabhbhardwaj/SPARK-11445.\n","date":"2015-11-14 00:36:46","modifiedFileCount":"0","status":"M","submitter":"Rishabh Bhardwaj"},{"authorTime":"2016-03-09 18:12:23","codes":[{"authorDate":"2015-11-11 02:05:53","commitOrder":3,"curCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","date":"2015-11-11 02:05:53","endLine":90,"groupId":"1785","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/58/39b0cf8a8f8c388c52ec65fac6469b90906135.src","preCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"N"},{"authorDate":"2016-03-09 18:12:23","commitOrder":3,"curCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-09 18:12:23","endLine":97,"groupId":"1530","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c1/bc2098dcd7e5307c0ae8377f11024ebe13ca78.src","preCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"M"}],"commitId":"f3201aeeb06aae3b11e8cf6ee9693182dd896b32","commitMessage":"@@@[SPARK-13692][CORE][SQL] Fix trivial Coverity/Checkstyle defects\n\n## What changes were proposed in this pull request?\n\nThis issue fixes the following potential bugs and Java coding style detected by Coverity and Checkstyle.\n\n- Implement both null and type checking in equals functions.\n- Fix wrong type casting logic in SimpleJavaBean2.equals.\n- Add `implement Cloneable` to `UTF8String` and `SortedIterator`.\n- Remove dereferencing before null check in `AbstractBytesToBytesMapSuite`.\n- Fix coding style: Add '{}' to single `for` statement in mllib examples.\n- Remove unused imports in `ColumnarBatch` and `JavaKinesisStreamSuite`.\n- Remove unused fields in `ChunkFetchIntegrationSuite`.\n- Add `stop()` to prevent resource leak.\n\nPlease note that the last two checkstyle errors exist on newly added commits after [SPARK-13583](https://issues.apache.org/jira/browse/SPARK-13583).\n\n## How was this patch tested?\n\nmanual via `./dev/lint-java` and Coverity site.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #11530 from dongjoon-hyun/SPARK-13692.\n","date":"2016-03-09 18:12:23","modifiedFileCount":"31","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-03-09 18:31:26","codes":[{"authorDate":"2016-03-09 18:31:26","commitOrder":4,"curCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","date":"2016-03-09 18:31:26","endLine":90,"groupId":"2697","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/66/387b9df51c78f1b779826bc404ea63cf40cb98.src","preCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"M"},{"authorDate":"2016-03-09 18:31:26","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-09 18:31:26","endLine":97,"groupId":"2056","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/78/db442dbc99d4a99dcc6145dfbd2253d43c0c52.src","preCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<Double, Double>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"M"}],"commitId":"c3689bc24e03a9471cd6e8169da61963c4528252","commitMessage":"@@@[SPARK-13702][CORE][SQL][MLLIB] Use diamond operator for generic instance creation in Java code.\n\n## What changes were proposed in this pull request?\n\nIn order to make `docs/examples` (and other related code) more simple/readable/user-friendly.  this PR replaces existing codes like the followings by using `diamond` operator.\n\n```\n-    final ArrayList<Product2<Object.  Object>> dataToWrite =\n-      new ArrayList<Product2<Object.  Object>>();\n+    final ArrayList<Product2<Object.  Object>> dataToWrite = new ArrayList<>();\n```\n\nJava 7 or higher supports **diamond** operator which replaces the type arguments required to invoke the constructor of a generic class with an empty set of type parameters (<>). Currently.  Spark Java code use mixed usage of this.\n\n## How was this patch tested?\n\nManual.\nPass the existing tests.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #11541 from dongjoon-hyun/SPARK-13702.\n","date":"2016-03-09 18:31:26","modifiedFileCount":"57","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2017-02-20 01:37:56","codes":[{"authorDate":"2017-02-20 01:37:56","commitOrder":5,"curCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    int numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    String impurity = \"gini\";\n    int maxDepth = 5;\n    int maxBins = 32;\n\n    \r\n    DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(p -> new Tuple2<>(model.predict(p.features()), p.label()));\n    double testErr =\n      predictionAndLabel.filter(pl -> !pl._1().equals(pl._2())).count() / (double) testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","date":"2017-02-20 01:37:56","endLine":78,"groupId":"10499","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/03/2c168b946d6163b3f9352676f6341771bd825a.src","preCode":"  public static void main(String[] args) {\n\n    \r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    Integer numClasses = 2;\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    String impurity = \"gini\";\n    Integer maxDepth = 5;\n    Integer maxBins = 32;\n\n    \r\n    final DecisionTreeModel model = DecisionTree.trainClassifier(trainingData, numClasses,\n      categoricalFeaturesInfo, impurity, maxDepth, maxBins);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testErr =\n      1.0 * predictionAndLabel.filter(new Function<Tuple2<Double, Double>, Boolean>() {\n        @Override\n        public Boolean call(Tuple2<Double, Double> pl) {\n          return !pl._1().equals(pl._2());\n        }\n      }).count() / testData.count();\n\n    System.out.println(\"Test Error: \" + testErr);\n    System.out.println(\"Learned classification tree model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    DecisionTreeModel sameModel = DecisionTreeModel\n      .load(jsc.sc(), \"target/tmp/myDecisionTreeClassificationModel\");\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"M"},{"authorDate":"2017-02-20 01:37:56","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    GradientBoostedTreesModel model = GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(p -> new Tuple2<>(model.predict(p.features()), p.label()));\n    double testMSE = predictionAndLabel.mapToDouble(pl -> {\n      double diff = pl._1() - pl._2();\n      return diff * diff;\n    }).mean();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n\n    jsc.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":79,"groupId":"10499","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b3/45d19f59ab605fb625de351beff75faa1859e9.src","preCode":"  public static void main(String[] args) {\n    \r\n    SparkConf sparkConf = new SparkConf()\n      .setAppName(\"JavaGradientBoostedTreesRegressionExample\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n    \r\n    String datapath = \"data/mllib/sample_libsvm_data.txt\";\n    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(jsc.sc(), datapath).toJavaRDD();\n    \r\n    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    JavaRDD<LabeledPoint> trainingData = splits[0];\n    JavaRDD<LabeledPoint> testData = splits[1];\n\n    \r\n    \r\n    BoostingStrategy boostingStrategy = BoostingStrategy.defaultParams(\"Regression\");\n    boostingStrategy.setNumIterations(3); \r\n    boostingStrategy.getTreeStrategy().setMaxDepth(5);\n    \r\n    Map<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    boostingStrategy.treeStrategy().setCategoricalFeaturesInfo(categoricalFeaturesInfo);\n\n    final GradientBoostedTreesModel model =\n      GradientBoostedTrees.train(trainingData, boostingStrategy);\n\n    \r\n    JavaPairRDD<Double, Double> predictionAndLabel =\n      testData.mapToPair(new PairFunction<LabeledPoint, Double, Double>() {\n        @Override\n        public Tuple2<Double, Double> call(LabeledPoint p) {\n          return new Tuple2<>(model.predict(p.features()), p.label());\n        }\n      });\n    Double testMSE =\n      predictionAndLabel.map(new Function<Tuple2<Double, Double>, Double>() {\n        @Override\n        public Double call(Tuple2<Double, Double> pl) {\n          Double diff = pl._1() - pl._2();\n          return diff * diff;\n        }\n      }).reduce(new Function2<Double, Double, Double>() {\n        @Override\n        public Double call(Double a, Double b) {\n          return a + b;\n        }\n      }) / data.count();\n    System.out.println(\"Test Mean Squared Error: \" + testMSE);\n    System.out.println(\"Learned regression GBT model:\\n\" + model.toDebugString());\n\n    \r\n    model.save(jsc.sc(), \"target/tmp/myGradientBoostingRegressionModel\");\n    GradientBoostedTreesModel sameModel = GradientBoostedTreesModel.load(jsc.sc(),\n      \"target/tmp/myGradientBoostingRegressionModel\");\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"M"}],"commitId":"de14d35f77071932963a994fac5aec0e5df838a1","commitMessage":"@@@[SPARK-19533][EXAMPLES] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert Java tests to use lambdas.  Java 8 features.\n\n## How was this patch tested?\n\nJenkins tests.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16961 from srowen/SPARK-19533.\n","date":"2017-02-20 01:37:56","modifiedFileCount":"52","status":"M","submitter":"Sean Owen"}]
