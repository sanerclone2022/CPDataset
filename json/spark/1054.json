[{"authorTime":"2016-02-29 09:25:07","codes":[{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","date":"2016-02-29 09:25:07","endLine":64,"groupId":"1648","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testServerToClient","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/6c/8dd742f4b6412f85901c5a8051051e4278fa54.src","preCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"B"},{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","date":"2016-02-29 09:25:07","endLine":80,"groupId":"1648","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testClientToServer","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/6c/8dd742f4b6412f85901c5a8051051e4278fa54.src","preCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"B"}],"commitId":"9e01dcc6446f8648e61062f8afe62589b9d4b5ab","commitMessage":"@@@[SPARK-13529][BUILD] Move network/* modules into common/network-*\n\n## What changes were proposed in this pull request?\nAs the title says.  this moves the three modules currently in network/ into common/network-*. This removes one top level.  non-user-facing folder.\n\n## How was this patch tested?\nCompilation and existing tests. We should run both SBT and Maven.\n\nAuthor: Reynold Xin <rxin@databricks.com>\n\nCloses #11409 from rxin/SPARK-13529.\n","date":"2016-02-29 09:25:07","modifiedFileCount":"1","status":"B","submitter":"Reynold Xin"},{"authorTime":"2017-02-14 04:03:36","codes":[{"authorDate":"2017-02-14 04:03:36","commitOrder":2,"curCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","date":"2017-02-14 04:03:36","endLine":64,"groupId":"1602","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testServerToClient","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bb/1c40c4b0e0686dfaa4a2aa01249122e988fa8c.src","preCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"M"},{"authorDate":"2017-02-14 04:03:36","commitOrder":2,"curCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","date":"2017-02-14 04:03:36","endLine":80,"groupId":"1602","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testClientToServer","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bb/1c40c4b0e0686dfaa4a2aa01249122e988fa8c.src","preCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      new MessageEncoder());\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), new MessageDecoder());\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"}],"commitId":"905fdf0c243e1776c54c01a25b17878361400225","commitMessage":"@@@[SPARK-17714][CORE][TEST-MAVEN][TEST-HADOOP2.6] Avoid using ExecutorClassLoader to load Netty generated classes\n\n## What changes were proposed in this pull request?\n\nNetty's `MessageToMessageEncoder` uses [Javassist](https://github.com/netty/netty/blob/91a0bdc17a8298437d6de08a8958d753799bd4a6/common/src/main/java/io/netty/util/internal/JavassistTypeParameterMatcherGenerator.java#L62) to generate a matcher class and the implementation calls `Class.forName` to check if this class is already generated. If `MessageEncoder` or `MessageDecoder` is created in `ExecutorClassLoader.findClass`.  it will cause `ClassCircularityError`. This is because loading this Netty generated class will call `ExecutorClassLoader.findClass` to search this class.  and `ExecutorClassLoader` will try to use RPC to load it and cause to load the non-exist matcher class again. JVM will report `ClassCircularityError` to prevent such infinite recursion.\n\n\n## Why it only happens in Maven builds\n\nIt's because Maven and SBT have different class loader tree. The Maven build will set a URLClassLoader as the current context class loader to run the tests and expose this issue. The class loader tree is as following:\n\n```\nbootstrap class loader ------ ... ----- REPL class loader ---- ExecutorClassLoader\n|\n|\nURLClasssLoader\n```\n\nThe SBT build uses the bootstrap class loader directly and `ReplSuite.test(\"propagation of local properties\")` is the first test in ReplSuite.  which happens to load `io/netty/util/internal/__matchers__/org/apache/spark/network/protocol/MessageMatcher` into the bootstrap class loader (Note: in maven build.  it's loaded into URLClasssLoader so it cannot be found in ExecutorClassLoader). This issue can be reproduced in SBT as well. Here are the produce steps:\n- Enable `hadoop.caller.context.enabled`.\n- Replace `Class.forName` with `Utils.classForName` in `object CallerContext`.\n- Ignore `ReplSuite.test(\"propagation of local properties\")`.\n- Run `ReplSuite` using SBT.\n\nThis PR just creates a singleton MessageEncoder and MessageDecoder and makes sure they are created before switching to ExecutorClassLoader. TransportContext will be created when creating RpcEnv and that happens before creating ExecutorClassLoader.\n\n## How was this patch tested?\n\nJenkins\n\nAuthor: Shixiong Zhu <shixiong@databricks.com>\n\nCloses #16859 from zsxwing/SPARK-17714.\n","date":"2017-02-14 04:03:36","modifiedFileCount":"5","status":"M","submitter":"Shixiong Zhu"},{"authorTime":"2017-12-21 19:43:56","codes":[{"authorDate":"2017-12-21 19:43:56","commitOrder":3,"curCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeOneInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","date":"2017-12-21 19:43:56","endLine":64,"groupId":"1054","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testServerToClient","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bc/94f7ca63a96ef604c278433e880113b45de535.src","preCode":"  private void testServerToClient(Message msg) {\n    EmbeddedChannel serverChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    serverChannel.writeOutbound(msg);\n\n    EmbeddedChannel clientChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!serverChannel.outboundMessages().isEmpty()) {\n      clientChannel.writeInbound(serverChannel.readOutbound());\n    }\n\n    assertEquals(1, clientChannel.inboundMessages().size());\n    assertEquals(msg, clientChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"M"},{"authorDate":"2017-12-21 19:43:56","commitOrder":3,"curCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeOneInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","date":"2017-12-21 19:43:56","endLine":80,"groupId":"1054","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testClientToServer","params":"(Messagemsg)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bc/94f7ca63a96ef604c278433e880113b45de535.src","preCode":"  private void testClientToServer(Message msg) {\n    EmbeddedChannel clientChannel = new EmbeddedChannel(new FileRegionEncoder(),\n      MessageEncoder.INSTANCE);\n    clientChannel.writeOutbound(msg);\n\n    EmbeddedChannel serverChannel = new EmbeddedChannel(\n        NettyUtils.createFrameDecoder(), MessageDecoder.INSTANCE);\n\n    while (!clientChannel.outboundMessages().isEmpty()) {\n      serverChannel.writeInbound(clientChannel.readOutbound());\n    }\n\n    assertEquals(1, serverChannel.inboundMessages().size());\n    assertEquals(msg, serverChannel.readInbound());\n  }\n","realPath":"common/network-common/src/test/java/org/apache/spark/network/ProtocolSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"}],"commitId":"59d52631eb86394f1d981419cb744c20bd4e0b87","commitMessage":"@@@[SPARK-22324][SQL][PYTHON] Upgrade Arrow to 0.8.0\n\n## What changes were proposed in this pull request?\n\nUpgrade Spark to Arrow 0.8.0 for Java and Python.  Also includes an upgrade of Netty to 4.1.17 to resolve dependency requirements.\n\nThe highlights that pertain to Spark for the update from Arrow versoin 0.4.1 to 0.8.0 include:\n\n* Java refactoring for more simple API\n* Java reduced heap usage and streamlined hot code paths\n* Type support for DecimalType.  ArrayType\n* Improved type casting support in Python\n* Simplified type checking in Python\n\n## How was this patch tested?\n\nExisting tests\n\nAuthor: Bryan Cutler <cutlerb@gmail.com>\nAuthor: Shixiong Zhu <zsxwing@gmail.com>\n\nCloses #19884 from BryanCutler/arrow-upgrade-080-SPARK-22324.\n","date":"2017-12-21 19:43:56","modifiedFileCount":"6","status":"M","submitter":"Bryan Cutler"}]
