[{"authorTime":"2015-12-08 15:26:34","codes":[{"authorDate":"2015-09-24 13:49:08","commitOrder":4,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    DataFrame dataset = jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").take(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2015-09-24 13:49:08","endLine":85,"groupId":"210","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/00/174e6a683d60c11696503af080a0b67362280e.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    DataFrame dataset = jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").take(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"NB"},{"authorDate":"2015-12-08 15:26:34","commitOrder":4,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    DataFrame dataset = jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","date":"2015-12-08 15:26:34","endLine":71,"groupId":"210","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/4d/5cb04ff5e2bf86cada0eca63f9b33724a5bbf2.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    DataFrame dataset = jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"B"}],"commitId":"78209b0ccaf3f22b5e2345dfb2b98edfdb746819","commitMessage":"@@@[SPARK-11551][DOC][EXAMPLE] Replace example code in ml-features.md using include_example\n\nMade new patch contaning only markdown examples moved to exmaple/folder.\nOny three  java code were not shfted since they were contaning compliation error . these classes are\n1)StandardScale 2)NormalizerExample 3)VectorIndexer\n\nAuthor: Xusen Yin <yinxusen@gmail.com>\nAuthor: somideshmukh <somilde@us.ibm.com>\n\nCloses #10002 from somideshmukh/SomilBranch1.33.\n","date":"2015-12-08 15:26:34","modifiedFileCount":"0","status":"M","submitter":"somideshmukh"},{"authorTime":"2016-03-11 09:00:17","codes":[{"authorDate":"2016-03-11 09:00:17","commitOrder":5,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeRows(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-03-11 09:00:17","endLine":85,"groupId":"210","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b8/7605ebfd6a3d29ae40c4952af1b4aacf03fcc6.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    DataFrame dataset = jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").take(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"},{"authorDate":"2016-03-11 09:00:17","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","date":"2016-03-11 09:00:17","endLine":72,"groupId":"210","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2a/e57c3577eff057659ff4679f9c5b21656c6293.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    DataFrame dataset = jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    DataFrame output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"M"}],"commitId":"1d542785b9949e7f92025e6754973a779cc37c52","commitMessage":"@@@[SPARK-13244][SQL] Migrates DataFrame to Dataset\n\n## What changes were proposed in this pull request?\n\nThis PR unifies DataFrame and Dataset by migrating existing DataFrame operations to Dataset and make `DataFrame` a type alias of `Dataset[Row]`.\n\nMost Scala code changes are source compatible.  but Java API is broken as Java knows nothing about Scala type alias (mostly replacing `DataFrame` with `Dataset<Row>`).\n\nThere are several noticeable API changes related to those returning arrays:\n\n1.  `collect`/`take`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def collect(): Array[Row]\n        def take(n: Int): Array[Row]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def collect(): Array[T]\n        def take(n: Int): Array[T]\n\n        def collectRows(): Array[Row]\n        def takeRows(n: Int): Array[Row]\n        ```\n\n    Two specialized methods `collectRows` and `takeRows` are added because Java doesn't support returning generic arrays. Thus.  for example.  `DataFrame.collect(): Array[T]` actually returns `Object` instead of `Array<T>` from Java side.\n\n    Normally.  Java users may fall back to `collectAsList` and `takeAsList`.  The two new specialized versions are added to avoid performance regression in ML related code (but maybe I'm wrong and they are not necessary here).\n\n1.  `randomSplit`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[DataFrame]\n        def randomSplit(weights: Array[Double]): Array[DataFrame]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[Dataset[T]]\n        def randomSplit(weights: Array[Double]): Array[Dataset[T]]\n        ```\n\n    Similar problem as above.  but hasn't been addressed for Java API yet.  We can probably add `randomSplitAsList` to fix this one.\n\n1.  `groupBy`\n\n    Some original `DataFrame.groupBy` methods have conflicting signature with original `Dataset.groupBy` methods.  To distinguish these two.  typed `Dataset.groupBy` methods are renamed to `groupByKey`.\n\nOther noticeable changes:\n\n1.  Dataset always do eager analysis now\n\n    We used to support disabling DataFrame eager analysis to help reporting partially analyzed malformed logical plan on analysis failure.  However.  Dataset encoders requires eager analysi during Dataset construction.  To preserve the error reporting feature.  `AnalysisException` now takes an extra `Option[LogicalPlan]` argument to hold the partially analyzed plan.  so that we can check the plan tree when reporting test failures.  This plan is passed by `QueryExecution.assertAnalyzed`.\n\n## How was this patch tested?\n\nExisting tests do the work.\n\n## TODO\n\n- [ ] Fix all tests\n- [ ] Re-enable MiMA check\n- [ ] Update ScalaDoc (`since`.  `group`.  and example code)\n\nAuthor: Cheng Lian <lian@databricks.com>\nAuthor: Yin Huai <yhuai@databricks.com>\nAuthor: Wenchen Fan <wenchen@databricks.com>\nAuthor: Cheng Lian <liancheng@users.noreply.github.com>\n\nCloses #11443 from liancheng/ds-to-df.\n","date":"2016-03-11 09:00:17","modifiedFileCount":"87","status":"M","submitter":"Cheng Lian"},{"authorTime":"2016-03-11 09:00:17","codes":[{"authorDate":"2016-03-13 12:02:52","commitOrder":6,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-03-13 12:02:52","endLine":85,"groupId":"210","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e2/da11183b93f1ccf30fc3826dd7d63493cdb817.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeRows(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"},{"authorDate":"2016-03-11 09:00:17","commitOrder":6,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","date":"2016-03-11 09:00:17","endLine":72,"groupId":"210","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2a/e57c3577eff057659ff4679f9c5b21656c6293.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"N"}],"commitId":"c079420d7c55d8972db716a2695a5ddd606d11cd","commitMessage":"@@@[SPARK-13841][SQL] Removes Dataset.collectRows()/takeRows()\n\n## What changes were proposed in this pull request?\n\nThis PR removes two methods.  `collectRows()` and `takeRows()`.  from `Dataset[T]`. These methods were added in PR #11443.  and were later considered not useful.\n\n## How was this patch tested?\n\nExisting tests should do the work.\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #11678 from liancheng/remove-collect-rows-and-take-rows.\n","date":"2016-03-13 12:02:52","modifiedFileCount":"16","status":"M","submitter":"Cheng Lian"},{"authorTime":"2016-05-05 05:31:36","codes":[{"authorDate":"2016-03-13 12:02:52","commitOrder":7,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-03-13 12:02:52","endLine":85,"groupId":"210","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e2/da11183b93f1ccf30fc3826dd7d63493cdb817.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"},{"authorDate":"2016-05-05 05:31:36","commitOrder":7,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaVectorSlicerExample\").getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":69,"groupId":"210","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/4f/1ea824a3a9f267eabe2a39252dbf851493740d.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaVectorSlicerExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext jsql = new SQLContext(jsc);\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    ));\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(jrdd, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"}],"commitId":"cdce4e62a5674e2034e5d395578b1a60e3d8c435","commitMessage":"@@@[SPARK-15031][EXAMPLE] Use SparkSession in Scala/Python/Java example.\n\n## What changes were proposed in this pull request?\n\nThis PR aims to update Scala/Python/Java examples by replacing `SQLContext` with newly added `SparkSession`.\n\n- Use **SparkSession Builder Pattern** in 154(Scala 55.  Java 52.  Python 47) files.\n- Add `getConf` in Python SparkContext class: `python/pyspark/context.py`\n- Replace **SQLContext Singleton Pattern** with **SparkSession Singleton Pattern**:\n  - `SqlNetworkWordCount.scala`\n  - `JavaSqlNetworkWordCount.java`\n  - `sql_network_wordcount.py`\n\nNow.  `SQLContexts` are used only in R examples and the following two Python examples. The python examples are untouched in this PR since it already fails some unknown issue.\n- `simple_params_example.py`\n- `aft_survival_regression.py`\n\n## How was this patch tested?\n\nManual.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #12809 from dongjoon-hyun/SPARK-15031.\n","date":"2016-05-05 05:31:36","modifiedFileCount":"52","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-05-05 05:31:36","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":8,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":85,"groupId":"210","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/59/ad3c2f61e8578cd9452820e8e1d4e0d25bf24f.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n        jsql.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"M"},{"authorDate":"2016-05-05 05:31:36","commitOrder":8,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaVectorSlicerExample\").getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":69,"groupId":"210","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/4f/1ea824a3a9f267eabe2a39252dbf851493740d.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaVectorSlicerExample\").getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"N"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"},{"authorTime":"2016-08-06 03:57:46","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":9,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":85,"groupId":"210","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/59/ad3c2f61e8578cd9452820e8e1d4e0d25bf24f.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"},{"authorDate":"2016-08-06 03:57:46","commitOrder":9,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n    output.show(false);\n    \r\n\n    spark.stop();\n  }\n","date":"2016-08-06 03:57:46","endLine":72,"groupId":"210","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/19/22514c87dff3b1647a6fc884208d08fec17815.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    System.out.println(output.select(\"userFeatures\", \"features\").first());\n    \r\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"}],"commitId":"180fd3e0a3426db200c97170926afb60751dfd0e","commitMessage":"@@@[SPARK-16421][EXAMPLES][ML] Improve ML Example Outputs\n\n## What changes were proposed in this pull request?\nImprove example outputs to better reflect the functionality that is being presented.  This mostly consisted of modifying what was printed at the end of the example.  such as calling show() with truncate=False.  but sometimes required minor tweaks in the example data to get relevant output.  Explicitly set parameters when they are used as part of the example.  Fixed Java examples that failed to run because of using old-style MLlib Vectors or problem with schema.  Synced examples between different APIs.\n\n## How was this patch tested?\nRan each example for Scala.  Python.  and Java and made sure output was legible on a terminal of width 100.\n\nAuthor: Bryan Cutler <cutlerb@gmail.com>\n\nCloses #14308 from BryanCutler/ml-examples-improve-output-SPARK-16260.\n","date":"2016-08-06 03:57:46","modifiedFileCount":"27","status":"M","submitter":"Bryan Cutler"},{"authorTime":"2017-02-20 01:37:56","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":10,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":85,"groupId":"210","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/59/ad3c2f61e8578cd9452820e8e1d4e0d25bf24f.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":58,"status":"N"},{"authorDate":"2017-02-20 01:37:56","commitOrder":10,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = {\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n    output.show(false);\n    \r\n\n    spark.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":71,"groupId":"210","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/1a/e48be2660bca8981c0c11fe9777e5a42181d32.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Lists.newArrayList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n    output.show(false);\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"M"}],"commitId":"de14d35f77071932963a994fac5aec0e5df838a1","commitMessage":"@@@[SPARK-19533][EXAMPLES] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert Java tests to use lambdas.  Java 8 features.\n\n## How was this patch tested?\n\nJenkins tests.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16961 from srowen/SPARK-19533.\n","date":"2017-02-20 01:37:56","modifiedFileCount":"52","status":"M","submitter":"Sean Owen"},{"authorTime":"2017-02-20 01:37:56","codes":[{"authorDate":"2019-11-04 03:21:28","commitOrder":11,"curCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(2, features.size());\n    }\n  }\n","date":"2019-11-04 03:21:28","endLine":68,"groupId":"10491","id":15,"instanceNumber":1,"isCurCommit":1,"methodName":"vectorSlice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b9/bca9d5a3be3478111996504438131ad4e1da13.src","preCode":"  public void vectorSlice() {\n    Attribute[] attrs = new Attribute[]{\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n\n    for (Row r : output.select(\"userFeatures\", \"features\").takeAsList(2)) {\n      Vector features = r.getAs(1);\n      Assert.assertEquals(features.size(), 2);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaVectorSlicerSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"M"},{"authorDate":"2017-02-20 01:37:56","commitOrder":11,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = {\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n    output.show(false);\n    \r\n\n    spark.stop();\n  }\n","date":"2017-02-20 01:37:56","endLine":71,"groupId":"10491","id":16,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/1a/e48be2660bca8981c0c11fe9777e5a42181d32.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaVectorSlicerExample\")\n      .getOrCreate();\n\n    \r\n    Attribute[] attrs = {\n      NumericAttribute.defaultAttr().withName(\"f1\"),\n      NumericAttribute.defaultAttr().withName(\"f2\"),\n      NumericAttribute.defaultAttr().withName(\"f3\")\n    };\n    AttributeGroup group = new AttributeGroup(\"userFeatures\", attrs);\n\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Vectors.sparse(3, new int[]{0, 1}, new double[]{-2.0, 2.3})),\n      RowFactory.create(Vectors.dense(-2.0, 2.3, 0.0))\n    );\n\n    Dataset<Row> dataset =\n      spark.createDataFrame(data, (new StructType()).add(group.toStructField()));\n\n    VectorSlicer vectorSlicer = new VectorSlicer()\n      .setInputCol(\"userFeatures\").setOutputCol(\"features\");\n\n    vectorSlicer.setIndices(new int[]{1}).setNames(new String[]{\"f3\"});\n    \r\n\n    Dataset<Row> output = vectorSlicer.transform(dataset);\n    output.show(false);\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"N"}],"commitId":"80a89873b20aa07e2522bed5da0fc50e616246d9","commitMessage":"@@@[SPARK-29733][TESTS] Fix wrong order of parameters passed to `assertEquals`\n\n\n What changes were proposed in this pull request?\nThe `assertEquals` method of JUnit Assert requires the first parameter to be the expected value. In this PR.  I propose to change the order of parameters when the expected value is passed as the second parameter.\n\n\n Why are the changes needed?\nWrong order of assert parameters confuses when the assert fails and the parameters have special string representation. For example:\n```java\nassertEquals(input1.add(input2).  new CalendarInterval(5.  5.  367200000000L));\n```\n```\njava.lang.AssertionError:\nExpected :interval 5 months 5 days 101 hours\nActual   :interval 5 months 5 days 102 hours\n```\n\n\n Does this PR introduce any user-facing change?\nNo\n\n\n How was this patch tested?\nBy existing tests.\n\nCloses #26377 from MaxGekk/fix-order-in-assert-equals.\n\nAuthored-by: Maxim Gekk <max.gekk@gmail.com>\nSigned-off-by: Dongjoon Hyun <dhyun@apple.com>\n","date":"2019-11-04 03:21:28","modifiedFileCount":"21","status":"M","submitter":"Maxim Gekk"}]
