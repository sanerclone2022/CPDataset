[{"authorTime":"2014-09-27 00:58:47","codes":[{"authorDate":"2014-08-01 03:55:00","commitOrder":2,"curCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2014-08-01 03:55:00","endLine":65,"groupId":"55","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"tfIdf","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e8/d99f4ae43aecb7b04cd5b09d5b9f5854ec41ec.src","preCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":49,"status":"NB"},{"authorDate":"2014-09-27 00:58:47","commitOrder":2,"curCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2014-09-27 00:58:47","endLine":84,"groupId":"103","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"tfIdfMinimumDocumentFrequency","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/06/4263e02cd11cf2b418a494585af7428c426a63.src","preCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"B"}],"commitId":"ec9df6a765701fa41390083df12e1dc1fee50662","commitMessage":"@@@[SPARK-3614][MLLIB] Add minimumOccurence filtering to IDF\n\nThis PR for [SPARK-3614](https://issues.apache.org/jira/browse/SPARK-3614) adds functionality for filtering out terms which do not appear in at least a minimum number of documents.\n\nThis is implemented using a minimumOccurence parameter (default 0).  When terms' document frequencies are less than minimumOccurence.  their IDFs are set to 0.  just like when the DF is 0.  As a result.  the TF-IDFs for the terms are found to be 0.  as if the terms were not present in the documents.\n\nThis PR makes the following changes:\n* Add a minimumOccurence parameter to the IDF and DocumentFrequencyAggregator classes.\n* Create a parameter-less constructor for IDF with a default minimumOccurence value of 0 to remain backwards-compatibility with the original IDF API.\n* Sets the IDFs to 0 for terms which DFs are less than minimumOccurence\n* Add tests to the Spark IDFSuite and Java JavaTfIdfSuite test suites\n* Updated the MLLib Feature Extraction programming guide to describe the new feature\n\nAuthor: RJ Nowling <rnowling@gmail.com>\n\nCloses #2494 from rnowling/spark-3614-idf-filter and squashes the following commits:\n\n0aa3c63 [RJ Nowling] Fix identation\ne6523a8 [RJ Nowling] Remove unnecessary toDouble's from IDFSuite\nbfa82ec [RJ Nowling] Add space after if\n30d20b3 [RJ Nowling] Add spaces around equals signs\n9013447 [RJ Nowling] Add space before division operator\n79978fc [RJ Nowling] Remove unnecessary semi-colon\n40fd70c [RJ Nowling] Change minimumOccurence to minDocFreq in code and docs\n47850ab [RJ Nowling] Changed minimumOccurence to Int from Long\n9fb4093 [RJ Nowling] Remove unnecessary lines from IDF class docs\n1fc09d8 [RJ Nowling] Add backwards-compatible constructor to DocumentFrequencyAggregator\n1801fd2 [RJ Nowling] Fix style errors in IDF.scala\n6897252 [RJ Nowling] Preface minimumOccurence members with val to make them final and immutable\na200bab [RJ Nowling] Remove unnecessary else statement\n4b974f5 [RJ Nowling] Remove accidentally-added import from testing\nc0cc643 [RJ Nowling] Add minimumOccurence filtering to IDF\n","date":"2014-09-27 00:58:47","modifiedFileCount":"1","status":"M","submitter":"RJ Nowling"},{"authorTime":"2014-12-25 05:32:51","codes":[{"authorDate":"2014-12-25 05:32:51","commitOrder":3,"curCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2014-12-25 05:32:51","endLine":66,"groupId":"55","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"tfIdf","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fb/c26167ce66f15d261d6fde5f62f4bd08eb0e60.src","preCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":49,"status":"M"},{"authorDate":"2014-12-25 05:32:51","commitOrder":3,"curCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2014-12-25 05:32:51","endLine":86,"groupId":"103","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"tfIdfMinimumDocumentFrequency","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fb/c26167ce66f15d261d6fde5f62f4bd08eb0e60.src","preCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"M"}],"commitId":"29fabb1b528e60b2f65132a9ab64f2fd95b729ba","commitMessage":"@@@SPARK-4297 [BUILD] Build warning fixes omnibus\n\nThere are a number of warnings generated in a normal.  successful build right now. They're mostly Java unchecked cast warnings.  which can be suppressed. But there's a grab bag of other Scala language warnings and so on that can all be easily fixed. The forthcoming PR fixes about 90% of the build warnings I see now.\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #3157 from srowen/SPARK-4297 and squashes the following commits:\n\n8c9e469 [Sean Owen] Suppress unchecked cast warnings.  and several other build warning fixes\n","date":"2014-12-25 05:32:51","modifiedFileCount":"6","status":"M","submitter":"Sean Owen"},{"authorTime":"2015-08-28 01:46:41","codes":[{"authorDate":"2015-08-28 01:46:41","commitOrder":4,"curCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = sc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":65,"groupId":"761","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"tfIdf","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8a/320afa4b13d9d73c1244bbc93158f4876719f7.src","preCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"M"},{"authorDate":"2015-08-28 01:46:41","commitOrder":4,"curCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = sc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":85,"groupId":"763","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"tfIdfMinimumDocumentFrequency","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8a/320afa4b13d9d73c1244bbc93158f4876719f7.src","preCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<ArrayList<String>> documents = sc.parallelize(Lists.newArrayList(\n      Lists.newArrayList(\"this is a sentence\".split(\" \")),\n      Lists.newArrayList(\"this is another sentence\".split(\" \")),\n      Lists.newArrayList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"}],"commitId":"e1f4de4a7d15d4ca4b5c64ff929ac3980f5d706f","commitMessage":"@@@[SPARK-10257] [MLLIB] Removes Guava from all spark.mllib Java tests\n\n* Replaces instances of `Lists.newArrayList` with `Arrays.asList`\n* Replaces `commons.lang.StringUtils` over `com.google.collections.Strings`\n* Replaces `List` interface over `ArrayList` implementations\n\nThis PR along with #8445 #8446 #8447 completely removes all `com.google.collections.Lists` dependencies within mllib's Java tests.\n\nAuthor: Feynman Liang <fliang@databricks.com>\n\nCloses #8451 from feynmanliang/SPARK-10257.\n","date":"2015-08-28 01:46:41","modifiedFileCount":"14","status":"M","submitter":"Feynman Liang"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":5,"curCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = jsc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v : localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":71,"groupId":"10475","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"tfIdf","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/de/50fb8c4fdb26e3b710935cac98603d496576c4.src","preCode":"  public void tfIdf() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = sc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF();\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":5,"curCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = jsc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v : localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":91,"groupId":"10475","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"tfIdfMinimumDocumentFrequency","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/de/50fb8c4fdb26e3b710935cac98603d496576c4.src","preCode":"  public void tfIdfMinimumDocumentFrequency() {\n    \r\n    HashingTF tf = new HashingTF();\n    @SuppressWarnings(\"unchecked\")\n    JavaRDD<List<String>> documents = sc.parallelize(Arrays.asList(\n      Arrays.asList(\"this is a sentence\".split(\" \")),\n      Arrays.asList(\"this is another sentence\".split(\" \")),\n      Arrays.asList(\"this is still a sentence\".split(\" \"))), 2);\n    JavaRDD<Vector> termFreqs = tf.transform(documents);\n    termFreqs.collect();\n    IDF idf = new IDF(2);\n    JavaRDD<Vector> tfIdfs = idf.fit(termFreqs).transform(termFreqs);\n    List<Vector> localTfIdfs = tfIdfs.collect();\n    int indexOfThis = tf.indexOf(\"this\");\n    for (Vector v: localTfIdfs) {\n      Assert.assertEquals(0.0, v.apply(indexOfThis), 1e-15);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/feature/JavaTfIdfSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":74,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"}]
