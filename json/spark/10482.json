[{"authorTime":"2015-02-06 15:43:47","codes":[{"authorDate":"2015-02-06 15:43:47","commitOrder":1,"curCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2015-02-06 15:43:47","endLine":55,"groupId":"2222","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/26/284023b0f69ad4da818d9634232fd25165aabc.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/classification/JavaLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"B"},{"authorDate":"2015-02-06 15:43:47","commitOrder":1,"curCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLinearRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2015-02-06 15:43:47","endLine":51,"groupId":"2222","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/5b/d616e74d86cb006d62be2ec5cb5226eb89996d.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLinearRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/regression/JavaLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"B"}],"commitId":"dc0c4490a12ecedd8ca5a1bb256c7ccbdf0be04f","commitMessage":"@@@[SPARK-4789] [SPARK-4942] [SPARK-5031] [mllib] Standardize ML Prediction APIs\n\nThis is part (1a) of the updates from the design doc in [https://docs.google.com/document/d/1BH9el33kBX8JiDdgUJXdLW14CA2qhTCWIG46eXZVoJs]\n\n**UPDATE**: Most of the APIs are being kept private[spark] to allow further discussion.  Here is a list of changes which are public:\n* new output columns: rawPrediction.  probabilities\n  * The ?score? column is now called ?rawPrediction?\n* Classifiers now provide numClasses\n* Params.get and .set are now protected instead of private[ml].\n* ParamMap now has a size method.\n* new classes: LinearRegression.  LinearRegressionModel\n* LogisticRegression now has an intercept.\n\n\n Sketch of APIs (most of which are private[spark] for now)\n\nAbstract classes for learning algorithms (+ corresponding Model abstractions):\n* Classifier (+ ClassificationModel)\n* ProbabilisticClassifier (+ ProbabilisticClassificationModel)\n* Regressor (+ RegressionModel)\n* Predictor (+ PredictionModel)\n* *For all of these*:\n * There is no strongly typed training-time API.\n * There is a strongly typed test-time (prediction) API which helps developers implement new algorithms.\n\nConcrete classes: learning algorithms\n* LinearRegression\n* LogisticRegression (updated to use new abstract classes)\n * Also.  removed \"score\" in favor of \"probability\" output column.  Changed BinaryClassificationEvaluator to match. (SPARK-5031)\n\nOther updates:\n* params.scala: Changed Params.set/get to be protected instead of private[ml]\n * This was needed for the example of defining a class from outside of the MLlib namespace.\n* VectorUDT: Will later change from private[spark] to public.\n * This is needed for outside users to write their own validateAndTransformSchema() methods using vectors.\n * Also.  added equals() method.f\n* SPARK-4942 : ML Transformers should allow output cols to be turned on. off\n * Update validateAndTransformSchema\n * Update transform\n* (Updated examples.  test suites according to other changes)\n\nNew examples:\n* DeveloperApiExample.scala (example of defining algorithm from outside of the MLlib namespace)\n * Added Java version too\n\nTest Suites:\n* LinearRegressionSuite\n* LogisticRegressionSuite\n* + Java versions of above suites\n\nCC: mengxr  etrain  shivaram\n\nAuthor: Joseph K. Bradley <joseph@databricks.com>\n\nCloses #3637 from jkbradley/ml-api-part1 and squashes the following commits:\n\n405bfb8 [Joseph K. Bradley] Last edits based on code review.  Small cleanups\nfec348a [Joseph K. Bradley] Added JavaDeveloperApiExample.java and fixed other issues: Made developer API private[spark] for now. Added constructors Java can understand to specialized Param types.\n8316d5e [Joseph K. Bradley] fixes after rebasing on master\nfc62406 [Joseph K. Bradley] fixed test suites after last commit\nbcb9549 [Joseph K. Bradley] Fixed issues after rebasing from master (after move from SchemaRDD to DataFrame)\n9872424 [Joseph K. Bradley] fixed JavaLinearRegressionSuite.java Java sql api\nf542997 [Joseph K. Bradley] Added MIMA excludes for VectorUDT (now public).  and added DeveloperApi annotation to it\n216d199 [Joseph K. Bradley] fixed after sql datatypes PR got merged\nf549e34 [Joseph K. Bradley] Updates based on code review.  Major ones are: * Created weakly typed Predictor.train() method which is called by fit() so that developers do not have to call schema validation or copy parameters. * Made Predictor.featuresDataType have a default value of VectorUDT.   * NOTE: This could be dangerous since the FeaturesType type parameter cannot have a default value.\n343e7bd [Joseph K. Bradley] added blanket mima exclude for ml package\n82f340b [Joseph K. Bradley] Fixed bug in LogisticRegression (introduced in this PR).  Fixed Java suites\n0a16da9 [Joseph K. Bradley] Fixed Linear/Logistic RegressionSuites\nc3c8da5 [Joseph K. Bradley] small cleanup\n934f97b [Joseph K. Bradley] Fixed bugs from previous commit.\n1c61723 [Joseph K. Bradley] * Made ProbabilisticClassificationModel into a subclass of ClassificationModel.  Also introduced ProbabilisticClassifier.  * This was to support output column ?probabilityCol? in transform().\n4e2f711 [Joseph K. Bradley] rat fix\nbc654e1 [Joseph K. Bradley] Added spark.ml LinearRegressionSuite\n8d13233 [Joseph K. Bradley] Added methods: * Classifier: batch predictRaw() * Predictor: train() without paramMap ProbabilisticClassificationModel.predictProbabilities() * Java versions of all above batch methods + others\n1680905 [Joseph K. Bradley] Added JavaLabeledPointSuite.java for spark.ml.  and added constructor to LabeledPoint which defaults weight to 1.0\nadbe50a [Joseph K. Bradley] * fixed LinearRegression train() to use embedded paramMap * added Predictor.predict(RDD[Vector]) method * updated Linear/LogisticRegressionSuites\n58802e3 [Joseph K. Bradley] added train() to Predictor subclasses which does not take a ParamMap.\n57d54ab [Joseph K. Bradley] * Changed semantics of Predictor.train() to merge the given paramMap with the embedded paramMap. * remove threshold_internal from logreg * Added Predictor.copy() * Extended LogisticRegressionSuite\ne433872 [Joseph K. Bradley] Updated docs.  Added LabeledPointSuite to spark.ml\n54b7b31 [Joseph K. Bradley] Fixed issue with logreg threshold being set correctly\n0617d61 [Joseph K. Bradley] Fixed bug from last commit (sorting paramMap by parameter names in toString).  Fixed bug in persisting logreg data.  Added threshold_internal to logreg for faster test-time prediction (avoiding map lookup).\n601e792 [Joseph K. Bradley] Modified ParamMap to sort parameters in toString.  Cleaned up classes in class hierarchy.  before implementing tests and examples.\nd705e87 [Joseph K. Bradley] Added LinearRegression and Regressor back from ml-api branch\n52f4fde [Joseph K. Bradley] removing everything except for simple class hierarchy for classification\nd35bb5d [Joseph K. Bradley] fixed compilation issues.  but have not added tests yet\nbfade12 [Joseph K. Bradley] Added lots of classes for new ML API:\n","date":"2015-02-06 15:43:47","modifiedFileCount":"5","status":"B","submitter":"Joseph K. Bradley"},{"authorTime":"2015-02-11 11:40:12","codes":[{"authorDate":"2015-02-11 11:40:12","commitOrder":2,"curCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2015-02-11 11:40:12","endLine":55,"groupId":"2222","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3f/8e59de0f05c47f6edc7b5367ba6e98864a465c.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/classification/JavaLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"M"},{"authorDate":"2015-02-11 11:40:12","commitOrder":2,"curCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLinearRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2015-02-11 11:40:12","endLine":51,"groupId":"2222","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0c/c36c8d56d705dd1be9636f44a890e281ca82de.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLinearRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.applySchema(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/regression/JavaLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"ea60284095cad43aa7ac98256576375d0e91a52a","commitMessage":"@@@[SPARK-5704] [SQL] [PySpark] createDataFrame from RDD with columns\n\nDeprecate inferSchema() and applySchema().  use createDataFrame() instead.  which could take an optional `schema` to create an DataFrame from an RDD. The `schema` could be StructType or list of names of columns.\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #4498 from davies/create and squashes the following commits:\n\n08469c1 [Davies Liu] remove Scala/Java API for now\nc80a7a9 [Davies Liu] fix hive test\nd1bd8f2 [Davies Liu] cleanup applySchema\n9526e97 [Davies Liu] createDataFrame from RDD with columns\n","date":"2015-02-11 11:40:12","modifiedFileCount":"9","status":"M","submitter":"Davies Liu"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":3,"curCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLogisticRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2016-05-11 02:17:47","endLine":58,"groupId":"1959","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e3/ff68364e69026d300c4059094fcea321e351ab.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/classification/JavaLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":3,"curCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLinearRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","date":"2016-05-11 02:17:47","endLine":54,"groupId":"1959","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/00/c59f08b679af05ef8f0032a3ab987416be4b7e.src","preCode":"  public void setUp() {\n    jsc = new JavaSparkContext(\"local\", \"JavaLinearRegressionSuite\");\n    jsql = new SQLContext(jsc);\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = jsql.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/regression/JavaLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"},{"authorTime":"2016-05-18 09:01:59","codes":[{"authorDate":"2016-05-18 09:01:59","commitOrder":4,"curCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLogisticRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","date":"2016-05-18 09:01:59","endLine":58,"groupId":"1959","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b8/da04c26a49d44c2a78e21392cba52005a659d2.src","preCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLogisticRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/classification/JavaLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"M"},{"authorDate":"2016-05-18 09:01:59","commitOrder":4,"curCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLinearRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","date":"2016-05-18 09:01:59","endLine":54,"groupId":"1959","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/12/6aa6298f3de771b361a8d2ee70e36a887a3f9a.src","preCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLinearRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.registerTempTable(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/regression/JavaLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"25b315e6cad7c27b62dcaa2c194293c1115fdfb3","commitMessage":"@@@[SPARK-15171][SQL] Remove the references to deprecated method dataset.registerTempTable\n\n## What changes were proposed in this pull request?\n\nUpdate the unit test code.  examples.  and documents to remove calls to deprecated method `dataset.registerTempTable`.\n\n## How was this patch tested?\n\nThis PR only changes the unit test code.  examples.  and comments. It should be safe.\nThis is a follow up of PR https://github.com/apache/spark/pull/12945 which was merged.\n\nAuthor: Sean Zhong <seanzhong@databricks.com>\n\nCloses #13098 from clockfly/spark-15171-remove-deprecation.\n","date":"2016-05-18 09:01:59","modifiedFileCount":"9","status":"M","submitter":"Sean Zhong"},{"authorTime":"2016-05-20 11:38:44","codes":[{"authorDate":"2016-05-20 11:38:44","commitOrder":5,"curCode":"  public void setUp() throws IOException {\n    super.setUp();\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","date":"2016-05-20 11:38:44","endLine":48,"groupId":"10482","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/00/4102103d52c67bc65ccd251b671aa6378fe077.src","preCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLogisticRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/classification/JavaLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2016-05-20 11:38:44","commitOrder":5,"curCode":"  public void setUp() throws IOException {\n    super.setUp();\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","date":"2016-05-20 11:38:44","endLine":44,"groupId":"10482","id":10,"instanceNumber":2,"isCurCommit":1,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/6c/dcdda1a6480c78a755841b6832e5e86e69d2b8.src","preCode":"  public void setUp() {\n    spark = SparkSession.builder()\n      .master(\"local\")\n      .appName(\"JavaLinearRegressionSuite\")\n      .getOrCreate();\n    jsc = new JavaSparkContext(spark.sparkContext());\n    List<LabeledPoint> points = generateLogisticInputAsList(1.0, 1.0, 100, 42);\n    datasetRDD = jsc.parallelize(points, 2);\n    dataset = spark.createDataFrame(datasetRDD, LabeledPoint.class);\n    dataset.createOrReplaceTempView(\"dataset\");\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/regression/JavaLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":38,"status":"M"}],"commitId":"01cf649c4f96f64fb4bd09e0e1811cabcc5ead2e","commitMessage":"@@@[SPARK-15296][MLLIB] Refactor All Java Tests that use SparkSession\n\n## What changes were proposed in this pull request?\nRefactor All Java Tests that use SparkSession.  to extend SharedSparkSesion\n\n## How was this patch tested?\nExisting Tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #13101 from techaddict/SPARK-15296.\n","date":"2016-05-20 11:38:44","modifiedFileCount":"58","status":"M","submitter":"Sandeep Singh"}]
