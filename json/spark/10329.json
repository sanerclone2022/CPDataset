[{"authorTime":"2015-08-03 14:41:16","codes":[{"authorDate":"2015-08-03 14:41:16","commitOrder":3,"curCode":"  public InternalRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","date":"2015-08-03 14:41:16","endLine":273,"groupId":"3179","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/03/74846d71674ef523773211a42b0b40e687ca06.src","preCode":"  public InternalRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":265,"status":"B"},{"authorDate":"2015-08-03 14:41:16","commitOrder":3,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","date":"2015-08-03 14:41:16","endLine":421,"groupId":"1365","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c5/d42d73a43a4a1758e830d614526cafa5b02e39.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"MB"}],"commitId":"608353c8e8e50461fafff91a2c885dca8af3aaa8","commitMessage":"@@@[SPARK-9404][SPARK-9542][SQL] unsafe array data and map data\n\nThis PR adds a UnsafeArrayData.  current we encode it in this way:\n\nfirst 4 bytes is the # elements\nthen each 4 byte is the start offset of the element.  unless it is negative.  in which case the element is null.\nfollowed by the elements themselves\n\nan example:  [10.  11.  12.  13.  null.  14] will be encoded as:\n5.  28.  32.  36.  40.  -44.  44.  10.  11.  12.  13.  14\n\nNote that.  when we read a UnsafeArrayData from bytes.  we can read the first 4 bytes as numElements and take the rest(first 4 bytes skipped) as value region.\n\nunsafe map data just use 2 unsafe array data.  first 4 bytes is # of elements.  second 4 bytes is numBytes of key array.  the follows key array data and value array data.\n\nAuthor: Wenchen Fan <cloud0fan@outlook.com>\n\nCloses #7752 from cloud-fan/unsafe-array and squashes the following commits:\n\n3269bd7 [Wenchen Fan] fix a bug\n6445289 [Wenchen Fan] add unit tests\n49adf26 [Wenchen Fan] add unsafe map\n20d1039 [Wenchen Fan] add comments and unsafe converter\n821b8db [Wenchen Fan] add unsafe array\n","date":"2015-08-03 14:41:16","modifiedFileCount":"3","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2015-08-03 14:41:16","codes":[{"authorDate":"2015-10-06 04:00:58","commitOrder":4,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","date":"2015-10-06 04:00:58","endLine":266,"groupId":"3179","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/da/9538b3f13cc2f4d448ac16447e3058afe0e634.src","preCode":"  public InternalRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2015-08-03 14:41:16","commitOrder":4,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","date":"2015-08-03 14:41:16","endLine":421,"groupId":"1365","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c5/d42d73a43a4a1758e830d614526cafa5b02e39.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"N"}],"commitId":"c4871369db96fc33c465d11b3bbd1ffeb3b94e89","commitMessage":"@@@[SPARK-10585] [SQL] only copy data once when generate unsafe projection\n\nThis PR is a completely rewritten of GenerateUnsafeProjection.  to accomplish the goal of copying data only once. The old code of GenerateUnsafeProjection is still there to reduce review difficulty.\n\nInstead of creating unsafe conversion code for struct.  array and map.  we create code of writing the content to the global row buffer.\n\nAuthor: Wenchen Fan <cloud0fan@163.com>\nAuthor: Wenchen Fan <cloud0fan@outlook.com>\n\nCloses #8747 from cloud-fan/copy-once.\n","date":"2015-10-06 04:00:58","modifiedFileCount":"6","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2015-10-22 10:20:31","codes":[{"authorDate":"2015-10-06 04:00:58","commitOrder":5,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","date":"2015-10-06 04:00:58","endLine":266,"groupId":"3179","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/da/9538b3f13cc2f4d448ac16447e3058afe0e634.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"N"},{"authorDate":"2015-10-22 10:20:31","commitOrder":5,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) offsetAndSize;\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","date":"2015-10-22 10:20:31","endLine":454,"groupId":"2775","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/85/0838af9be359e2c65178b0ba79a662e241e654.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":443,"status":"M"}],"commitId":"1d9733271595596683a6d956a7433fa601df1cc1","commitMessage":"@@@[SPARK-11243][SQL] output UnsafeRow from columnar cache\n\nThis PR change InMemoryTableScan to output UnsafeRow.  and optimize the unrolling and scanning by coping the bytes for var-length types between UnsafeRow and ByteBuffer directly without creating the wrapper objects. When scanning the decimals in TPC-DS store_sales table.  it's 80% faster (copy it as long without create Decimal objects).\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #9203 from davies/unsafe_cache.\n","date":"2015-10-22 10:20:31","modifiedFileCount":"3","status":"M","submitter":"Davies Liu"},{"authorTime":"2015-12-31 14:16:37","codes":[{"authorDate":"2015-12-31 14:16:37","commitOrder":6,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow(numFields);\n    row.pointTo(baseObject, baseOffset + offset, size);\n    return row;\n  }\n","date":"2015-12-31 14:16:37","endLine":276,"groupId":"51","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/80df227151d1118c508a998815019502aa75a0.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow();\n    row.pointTo(baseObject, baseOffset + offset, numFields, size);\n    return row;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"M"},{"authorDate":"2015-12-31 14:16:37","commitOrder":6,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) offsetAndSize;\n      final UnsafeRow row = new UnsafeRow(numFields);\n      row.pointTo(baseObject, baseOffset + offset, size);\n      return row;\n    }\n  }\n","date":"2015-12-31 14:16:37","endLine":458,"groupId":"2775","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/74/92b88c471a4447e7bc3393bc3f74ce2c2f5fe9.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) offsetAndSize;\n      final UnsafeRow row = new UnsafeRow();\n      row.pointTo(baseObject, baseOffset + offset, numFields, size);\n      return row;\n    }\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":447,"status":"M"}],"commitId":"e6c77874b915691dead91e8d96ad9f58ba3a73db","commitMessage":"@@@[SPARK-12585] [SQL] move numFields to constructor of UnsafeRow\n\nRight now.  numFields will be passed in by pointTo().  then bitSetWidthInBytes is calculated.  making pointTo() a little bit heavy.\n\nIt should be part of constructor of UnsafeRow.\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #10528 from davies/numFields.\n","date":"2015-12-31 14:16:37","modifiedFileCount":"6","status":"M","submitter":"Davies Liu"},{"authorTime":"2015-12-31 14:16:37","codes":[{"authorDate":"2016-09-27 14:18:32","commitOrder":7,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeRow row = new UnsafeRow(numFields);\n    row.pointTo(baseObject, baseOffset + offset, size);\n    return row;\n  }\n","date":"2016-09-27 14:18:32","endLine":265,"groupId":"10329","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/86/523c14740157e32d534185bdc170733f7476b4.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeRow row = new UnsafeRow(numFields);\n    row.pointTo(baseObject, baseOffset + offset, size);\n    return row;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":257,"status":"M"},{"authorDate":"2015-12-31 14:16:37","commitOrder":7,"curCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) offsetAndSize;\n      final UnsafeRow row = new UnsafeRow(numFields);\n      row.pointTo(baseObject, baseOffset + offset, size);\n      return row;\n    }\n  }\n","date":"2015-12-31 14:16:37","endLine":458,"groupId":"10329","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getStruct","params":"(intordinal@intnumFields)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/74/92b88c471a4447e7bc3393bc3f74ce2c2f5fe9.src","preCode":"  public UnsafeRow getStruct(int ordinal, int numFields) {\n    if (isNullAt(ordinal)) {\n      return null;\n    } else {\n      final long offsetAndSize = getLong(ordinal);\n      final int offset = (int) (offsetAndSize >> 32);\n      final int size = (int) offsetAndSize;\n      final UnsafeRow row = new UnsafeRow(numFields);\n      row.pointTo(baseObject, baseOffset + offset, size);\n      return row;\n    }\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":447,"status":"N"}],"commitId":"85b0a157543201895557d66306b38b3ca52f2151","commitMessage":"@@@[SPARK-15962][SQL] Introduce implementation with a dense format for UnsafeArrayData\n\n## What changes were proposed in this pull request?\n\nThis PR introduces more compact representation for ```UnsafeArrayData```.\n\n```UnsafeArrayData``` needs to accept ```null``` value in each entry of an array. In the current version.  it has three parts\n```\n[numElements] [offsets] [values]\n```\n`Offsets` has the number of `numElements`.  and represents `null` if its value is negative. It may increase memory footprint.  and introduces an indirection for accessing each of `values`.\n\nThis PR uses bitvectors to represent nullability for each element like `UnsafeRow`.  and eliminates an indirection for accessing each element. The new ```UnsafeArrayData``` has four parts.\n```\n[numElements][null bits][values or offset&length][variable length portion]\n```\nIn the `null bits` region.  we store 1 bit per element.  represents whether an element is null. Its total size is ceil(numElements / 8) bytes.  and it is aligned to 8-byte boundaries.\nIn the `values or offset&length` region.  we store the content of elements. For fields that hold fixed-length primitive types.  such as long.  double.  or int.  we store the value directly in the field. For fields with non-primitive or variable-length values.  we store a relative offset (w.r.t. the base address of the array) that points to the beginning of the variable-length field and length (they are combined into a long). Each is word-aligned. For `variable length portion`.  each is aligned to 8-byte boundaries.\n\nThe new format can reduce memory footprint and improve performance of accessing each element. An example of memory foot comparison:\n1024x1024 elements integer array\nSize of ```baseObject``` for ```UnsafeArrayData```: 8 + 1024x1024 + 1024x1024 = 2M bytes\nSize of ```baseObject``` for ```UnsafeArrayData```: 8 + 1024x1024/8 + 1024x1024 = 1.25M bytes\n\nIn summary.  we got 1.0-2.6x performance improvements over the code before applying this PR.\nHere are performance results of [benchmark programs](https://github.com/kiszk/spark/blob/04d2e4b6dbdc4eff43ce18b3c9b776e0129257c7/sql/core/src/test/scala/org/apache/spark/sql/execution/benchmark/UnsafeArrayDataBenchmark.scala):\n\n**Read UnsafeArrayData**: 1.7x and 1.6x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.4.11-200.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nRead UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            430 /  436        390.0           2.6       1.0X\nDouble                                         456 /  485        367.8           2.7       0.9X\n\nWith SPARK-15962\nRead UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            252 /  260        666.1           1.5       1.0X\nDouble                                         281 /  292        597.7           1.7       0.9X\n````\n**Write UnsafeArrayData**: 1.0x and 1.1x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nWrite UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            203 /  273        103.4           9.7       1.0X\nDouble                                         239 /  356         87.9          11.4       0.8X\n\nWith SPARK-15962\nWrite UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            196 /  249        107.0           9.3       1.0X\nDouble                                         227 /  367         92.3          10.8       0.9X\n````\n\n**Get primitive array from UnsafeArrayData**: 2.6x and 1.6x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nGet primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            207 /  217        304.2           3.3       1.0X\nDouble                                         257 /  363        245.2           4.1       0.8X\n\nWith SPARK-15962\nGet primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            151 /  198        415.8           2.4       1.0X\nDouble                                         214 /  394        293.6           3.4       0.7X\n````\n\n**Create UnsafeArrayData from primitive array**: 1.7x and 2.1x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nCreate UnsafeArrayData from primitive array: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            340 /  385        185.1           5.4       1.0X\nDouble                                         479 /  705        131.3           7.6       0.7X\n\nWith SPARK-15962\nCreate UnsafeArrayData from primitive array: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            206 /  211        306.0           3.3       1.0X\nDouble                                         232 /  406        271.6           3.7       0.9X\n````\n\n1.7x and 1.4x performance improvements in [```UDTSerializationBenchmark```](https://github.com/apache/spark/blob/master/mllib/src/test/scala/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.scala)  over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.4.11-200.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nVectorUDT de/serialization:              Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nserialize                                      442 /  533          0.0      441927.1       1.0X\ndeserialize                                    217 /  274          0.0      217087.6       2.0X\n\nWith SPARK-15962\nVectorUDT de/serialization:              Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nserialize                                      265 /  318          0.0      265138.5       1.0X\ndeserialize                                    155 /  197          0.0      154611.4       1.7X\n````\n\n## How was this patch tested?\n\nAdded unit tests into ```UnsafeArraySuite```\n\nAuthor: Kazuaki Ishizaki <ishizaki@jp.ibm.com>\n\nCloses #13680 from kiszk/SPARK-15962.\n","date":"2016-09-27 14:18:32","modifiedFileCount":"4","status":"M","submitter":"Kazuaki Ishizaki"}]
