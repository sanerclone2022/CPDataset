[{"authorTime":"2016-04-22 07:48:51","codes":[{"authorDate":"2016-04-22 07:48:51","commitOrder":1,"curCode":"  public static int sort(\n      LongArray array, int numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","date":"2016-04-22 07:48:51","endLine":65,"groupId":"1244","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"sort","params":"(LongArrayarray@intnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  public static int sort(\n      LongArray array, int numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"B"},{"authorDate":"2016-04-22 07:48:51","commitOrder":1,"curCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      int numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords * 2;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","date":"2016-04-22 07:48:51","endLine":201,"groupId":"1244","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"sortKeyPrefixArray","params":"(LongArrayarray@intnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      int numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords * 2;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":174,"status":"B"}],"commitId":"e2b5647ab92eb478b3f7b36a0ce6faf83e24c0e5","commitMessage":"@@@[SPARK-14724] Use radix sort for shuffles and sort operator when possible\n\n## What changes were proposed in this pull request?\n\nSpark currently uses TimSort for all in-memory sorts.  including sorts done for shuffle. One low-hanging fruit is to use radix sort when possible (e.g. sorting by integer keys). This PR adds a radix sort implementation to the unsafe sort package and switches shuffles and sorts to use it when possible.\n\nThe current implementation does not have special support for null values.  so we cannot radix-sort `LongType`. I will address this in a follow-up PR.\n\n## How was this patch tested?\n\nUnit tests.  enabling radix sort on existing tests. Microbenchmark results:\n\n```\nRunning benchmark: radix sort 25000000\nJava HotSpot(TM) 64-Bit Server VM 1.8.0_66-b17 on Linux 3.13.0-44-generic\nIntel(R) Core(TM) i7-4600U CPU  2.10GHz\n\nradix sort 25000000:                Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n-------------------------------------------------------------------------------------------\nreference TimSort key prefix array     15546 / 15859          1.6         621.9       1.0X\nreference Arrays.sort                    2416 / 2446         10.3          96.6       6.4X\nradix sort one byte                       133 /  137        188.4           5.3     117.2X\nradix sort two bytes                      255 /  258         98.2          10.2      61.1X\nradix sort eight bytes                    991 /  997         25.2          39.6      15.7X\nradix sort key prefix array              1540 / 1563         16.2          61.6      10.1X\n```\n\nI also ran a mix of the supported TPCDS queries and compared TimSort vs RadixSort metrics. The overall benchmark ran ~10% faster with radix sort on. In the breakdown below.  the radix-enabled sort phases averaged about 20x faster than TimSort.  however sorting is only a small fraction of the overall runtime. About half of the TPCDS queries were able to take advantage of radix sort.\n\n```\nTPCDS on master: 2499s real time.  8185s executor\n    - 1171s in TimSort.  avg 267 MB/s\n(note the /s accounting is weird here since dataSize counts the record sizes too)\n\nTPCDS with radix enabled: 2294s real time.  7391s executor\n    - 596s in TimSort.  avg 254 MB/s\n    - 26s in radix sort.  avg 4.2 GB/s\n```\n\ncc davies rxin\n\nAuthor: Eric Liang <ekl@databricks.com>\n\nCloses #12490 from ericl/sort-benchmark.\n","date":"2016-04-22 07:48:51","modifiedFileCount":"12","status":"B","submitter":"Eric Liang"},{"authorTime":"2016-06-12 06:42:58","codes":[{"authorDate":"2016-04-22 07:48:51","commitOrder":2,"curCode":"  public static int sort(\n      LongArray array, int numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","date":"2016-04-22 07:48:51","endLine":65,"groupId":"1244","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"sort","params":"(LongArrayarray@intnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  public static int sort(\n      LongArray array, int numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"},{"authorDate":"2016-06-12 06:42:58","commitOrder":2,"curCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      int startIndex,\n      int numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    int inIndex = startIndex;\n    int outIndex = startIndex + numRecords * 2;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(\n        array, startIndex, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","date":"2016-06-12 06:42:58","endLine":206,"groupId":"0","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"sortKeyPrefixArray","params":"(LongArrayarray@intstartIndex@intnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/40/4361734a55ba3ad5975dfc3f9523be93890db9.src","preCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      int numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords * 2;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":177,"status":"M"}],"commitId":"c06c58bbbb2de0c22cfc70c486d23a94c3079ba4","commitMessage":"@@@[SPARK-14851][CORE] Support radix sort with nullable longs\n\n## What changes were proposed in this pull request?\n\nThis adds support for radix sort of nullable long fields. When a sort field is null and radix sort is enabled.  we keep nulls in a separate region of the sort buffer so that radix sort does not need to deal with them. This also has performance benefits when sorting smaller integer types.  since the current representation of nulls in two's complement (Long.MIN_VALUE) otherwise forces a full-width radix sort.\n\nThis strategy for nulls does mean the sort is no longer stable. cc davies\n\n## How was this patch tested?\n\nExisting randomized sort tests for correctness. I also tested some TPCDS queries and there does not seem to be any significant regression for non-null sorts.\n\nSome test queries (best of 5 runs each).\nBefore change:\nscala> val start = System.nanoTime; spark.range(5000000).selectExpr(\"if(id > 5.  cast(hash(id) as long).  NULL) as h\").coalesce(1).orderBy(\"h\").collect(); (System.nanoTime - start) / 1e6\nstart: Long = 3190437233227987\nres3: Double = 4716.471091\n\nAfter change:\nscala> val start = System.nanoTime; spark.range(5000000).selectExpr(\"if(id > 5.  cast(hash(id) as long).  NULL) as h\").coalesce(1).orderBy(\"h\").collect(); (System.nanoTime - start) / 1e6\nstart: Long = 3190367870952791\nres4: Double = 2981.143045\n\nAuthor: Eric Liang <ekl@databricks.com>\n\nCloses #13161 from ericl/sc-2998.\n","date":"2016-06-12 06:42:58","modifiedFileCount":"7","status":"M","submitter":"Eric Liang"},{"authorTime":"2016-11-20 13:50:20","codes":[{"authorDate":"2016-11-20 13:50:20","commitOrder":3,"curCode":"  public static int sort(\n      LongArray array, long numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    long inIndex = 0;\n    long outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          long tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return Ints.checkedCast(inIndex);\n  }\n","date":"2016-11-20 13:50:20","endLine":67,"groupId":"10578","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"sort","params":"(LongArrayarray@longnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/d318471008bb0b1134b8ac2d775c72a4dc308a.src","preCode":"  public static int sort(\n      LongArray array, int numRecords, int startByteIndex, int endByteIndex,\n      boolean desc, boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 2 <= array.size();\n    int inIndex = 0;\n    int outIndex = numRecords;\n    if (numRecords > 0) {\n      long[][] counts = getCounts(array, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"},{"authorDate":"2016-11-20 13:50:20","commitOrder":3,"curCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      long startIndex,\n      long numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    long inIndex = startIndex;\n    long outIndex = startIndex + numRecords * 2L;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(\n        array, startIndex, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          long tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return Ints.checkedCast(inIndex);\n  }\n","date":"2016-11-20 13:50:20","endLine":208,"groupId":"10578","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"sortKeyPrefixArray","params":"(LongArrayarray@longstartIndex@longnumRecords@intstartByteIndex@intendByteIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/d318471008bb0b1134b8ac2d775c72a4dc308a.src","preCode":"  public static int sortKeyPrefixArray(\n      LongArray array,\n      int startIndex,\n      int numRecords,\n      int startByteIndex,\n      int endByteIndex,\n      boolean desc,\n      boolean signed) {\n    assert startByteIndex >= 0 : \"startByteIndex (\" + startByteIndex + \") should >= 0\";\n    assert endByteIndex <= 7 : \"endByteIndex (\" + endByteIndex + \") should <= 7\";\n    assert endByteIndex > startByteIndex;\n    assert numRecords * 4 <= array.size();\n    int inIndex = startIndex;\n    int outIndex = startIndex + numRecords * 2;\n    if (numRecords > 0) {\n      long[][] counts = getKeyPrefixArrayCounts(\n        array, startIndex, numRecords, startByteIndex, endByteIndex);\n      for (int i = startByteIndex; i <= endByteIndex; i++) {\n        if (counts[i] != null) {\n          sortKeyPrefixArrayAtByte(\n            array, numRecords, counts[i], i, inIndex, outIndex,\n            desc, signed && i == endByteIndex);\n          int tmp = inIndex;\n          inIndex = outIndex;\n          outIndex = tmp;\n        }\n      }\n    }\n    return inIndex;\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"M"}],"commitId":"d93b6552473468df297a08c0bef9ea0bf0f5c13a","commitMessage":"@@@[SPARK-18458][CORE] Fix signed integer overflow problem at an expression in RadixSort.java\n\n## What changes were proposed in this pull request?\n\nThis PR avoids that a result of an expression is negative due to signed integer overflow (e.g. 0x10?????? * 8 < 0). This PR casts each operand to `long` before executing a calculation. Since the result is interpreted as long.  the result of the expression is positive.\n\n## How was this patch tested?\n\nManually executed query82 of TPC-DS with 100TB\n\nAuthor: Kazuaki Ishizaki <ishizaki@jp.ibm.com>\n\nCloses #15907 from kiszk/SPARK-18458.\n","date":"2016-11-20 13:50:20","modifiedFileCount":"2","status":"M","submitter":"Kazuaki Ishizaki"}]
