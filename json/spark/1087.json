[{"authorTime":"2016-02-29 09:25:07","codes":[{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  public void fetchChunk(\n      long streamId,\n      final int chunkIndex,\n      final ChunkReceivedCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n\n    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n      new ChannelFutureListener() {\n        @Override\n        public void operationComplete(ChannelFuture future) throws Exception {\n          if (future.isSuccess()) {\n            long timeTaken = System.currentTimeMillis() - startTime;\n            logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n              timeTaken);\n          } else {\n            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n              serverAddr, future.cause());\n            logger.error(errorMsg, future.cause());\n            handler.removeFetchRequest(streamChunkId);\n            channel.close();\n            try {\n              callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n            } catch (Exception e) {\n              logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n            }\n          }\n        }\n      });\n  }\n","date":"2016-02-29 09:25:07","endLine":167,"groupId":"556","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchChunk","params":"(longstreamId@finalintchunkIndex@finalChunkReceivedCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e1/5f096d36913f9887bc6efcb8c0b6c041dd9dd7.src","preCode":"  public void fetchChunk(\n      long streamId,\n      final int chunkIndex,\n      final ChunkReceivedCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n\n    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n      new ChannelFutureListener() {\n        @Override\n        public void operationComplete(ChannelFuture future) throws Exception {\n          if (future.isSuccess()) {\n            long timeTaken = System.currentTimeMillis() - startTime;\n            logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n              timeTaken);\n          } else {\n            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n              serverAddr, future.cause());\n            logger.error(errorMsg, future.cause());\n            handler.removeFetchRequest(streamChunkId);\n            channel.close();\n            try {\n              callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n            } catch (Exception e) {\n              logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n            }\n          }\n        }\n      });\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"B"},{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  public void stream(final String streamId, final StreamCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending stream request for {} to {}\", streamId, serverAddr);\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(\n        new ChannelFutureListener() {\n          @Override\n          public void operationComplete(ChannelFuture future) throws Exception {\n            if (future.isSuccess()) {\n              long timeTaken = System.currentTimeMillis() - startTime;\n              logger.trace(\"Sending request for {} to {} took {} ms\", streamId, serverAddr,\n                timeTaken);\n            } else {\n              String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n                serverAddr, future.cause());\n              logger.error(errorMsg, future.cause());\n              channel.close();\n              try {\n                callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n              } catch (Exception e) {\n                logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n              }\n            }\n          }\n        });\n    }\n  }\n","date":"2016-02-29 09:25:07","endLine":207,"groupId":"559","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"stream","params":"(finalStringstreamId@finalStreamCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/e1/5f096d36913f9887bc6efcb8c0b6c041dd9dd7.src","preCode":"  public void stream(final String streamId, final StreamCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending stream request for {} to {}\", streamId, serverAddr);\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(\n        new ChannelFutureListener() {\n          @Override\n          public void operationComplete(ChannelFuture future) throws Exception {\n            if (future.isSuccess()) {\n              long timeTaken = System.currentTimeMillis() - startTime;\n              logger.trace(\"Sending request for {} to {} took {} ms\", streamId, serverAddr,\n                timeTaken);\n            } else {\n              String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n                serverAddr, future.cause());\n              logger.error(errorMsg, future.cause());\n              channel.close();\n              try {\n                callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n              } catch (Exception e) {\n                logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n              }\n            }\n          }\n        });\n    }\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":175,"status":"B"}],"commitId":"9e01dcc6446f8648e61062f8afe62589b9d4b5ab","commitMessage":"@@@[SPARK-13529][BUILD] Move network/* modules into common/network-*\n\n## What changes were proposed in this pull request?\nAs the title says.  this moves the three modules currently in network/ into common/network-*. This removes one top level.  non-user-facing folder.\n\n## How was this patch tested?\nCompilation and existing tests. We should run both SBT and Maven.\n\nAuthor: Reynold Xin <rxin@databricks.com>\n\nCloses #11409 from rxin/SPARK-13529.\n","date":"2016-02-29 09:25:07","modifiedFileCount":"1","status":"B","submitter":"Reynold Xin"},{"authorTime":"2016-08-26 02:57:38","codes":[{"authorDate":"2016-08-26 02:57:38","commitOrder":2,"curCode":"  public void fetchChunk(\n      long streamId,\n      final int chunkIndex,\n      final ChunkReceivedCallback callback) {\n    final long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n      new ChannelFutureListener() {\n        @Override\n        public void operationComplete(ChannelFuture future) throws Exception {\n          if (future.isSuccess()) {\n            long timeTaken = System.currentTimeMillis() - startTime;\n            if (logger.isTraceEnabled()) {\n              logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId, getRemoteAddress(channel),\n                timeTaken);\n            }\n          } else {\n            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n              getRemoteAddress(channel), future.cause());\n            logger.error(errorMsg, future.cause());\n            handler.removeFetchRequest(streamChunkId);\n            channel.close();\n            try {\n              callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n            } catch (Exception e) {\n              logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n            }\n          }\n        }\n      });\n  }\n","date":"2016-08-26 02:57:38","endLine":170,"groupId":"430","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchChunk","params":"(longstreamId@finalintchunkIndex@finalChunkReceivedCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a6/7683b89221836adb54f91edbcec754ad9591a3.src","preCode":"  public void fetchChunk(\n      long streamId,\n      final int chunkIndex,\n      final ChunkReceivedCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n\n    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n      new ChannelFutureListener() {\n        @Override\n        public void operationComplete(ChannelFuture future) throws Exception {\n          if (future.isSuccess()) {\n            long timeTaken = System.currentTimeMillis() - startTime;\n            logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n              timeTaken);\n          } else {\n            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n              serverAddr, future.cause());\n            logger.error(errorMsg, future.cause());\n            handler.removeFetchRequest(streamChunkId);\n            channel.close();\n            try {\n              callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n            } catch (Exception e) {\n              logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n            }\n          }\n        }\n      });\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"},{"authorDate":"2016-08-26 02:57:38","commitOrder":2,"curCode":"  public void stream(final String streamId, final StreamCallback callback) {\n    final long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(\n        new ChannelFutureListener() {\n          @Override\n          public void operationComplete(ChannelFuture future) throws Exception {\n            if (future.isSuccess()) {\n              long timeTaken = System.currentTimeMillis() - startTime;\n              if (logger.isTraceEnabled()) {\n                logger.trace(\"Sending request for {} to {} took {} ms\", streamId, getRemoteAddress(channel),\n                  timeTaken);\n              }\n            } else {\n              String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n                getRemoteAddress(channel), future.cause());\n              logger.error(errorMsg, future.cause());\n              channel.close();\n              try {\n                callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n              } catch (Exception e) {\n                logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n              }\n            }\n          }\n        });\n    }\n  }\n","date":"2016-08-26 02:57:38","endLine":213,"groupId":"431","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"stream","params":"(finalStringstreamId@finalStreamCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a6/7683b89221836adb54f91edbcec754ad9591a3.src","preCode":"  public void stream(final String streamId, final StreamCallback callback) {\n    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n    final long startTime = System.currentTimeMillis();\n    logger.debug(\"Sending stream request for {} to {}\", streamId, serverAddr);\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(\n        new ChannelFutureListener() {\n          @Override\n          public void operationComplete(ChannelFuture future) throws Exception {\n            if (future.isSuccess()) {\n              long timeTaken = System.currentTimeMillis() - startTime;\n              logger.trace(\"Sending request for {} to {} took {} ms\", streamId, serverAddr,\n                timeTaken);\n            } else {\n              String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n                serverAddr, future.cause());\n              logger.error(errorMsg, future.cause());\n              channel.close();\n              try {\n                callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n              } catch (Exception e) {\n                logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n              }\n            }\n          }\n        });\n    }\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":178,"status":"M"}],"commitId":"f2093107196b9af62908ecf15bac043f3b1e64c4","commitMessage":"@@@[SPARK-17231][CORE] Avoid building debug or trace log messages unless the respective log level is enabled\n\n(This PR addresses https://issues.apache.org/jira/browse/SPARK-17231)\n\n## What changes were proposed in this pull request?\n\nWhile debugging the performance of a large GraphX connected components computation.  we found several places in the `network-common` and `network-shuffle` code bases where trace or debug log messages are constructed even if the respective log level is disabled. According to YourKit.  these constructions were creating substantial churn in the eden region. Refactoring the respective code to avoid these unnecessary constructions except where necessary led to a modest but measurable reduction in our job's task time.  GC time and the ratio thereof.\n\n## How was this patch tested?\n\nWe computed the connected components of a graph with about 2.6 billion vertices and 1.7 billion edges four times. We used four different EC2 clusters each with 8 r3.8xl worker nodes. Two test runs used Spark master. Two used Spark master + this PR. The results from the first test run.  master and master+PR:\n![master](https://cloud.githubusercontent.com/assets/833693/17951634/7471cbca-6a18-11e6-9c26-78afe9319685.jpg)\n![logging_perf_improvements](https://cloud.githubusercontent.com/assets/833693/17951632/7467844e-6a18-11e6-9a0e-053dc7650413.jpg)\n\nThe results from the second test run.  master and master+PR:\n![master 2](https://cloud.githubusercontent.com/assets/833693/17951633/746dd6aa-6a18-11e6-8e27-606680b3f105.jpg)\n![logging_perf_improvements 2](https://cloud.githubusercontent.com/assets/833693/17951631/74488710-6a18-11e6-8a32-08692f373386.jpg)\n\nThough modest.  I believe these results are significant.\n\nAuthor: Michael Allman <michael@videoamp.com>\n\nCloses #14798 from mallman/spark-17231-logging_perf_improvements.\n","date":"2016-08-26 02:57:38","modifiedFileCount":"9","status":"M","submitter":"Michael Allman"},{"authorTime":"2017-02-16 20:32:45","codes":[{"authorDate":"2017-02-16 20:32:45","commitOrder":3,"curCode":"  public void fetchChunk(\n      long streamId,\n      int chunkIndex,\n      ChunkReceivedCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(future -> {\n      if (future.isSuccess()) {\n        long timeTaken = System.currentTimeMillis() - startTime;\n        if (logger.isTraceEnabled()) {\n          logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId,\n            getRemoteAddress(channel), timeTaken);\n        }\n      } else {\n        String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n          getRemoteAddress(channel), future.cause());\n        logger.error(errorMsg, future.cause());\n        handler.removeFetchRequest(streamChunkId);\n        channel.close();\n        try {\n          callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n        } catch (Exception e) {\n          logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n        }\n      }\n    });\n  }\n","date":"2017-02-16 20:32:45","endLine":164,"groupId":"430","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchChunk","params":"(longstreamId@intchunkIndex@ChunkReceivedCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a6/f527c118218992030d55069cfb553dbc8880e4.src","preCode":"  public void fetchChunk(\n      long streamId,\n      final int chunkIndex,\n      final ChunkReceivedCallback callback) {\n    final long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n      new ChannelFutureListener() {\n        @Override\n        public void operationComplete(ChannelFuture future) throws Exception {\n          if (future.isSuccess()) {\n            long timeTaken = System.currentTimeMillis() - startTime;\n            if (logger.isTraceEnabled()) {\n              logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId,\n                getRemoteAddress(channel), timeTaken);\n            }\n          } else {\n            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n              getRemoteAddress(channel), future.cause());\n            logger.error(errorMsg, future.cause());\n            handler.removeFetchRequest(streamChunkId);\n            channel.close();\n            try {\n              callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n            } catch (Exception e) {\n              logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n            }\n          }\n        }\n      });\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":132,"status":"M"},{"authorDate":"2017-02-16 20:32:45","commitOrder":3,"curCode":"  public void stream(String streamId, StreamCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(future -> {\n        if (future.isSuccess()) {\n          long timeTaken = System.currentTimeMillis() - startTime;\n          if (logger.isTraceEnabled()) {\n            logger.trace(\"Sending request for {} to {} took {} ms\", streamId,\n              getRemoteAddress(channel), timeTaken);\n          }\n        } else {\n          String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n            getRemoteAddress(channel), future.cause());\n          logger.error(errorMsg, future.cause());\n          channel.close();\n          try {\n            callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n          } catch (Exception e) {\n            logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n          }\n        }\n      });\n    }\n  }\n","date":"2017-02-16 20:32:45","endLine":203,"groupId":"431","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"stream","params":"(StringstreamId@StreamCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a6/f527c118218992030d55069cfb553dbc8880e4.src","preCode":"  public void stream(final String streamId, final StreamCallback callback) {\n    final long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(\n        new ChannelFutureListener() {\n          @Override\n          public void operationComplete(ChannelFuture future) throws Exception {\n            if (future.isSuccess()) {\n              long timeTaken = System.currentTimeMillis() - startTime;\n              if (logger.isTraceEnabled()) {\n                logger.trace(\"Sending request for {} to {} took {} ms\", streamId,\n                  getRemoteAddress(channel), timeTaken);\n              }\n            } else {\n              String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n                getRemoteAddress(channel), future.cause());\n              logger.error(errorMsg, future.cause());\n              channel.close();\n              try {\n                callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n              } catch (Exception e) {\n                logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n              }\n            }\n          }\n        });\n    }\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"M"}],"commitId":"0e2405490f2056728d1353abbac6f3ea177ae533","commitMessage":"@@@[SPARK-19550][BUILD][CORE][WIP] Remove Java 7 support\n\n- Move external/java8-tests tests into core.  streaming.  sql and remove\n- Remove MaxPermGen and related options\n- Fix some reflection / TODOs around Java 8+ methods\n- Update doc references to 1.7/1.8 differences\n- Remove Java 7/8 related build profiles\n- Update some plugins for better Java 8 compatibility\n- Fix a few Java-related warnings\n\nFor the future:\n\n- Update Java 8 examples to fully use Java 8\n- Update Java tests to use lambdas for simplicity\n- Update Java internal implementations to use lambdas\n\n## How was this patch tested?\n\nExisting tests\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16871 from srowen/SPARK-19493.\n","date":"2017-02-16 20:32:45","modifiedFileCount":"51","status":"M","submitter":"Sean Owen"},{"authorTime":"2017-06-30 10:56:48","codes":[{"authorDate":"2017-02-16 20:32:45","commitOrder":4,"curCode":"  public void fetchChunk(\n      long streamId,\n      int chunkIndex,\n      ChunkReceivedCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(future -> {\n      if (future.isSuccess()) {\n        long timeTaken = System.currentTimeMillis() - startTime;\n        if (logger.isTraceEnabled()) {\n          logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId,\n            getRemoteAddress(channel), timeTaken);\n        }\n      } else {\n        String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n          getRemoteAddress(channel), future.cause());\n        logger.error(errorMsg, future.cause());\n        handler.removeFetchRequest(streamChunkId);\n        channel.close();\n        try {\n          callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n        } catch (Exception e) {\n          logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n        }\n      }\n    });\n  }\n","date":"2017-02-16 20:32:45","endLine":164,"groupId":"430","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchChunk","params":"(longstreamId@intchunkIndex@ChunkReceivedCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a6/f527c118218992030d55069cfb553dbc8880e4.src","preCode":"  public void fetchChunk(\n      long streamId,\n      int chunkIndex,\n      ChunkReceivedCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(future -> {\n      if (future.isSuccess()) {\n        long timeTaken = System.currentTimeMillis() - startTime;\n        if (logger.isTraceEnabled()) {\n          logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId,\n            getRemoteAddress(channel), timeTaken);\n        }\n      } else {\n        String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n          getRemoteAddress(channel), future.cause());\n        logger.error(errorMsg, future.cause());\n        handler.removeFetchRequest(streamChunkId);\n        channel.close();\n        try {\n          callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n        } catch (Exception e) {\n          logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n        }\n      }\n    });\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":132,"status":"N"},{"authorDate":"2017-06-30 10:56:48","commitOrder":4,"curCode":"  public void stream(String streamId, StreamCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(streamId, callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(future -> {\n        if (future.isSuccess()) {\n          long timeTaken = System.currentTimeMillis() - startTime;\n          if (logger.isTraceEnabled()) {\n            logger.trace(\"Sending request for {} to {} took {} ms\", streamId,\n              getRemoteAddress(channel), timeTaken);\n          }\n        } else {\n          String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n            getRemoteAddress(channel), future.cause());\n          logger.error(errorMsg, future.cause());\n          channel.close();\n          try {\n            callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n          } catch (Exception e) {\n            logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n          }\n        }\n      });\n    }\n  }\n","date":"2017-06-30 10:56:48","endLine":203,"groupId":"431","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"stream","params":"(StringstreamId@StreamCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8f/354ad78bbaaa0b6a2ea2fdd3a477dc1b193157.src","preCode":"  public void stream(String streamId, StreamCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(future -> {\n        if (future.isSuccess()) {\n          long timeTaken = System.currentTimeMillis() - startTime;\n          if (logger.isTraceEnabled()) {\n            logger.trace(\"Sending request for {} to {} took {} ms\", streamId,\n              getRemoteAddress(channel), timeTaken);\n          }\n        } else {\n          String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n            getRemoteAddress(channel), future.cause());\n          logger.error(errorMsg, future.cause());\n          channel.close();\n          try {\n            callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n          } catch (Exception e) {\n            logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n          }\n        }\n      });\n    }\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"M"}],"commitId":"4996c53949376153f9ebdc74524fed7226968808","commitMessage":"@@@[SPARK-21253][CORE] Fix a bug that StreamCallback may not be notified if network errors happen\n\n## What changes were proposed in this pull request?\n\nIf a network error happens before processing StreamResponse/StreamFailure events.  StreamCallback.onFailure won't be called.\n\nThis PR fixes `failOutstandingRequests` to also notify outstanding StreamCallbacks.\n\n## How was this patch tested?\n\nThe new unit tests.\n\nAuthor: Shixiong Zhu <shixiong@databricks.com>\n\nCloses #18472 from zsxwing/fix-stream-2.\n","date":"2017-06-30 10:56:48","modifiedFileCount":"3","status":"M","submitter":"Shixiong Zhu"},{"authorTime":"2018-06-27 06:56:58","codes":[{"authorDate":"2018-06-27 06:56:58","commitOrder":5,"curCode":"  public void fetchChunk(\n      long streamId,\n      int chunkIndex,\n      ChunkReceivedCallback callback) {\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    StdChannelListener listener = new StdChannelListener(streamChunkId) {\n      @Override\n      void handleFailure(String errorMsg, Throwable cause) {\n        handler.removeFetchRequest(streamChunkId);\n        callback.onFailure(chunkIndex, new IOException(errorMsg, cause));\n      }\n    };\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(listener);\n  }\n","date":"2018-06-27 06:56:58","endLine":151,"groupId":"1087","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"fetchChunk","params":"(longstreamId@intchunkIndex@ChunkReceivedCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/32/5225dc0ea2c34df632d7ae05b69742acd4b6b1.src","preCode":"  public void fetchChunk(\n      long streamId,\n      int chunkIndex,\n      ChunkReceivedCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, getRemoteAddress(channel));\n    }\n\n    StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n    handler.addFetchRequest(streamChunkId, callback);\n\n    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(future -> {\n      if (future.isSuccess()) {\n        long timeTaken = System.currentTimeMillis() - startTime;\n        if (logger.isTraceEnabled()) {\n          logger.trace(\"Sending request {} to {} took {} ms\", streamChunkId,\n            getRemoteAddress(channel), timeTaken);\n        }\n      } else {\n        String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n          getRemoteAddress(channel), future.cause());\n        logger.error(errorMsg, future.cause());\n        handler.removeFetchRequest(streamChunkId);\n        channel.close();\n        try {\n          callback.onFailure(chunkIndex, new IOException(errorMsg, future.cause()));\n        } catch (Exception e) {\n          logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n        }\n      }\n    });\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":132,"status":"M"},{"authorDate":"2018-06-27 06:56:58","commitOrder":5,"curCode":"  public void stream(String streamId, StreamCallback callback) {\n    StdChannelListener listener = new StdChannelListener(streamId) {\n      @Override\n      void handleFailure(String errorMsg, Throwable cause) throws Exception {\n        callback.onFailure(streamId, new IOException(errorMsg, cause));\n      }\n    };\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(streamId, callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(listener);\n    }\n  }\n","date":"2018-06-27 06:56:58","endLine":177,"groupId":"1087","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"stream","params":"(StringstreamId@StreamCallbackcallback)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/32/5225dc0ea2c34df632d7ae05b69742acd4b6b1.src","preCode":"  public void stream(String streamId, StreamCallback callback) {\n    long startTime = System.currentTimeMillis();\n    if (logger.isDebugEnabled()) {\n      logger.debug(\"Sending stream request for {} to {}\", streamId, getRemoteAddress(channel));\n    }\n\n    \r\n    \r\n    \r\n    synchronized (this) {\n      handler.addStreamCallback(streamId, callback);\n      channel.writeAndFlush(new StreamRequest(streamId)).addListener(future -> {\n        if (future.isSuccess()) {\n          long timeTaken = System.currentTimeMillis() - startTime;\n          if (logger.isTraceEnabled()) {\n            logger.trace(\"Sending request for {} to {} took {} ms\", streamId,\n              getRemoteAddress(channel), timeTaken);\n          }\n        } else {\n          String errorMsg = String.format(\"Failed to send request for %s to %s: %s\", streamId,\n            getRemoteAddress(channel), future.cause());\n          logger.error(errorMsg, future.cause());\n          channel.close();\n          try {\n            callback.onFailure(streamId, new IOException(errorMsg, future.cause()));\n          } catch (Exception e) {\n            logger.error(\"Uncaught exception in RPC response callback handler!\", e);\n          }\n        }\n      });\n    }\n  }\n","realPath":"common/network-common/src/main/java/org/apache/spark/network/client/TransportClient.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":159,"status":"M"}],"commitId":"16f2c3ea46a330bff7fae33f2521eb36a6280f04","commitMessage":"@@@[SPARK-6237][NETWORK] Network-layer changes to allow stream upload.\n\nThese changes allow an RPCHandler to receive an upload as a stream of\ndata.  without having to buffer the entire message in the FrameDecoder.\nThe primary use case is for replicating large blocks.  By itself.  this change is adding dead-code that is not being used -- it is a step towards SPARK-24296.\n\nAdded unit tests for handling streaming data.  including successfully sending data.  and failures in reading the stream with concurrent requests.\n\nSummary of changes:\n\n* Introduce a new UploadStream RPC which is sent to push a large payload as a stream (in contrast.  the pre-existing StreamRequest and StreamResponse RPCs are used for pull-based streaming).\n* Generalize RpcHandler.receive() to support requests which contain streams.\n* Generalize StreamInterceptor to handle both request and response messages (previously it only handled responses).\n* Introduce StdChannelListener to abstract away common logging logic in ChannelFuture listeners.\n\nAuthor: Imran Rashid <irashid@cloudera.com>\n\nCloses #21346 from squito/upload_stream.\n","date":"2018-06-27 06:56:58","modifiedFileCount":"11","status":"M","submitter":"Imran Rashid"}]
