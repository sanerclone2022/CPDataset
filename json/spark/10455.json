[{"authorTime":"2014-05-16 02:59:59","codes":[{"authorDate":"2014-03-24 08:34:02","commitOrder":4,"curCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","date":"2014-03-24 08:34:02","endLine":90,"groupId":"1923","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runKMeansUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/49/a614bd90caba308466b222bef9e31635939470.src","preCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":70,"status":"NB"},{"authorDate":"2014-05-16 02:59:59","commitOrder":4,"curCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","date":"2014-05-16 02:59:59","endLine":104,"groupId":"1923","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testPredictJavaRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0c/916ca3780346943d88c66be6498d8f650d92b9.src","preCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":93,"status":"B"}],"commitId":"d52761d67f42ad4d2ff02d96f0675fb3ab709f38","commitMessage":"@@@[SPARK-1741][MLLIB] add predict(JavaRDD) to RegressionModel.  ClassificationModel.  and KMeans\n\n`model.predict` returns a RDD of Scala primitive type (Int/Double).  which is recognized as Object in Java. Adding predict(JavaRDD) could make life easier for Java users.\n\nAdded tests for KMeans.  LinearRegression.  and NaiveBayes.\n\nWill update examples after https://github.com/apache/spark/pull/653 gets merged.\n\ncc: @srowen\n\nAuthor: Xiangrui Meng <meng@databricks.com>\n\nCloses #670 from mengxr/predict-javardd and squashes the following commits:\n\nb77ccd8 [Xiangrui Meng] Merge branch 'master' into predict-javardd\n43caac9 [Xiangrui Meng] add predict(JavaRDD) to RegressionModel.  ClassificationModel.  and KMeans\n","date":"2014-05-16 02:59:59","modifiedFileCount":"3","status":"M","submitter":"Xiangrui Meng"},{"authorTime":"2015-08-28 01:46:41","codes":[{"authorDate":"2015-08-28 01:46:41","commitOrder":5,"curCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","date":"2015-08-28 01:46:41","endLine":88,"groupId":"1923","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runKMeansUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ad/06676c72ac6e0750bbbdb223fd7b62ef3cd4f1.src","preCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"},{"authorDate":"2015-08-28 01:46:41","commitOrder":5,"curCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","date":"2015-08-28 01:46:41","endLine":102,"groupId":"1923","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testPredictJavaRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ad/06676c72ac6e0750bbbdb223fd7b62ef3cd4f1.src","preCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Lists.newArrayList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":91,"status":"M"}],"commitId":"e1f4de4a7d15d4ca4b5c64ff929ac3980f5d706f","commitMessage":"@@@[SPARK-10257] [MLLIB] Removes Guava from all spark.mllib Java tests\n\n* Replaces instances of `Lists.newArrayList` with `Arrays.asList`\n* Replaces `commons.lang.StringUtils` over `com.google.collections.Strings`\n* Replaces `List` interface over `ArrayList` implementations\n\nThis PR along with #8445 #8446 #8447 completely removes all `com.google.collections.Lists` dependencies within mllib's Java tests.\n\nAuthor: Feynman Liang <fliang@databricks.com>\n\nCloses #8451 from feynmanliang/SPARK-10257.\n","date":"2015-08-28 01:46:41","modifiedFileCount":"14","status":"M","submitter":"Feynman Liang"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":6,"curCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = jsc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","date":"2016-05-11 02:17:47","endLine":95,"groupId":"10455","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"runKMeansUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/4e/5b87f588e3dc412925bc01002415e8e7c8e23d.src","preCode":"  public void runKMeansUsingConstructor() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n\n    Vector expectedCenter = Vectors.dense(1.0, 3.0, 4.0);\n\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    assertEquals(1, model.clusterCenters().length);\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n\n    model = new KMeans()\n      .setK(1)\n      .setMaxIterations(1)\n      .setInitializationMode(KMeans.RANDOM())\n      .run(data.rdd());\n    assertEquals(expectedCenter, model.clusterCenters()[0]);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":6,"curCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = jsc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","date":"2016-05-11 02:17:47","endLine":109,"groupId":"10455","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testPredictJavaRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/4e/5b87f588e3dc412925bc01002415e8e7c8e23d.src","preCode":"  public void testPredictJavaRDD() {\n    List<Vector> points = Arrays.asList(\n      Vectors.dense(1.0, 2.0, 6.0),\n      Vectors.dense(1.0, 3.0, 0.0),\n      Vectors.dense(1.0, 4.0, 6.0)\n    );\n    JavaRDD<Vector> data = sc.parallelize(points, 2);\n    KMeansModel model = new KMeans().setK(1).setMaxIterations(5).run(data.rdd());\n    JavaRDD<Integer> predictions = model.predict(data);\n    \r\n    predictions.first();\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/clustering/JavaKMeansSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"}]
