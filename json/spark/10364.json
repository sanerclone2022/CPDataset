[{"authorTime":"2015-07-23 16:51:34","codes":[{"authorDate":"2015-08-03 14:41:16","commitOrder":4,"curCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      arrayDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    arrayCopy.pointTo(arrayDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numElements, sizeInBytes);\n    return arrayCopy;\n  }\n","date":"2015-08-03 14:41:16","endLine":332,"groupId":"2165","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/03/74846d71674ef523773211a42b0b40e687ca06.src","preCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      arrayDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    arrayCopy.pointTo(arrayDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numElements, sizeInBytes);\n    return arrayCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":320,"status":"B"},{"authorDate":"2015-07-23 16:51:34","commitOrder":4,"curCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","date":"2015-07-23 16:51:34","endLine":337,"groupId":"2165","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fa/1216b455a9e2aac9a010813c35fbb1301b4174.src","preCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":325,"status":"NB"}],"commitId":"608353c8e8e50461fafff91a2c885dca8af3aaa8","commitMessage":"@@@[SPARK-9404][SPARK-9542][SQL] unsafe array data and map data\n\nThis PR adds a UnsafeArrayData.  current we encode it in this way:\n\nfirst 4 bytes is the # elements\nthen each 4 byte is the start offset of the element.  unless it is negative.  in which case the element is null.\nfollowed by the elements themselves\n\nan example:  [10.  11.  12.  13.  null.  14] will be encoded as:\n5.  28.  32.  36.  40.  -44.  44.  10.  11.  12.  13.  14\n\nNote that.  when we read a UnsafeArrayData from bytes.  we can read the first 4 bytes as numElements and take the rest(first 4 bytes skipped) as value region.\n\nunsafe map data just use 2 unsafe array data.  first 4 bytes is # of elements.  second 4 bytes is numBytes of key array.  the follows key array data and value array data.\n\nAuthor: Wenchen Fan <cloud0fan@outlook.com>\n\nCloses #7752 from cloud-fan/unsafe-array and squashes the following commits:\n\n3269bd7 [Wenchen Fan] fix a bug\n6445289 [Wenchen Fan] add unit tests\n49adf26 [Wenchen Fan] add unsafe map\n20d1039 [Wenchen Fan] add comments and unsafe converter\n821b8db [Wenchen Fan] add unsafe array\n","date":"2015-08-03 14:41:16","modifiedFileCount":"3","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2015-08-11 23:41:06","codes":[{"authorDate":"2015-08-11 23:41:06","commitOrder":5,"curCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject, baseOffset, arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    arrayCopy.pointTo(arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, numElements, sizeInBytes);\n    return arrayCopy;\n  }\n","date":"2015-08-11 23:41:06","endLine":315,"groupId":"2777","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/50/1dff090313cef44b0b3a2d15dda5d4a607e56e.src","preCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      arrayDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    arrayCopy.pointTo(arrayDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numElements, sizeInBytes);\n    return arrayCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":308,"status":"M"},{"authorDate":"2015-08-11 23:41:06","commitOrder":5,"curCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      Platform.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, Platform.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","date":"2015-08-11 23:41:06","endLine":502,"groupId":"2777","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/7f/d94772090dfd440003dc247071418d20da31fc.src","preCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    PlatformDependent.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      PlatformDependent.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, PlatformDependent.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":490,"status":"M"}],"commitId":"d378396f86f625f006738d87fe5dbc2ff8fd913d","commitMessage":"@@@[SPARK-9815] Rename PlatformDependent.UNSAFE -> Platform.\n\nPlatformDependent.UNSAFE is way too verbose.\n\nAuthor: Reynold Xin <rxin@databricks.com>\n\nCloses #8094 from rxin/SPARK-9815 and squashes the following commits:\n\n229b603 [Reynold Xin] [SPARK-9815] Rename PlatformDependent.UNSAFE -> Platform.\n","date":"2015-08-11 23:41:06","modifiedFileCount":"30","status":"M","submitter":"Reynold Xin"},{"authorTime":"2015-08-11 23:41:06","codes":[{"authorDate":"2015-10-20 02:02:26","commitOrder":6,"curCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject, baseOffset, arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    arrayCopy.pointTo(arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    return arrayCopy;\n  }\n","date":"2015-10-20 02:02:26","endLine":340,"groupId":"2777","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/76/1f0447943e8e4ecd5033bdb287bf81679574e1.src","preCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject, baseOffset, arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    arrayCopy.pointTo(arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, numElements, sizeInBytes);\n    return arrayCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":333,"status":"M"},{"authorDate":"2015-08-11 23:41:06","commitOrder":6,"curCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      Platform.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, Platform.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","date":"2015-08-11 23:41:06","endLine":502,"groupId":"2777","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/7f/d94772090dfd440003dc247071418d20da31fc.src","preCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      Platform.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, Platform.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":490,"status":"N"}],"commitId":"7893cd95db5f2caba59ff5c859d7e4964ad7938d","commitMessage":"@@@[SPARK-11119] [SQL] cleanup for unsafe array and map\n\nThe purpose of this PR is to keep the unsafe format detail only inside the unsafe class itself.  so when we use them(like use unsafe array in unsafe map.  use unsafe array and map in columnar cache).  we don't need to understand the format before use them.\n\nchange list:\n* unsafe array's 4-bytes numElements header is now required(was optional).  and become a part of unsafe array format.\n* w.r.t the previous changing.  the `sizeInBytes` of unsafe array now counts the 4-bytes header.\n* unsafe map's format was `[numElements] [key array numBytes] [key array content(without numElements header)] [value array content(without numElements header)]` before.  which is a little hacky as it makes unsafe array's header optional. I think saving 4 bytes is not a big deal.  so the format is now: `[key array numBytes] [unsafe key array] [unsafe value array]`.\n* w.r.t the previous changing.  the `sizeInBytes` of unsafe map now counts both map's header and array's header.\n\nAuthor: Wenchen Fan <wenchen@databricks.com>\n\nCloses #9131 from cloud-fan/unsafe.\n","date":"2015-10-20 02:02:26","modifiedFileCount":"5","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2015-12-31 14:16:37","codes":[{"authorDate":"2015-10-20 02:02:26","commitOrder":7,"curCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject, baseOffset, arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    arrayCopy.pointTo(arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    return arrayCopy;\n  }\n","date":"2015-10-20 02:02:26","endLine":340,"groupId":"10364","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/76/1f0447943e8e4ecd5033bdb287bf81679574e1.src","preCode":"  public UnsafeArrayData copy() {\n    UnsafeArrayData arrayCopy = new UnsafeArrayData();\n    final byte[] arrayDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject, baseOffset, arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    arrayCopy.pointTo(arrayDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    return arrayCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":333,"status":"N"},{"authorDate":"2015-12-31 14:16:37","commitOrder":7,"curCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow(numFields);\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      Platform.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, Platform.BYTE_ARRAY_OFFSET, sizeInBytes);\n    return rowCopy;\n  }\n","date":"2015-12-31 14:16:37","endLine":505,"groupId":"10364","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"copy","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/74/92b88c471a4447e7bc3393bc3f74ce2c2f5fe9.src","preCode":"  public UnsafeRow copy() {\n    UnsafeRow rowCopy = new UnsafeRow();\n    final byte[] rowDataCopy = new byte[sizeInBytes];\n    Platform.copyMemory(\n      baseObject,\n      baseOffset,\n      rowDataCopy,\n      Platform.BYTE_ARRAY_OFFSET,\n      sizeInBytes\n    );\n    rowCopy.pointTo(rowDataCopy, Platform.BYTE_ARRAY_OFFSET, numFields, sizeInBytes);\n    return rowCopy;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":493,"status":"M"}],"commitId":"e6c77874b915691dead91e8d96ad9f58ba3a73db","commitMessage":"@@@[SPARK-12585] [SQL] move numFields to constructor of UnsafeRow\n\nRight now.  numFields will be passed in by pointTo().  then bitSetWidthInBytes is calculated.  making pointTo() a little bit heavy.\n\nIt should be part of constructor of UnsafeRow.\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #10528 from davies/numFields.\n","date":"2015-12-31 14:16:37","modifiedFileCount":"6","status":"M","submitter":"Davies Liu"}]
