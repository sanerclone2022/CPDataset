[{"authorTime":"2016-07-27 09:08:07","codes":[{"authorDate":"2016-07-27 09:08:07","commitOrder":1,"curCode":"  public void setAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2016-07-27 09:08:07","endLine":220,"groupId":"3053","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0d/d129cea7b3f96cb65e1da6f3ee72f3d9e87aa9.src","preCode":"  public void setAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"B"},{"authorDate":"2016-07-27 09:08:07","commitOrder":1,"curCode":"  public void setUpdateAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2016-07-27 09:08:07","endLine":236,"groupId":"2865","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpdateAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0d/d129cea7b3f96cb65e1da6f3ee72f3d9e87aa9.src","preCode":"  public void setUpdateAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":223,"status":"B"}],"commitId":"738b4cc548ca48c010b682b8bc19a2f7e1947cfe","commitMessage":"@@@[SPARK-16524][SQL] Add RowBatch and RowBasedHashMapGenerator\n\n## What changes were proposed in this pull request?\n\nThis PR is the first step for the following feature:\n\nFor hash aggregation in Spark SQL.  we use a fast aggregation hashmap to act as a \"cache\" in order to boost aggregation performance. Previously.  the hashmap is backed by a `ColumnarBatch`. This has performance issues when we have wide schema for the aggregation table (large number of key fields or value fields).\nIn this JIRA.  we support another implementation of fast hashmap.  which is backed by a `RowBasedKeyValueBatch`. We then automatically pick between the two implementations based on certain knobs.\n\nIn this first-step PR.  implementations for `RowBasedKeyValueBatch` and `RowBasedHashMapGenerator` are added.\n\n## How was this patch tested?\n\nUnit tests: `RowBasedKeyValueBatchSuite`\n\nAuthor: Qifan Pu <qifan.pu@gmail.com>\n\nCloses #14349 from ooq/SPARK-16524.\n","date":"2016-07-27 09:08:07","modifiedFileCount":"0","status":"B","submitter":"Qifan Pu"},{"authorTime":"2018-10-05 09:58:25","codes":[{"authorDate":"2018-10-05 09:58:25","commitOrder":2,"curCode":"  public void setAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    }\n  }\n","date":"2018-10-05 09:58:25","endLine":200,"groupId":"3053","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ef/02f0ae72686535ec3409ada82ff562746feed3.src","preCode":"  public void setAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"M"},{"authorDate":"2018-10-05 09:58:25","commitOrder":2,"curCode":"  public void setUpdateAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    }\n  }\n","date":"2018-10-05 09:58:25","endLine":213,"groupId":"2865","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpdateAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ef/02f0ae72686535ec3409ada82ff562746feed3.src","preCode":"  public void setUpdateAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"M"}],"commitId":"44c1e1ab1c26560371831b1593f96f30344c4363","commitMessage":"@@@[SPARK-25408] Move to mode ideomatic Java8\n\nWhile working on another PR.  I noticed that there is quite some legacy Java in there that can be beautified. For example the use og features from Java8.  such as:\n- Collection libraries\n- Try-with-resource blocks\n\nNo code has been changed\n\nWhat are your thoughts on this?\n\nThis makes code easier to read.  and using try-with-resource makes is less likely to forget to close something.\n\n## What changes were proposed in this pull request?\n\n(Please fill in changes proposed in this fix)\n\n## How was this patch tested?\n\n(Please explain how this patch was tested. E.g. unit tests.  integration tests.  manual tests)\n(If this patch involves UI changes.  please attach a screenshot; otherwise.  remove this)\n\nPlease review http://spark.apache.org/contributing.html before opening a pull request.\n\nCloses #22399 from Fokko/SPARK-25408.\n\nAuthored-by: Fokko Driesprong <fokkodriesprong@godatadriven.com>\nSigned-off-by: Sean Owen <sean.owen@databricks.com>\n","date":"2018-10-05 09:58:25","modifiedFileCount":"19","status":"M","submitter":"Fokko Driesprong"},{"authorTime":"2018-10-05 11:03:41","codes":[{"authorDate":"2018-10-05 11:03:41","commitOrder":3,"curCode":"  public void setAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2018-10-05 11:03:41","endLine":210,"groupId":"3053","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/a87113c6229a807c41c7cae298bd8efe426034.src","preCode":"  public void setAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":176,"status":"M"},{"authorDate":"2018-10-05 11:03:41","commitOrder":3,"curCode":"  public void setUpdateAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2018-10-05 11:03:41","endLine":226,"groupId":"2865","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpdateAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/a87113c6229a807c41c7cae298bd8efe426034.src","preCode":"  public void setUpdateAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":213,"status":"M"}],"commitId":"5ae20cf1a96a33f5de4435fcfb55914d64466525","commitMessage":"@@@Revert \"[SPARK-25408] Move to mode ideomatic Java8\"\n\nThis reverts commit 44c1e1ab1c26560371831b1593f96f30344c4363.\n","date":"2018-10-05 11:03:41","modifiedFileCount":"19","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2018-10-08 22:58:52","codes":[{"authorDate":"2018-10-08 22:58:52","commitOrder":4,"curCode":"  public void setAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    }\n  }\n","date":"2018-10-08 22:58:52","endLine":200,"groupId":"3053","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"setAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/a778800bb9f253184321108e97a77143173c1a.src","preCode":"  public void setAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"M"},{"authorDate":"2018-10-08 22:58:52","commitOrder":4,"curCode":"  public void setUpdateAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    }\n  }\n","date":"2018-10-08 22:58:52","endLine":213,"groupId":"2865","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpdateAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/a778800bb9f253184321108e97a77143173c1a.src","preCode":"  public void setUpdateAndRetrieve() {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"M"}],"commitId":"1a28625355d75076bde4bcc95a72e9b187cda606","commitMessage":"@@@[SPARK-25408] Move to more ideomatic Java8\n\nWhile working on another PR.  I noticed that there is quite some legacy Java in there that can be beautified. For example the use of features from Java8.  such as:\n- Collection libraries\n- Try-with-resource blocks\n\nNo logic has been changed. I think it is important to have a solid codebase with examples that will inspire next PR's to follow up on the best practices.\n\nWhat are your thoughts on this?\n\nThis makes code easier to read.  and using try-with-resource makes is less likely to forget to close something.\n\n## What changes were proposed in this pull request?\n\nNo changes in the logic of Spark.  but more in the aesthetics of the code.\n\n## How was this patch tested?\n\nUsing the existing unit tests. Since no logic is changed.  the existing unit tests should pass.\n\nPlease review http://spark.apache.org/contributing.html before opening a pull request.\n\nCloses #22637 from Fokko/SPARK-25408.\n\nAuthored-by: Fokko Driesprong <fokkodriesprong@godatadriven.com>\nSigned-off-by: Sean Owen <sean.owen@databricks.com>\n","date":"2018-10-08 22:58:52","modifiedFileCount":"17","status":"M","submitter":"Fokko Driesprong"},{"authorTime":"2018-10-08 22:58:52","codes":[{"authorDate":"2021-08-01 13:35:57","commitOrder":5,"curCode":"  public void setAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n\n      boolean asserted = false;\n      try {\n        batch.getKeyRow(3);\n      } catch (AssertionError e) {\n        \r\n        asserted = true;\n      }\n      Assert.assertTrue(\"Should not be able to get row 3\", asserted);\n\n      asserted = false;\n      try {\n        batch.getValueRow(3);\n      } catch (AssertionError e) {\n        \r\n        asserted = true;\n      }\n      Assert.assertTrue(\"Should not be able to get row 3\", asserted);\n    }\n  }\n","date":"2021-08-01 13:35:57","endLine":220,"groupId":"10313","id":9,"instanceNumber":1,"isCurCommit":1,"methodName":"setAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d4/60a067636c0e9000cb9be3d2f97b86cd8ba76e.src","preCode":"  public void setAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      UnsafeRow ret1 = appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertTrue(checkValue(ret1, 1, 1));\n      UnsafeRow ret2 = appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      Assert.assertTrue(checkValue(ret2, 2, 2));\n      UnsafeRow ret3 = appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertTrue(checkValue(ret3, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 1, \"A\"));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 2, \"B\"));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      try {\n        batch.getKeyRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n      try {\n        batch.getValueRow(3);\n        Assert.fail(\"Should not be able to get row 3\");\n      } catch (AssertionError e) {\n        \r\n      }\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":183,"status":"M"},{"authorDate":"2018-10-08 22:58:52","commitOrder":5,"curCode":"  public void setUpdateAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    }\n  }\n","date":"2018-10-08 22:58:52","endLine":213,"groupId":"10313","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"setUpdateAndRetrieve","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/a778800bb9f253184321108e97a77143173c1a.src","preCode":"  public void setUpdateAndRetrieve() {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      Assert.assertEquals(1, batch.numRows());\n      UnsafeRow retrievedValue = batch.getValueRow(0);\n      updateValueRow(retrievedValue, 2, 2);\n      UnsafeRow retrievedValue2 = batch.getValueRow(0);\n      Assert.assertTrue(checkValue(retrievedValue2, 2, 2));\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":203,"status":"N"}],"commitId":"72615bc551adaa238d15a8b43a8f99aaf741c30f","commitMessage":"@@@[SPARK-36362][CORE][SQL][TESTS] Omnibus Java code static analyzer warning fixes\n\n\n What changes were proposed in this pull request?\n\nFix up some minor Java issues:\n\n- Some int*int multiplications that widen to long maybe could overflow\n- Unnecessarily non-static inner classes\n- Some tests \"catch (AssertionError)\" and do nothing\n- Manual array iteration vs very slightly faster/simpler foreach\n- Incorrect generic types that just happen to not cause a runtime error\n- Missed opportunities for try-close\n- Mutable enums\n- .. and a few other minor things\n\n\n Why are the changes needed?\n\nSome are minor but clear fixes; some may have a marginal perf impact or avoid a bug later. Also: maybe avoid future PRs to address these one by one.\n\n\n Does this PR introduce _any_ user-facing change?\n\nNo.\n\n\n How was this patch tested?\n\nExisting tests\n\nCloses #33594 from srowen/SPARK-36362.\n\nAuthored-by: Sean Owen <srowen@gmail.com>\nSigned-off-by: Dongjoon Hyun <dongjoon@apache.org>\n","date":"2021-08-01 13:35:57","modifiedFileCount":"41","status":"M","submitter":"Sean Owen"}]
