[{"authorTime":"2014-08-04 01:36:52","codes":[{"authorDate":"2014-08-04 01:36:52","commitOrder":1,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.train(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2014-08-04 01:36:52","endLine":81,"groupId":"1788","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2c/281a1ee71578b74ee8cca16cafa1a613b60348.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.train(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"B"},{"authorDate":"2014-08-04 01:36:52","commitOrder":1,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2014-08-04 01:36:52","endLine":100,"groupId":"1788","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2c/281a1ee71578b74ee8cca16cafa1a613b60348.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"B"}],"commitId":"2998e38a942351974da36cb619e863c6f0316e7a","commitMessage":"@@@[SPARK-2197] [mllib] Java DecisionTree bug fix and easy-of-use\n\nBug fix: Before.  when an RDD was created in Java and passed to DecisionTree.train().  the fake class tag caused problems.\n* Fix: DecisionTree: Used new RDD.retag() method to allow passing RDDs from Java.\n\nOther improvements to Decision Trees for easy-of-use with Java:\n* impurity classes: Added instance() methods to help with Java interface.\n* Strategy: Added Java-friendly constructor\n--> Note: I removed quantileCalculationStrategy from the Java-friendly constructor since (a) it is a special class and (b) there is only 1 option currently.  I suspect we will redo the API before the other options are included.\n\nCC: mengxr\n\nAuthor: Joseph K. Bradley <joseph.kurata.bradley@gmail.com>\n\nCloses #1740 from jkbradley/dt-java-new and squashes the following commits:\n\n0805dc6 [Joseph K. Bradley] Changed Strategy to use JavaConverters instead of JavaConversions\n519b1b7 [Joseph K. Bradley] * Organized imports in JavaDecisionTreeSuite.java * Using JavaConverters instead of JavaConversions in DecisionTreeSuite.scala\nf7b5ca1 [Joseph K. Bradley] Improvements to make it easier to run DecisionTree from Java. * DecisionTree: Used new RDD.retag() method to allow passing RDDs from Java. * impurity classes: Added instance() methods to help with Java interface. * Strategy: Added Java-friendly constructor ** Note: I removed quantileCalculationStrategy from the Java-friendly constructor since (a) it is a special class and (b) there is only 1 option currently.  I suspect we will redo the API before the other options are included.\nd78ada6 [Joseph K. Bradley] Merge remote-tracking branch 'upstream/master' into dt-java\n320853f [Joseph K. Bradley] Added JavaDecisionTreeSuite.  partly written\n13a585e [Joseph K. Bradley] Merge remote-tracking branch 'upstream/master' into dt-java\nf1a8283 [Joseph K. Bradley] Added old JavaDecisionTreeSuite.  to be updated later\n225822f [Joseph K. Bradley] Bug: In DecisionTree.  the method sequentialBinSearchForOrderedCategoricalFeatureInClassification() indexed bins from 0 to (math.pow(2.  featureCategories.toInt - 1) - 1). This upper bound is the bound for unordered categorical features.  not ordered ones. The upper bound should be the arity (i.e..  max value) of the feature.\n","date":"2014-08-04 01:36:52","modifiedFileCount":"0","status":"B","submitter":"Joseph K. Bradley"},{"authorTime":"2014-08-04 01:36:52","codes":[{"authorDate":"2014-11-20 16:48:59","commitOrder":2,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2014-11-20 16:48:59","endLine":81,"groupId":"1788","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/99/25aae441af9180c567f404d008726573ca07e5.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.train(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"},{"authorDate":"2014-08-04 01:36:52","commitOrder":2,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2014-08-04 01:36:52","endLine":100,"groupId":"1788","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2c/281a1ee71578b74ee8cca16cafa1a613b60348.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"N"}],"commitId":"15cacc81240eed8834b4730c5c6dc3238f003465","commitMessage":"@@@[SPARK-4486][MLLIB] Improve GradientBoosting APIs and doc\n\nThere are some inconsistencies in the gradient boosting APIs. The target is a general boosting meta-algorithm.  but the implementation is attached to trees. This was partially due to the delay of SPARK-1856. But for the 1.2 release.  we should make the APIs consistent.\n\n1. WeightedEnsembleModel -> private[tree] TreeEnsembleModel and renamed members accordingly.\n1. GradientBoosting -> GradientBoostedTrees\n1. Add RandomForestModel and GradientBoostedTreesModel and hide CombiningStrategy\n1. Slightly refactored TreeEnsembleModel (Vote takes weights into consideration.)\n1. Remove `trainClassifier` and `trainRegressor` from `GradientBoostedTrees` because they are the same as `train`\n1. Rename class `train` method to `run` because it hides the static methods with the same name in Java. Deprecated `DecisionTree.train` class method.\n1. Simplify BoostingStrategy and make sure the input strategy is not modified. Users should put algo and numClasses in treeStrategy. We create ensembleStrategy inside boosting.\n1. Fix a bug in GradientBoostedTreesSuite with AbsoluteError\n1. doc updates\n\nmanishamde jkbradley\n\nAuthor: Xiangrui Meng <meng@databricks.com>\n\nCloses #3374 from mengxr/SPARK-4486 and squashes the following commits:\n\n7097251 [Xiangrui Meng] address joseph's comments\n98dea09 [Xiangrui Meng] address manish's comments\n4aae3b7 [Xiangrui Meng] add RandomForestModel and GradientBoostedTreesModel.  hide CombiningStrategy\nea4c467 [Xiangrui Meng] fix unit tests\n751da4e [Xiangrui Meng] rename class method train -> run\n19030a5 [Xiangrui Meng] update boosting public APIs\n","date":"2014-11-20 16:48:59","modifiedFileCount":"1","status":"M","submitter":"Xiangrui Meng"},{"authorTime":"2016-03-09 18:31:26","codes":[{"authorDate":"2016-03-09 18:31:26","commitOrder":3,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-03-09 18:31:26","endLine":81,"groupId":"1788","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/d29061daaad1d857459cf31f72a78134eec0c8.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"},{"authorDate":"2016-03-09 18:31:26","commitOrder":3,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-03-09 18:31:26","endLine":100,"groupId":"1788","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/d29061daaad1d857459cf31f72a78134eec0c8.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<Integer, Integer>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"}],"commitId":"c3689bc24e03a9471cd6e8169da61963c4528252","commitMessage":"@@@[SPARK-13702][CORE][SQL][MLLIB] Use diamond operator for generic instance creation in Java code.\n\n## What changes were proposed in this pull request?\n\nIn order to make `docs/examples` (and other related code) more simple/readable/user-friendly.  this PR replaces existing codes like the followings by using `diamond` operator.\n\n```\n-    final ArrayList<Product2<Object.  Object>> dataToWrite =\n-      new ArrayList<Product2<Object.  Object>>();\n+    final ArrayList<Product2<Object.  Object>> dataToWrite = new ArrayList<>();\n```\n\nJava 7 or higher supports **diamond** operator which replaces the type arguments required to invoke the constructor of a generic class with an empty set of type parameters (<>). Currently.  Spark Java code use mixed usage of this.\n\n## How was this patch tested?\n\nManual.\nPass the existing tests.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #11541 from dongjoon-hyun/SPARK-13702.\n","date":"2016-03-09 18:31:26","modifiedFileCount":"57","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-05-09 16:08:54","codes":[{"authorDate":"2016-03-09 18:31:26","commitOrder":4,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-03-09 18:31:26","endLine":81,"groupId":"1788","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/d29061daaad1d857459cf31f72a78134eec0c8.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"N"},{"authorDate":"2016-05-09 16:08:54","commitOrder":4,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    \r\n    JavaRDD<Double> predictions = model.predict(rdd.map(new Function<LabeledPoint, Vector>() {\n      @Override\n      public Vector call(LabeledPoint v1) {\n        return v1.features();\n      }\n    }));\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-05-09 16:08:54","endLine":110,"groupId":"1788","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/60/585d27277d1c211a0ab260e935a3919824e53a.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":86,"status":"M"}],"commitId":"68abc1b4e9afbb6c2a87689221a46b835dded102","commitMessage":"@@@[SPARK-14814][MLLIB] API: Java compatibility.  docs\n\n## What changes were proposed in this pull request?\njira: https://issues.apache.org/jira/browse/SPARK-14814\nfix a java compatibility function in mllib DecisionTreeModel. As synced in jira.  other compatibility issues don't need fixes.\n\n## How was this patch tested?\n\nexisting ut\n\nAuthor: Yuhao Yang <hhbyyh@gmail.com>\n\nCloses #12971 from hhbyyh/javacompatibility.\n","date":"2016-05-09 16:08:54","modifiedFileCount":"1","status":"M","submitter":"Yuhao Yang"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":5,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-05-11 02:17:47","endLine":89,"groupId":"1788","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/5b/464a4722d92113e8b1ad72621000ec53cfbd61.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":5,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    \r\n    JavaRDD<Double> predictions = model.predict(rdd.map(new Function<LabeledPoint, Vector>() {\n      @Override\n      public Vector call(LabeledPoint v1) {\n        return v1.features();\n      }\n    }));\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","date":"2016-05-11 02:17:47","endLine":116,"groupId":"1788","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/5b/464a4722d92113e8b1ad72621000ec53cfbd61.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = sc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n        maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    \r\n    JavaRDD<Double> predictions = model.predict(rdd.map(new Function<LabeledPoint, Vector>() {\n      @Override\n      public Vector call(LabeledPoint v1) {\n        return v1.features();\n      }\n    }));\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":92,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"},{"authorTime":"2017-02-20 01:42:50","codes":[{"authorDate":"2017-02-20 01:42:50","commitOrder":6,"curCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertEquals(numCorrect, rdd.count());\n  }\n","date":"2017-02-20 01:42:50","endLine":65,"groupId":"10451","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"runDTUsingConstructor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0f/71deb9ea5287f826f55994c749d5e3147fc461.src","preCode":"  public void runDTUsingConstructor() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTree learner = new DecisionTree(strategy);\n    DecisionTreeModel model = learner.run(rdd.rdd());\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"M"},{"authorDate":"2017-02-20 01:42:50","commitOrder":6,"curCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    \r\n    JavaRDD<Double> predictions = model.predict(rdd.map(LabeledPoint::features));\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertEquals(numCorrect, rdd.count());\n  }\n","date":"2017-02-20 01:42:50","endLine":87,"groupId":"10451","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"runDTUsingStaticMethods","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0f/71deb9ea5287f826f55994c749d5e3147fc461.src","preCode":"  public void runDTUsingStaticMethods() {\n    List<LabeledPoint> arr = DecisionTreeSuite.generateCategoricalDataPointsAsJavaList();\n    JavaRDD<LabeledPoint> rdd = jsc.parallelize(arr);\n    HashMap<Integer, Integer> categoricalFeaturesInfo = new HashMap<>();\n    categoricalFeaturesInfo.put(1, 2); \r\n\n    int maxDepth = 4;\n    int numClasses = 2;\n    int maxBins = 100;\n    Strategy strategy = new Strategy(Algo.Classification(), Gini.instance(), maxDepth, numClasses,\n      maxBins, categoricalFeaturesInfo);\n\n    DecisionTreeModel model = DecisionTree$.MODULE$.train(rdd.rdd(), strategy);\n\n    \r\n    JavaRDD<Double> predictions = model.predict(rdd.map(new Function<LabeledPoint, Vector>() {\n      @Override\n      public Vector call(LabeledPoint v1) {\n        return v1.features();\n      }\n    }));\n\n    int numCorrect = validatePrediction(arr, model);\n    Assert.assertTrue(numCorrect == rdd.count());\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/tree/JavaDecisionTreeSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"}],"commitId":"1487c9af20a333ead55955acf4c0aa323bea0d07","commitMessage":"@@@[SPARK-19534][TESTS] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert tests to use Java 8 lambdas.  and modest related fixes to surrounding code.\n\n## How was this patch tested?\n\nJenkins tests\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16964 from srowen/SPARK-19534.\n","date":"2017-02-20 01:42:50","modifiedFileCount":"45","status":"M","submitter":"Sean Owen"}]
