[{"authorTime":"2016-03-11 09:00:17","codes":[{"authorDate":"2016-03-11 09:00:17","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data = sqlContext.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-11 09:00:17","endLine":101,"groupId":"1587","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/5b/d61fe508bd5d5581a812d7b7ec7f0f2155ed7f.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data = sqlContext.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"MB"},{"authorDate":"2016-03-11 09:00:17","commitOrder":5,"curCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaRandomForestClassifierExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data =\n        sqlContext.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-11 09:00:17","endLine":102,"groupId":"1587","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/05/c2bc9622e1b19b48fe73466548c7881dc294ca.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaRandomForestClassifierExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data =\n        sqlContext.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"MB"}],"commitId":"1d542785b9949e7f92025e6754973a779cc37c52","commitMessage":"@@@[SPARK-13244][SQL] Migrates DataFrame to Dataset\n\n## What changes were proposed in this pull request?\n\nThis PR unifies DataFrame and Dataset by migrating existing DataFrame operations to Dataset and make `DataFrame` a type alias of `Dataset[Row]`.\n\nMost Scala code changes are source compatible.  but Java API is broken as Java knows nothing about Scala type alias (mostly replacing `DataFrame` with `Dataset<Row>`).\n\nThere are several noticeable API changes related to those returning arrays:\n\n1.  `collect`/`take`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def collect(): Array[Row]\n        def take(n: Int): Array[Row]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def collect(): Array[T]\n        def take(n: Int): Array[T]\n\n        def collectRows(): Array[Row]\n        def takeRows(n: Int): Array[Row]\n        ```\n\n    Two specialized methods `collectRows` and `takeRows` are added because Java doesn't support returning generic arrays. Thus.  for example.  `DataFrame.collect(): Array[T]` actually returns `Object` instead of `Array<T>` from Java side.\n\n    Normally.  Java users may fall back to `collectAsList` and `takeAsList`.  The two new specialized versions are added to avoid performance regression in ML related code (but maybe I'm wrong and they are not necessary here).\n\n1.  `randomSplit`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[DataFrame]\n        def randomSplit(weights: Array[Double]): Array[DataFrame]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[Dataset[T]]\n        def randomSplit(weights: Array[Double]): Array[Dataset[T]]\n        ```\n\n    Similar problem as above.  but hasn't been addressed for Java API yet.  We can probably add `randomSplitAsList` to fix this one.\n\n1.  `groupBy`\n\n    Some original `DataFrame.groupBy` methods have conflicting signature with original `Dataset.groupBy` methods.  To distinguish these two.  typed `Dataset.groupBy` methods are renamed to `groupByKey`.\n\nOther noticeable changes:\n\n1.  Dataset always do eager analysis now\n\n    We used to support disabling DataFrame eager analysis to help reporting partially analyzed malformed logical plan on analysis failure.  However.  Dataset encoders requires eager analysi during Dataset construction.  To preserve the error reporting feature.  `AnalysisException` now takes an extra `Option[LogicalPlan]` argument to hold the partially analyzed plan.  so that we can check the plan tree when reporting test failures.  This plan is passed by `QueryExecution.assertAnalyzed`.\n\n## How was this patch tested?\n\nExisting tests do the work.\n\n## TODO\n\n- [ ] Fix all tests\n- [ ] Re-enable MiMA check\n- [ ] Update ScalaDoc (`since`.  `group`.  and example code)\n\nAuthor: Cheng Lian <lian@databricks.com>\nAuthor: Yin Huai <yhuai@databricks.com>\nAuthor: Wenchen Fan <wenchen@databricks.com>\nAuthor: Cheng Lian <liancheng@users.noreply.github.com>\n\nCloses #11443 from liancheng/ds-to-df.\n","date":"2016-03-11 09:00:17","modifiedFileCount":"87","status":"M","submitter":"Cheng Lian"},{"authorTime":"2016-05-05 05:31:36","codes":[{"authorDate":"2016-05-05 05:31:36","commitOrder":6,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder().appName(\"JavaDecisionTreeClassificationExample\").getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":101,"groupId":"1587","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/73/3bc4181c70b0b1de6aba3e5be00965d1f3c50c.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaDecisionTreeClassificationExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data = sqlContext\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":33,"status":"M"},{"authorDate":"2016-05-05 05:31:36","commitOrder":6,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder().appName(\"JavaRandomForestClassifierExample\").getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":98,"groupId":"1587","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/21/e783a96897f5f0509274d371d8f0be119c2bf0.src","preCode":"  public static void main(String[] args) {\n    SparkConf conf = new SparkConf().setAppName(\"JavaRandomForestClassifierExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    Dataset<Row> data =\n        sqlContext.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"M"}],"commitId":"cdce4e62a5674e2034e5d395578b1a60e3d8c435","commitMessage":"@@@[SPARK-15031][EXAMPLE] Use SparkSession in Scala/Python/Java example.\n\n## What changes were proposed in this pull request?\n\nThis PR aims to update Scala/Python/Java examples by replacing `SQLContext` with newly added `SparkSession`.\n\n- Use **SparkSession Builder Pattern** in 154(Scala 55.  Java 52.  Python 47) files.\n- Add `getConf` in Python SparkContext class: `python/pyspark/context.py`\n- Replace **SQLContext Singleton Pattern** with **SparkSession Singleton Pattern**:\n  - `SqlNetworkWordCount.scala`\n  - `JavaSqlNetworkWordCount.java`\n  - `sql_network_wordcount.py`\n\nNow.  `SQLContexts` are used only in R examples and the following two Python examples. The python examples are untouched in this PR since it already fails some unknown issue.\n- `simple_params_example.py`\n- `aft_survival_regression.py`\n\n## How was this patch tested?\n\nManual.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #12809 from dongjoon-hyun/SPARK-15031.\n","date":"2016-05-05 05:31:36","modifiedFileCount":"52","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-06-06 16:36:34","codes":[{"authorDate":"2016-06-06 16:36:34","commitOrder":7,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaDecisionTreeClassificationExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2016-06-06 16:36:34","endLine":103,"groupId":"1587","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a9/c6e7f0bf6c54e542c08ecbbfbbf91400617f46.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaDecisionTreeClassificationExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":33,"status":"M"},{"authorDate":"2016-06-06 16:36:34","commitOrder":7,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaRandomForestClassifierExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2016-06-06 16:36:34","endLine":100,"groupId":"1587","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/da/2633e8860accb0c89eef5042e4a026b3d8c051.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaRandomForestClassifierExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"precision\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"M"}],"commitId":"a95252823e09939b654dd425db38dadc4100bc87","commitMessage":"@@@[SPARK-15771][ML][EXAMPLES] Use 'accuracy' rather than 'precision' in many ML examples\n\n## What changes were proposed in this pull request?\nSince [SPARK-15617](https://issues.apache.org/jira/browse/SPARK-15617) deprecated ```precision``` in ```MulticlassClassificationEvaluator```.  many ML examples broken.\n```python\npyspark.sql.utils.IllegalArgumentException: u'MulticlassClassificationEvaluator_4c3bb1d73d8cc0cedae6 parameter metricName given invalid value precision.'\n```\nWe should use ```accuracy``` to replace ```precision``` in these examples.\n\n## How was this patch tested?\nOffline tests.\n\nAuthor: Yanbo Liang <ybliang8@gmail.com>\n\nCloses #13519 from yanboliang/spark-15771.\n","date":"2016-06-06 16:36:34","modifiedFileCount":"6","status":"M","submitter":"Yanbo Liang"},{"authorTime":"2019-08-27 21:58:32","codes":[{"authorDate":"2019-08-27 21:58:32","commitOrder":8,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaDecisionTreeClassificationExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labelsArray()[0]);\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2019-08-27 21:58:32","endLine":103,"groupId":"10506","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f7/e114483ac5aee8169f8ae65a30eb75f3189429.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaDecisionTreeClassificationExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark\n      .read()\n      .format(\"libsvm\")\n      .load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4) \r\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[]{0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    DecisionTreeClassifier dt = new DecisionTreeClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[]{labelIndexer, featureIndexer, dt, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    DecisionTreeClassificationModel treeModel =\n      (DecisionTreeClassificationModel) (model.stages()[2]);\n    System.out.println(\"Learned classification tree model:\\n\" + treeModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":33,"status":"M"},{"authorDate":"2019-08-27 21:58:32","commitOrder":8,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaRandomForestClassifierExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labelsArray()[0]);\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","date":"2019-08-27 21:58:32","endLine":100,"groupId":"10506","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/88/63f187db260b94d562e7906c1e163d9314f9a8.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaRandomForestClassifierExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    Dataset<Row> data = spark.read().format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\");\n\n    \r\n    \r\n    StringIndexerModel labelIndexer = new StringIndexer()\n      .setInputCol(\"label\")\n      .setOutputCol(\"indexedLabel\")\n      .fit(data);\n    \r\n    \r\n    VectorIndexerModel featureIndexer = new VectorIndexer()\n      .setInputCol(\"features\")\n      .setOutputCol(\"indexedFeatures\")\n      .setMaxCategories(4)\n      .fit(data);\n\n    \r\n    Dataset<Row>[] splits = data.randomSplit(new double[] {0.7, 0.3});\n    Dataset<Row> trainingData = splits[0];\n    Dataset<Row> testData = splits[1];\n\n    \r\n    RandomForestClassifier rf = new RandomForestClassifier()\n      .setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"indexedFeatures\");\n\n    \r\n    IndexToString labelConverter = new IndexToString()\n      .setInputCol(\"prediction\")\n      .setOutputCol(\"predictedLabel\")\n      .setLabels(labelIndexer.labels());\n\n    \r\n    Pipeline pipeline = new Pipeline()\n      .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n    \r\n    PipelineModel model = pipeline.fit(trainingData);\n\n    \r\n    Dataset<Row> predictions = model.transform(testData);\n\n    \r\n    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5);\n\n    \r\n    MulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n      .setLabelCol(\"indexedLabel\")\n      .setPredictionCol(\"prediction\")\n      .setMetricName(\"accuracy\");\n    double accuracy = evaluator.evaluate(predictions);\n    System.out.println(\"Test Error = \" + (1.0 - accuracy));\n\n    RandomForestClassificationModel rfModel = (RandomForestClassificationModel)(model.stages()[2]);\n    System.out.println(\"Learned classification forest model:\\n\" + rfModel.toDebugString());\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"M"}],"commitId":"7fe750674e85d596aa7e788bf207c3b2073ea7cf","commitMessage":"@@@[SPARK-11215][ML][FOLLOWUP] update the examples and suites using new api\n\n## What changes were proposed in this pull request?\nsince method `labels` is already deprecated.  we should update the examples and suites to turn off warings when compiling spark:\n```\n[warn] /Users/zrf/Dev/OpenSource/spark/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala:65: method labels in class StringIndexerModel is deprecated (since 3.0.0): `labels` is deprecated and will be removed in 3.1.0. Use `labelsArray` instead.\n[warn]       .setLabels(labelIndexer.labels)\n[warn]                               ^\n[warn] /Users/zrf/Dev/OpenSource/spark/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala:68: method labels in class StringIndexerModel is deprecated (since 3.0.0): `labels` is deprecated and will be removed in 3.1.0. Use `labelsArray` instead.\n[warn]       .setLabels(labelIndexer.labels)\n[warn]                               ^\n```\n\n## How was this patch tested?\nexisting suites\n\nCloses #25428 from zhengruifeng/del_stringindexer_labels_usage.\n\nAuthored-by: zhengruifeng <ruifengz@foxmail.com>\nSigned-off-by: Sean Owen <sean.owen@databricks.com>\n","date":"2019-08-27 21:58:32","modifiedFileCount":"3","status":"M","submitter":"zhengruifeng"}]
