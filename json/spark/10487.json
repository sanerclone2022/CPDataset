[{"authorTime":"2015-10-27 12:17:53","codes":[{"authorDate":"2015-09-24 13:49:08","commitOrder":4,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collect()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2015-09-24 13:49:08","endLine":76,"groupId":"2137","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0c/0c1c4d12d0ffc6d31ad3b5cf91cb4be99eacc1.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collect()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"NB"},{"authorDate":"2015-10-27 12:17:53","commitOrder":4,"curCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").take(3)) {\n      System.out.println(r);\n    }\n    \r\n  }\n","date":"2015-10-27 12:17:53","endLine":66,"groupId":"3475","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d4/72375ca982542566db3f63f2b150114a7870fb.src","preCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").take(3)) {\n      System.out.println(r);\n    }\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"B"}],"commitId":"943d4fa204a827ca8ecc39d9cf04e86890ee9840","commitMessage":"@@@[SPARK-11289][DOC] Substitute code examples in ML features extractors with include_example\n\nmengxr https://issues.apache.org/jira/browse/SPARK-11289\n\nI make some changes in ML feature extractors. I.e. TF-IDF.  Word2Vec.  and CountVectorizer. I add new example code in spark/examples.  hope it is the right place to add those examples.\n\nAuthor: Xusen Yin <yinxusen@gmail.com>\n\nCloses #9266 from yinxusen/SPARK-11289.\n","date":"2015-10-27 12:17:53","modifiedFileCount":"0","status":"M","submitter":"Xusen Yin"},{"authorTime":"2016-03-09 18:12:23","codes":[{"authorDate":"2015-09-24 13:49:08","commitOrder":5,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collect()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2015-09-24 13:49:08","endLine":76,"groupId":"2137","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0c/0c1c4d12d0ffc6d31ad3b5cf91cb4be99eacc1.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collect()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"N"},{"authorDate":"2016-03-09 18:12:23","commitOrder":5,"curCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").take(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-09 18:12:23","endLine":68,"groupId":"3475","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a4/a05af7c6f833f310d36bded905405d773720be.src","preCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").take(3)) {\n      System.out.println(r);\n    }\n    \r\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"f3201aeeb06aae3b11e8cf6ee9693182dd896b32","commitMessage":"@@@[SPARK-13692][CORE][SQL] Fix trivial Coverity/Checkstyle defects\n\n## What changes were proposed in this pull request?\n\nThis issue fixes the following potential bugs and Java coding style detected by Coverity and Checkstyle.\n\n- Implement both null and type checking in equals functions.\n- Fix wrong type casting logic in SimpleJavaBean2.equals.\n- Add `implement Cloneable` to `UTF8String` and `SortedIterator`.\n- Remove dereferencing before null check in `AbstractBytesToBytesMapSuite`.\n- Fix coding style: Add '{}' to single `for` statement in mllib examples.\n- Remove unused imports in `ColumnarBatch` and `JavaKinesisStreamSuite`.\n- Remove unused fields in `ChunkFetchIntegrationSuite`.\n- Add `stop()` to prevent resource leak.\n\nPlease note that the last two checkstyle errors exist on newly added commits after [SPARK-13583](https://issues.apache.org/jira/browse/SPARK-13583).\n\n## How was this patch tested?\n\nmanual via `./dev/lint-java` and Coverity site.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #11530 from dongjoon-hyun/SPARK-13692.\n","date":"2016-03-09 18:12:23","modifiedFileCount":"31","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-03-11 09:00:17","codes":[{"authorDate":"2016-03-11 09:00:17","commitOrder":6,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2016-03-11 09:00:17","endLine":75,"groupId":"2456","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/75/17b70cc9bee49adb7382d345a636577213a6b5.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collect()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2016-03-11 09:00:17","commitOrder":6,"curCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeRows(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-11 09:00:17","endLine":68,"groupId":"3475","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/ce8c2168c2df5a9beb1cca04e398c9afddb83e.src","preCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    DataFrame documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    DataFrame result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").take(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"1d542785b9949e7f92025e6754973a779cc37c52","commitMessage":"@@@[SPARK-13244][SQL] Migrates DataFrame to Dataset\n\n## What changes were proposed in this pull request?\n\nThis PR unifies DataFrame and Dataset by migrating existing DataFrame operations to Dataset and make `DataFrame` a type alias of `Dataset[Row]`.\n\nMost Scala code changes are source compatible.  but Java API is broken as Java knows nothing about Scala type alias (mostly replacing `DataFrame` with `Dataset<Row>`).\n\nThere are several noticeable API changes related to those returning arrays:\n\n1.  `collect`/`take`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def collect(): Array[Row]\n        def take(n: Int): Array[Row]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def collect(): Array[T]\n        def take(n: Int): Array[T]\n\n        def collectRows(): Array[Row]\n        def takeRows(n: Int): Array[Row]\n        ```\n\n    Two specialized methods `collectRows` and `takeRows` are added because Java doesn't support returning generic arrays. Thus.  for example.  `DataFrame.collect(): Array[T]` actually returns `Object` instead of `Array<T>` from Java side.\n\n    Normally.  Java users may fall back to `collectAsList` and `takeAsList`.  The two new specialized versions are added to avoid performance regression in ML related code (but maybe I'm wrong and they are not necessary here).\n\n1.  `randomSplit`\n\n    -   Old APIs in class `DataFrame`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[DataFrame]\n        def randomSplit(weights: Array[Double]): Array[DataFrame]\n        ```\n\n    -   New APIs in class `Dataset[T]`:\n\n        ```scala\n        def randomSplit(weights: Array[Double].  seed: Long): Array[Dataset[T]]\n        def randomSplit(weights: Array[Double]): Array[Dataset[T]]\n        ```\n\n    Similar problem as above.  but hasn't been addressed for Java API yet.  We can probably add `randomSplitAsList` to fix this one.\n\n1.  `groupBy`\n\n    Some original `DataFrame.groupBy` methods have conflicting signature with original `Dataset.groupBy` methods.  To distinguish these two.  typed `Dataset.groupBy` methods are renamed to `groupByKey`.\n\nOther noticeable changes:\n\n1.  Dataset always do eager analysis now\n\n    We used to support disabling DataFrame eager analysis to help reporting partially analyzed malformed logical plan on analysis failure.  However.  Dataset encoders requires eager analysi during Dataset construction.  To preserve the error reporting feature.  `AnalysisException` now takes an extra `Option[LogicalPlan]` argument to hold the partially analyzed plan.  so that we can check the plan tree when reporting test failures.  This plan is passed by `QueryExecution.assertAnalyzed`.\n\n## How was this patch tested?\n\nExisting tests do the work.\n\n## TODO\n\n- [ ] Fix all tests\n- [ ] Re-enable MiMA check\n- [ ] Update ScalaDoc (`since`.  `group`.  and example code)\n\nAuthor: Cheng Lian <lian@databricks.com>\nAuthor: Yin Huai <yhuai@databricks.com>\nAuthor: Wenchen Fan <wenchen@databricks.com>\nAuthor: Cheng Lian <liancheng@users.noreply.github.com>\n\nCloses #11443 from liancheng/ds-to-df.\n","date":"2016-03-11 09:00:17","modifiedFileCount":"87","status":"M","submitter":"Cheng Lian"},{"authorTime":"2016-03-13 12:02:52","codes":[{"authorDate":"2016-03-11 09:00:17","commitOrder":7,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2016-03-11 09:00:17","endLine":75,"groupId":"2456","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/75/17b70cc9bee49adb7382d345a636577213a6b5.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2016-03-13 12:02:52","commitOrder":7,"curCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","date":"2016-03-13 12:02:52","endLine":68,"groupId":"3475","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c5/bb1eaaa34461055bc8d0dc1745d56249110b14.src","preCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeRows(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":36,"status":"M"}],"commitId":"c079420d7c55d8972db716a2695a5ddd606d11cd","commitMessage":"@@@[SPARK-13841][SQL] Removes Dataset.collectRows()/takeRows()\n\n## What changes were proposed in this pull request?\n\nThis PR removes two methods.  `collectRows()` and `takeRows()`.  from `Dataset[T]`. These methods were added in PR #11443.  and were later considered not useful.\n\n## How was this patch tested?\n\nExisting tests should do the work.\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #11678 from liancheng/remove-collect-rows-and-take-rows.\n","date":"2016-03-13 12:02:52","modifiedFileCount":"16","status":"M","submitter":"Cheng Lian"},{"authorTime":"2016-05-05 05:31:36","codes":[{"authorDate":"2016-03-11 09:00:17","commitOrder":8,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2016-03-11 09:00:17","endLine":75,"groupId":"2456","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/75/17b70cc9bee49adb7382d345a636577213a6b5.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2016-05-05 05:31:36","commitOrder":8,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaWord2VecExample\").getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":63,"groupId":"3415","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d9/b1a79b525483e7bcfb242f929abfba87aa3dc5.src","preCode":"  public static void main(String[] args) {\n\n    SparkConf conf = new SparkConf().setAppName(\"JavaWord2VecExample\");\n    JavaSparkContext jsc = new JavaSparkContext(conf);\n    SQLContext sqlContext = new SQLContext(jsc);\n\n    \r\n    \r\n    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    ));\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(jrdd, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    jsc.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"M"}],"commitId":"cdce4e62a5674e2034e5d395578b1a60e3d8c435","commitMessage":"@@@[SPARK-15031][EXAMPLE] Use SparkSession in Scala/Python/Java example.\n\n## What changes were proposed in this pull request?\n\nThis PR aims to update Scala/Python/Java examples by replacing `SQLContext` with newly added `SparkSession`.\n\n- Use **SparkSession Builder Pattern** in 154(Scala 55.  Java 52.  Python 47) files.\n- Add `getConf` in Python SparkContext class: `python/pyspark/context.py`\n- Replace **SQLContext Singleton Pattern** with **SparkSession Singleton Pattern**:\n  - `SqlNetworkWordCount.scala`\n  - `JavaSqlNetworkWordCount.java`\n  - `sql_network_wordcount.py`\n\nNow.  `SQLContexts` are used only in R examples and the following two Python examples. The python examples are untouched in this PR since it already fails some unknown issue.\n- `simple_params_example.py`\n- `aft_survival_regression.py`\n\n## How was this patch tested?\n\nManual.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #12809 from dongjoon-hyun/SPARK-15031.\n","date":"2016-05-05 05:31:36","modifiedFileCount":"52","status":"M","submitter":"Dongjoon Hyun"},{"authorTime":"2016-05-05 05:31:36","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":9,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r : result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector) r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":75,"groupId":"2456","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/39/2aabc96d372ae408691d61bd25d484729c8f5f.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = sqlContext.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r: result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector)r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2016-05-05 05:31:36","commitOrder":9,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaWord2VecExample\").getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    spark.stop();\n  }\n","date":"2016-05-05 05:31:36","endLine":63,"groupId":"3415","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/d9/b1a79b525483e7bcfb242f929abfba87aa3dc5.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession.builder().appName(\"JavaWord2VecExample\").getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":34,"status":"N"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"},{"authorTime":"2016-08-06 03:57:46","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":10,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r : result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector) r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":75,"groupId":"2456","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/39/2aabc96d372ae408691d61bd25d484729c8f5f.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r : result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector) r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2016-08-06 03:57:46","commitOrder":10,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaWord2VecExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row row : result.collectAsList()) {\n      List<String> text = row.getList(0);\n      Vector vector = (Vector) row.get(1);\n      System.out.println(\"Text: \" + text + \" => \\nVector: \" + vector + \"\\n\");\n    }\n    \r\n\n    spark.stop();\n  }\n","date":"2016-08-06 03:57:46","endLine":71,"groupId":"3415","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fc/9b45968874ae646e490d442420b96a0db2cc1b.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaWord2VecExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n    for (Row r : result.select(\"result\").takeAsList(3)) {\n      System.out.println(r);\n    }\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"}],"commitId":"180fd3e0a3426db200c97170926afb60751dfd0e","commitMessage":"@@@[SPARK-16421][EXAMPLES][ML] Improve ML Example Outputs\n\n## What changes were proposed in this pull request?\nImprove example outputs to better reflect the functionality that is being presented.  This mostly consisted of modifying what was printed at the end of the example.  such as calling show() with truncate=False.  but sometimes required minor tweaks in the example data to get relevant output.  Explicitly set parameters when they are used as part of the example.  Fixed Java examples that failed to run because of using old-style MLlib Vectors or problem with schema.  Synced examples between different APIs.\n\n## How was this patch tested?\nRan each example for Scala.  Python.  and Java and made sure output was legible on a terminal of width 100.\n\nAuthor: Bryan Cutler <cutlerb@gmail.com>\n\nCloses #14308 from BryanCutler/ml-examples-improve-output-SPARK-16260.\n","date":"2016-08-06 03:57:46","modifiedFileCount":"27","status":"M","submitter":"Bryan Cutler"},{"authorTime":"2016-08-06 03:57:46","codes":[{"authorDate":"2019-11-04 03:21:28","commitOrder":11,"curCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r : result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector) r.get(0)).toArray();\n      Assert.assertEquals(3, polyFeatures.length);\n    }\n  }\n","date":"2019-11-04 03:21:28","endLine":58,"groupId":"10487","id":15,"instanceNumber":1,"isCurCommit":1,"methodName":"testJavaWord2Vec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/f6/041e0528719bfabb391b8394b8243728ef32b7.src","preCode":"  public void testJavaWord2Vec() {\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(\n      Arrays.asList(\n        RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n        RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))),\n      schema);\n\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row r : result.select(\"result\").collectAsList()) {\n      double[] polyFeatures = ((Vector) r.get(0)).toArray();\n      Assert.assertEquals(polyFeatures.length, 3);\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/ml/feature/JavaWord2VecSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"M"},{"authorDate":"2016-08-06 03:57:46","commitOrder":11,"curCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaWord2VecExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row row : result.collectAsList()) {\n      List<String> text = row.getList(0);\n      Vector vector = (Vector) row.get(1);\n      System.out.println(\"Text: \" + text + \" => \\nVector: \" + vector + \"\\n\");\n    }\n    \r\n\n    spark.stop();\n  }\n","date":"2016-08-06 03:57:46","endLine":71,"groupId":"10487","id":16,"instanceNumber":2,"isCurCommit":1,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fc/9b45968874ae646e490d442420b96a0db2cc1b.src","preCode":"  public static void main(String[] args) {\n    SparkSession spark = SparkSession\n      .builder()\n      .appName(\"JavaWord2VecExample\")\n      .getOrCreate();\n\n    \r\n    \r\n    List<Row> data = Arrays.asList(\n      RowFactory.create(Arrays.asList(\"Hi I heard about Spark\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"I wish Java could use case classes\".split(\" \"))),\n      RowFactory.create(Arrays.asList(\"Logistic regression models are neat\".split(\" \")))\n    );\n    StructType schema = new StructType(new StructField[]{\n      new StructField(\"text\", new ArrayType(DataTypes.StringType, true), false, Metadata.empty())\n    });\n    Dataset<Row> documentDF = spark.createDataFrame(data, schema);\n\n    \r\n    Word2Vec word2Vec = new Word2Vec()\n      .setInputCol(\"text\")\n      .setOutputCol(\"result\")\n      .setVectorSize(3)\n      .setMinCount(0);\n\n    Word2VecModel model = word2Vec.fit(documentDF);\n    Dataset<Row> result = model.transform(documentDF);\n\n    for (Row row : result.collectAsList()) {\n      List<String> text = row.getList(0);\n      Vector vector = (Vector) row.get(1);\n      System.out.println(\"Text: \" + text + \" => \\nVector: \" + vector + \"\\n\");\n    }\n    \r\n\n    spark.stop();\n  }\n","realPath":"examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":35,"status":"N"}],"commitId":"80a89873b20aa07e2522bed5da0fc50e616246d9","commitMessage":"@@@[SPARK-29733][TESTS] Fix wrong order of parameters passed to `assertEquals`\n\n\n What changes were proposed in this pull request?\nThe `assertEquals` method of JUnit Assert requires the first parameter to be the expected value. In this PR.  I propose to change the order of parameters when the expected value is passed as the second parameter.\n\n\n Why are the changes needed?\nWrong order of assert parameters confuses when the assert fails and the parameters have special string representation. For example:\n```java\nassertEquals(input1.add(input2).  new CalendarInterval(5.  5.  367200000000L));\n```\n```\njava.lang.AssertionError:\nExpected :interval 5 months 5 days 101 hours\nActual   :interval 5 months 5 days 102 hours\n```\n\n\n Does this PR introduce any user-facing change?\nNo\n\n\n How was this patch tested?\nBy existing tests.\n\nCloses #26377 from MaxGekk/fix-order-in-assert-equals.\n\nAuthored-by: Maxim Gekk <max.gekk@gmail.com>\nSigned-off-by: Dongjoon Hyun <dhyun@apple.com>\n","date":"2019-11-04 03:21:28","modifiedFileCount":"21","status":"M","submitter":"Maxim Gekk"}]
