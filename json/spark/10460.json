[{"authorTime":"2015-02-07 07:42:59","codes":[{"authorDate":"2015-06-04 05:34:20","commitOrder":2,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2015-06-04 05:34:20","endLine":80,"groupId":"1165","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/55/787f8606d486ddf694da2acb3239ab3364e38c.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/classification/JavaStreamingLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"B"},{"authorDate":"2015-02-07 07:42:59","commitOrder":2,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2015-02-07 07:42:59","endLine":79,"groupId":"1165","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a4/dd1ac39a3c80454d070e6c996873c31074d53b.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/regression/JavaStreamingLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"NB"}],"commitId":"20a26b595c74ac41cf7c19e6091d7e675e503321","commitMessage":"@@@[SPARK-8054] [MLLIB] Added several Java-friendly APIs + unit tests\n\nJava-friendly APIs added:\n* GaussianMixture.run()\n* GaussianMixtureModel.predict()\n* DistributedLDAModel.javaTopicDistributions()\n* StreamingKMeans: trainOn.  predictOn.  predictOnValues\n* Statistics.corr\n* params\n  * added doc to w() since Java docs do not inherit doc\n  * removed non-Java-friendly w() from StringArrayParam and DoubleArrayParam\n  * made DoubleArrayParam Java-friendly w() actually Java-friendly\n\nI generated the doc and verified all changes.\n\nCC: mengxr\n\nAuthor: Joseph K. Bradley <joseph@databricks.com>\n\nCloses #6562 from jkbradley/java-api-1.4 and squashes the following commits:\n\nc16821b [Joseph K. Bradley] Small fixes based on code review.\nd955581 [Joseph K. Bradley] unit test fixes\n29b6b0d [Joseph K. Bradley] small fixes\nfe6dcfe [Joseph K. Bradley] Added several Java-friendly APIs + unit tests: NaiveBayes.  GaussianMixture.  LDA.  StreamingKMeans.  Statistics.corr.  params\n","date":"2015-06-04 05:34:20","modifiedFileCount":"3","status":"M","submitter":"Joseph K. Bradley"},{"authorTime":"2015-08-28 01:46:41","codes":[{"authorDate":"2015-08-28 01:46:41","commitOrder":3,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2015-08-28 01:46:41","endLine":80,"groupId":"2783","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c9/e5ee22f32737d16847f1e7c92824d8fb9611c5.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/classification/JavaStreamingLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"M"},{"authorDate":"2015-08-28 01:46:41","commitOrder":3,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2015-08-28 01:46:41","endLine":79,"groupId":"2783","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/db/f6488d410853e33e6183f5e2448501de4fa965.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Lists.newArrayList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Lists.newArrayList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Lists.newArrayList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Lists.newArrayList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/regression/JavaStreamingLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"}],"commitId":"e1f4de4a7d15d4ca4b5c64ff929ac3980f5d706f","commitMessage":"@@@[SPARK-10257] [MLLIB] Removes Guava from all spark.mllib Java tests\n\n* Replaces instances of `Lists.newArrayList` with `Arrays.asList`\n* Replaces `commons.lang.StringUtils` over `com.google.collections.Strings`\n* Replaces `List` interface over `ArrayList` implementations\n\nThis PR along with #8445 #8446 #8447 completely removes all `com.google.collections.Lists` dependencies within mllib's Java tests.\n\nAuthor: Feynman Liang <fliang@databricks.com>\n\nCloses #8451 from feynmanliang/SPARK-10257.\n","date":"2015-08-28 01:46:41","modifiedFileCount":"14","status":"M","submitter":"Feynman Liang"},{"authorTime":"2016-04-04 09:14:16","codes":[{"authorDate":"2016-04-04 09:14:16","commitOrder":4,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<>(10, Vectors.dense(1.0)),\n      new Tuple2<>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2016-04-04 09:14:16","endLine":80,"groupId":"10460","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/62/c6d9b7e390af00967da5c2136fb0637cc1561a.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLogisticRegressionWithSGD slr = new StreamingLogisticRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/classification/JavaStreamingLogisticRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":62,"status":"M"},{"authorDate":"2016-04-04 09:14:16","commitOrder":4,"curCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<>(10, Vectors.dense(1.0)),\n      new Tuple2<>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","date":"2016-04-04 09:14:16","endLine":79,"groupId":"10460","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"javaAPI","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ea/0ccd74489863f0749768083763a2c0bfa4f7fc.src","preCode":"  public void javaAPI() {\n    List<LabeledPoint> trainingBatch = Arrays.asList(\n      new LabeledPoint(1.0, Vectors.dense(1.0)),\n      new LabeledPoint(0.0, Vectors.dense(0.0)));\n    JavaDStream<LabeledPoint> training =\n      attachTestInputStream(ssc, Arrays.asList(trainingBatch, trainingBatch), 2);\n    List<Tuple2<Integer, Vector>> testBatch = Arrays.asList(\n      new Tuple2<Integer, Vector>(10, Vectors.dense(1.0)),\n      new Tuple2<Integer, Vector>(11, Vectors.dense(0.0)));\n    JavaPairDStream<Integer, Vector> test = JavaPairDStream.fromJavaDStream(\n      attachTestInputStream(ssc, Arrays.asList(testBatch, testBatch), 2));\n    StreamingLinearRegressionWithSGD slr = new StreamingLinearRegressionWithSGD()\n      .setNumIterations(2)\n      .setInitialWeights(Vectors.dense(0.0));\n    slr.trainOn(training);\n    JavaPairDStream<Integer, Double> prediction = slr.predictOnValues(test);\n    attachTestOutputStream(prediction.count());\n    runStreams(ssc, 2, 2);\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/regression/JavaStreamingLinearRegressionSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"}],"commitId":"3f749f7ed443899d667c9e2b2a11bc595d6fc7f6","commitMessage":"@@@[SPARK-14355][BUILD] Fix typos in Exception/Testcase/Comments and static analysis results\n\n## What changes were proposed in this pull request?\n\nThis PR contains the following 5 types of maintenance fix over 59 files (+94 lines.  -93 lines).\n- Fix typos(exception/log strings.  testcase name.  comments) in 44 lines.\n- Fix lint-java errors (MaxLineLength) in 6 lines. (New codes after SPARK-14011)\n- Use diamond operators in 40 lines. (New codes after SPARK-13702)\n- Fix redundant semicolon in 5 lines.\n- Rename class `InferSchemaSuite` to `CSVInferSchemaSuite` in CSVInferSchemaSuite.scala.\n\n## How was this patch tested?\n\nManual and pass the Jenkins tests.\n\nAuthor: Dongjoon Hyun <dongjoon@apache.org>\n\nCloses #12139 from dongjoon-hyun/SPARK-14355.\n","date":"2016-04-04 09:14:16","modifiedFileCount":"26","status":"M","submitter":"Dongjoon Hyun"}]
