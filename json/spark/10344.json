[{"authorTime":"2015-08-03 14:41:16","codes":[{"authorDate":"2015-10-20 02:02:26","commitOrder":5,"curCode":"  public UnsafeArrayData getArray(int ordinal) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","date":"2015-10-20 02:02:26","endLine":286,"groupId":"108","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getArray","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/76/1f0447943e8e4ecd5033bdb287bf81679574e1.src","preCode":"  public UnsafeArrayData getArray(int ordinal) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":278,"status":"B"},{"authorDate":"2015-08-03 14:41:16","commitOrder":5,"curCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","date":"2015-08-03 14:41:16","endLine":373,"groupId":"1673","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getUTF8String","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/c5/d42d73a43a4a1758e830d614526cafa5b02e39.src","preCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":367,"status":"NB"}],"commitId":"7893cd95db5f2caba59ff5c859d7e4964ad7938d","commitMessage":"@@@[SPARK-11119] [SQL] cleanup for unsafe array and map\n\nThe purpose of this PR is to keep the unsafe format detail only inside the unsafe class itself.  so when we use them(like use unsafe array in unsafe map.  use unsafe array and map in columnar cache).  we don't need to understand the format before use them.\n\nchange list:\n* unsafe array's 4-bytes numElements header is now required(was optional).  and become a part of unsafe array format.\n* w.r.t the previous changing.  the `sizeInBytes` of unsafe array now counts the 4-bytes header.\n* unsafe map's format was `[numElements] [key array numBytes] [key array content(without numElements header)] [value array content(without numElements header)]` before.  which is a little hacky as it makes unsafe array's header optional. I think saving 4 bytes is not a big deal.  so the format is now: `[key array numBytes] [unsafe key array] [unsafe value array]`.\n* w.r.t the previous changing.  the `sizeInBytes` of unsafe map now counts both map's header and array's header.\n\nAuthor: Wenchen Fan <wenchen@databricks.com>\n\nCloses #9131 from cloud-fan/unsafe.\n","date":"2015-10-20 02:02:26","modifiedFileCount":"5","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2015-10-22 10:20:31","codes":[{"authorDate":"2015-10-20 02:02:26","commitOrder":6,"curCode":"  public UnsafeArrayData getArray(int ordinal) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","date":"2015-10-20 02:02:26","endLine":286,"groupId":"108","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getArray","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/76/1f0447943e8e4ecd5033bdb287bf81679574e1.src","preCode":"  public UnsafeArrayData getArray(int ordinal) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":278,"status":"N"},{"authorDate":"2015-10-22 10:20:31","commitOrder":6,"curCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","date":"2015-10-22 10:20:31","endLine":407,"groupId":"2774","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getUTF8String","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/85/0838af9be359e2c65178b0ba79a662e241e654.src","preCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) (offsetAndSize & ((1L << 32) - 1));\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":401,"status":"M"}],"commitId":"1d9733271595596683a6d956a7433fa601df1cc1","commitMessage":"@@@[SPARK-11243][SQL] output UnsafeRow from columnar cache\n\nThis PR change InMemoryTableScan to output UnsafeRow.  and optimize the unrolling and scanning by coping the bytes for var-length types between UnsafeRow and ByteBuffer directly without creating the wrapper objects. When scanning the decimals in TPC-DS store_sales table.  it's 80% faster (copy it as long without create Decimal objects).\n\nAuthor: Davies Liu <davies@databricks.com>\n\nCloses #9203 from davies/unsafe_cache.\n","date":"2015-10-22 10:20:31","modifiedFileCount":"3","status":"M","submitter":"Davies Liu"},{"authorTime":"2015-10-22 10:20:31","codes":[{"authorDate":"2016-09-27 14:18:32","commitOrder":7,"curCode":"  public UnsafeArrayData getArray(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","date":"2016-09-27 14:18:32","endLine":276,"groupId":"2774","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getArray","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/86/523c14740157e32d534185bdc170733f7476b4.src","preCode":"  public UnsafeArrayData getArray(int ordinal) {\n    assertIndexIsValid(ordinal);\n    final int offset = getElementOffset(ordinal);\n    if (offset < 0) return null;\n    final int size = getElementSize(offset, ordinal);\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"M"},{"authorDate":"2015-10-22 10:20:31","commitOrder":7,"curCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","date":"2015-10-22 10:20:31","endLine":407,"groupId":"2774","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getUTF8String","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/85/0838af9be359e2c65178b0ba79a662e241e654.src","preCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":401,"status":"N"}],"commitId":"85b0a157543201895557d66306b38b3ca52f2151","commitMessage":"@@@[SPARK-15962][SQL] Introduce implementation with a dense format for UnsafeArrayData\n\n## What changes were proposed in this pull request?\n\nThis PR introduces more compact representation for ```UnsafeArrayData```.\n\n```UnsafeArrayData``` needs to accept ```null``` value in each entry of an array. In the current version.  it has three parts\n```\n[numElements] [offsets] [values]\n```\n`Offsets` has the number of `numElements`.  and represents `null` if its value is negative. It may increase memory footprint.  and introduces an indirection for accessing each of `values`.\n\nThis PR uses bitvectors to represent nullability for each element like `UnsafeRow`.  and eliminates an indirection for accessing each element. The new ```UnsafeArrayData``` has four parts.\n```\n[numElements][null bits][values or offset&length][variable length portion]\n```\nIn the `null bits` region.  we store 1 bit per element.  represents whether an element is null. Its total size is ceil(numElements / 8) bytes.  and it is aligned to 8-byte boundaries.\nIn the `values or offset&length` region.  we store the content of elements. For fields that hold fixed-length primitive types.  such as long.  double.  or int.  we store the value directly in the field. For fields with non-primitive or variable-length values.  we store a relative offset (w.r.t. the base address of the array) that points to the beginning of the variable-length field and length (they are combined into a long). Each is word-aligned. For `variable length portion`.  each is aligned to 8-byte boundaries.\n\nThe new format can reduce memory footprint and improve performance of accessing each element. An example of memory foot comparison:\n1024x1024 elements integer array\nSize of ```baseObject``` for ```UnsafeArrayData```: 8 + 1024x1024 + 1024x1024 = 2M bytes\nSize of ```baseObject``` for ```UnsafeArrayData```: 8 + 1024x1024/8 + 1024x1024 = 1.25M bytes\n\nIn summary.  we got 1.0-2.6x performance improvements over the code before applying this PR.\nHere are performance results of [benchmark programs](https://github.com/kiszk/spark/blob/04d2e4b6dbdc4eff43ce18b3c9b776e0129257c7/sql/core/src/test/scala/org/apache/spark/sql/execution/benchmark/UnsafeArrayDataBenchmark.scala):\n\n**Read UnsafeArrayData**: 1.7x and 1.6x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.4.11-200.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nRead UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            430 /  436        390.0           2.6       1.0X\nDouble                                         456 /  485        367.8           2.7       0.9X\n\nWith SPARK-15962\nRead UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            252 /  260        666.1           1.5       1.0X\nDouble                                         281 /  292        597.7           1.7       0.9X\n````\n**Write UnsafeArrayData**: 1.0x and 1.1x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nWrite UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            203 /  273        103.4           9.7       1.0X\nDouble                                         239 /  356         87.9          11.4       0.8X\n\nWith SPARK-15962\nWrite UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            196 /  249        107.0           9.3       1.0X\nDouble                                         227 /  367         92.3          10.8       0.9X\n````\n\n**Get primitive array from UnsafeArrayData**: 2.6x and 1.6x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nGet primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            207 /  217        304.2           3.3       1.0X\nDouble                                         257 /  363        245.2           4.1       0.8X\n\nWith SPARK-15962\nGet primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            151 /  198        415.8           2.4       1.0X\nDouble                                         214 /  394        293.6           3.4       0.7X\n````\n\n**Create UnsafeArrayData from primitive array**: 1.7x and 2.1x performance improvements over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nCreate UnsafeArrayData from primitive array: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            340 /  385        185.1           5.4       1.0X\nDouble                                         479 /  705        131.3           7.6       0.7X\n\nWith SPARK-15962\nCreate UnsafeArrayData from primitive array: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nInt                                            206 /  211        306.0           3.3       1.0X\nDouble                                         232 /  406        271.6           3.7       0.9X\n````\n\n1.7x and 1.4x performance improvements in [```UDTSerializationBenchmark```](https://github.com/apache/spark/blob/master/mllib/src/test/scala/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.scala)  over the code before applying this PR\n````\nOpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.4.11-200.fc22.x86_64\nIntel Xeon E3-12xx v2 (Ivy Bridge)\n\nWithout SPARK-15962\nVectorUDT de/serialization:              Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nserialize                                      442 /  533          0.0      441927.1       1.0X\ndeserialize                                    217 /  274          0.0      217087.6       2.0X\n\nWith SPARK-15962\nVectorUDT de/serialization:              Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nserialize                                      265 /  318          0.0      265138.5       1.0X\ndeserialize                                    155 /  197          0.0      154611.4       1.7X\n````\n\n## How was this patch tested?\n\nAdded unit tests into ```UnsafeArraySuite```\n\nAuthor: Kazuaki Ishizaki <ishizaki@jp.ibm.com>\n\nCloses #13680 from kiszk/SPARK-15962.\n","date":"2016-09-27 14:18:32","modifiedFileCount":"4","status":"M","submitter":"Kazuaki Ishizaki"},{"authorTime":"2018-04-06 10:13:59","codes":[{"authorDate":"2016-09-27 14:18:32","commitOrder":8,"curCode":"  public UnsafeArrayData getArray(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","date":"2016-09-27 14:18:32","endLine":276,"groupId":"2774","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getArray","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/86/523c14740157e32d534185bdc170733f7476b4.src","preCode":"  public UnsafeArrayData getArray(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"N"},{"authorDate":"2018-04-06 10:13:59","commitOrder":8,"curCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    MemoryBlock mb = MemoryBlock.allocateFromObject(baseObject, baseOffset + offset, size);\n    return new UTF8String(mb);\n  }\n","date":"2018-04-06 10:13:59","endLine":420,"groupId":"122","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getUTF8String","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/29/a1411241cf6690c1221729c12ef33ee8e93c9f.src","preCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":413,"status":"M"}],"commitId":"4807d381bb113a5c61e6dad88202f23a8b6dd141","commitMessage":"@@@[SPARK-10399][CORE][SQL] Introduce multiple MemoryBlocks to choose several types of memory block\n\n## What changes were proposed in this pull request?\n\nThis PR allows us to use one of several types of `MemoryBlock`.  such as byte array.  int array.  long array.  or `java.nio.DirectByteBuffer`. To use `java.nio.DirectByteBuffer` allows to have off heap memory which is automatically deallocated by JVM. `MemoryBlock`  class has primitive accessors like `Platform.getInt()`.  `Platform.putint()`.  or `Platform.copyMemory()`.\n\nThis PR uses `MemoryBlock` for `OffHeapColumnVector`.  `UTF8String`.  and other places. This PR can improve performance of operations involving memory accesses (e.g. `UTF8String.trim`) by 1.8x.\n\nFor now.  this PR does not use `MemoryBlock` for `BufferHolder` based on cloud-fan's [suggestion](https://github.com/apache/spark/pull/11494#issuecomment-309694290).\n\nSince this PR is a successor of #11494.  close #11494. Many codes were ported from #11494. Many efforts were put here. **I think this PR should credit to yzotov.**\n\nThis PR can achieve **1.1-1.4x performance improvements** for  operations in `UTF8String` or `Murmur3_x86_32`. Other operations are almost comparable performances.\n\nWithout this PR\n```\nOpenJDK 64-Bit Server VM 1.8.0_121-8u121-b13-0ubuntu1.16.04.2-b13 on Linux 4.4.0-22-generic\nIntel(R) Xeon(R) CPU E5-2667 v3  3.20GHz\nOpenJDK 64-Bit Server VM 1.8.0_121-8u121-b13-0ubuntu1.16.04.2-b13 on Linux 4.4.0-22-generic\nIntel(R) Xeon(R) CPU E5-2667 v3  3.20GHz\nHash byte arrays with length 268435487:  Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nMurmur3_x86_32                                 526 /  536          0.0   131399881.5       1.0X\n\nUTF8String benchmark:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nhashCode                                       525 /  552       1022.6           1.0       1.0X\nsubstring                                      414 /  423       1298.0           0.8       1.3X\n```\n\nWith this PR\n```\nOpenJDK 64-Bit Server VM 1.8.0_121-8u121-b13-0ubuntu1.16.04.2-b13 on Linux 4.4.0-22-generic\nIntel(R) Xeon(R) CPU E5-2667 v3  3.20GHz\nHash byte arrays with length 268435487:  Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nMurmur3_x86_32                                 474 /  488          0.0   118552232.0       1.0X\n\nUTF8String benchmark:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nhashCode                                       476 /  480       1127.3           0.9       1.0X\nsubstring                                      287 /  291       1869.9           0.5       1.7X\n```\n\nBenchmark program\n```\ntest(\"benchmark Murmur3_x86_32\") {\n  val length = 8192 * 32768 + 31\n  val seed = 42L\n  val iters = 1 << 2\n  val random = new Random(seed)\n  val arrays = Array.fill[MemoryBlock](numArrays) {\n    val bytes = new Array[Byte](length)\n    random.nextBytes(bytes)\n    new ByteArrayMemoryBlock(bytes.  Platform.BYTE_ARRAY_OFFSET.  length)\n  }\n\n  val benchmark = new Benchmark(\"Hash byte arrays with length \" + length. \n    iters * numArrays.  minNumIters = 20)\n  benchmark.addCase(\"HiveHasher\") { _: Int =>\n    var sum = 0L\n    for (_ <- 0L until iters) {\n      sum += HiveHasher.hashUnsafeBytesBlock(\n        arrays(i).  Platform.BYTE_ARRAY_OFFSET.  length)\n    }\n  }\n  benchmark.run()\n}\n\ntest(\"benchmark UTF8String\") {\n  val N = 512 * 1024 * 1024\n  val iters = 2\n  val benchmark = new Benchmark(\"UTF8String benchmark\".  N.  minNumIters = 20)\n  val str0 = new java.io.StringWriter() { { for (i <- 0 until N) { write(\" \") } } }.toString\n  val s0 = UTF8String.fromString(str0)\n  benchmark.addCase(\"hashCode\") { _: Int =>\n    var h: Int = 0\n    for (_ <- 0L until iters) { h += s0.hashCode }\n  }\n  benchmark.addCase(\"substring\") { _: Int =>\n    var s: UTF8String = null\n    for (_ <- 0L until iters) { s = s0.substring(N / 2 - 5.  N / 2 + 5) }\n  }\n  benchmark.run()\n}\n```\n\nI run [this benchmark program](https://gist.github.com/kiszk/94f75b506c93a663bbbc372ffe8f05de) using [the commit](https://github.com/apache/spark/pull/19222/commits/ee5a79861c18725fb1cd9b518cdfd2489c05b81d6). I got the following results:\n\n```\nOpenJDK 64-Bit Server VM 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12 on Linux 4.4.0-66-generic\nIntel(R) Xeon(R) CPU E5-2667 v3  3.20GHz\nMemory access benchmarks:                Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nByteArrayMemoryBlock get/putInt()              220 /  221        609.3           1.6       1.0X\nPlatform get/putInt(byte[])                    220 /  236        610.9           1.6       1.0X\nPlatform get/putInt(Object)                    492 /  494        272.8           3.7       0.4X\nOnHeapMemoryBlock get/putLong()                322 /  323        416.5           2.4       0.7X\nlong[]                                         221 /  221        608.0           1.6       1.0X\nPlatform get/putLong(long[])                   321 /  321        418.7           2.4       0.7X\nPlatform get/putLong(Object)                   561 /  563        239.2           4.2       0.4X\n```\n\nI also run [this benchmark program](https://gist.github.com/kiszk/5fdb4e03733a5d110421177e289d1fb5) for comparing performance of `Platform.copyMemory()`.\n```\nOpenJDK 64-Bit Server VM 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12 on Linux 4.4.0-66-generic\nIntel(R) Xeon(R) CPU E5-2667 v3  3.20GHz\nPlatform copyMemory:                     Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------\nObject to Object                              1961 / 1967          8.6         116.9       1.0X\nSystem.arraycopy Object to Object             1917 / 1921          8.8         114.3       1.0X\nbyte array to byte array                      1961 / 1968          8.6         116.9       1.0X\nSystem.arraycopy byte array to byte array      1909 / 1937          8.8         113.8       1.0X\nint array to int array                        1921 / 1990          8.7         114.5       1.0X\ndouble array to double array                  1918 / 1923          8.7         114.3       1.0X\nObject to byte array                          1961 / 1967          8.6         116.9       1.0X\nObject to short array                         1965 / 1972          8.5         117.1       1.0X\nObject to int array                           1910 / 1915          8.8         113.9       1.0X\nObject to float array                         1971 / 1978          8.5         117.5       1.0X\nObject to double array                        1919 / 1944          8.7         114.4       1.0X\nbyte array to Object                          1959 / 1967          8.6         116.8       1.0X\nint array to Object                           1961 / 1970          8.6         116.9       1.0X\ndouble array to Object                        1917 / 1924          8.8         114.3       1.0X\n```\n\nThese results show three facts:\n1. According to the second/third or sixth/seventh results in the first experiment.  if we use `Platform.get/putInt(Object)`.  we achieve more than 2x worse performance than `Platform.get/putInt(byte[])` with concrete type (i.e. `byte[]`).\n2. According to the second/third or fourth/fifth/sixth results in the first experiment.  the fastest way to access an array element on Java heap is `array[]`. **Cons of `array[]` is that it is not possible to support unaligned-8byte access.**\n3. According to the first/second/third or fourth/sixth/seventh results in the first experiment.  `getInt()/putInt() or getLong()/putLong()` in subclasses of `MemoryBlock` can achieve comparable performance to `Platform.get/putInt()` or `Platform.get/putLong()` with concrete type (second or sixth result). There is no overhead regarding virtual call.\n4. According to results in the second experiment.  for `Platform.copy()`.  to pass `Object` can achieve the same performance as to pass any type of primitive array as source or destination.\n5. According to second/fourth results in the second experiment.  `Platform.copy()` can achieve the same performance as `System.arrayCopy`. **It would be good to use `Platform.copy()` since `Platform.copy()` can take any types for src and dst.**\n\nWe are incrementally replace `Platform.get/putXXX` with `MemoryBlock.get/putXXX`. This is because we have two advantages.\n1) Achieve better performance due to having a concrete type for an array.\n2) Use simple OO design instead of passing `Object`\nIt is easy to use `MemoryBlock` in `InternalRow`.  `BufferHolder`.  `TaskMemoryManager`.  and others that are already abstracted. It is not easy to use `MemoryBlock` in utility classes related to hashing or others.\n\nOther candidates are\n- UnsafeRow.  UnsafeArrayData.  UnsafeMapData.  SpecificUnsafeRowJoiner\n- UTF8StringBuffer\n- BufferHolder\n- TaskMemoryManager\n- OnHeapColumnVector\n- BytesToBytesMap\n- CachedBatch\n- classes for hash\n- others.\n\n## How was this patch tested?\n\nAdded `UnsafeMemoryAllocator`\n\nAuthor: Kazuaki Ishizaki <ishizaki@jp.ibm.com>\n\nCloses #19222 from kiszk/SPARK-10399.\n","date":"2018-04-06 10:13:59","modifiedFileCount":"27","status":"M","submitter":"Kazuaki Ishizaki"},{"authorTime":"2018-09-09 21:25:19","codes":[{"authorDate":"2016-09-27 14:18:32","commitOrder":9,"curCode":"  public UnsafeArrayData getArray(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","date":"2016-09-27 14:18:32","endLine":276,"groupId":"10344","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getArray","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/86/523c14740157e32d534185bdc170733f7476b4.src","preCode":"  public UnsafeArrayData getArray(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    final UnsafeArrayData array = new UnsafeArrayData();\n    array.pointTo(baseObject, baseOffset + offset, size);\n    return array;\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeArrayData.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"N"},{"authorDate":"2018-09-09 21:25:19","commitOrder":9,"curCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    return UTF8String.fromAddress(baseObject, baseOffset + offset, size);\n  }\n","date":"2018-09-09 21:25:19","endLine":420,"groupId":"10344","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getUTF8String","params":"(intordinal)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a7/6e6ef8c91c11004c3f8cf72f41f133548c6d63.src","preCode":"  public UTF8String getUTF8String(int ordinal) {\n    if (isNullAt(ordinal)) return null;\n    final long offsetAndSize = getLong(ordinal);\n    final int offset = (int) (offsetAndSize >> 32);\n    final int size = (int) offsetAndSize;\n    MemoryBlock mb = MemoryBlock.allocateFromObject(baseObject, baseOffset + offset, size);\n    return new UTF8String(mb);\n  }\n","realPath":"sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/UnsafeRow.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":414,"status":"M"}],"commitId":"0b9ccd55c2986957863dcad3b44ce80403eecfa1","commitMessage":"@@@Revert [SPARK-10399] [SPARK-23879] [SPARK-23762] [SPARK-25317]\n\n## What changes were proposed in this pull request?\n\nWhen running TPC-DS benchmarks on 2.4 release.  npoggi and winglungngai  saw more than 10% performance regression on the following queries: q67.  q24a and q24b. After we applying the PR https://github.com/apache/spark/pull/22338.  the performance regression still exists. If we revert the changes in https://github.com/apache/spark/pull/19222.  npoggi and winglungngai  found the performance regression was resolved. Thus.  this PR is to revert the related changes for unblocking the 2.4 release.\n\nIn the future release.  we still can continue the investigation and find out the root cause of the regression.\n\n## How was this patch tested?\n\nThe existing test cases\n\nCloses #22361 from gatorsmile/revertMemoryBlock.\n\nAuthored-by: gatorsmile <gatorsmile@gmail.com>\nSigned-off-by: Wenchen Fan <wenchen@databricks.com>\n","date":"2018-09-09 21:25:19","modifiedFileCount":"28","status":"M","submitter":"gatorsmile"}]
