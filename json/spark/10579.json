[{"authorTime":"2016-04-22 07:48:51","codes":[{"authorDate":"2016-04-22 07:48:51","commitOrder":1,"curCode":"  private static void sortAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 8;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","date":"2016-04-22 07:48:51","endLine":95,"groupId":"1245","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"sortAtByte","params":"(LongArrayarray@intnumRecords@long[]counts@intbyteIdx@intinIndex@intoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  private static void sortAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 8;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"B"},{"authorDate":"2016-04-22 07:48:51","commitOrder":1,"curCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 16;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","date":"2016-04-22 07:48:51","endLine":252,"groupId":"1249","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"sortKeyPrefixArrayAtByte","params":"(LongArrayarray@intnumRecords@long[]counts@intbyteIdx@intinIndex@intoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 16;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":234,"status":"B"}],"commitId":"e2b5647ab92eb478b3f7b36a0ce6faf83e24c0e5","commitMessage":"@@@[SPARK-14724] Use radix sort for shuffles and sort operator when possible\n\n## What changes were proposed in this pull request?\n\nSpark currently uses TimSort for all in-memory sorts.  including sorts done for shuffle. One low-hanging fruit is to use radix sort when possible (e.g. sorting by integer keys). This PR adds a radix sort implementation to the unsafe sort package and switches shuffles and sorts to use it when possible.\n\nThe current implementation does not have special support for null values.  so we cannot radix-sort `LongType`. I will address this in a follow-up PR.\n\n## How was this patch tested?\n\nUnit tests.  enabling radix sort on existing tests. Microbenchmark results:\n\n```\nRunning benchmark: radix sort 25000000\nJava HotSpot(TM) 64-Bit Server VM 1.8.0_66-b17 on Linux 3.13.0-44-generic\nIntel(R) Core(TM) i7-4600U CPU  2.10GHz\n\nradix sort 25000000:                Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n-------------------------------------------------------------------------------------------\nreference TimSort key prefix array     15546 / 15859          1.6         621.9       1.0X\nreference Arrays.sort                    2416 / 2446         10.3          96.6       6.4X\nradix sort one byte                       133 /  137        188.4           5.3     117.2X\nradix sort two bytes                      255 /  258         98.2          10.2      61.1X\nradix sort eight bytes                    991 /  997         25.2          39.6      15.7X\nradix sort key prefix array              1540 / 1563         16.2          61.6      10.1X\n```\n\nI also ran a mix of the supported TPCDS queries and compared TimSort vs RadixSort metrics. The overall benchmark ran ~10% faster with radix sort on. In the breakdown below.  the radix-enabled sort phases averaged about 20x faster than TimSort.  however sorting is only a small fraction of the overall runtime. About half of the TPCDS queries were able to take advantage of radix sort.\n\n```\nTPCDS on master: 2499s real time.  8185s executor\n    - 1171s in TimSort.  avg 267 MB/s\n(note the /s accounting is weird here since dataSize counts the record sizes too)\n\nTPCDS with radix enabled: 2294s real time.  7391s executor\n    - 596s in TimSort.  avg 254 MB/s\n    - 26s in radix sort.  avg 4.2 GB/s\n```\n\ncc davies rxin\n\nAuthor: Eric Liang <ekl@databricks.com>\n\nCloses #12490 from ericl/sort-benchmark.\n","date":"2016-04-22 07:48:51","modifiedFileCount":"12","status":"B","submitter":"Eric Liang"},{"authorTime":"2016-06-12 06:42:58","codes":[{"authorDate":"2016-04-22 07:48:51","commitOrder":2,"curCode":"  private static void sortAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 8;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","date":"2016-04-22 07:48:51","endLine":95,"groupId":"1245","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"sortAtByte","params":"(LongArrayarray@intnumRecords@long[]counts@intbyteIdx@intinIndex@intoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/57b8e4749761366bb8e1f349d9e2c827d49c45.src","preCode":"  private static void sortAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 8;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"N"},{"authorDate":"2016-06-12 06:42:58","commitOrder":2,"curCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8L;\n    long maxOffset = baseOffset + numRecords * 16L;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","date":"2016-06-12 06:42:58","endLine":258,"groupId":"1249","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"sortKeyPrefixArrayAtByte","params":"(LongArrayarray@intnumRecords@long[]counts@intbyteIdx@intinIndex@intoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/40/4361734a55ba3ad5975dfc3f9523be93890db9.src","preCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 16;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"}],"commitId":"c06c58bbbb2de0c22cfc70c486d23a94c3079ba4","commitMessage":"@@@[SPARK-14851][CORE] Support radix sort with nullable longs\n\n## What changes were proposed in this pull request?\n\nThis adds support for radix sort of nullable long fields. When a sort field is null and radix sort is enabled.  we keep nulls in a separate region of the sort buffer so that radix sort does not need to deal with them. This also has performance benefits when sorting smaller integer types.  since the current representation of nulls in two's complement (Long.MIN_VALUE) otherwise forces a full-width radix sort.\n\nThis strategy for nulls does mean the sort is no longer stable. cc davies\n\n## How was this patch tested?\n\nExisting randomized sort tests for correctness. I also tested some TPCDS queries and there does not seem to be any significant regression for non-null sorts.\n\nSome test queries (best of 5 runs each).\nBefore change:\nscala> val start = System.nanoTime; spark.range(5000000).selectExpr(\"if(id > 5.  cast(hash(id) as long).  NULL) as h\").coalesce(1).orderBy(\"h\").collect(); (System.nanoTime - start) / 1e6\nstart: Long = 3190437233227987\nres3: Double = 4716.471091\n\nAfter change:\nscala> val start = System.nanoTime; spark.range(5000000).selectExpr(\"if(id > 5.  cast(hash(id) as long).  NULL) as h\").coalesce(1).orderBy(\"h\").collect(); (System.nanoTime - start) / 1e6\nstart: Long = 3190367870952791\nres4: Double = 2981.143045\n\nAuthor: Eric Liang <ekl@databricks.com>\n\nCloses #13161 from ericl/sc-2998.\n","date":"2016-06-12 06:42:58","modifiedFileCount":"7","status":"M","submitter":"Eric Liang"},{"authorTime":"2016-11-20 13:50:20","codes":[{"authorDate":"2016-11-20 13:50:20","commitOrder":3,"curCode":"  private static void sortAtByte(\n      LongArray array, long numRecords, long[] counts, int byteIdx, long inIndex, long outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8L, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8L;\n    long maxOffset = baseOffset + numRecords * 8L;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","date":"2016-11-20 13:50:20","endLine":97,"groupId":"10579","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"sortAtByte","params":"(LongArrayarray@longnumRecords@long[]counts@intbyteIdx@longinIndex@longoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/d318471008bb0b1134b8ac2d775c72a4dc308a.src","preCode":"  private static void sortAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 8, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8;\n    long maxOffset = baseOffset + numRecords * 8;\n    for (long offset = baseOffset; offset < maxOffset; offset += 8) {\n      long value = Platform.getLong(baseObject, offset);\n      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);\n      Platform.putLong(baseObject, offsets[bucket], value);\n      offsets[bucket] += 8;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"},{"authorDate":"2016-11-20 13:50:20","commitOrder":3,"curCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, long numRecords, long[] counts, int byteIdx, long inIndex, long outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8L, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8L;\n    long maxOffset = baseOffset + numRecords * 16L;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","date":"2016-11-20 13:50:20","endLine":260,"groupId":"10579","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"sortKeyPrefixArrayAtByte","params":"(LongArrayarray@longnumRecords@long[]counts@intbyteIdx@longinIndex@longoutIndex@booleandesc@booleansigned)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/3d/d318471008bb0b1134b8ac2d775c72a4dc308a.src","preCode":"  private static void sortKeyPrefixArrayAtByte(\n      LongArray array, int numRecords, long[] counts, int byteIdx, int inIndex, int outIndex,\n      boolean desc, boolean signed) {\n    assert counts.length == 256;\n    long[] offsets = transformCountsToOffsets(\n      counts, numRecords, array.getBaseOffset() + outIndex * 8, 16, desc, signed);\n    Object baseObject = array.getBaseObject();\n    long baseOffset = array.getBaseOffset() + inIndex * 8L;\n    long maxOffset = baseOffset + numRecords * 16L;\n    for (long offset = baseOffset; offset < maxOffset; offset += 16) {\n      long key = Platform.getLong(baseObject, offset);\n      long prefix = Platform.getLong(baseObject, offset + 8);\n      int bucket = (int)((prefix >>> (byteIdx * 8)) & 0xff);\n      long dest = offsets[bucket];\n      Platform.putLong(baseObject, dest, key);\n      Platform.putLong(baseObject, dest + 8, prefix);\n      offsets[bucket] += 16;\n    }\n  }\n","realPath":"core/src/main/java/org/apache/spark/util/collection/unsafe/sort/RadixSort.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":242,"status":"M"}],"commitId":"d93b6552473468df297a08c0bef9ea0bf0f5c13a","commitMessage":"@@@[SPARK-18458][CORE] Fix signed integer overflow problem at an expression in RadixSort.java\n\n## What changes were proposed in this pull request?\n\nThis PR avoids that a result of an expression is negative due to signed integer overflow (e.g. 0x10?????? * 8 < 0). This PR casts each operand to `long` before executing a calculation. Since the result is interpreted as long.  the result of the expression is positive.\n\n## How was this patch tested?\n\nManually executed query82 of TPC-DS with 100TB\n\nAuthor: Kazuaki Ishizaki <ishizaki@jp.ibm.com>\n\nCloses #15907 from kiszk/SPARK-18458.\n","date":"2016-11-20 13:50:20","modifiedFileCount":"2","status":"M","submitter":"Kazuaki Ishizaki"}]
