[{"authorTime":"2016-02-29 09:25:07","codes":[{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  public void cleanupMultipleExecutors() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app\", \"exec1\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n    resolver.applicationRemoved(\"app\", true);\n\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","date":"2016-02-29 09:25:07","endLine":95,"groupId":"3137","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"cleanupMultipleExecutors","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/53/2d7ab8d01bd60e608f4d0a658d157e68a76034.src","preCode":"  public void cleanupMultipleExecutors() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app\", \"exec1\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n    resolver.applicationRemoved(\"app\", true);\n\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/ExternalShuffleCleanupSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"B"},{"authorDate":"2016-02-29 09:25:07","commitOrder":1,"curCode":"  public void cleanupOnlyRemovedApp() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app-0\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app-1\", \"exec0\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n\n    resolver.applicationRemoved(\"app-nonexistent\", true);\n    assertStillThere(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-0\", true);\n    assertCleanedUp(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n\n    \r\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","date":"2016-02-29 09:25:07","endLine":124,"groupId":"2072","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"cleanupOnlyRemovedApp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/53/2d7ab8d01bd60e608f4d0a658d157e68a76034.src","preCode":"  public void cleanupOnlyRemovedApp() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app-0\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app-1\", \"exec0\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n\n    resolver.applicationRemoved(\"app-nonexistent\", true);\n    assertStillThere(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-0\", true);\n    assertCleanedUp(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n\n    \r\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/ExternalShuffleCleanupSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"B"}],"commitId":"9e01dcc6446f8648e61062f8afe62589b9d4b5ab","commitMessage":"@@@[SPARK-13529][BUILD] Move network/* modules into common/network-*\n\n## What changes were proposed in this pull request?\nAs the title says.  this moves the three modules currently in network/ into common/network-*. This removes one top level.  non-user-facing folder.\n\n## How was this patch tested?\nCompilation and existing tests. We should run both SBT and Maven.\n\nAuthor: Reynold Xin <rxin@databricks.com>\n\nCloses #11409 from rxin/SPARK-13529.\n","date":"2016-02-29 09:25:07","modifiedFileCount":"1","status":"B","submitter":"Reynold Xin"},{"authorTime":"2016-04-26 03:33:32","codes":[{"authorDate":"2016-04-26 03:33:32","commitOrder":2,"curCode":"  public void cleanupMultipleExecutors() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app\", \"exec0\", dataContext0.createExecutorInfo(SORT_MANAGER));\n    resolver.registerExecutor(\"app\", \"exec1\", dataContext1.createExecutorInfo(SORT_MANAGER));\n    resolver.applicationRemoved(\"app\", true);\n\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","date":"2016-04-26 03:33:32","endLine":97,"groupId":"1096","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"cleanupMultipleExecutors","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bd/d218db69b546dc36855e8fdcaa286eff15d6a7.src","preCode":"  public void cleanupMultipleExecutors() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app\", \"exec1\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n    resolver.applicationRemoved(\"app\", true);\n\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/ExternalShuffleCleanupSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2016-04-26 03:33:32","commitOrder":2,"curCode":"  public void cleanupOnlyRemovedApp() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app-0\", \"exec0\", dataContext0.createExecutorInfo(SORT_MANAGER));\n    resolver.registerExecutor(\"app-1\", \"exec0\", dataContext1.createExecutorInfo(SORT_MANAGER));\n\n    resolver.applicationRemoved(\"app-nonexistent\", true);\n    assertStillThere(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-0\", true);\n    assertCleanedUp(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n\n    \r\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","date":"2016-04-26 03:33:32","endLine":126,"groupId":"1096","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"cleanupOnlyRemovedApp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/bd/d218db69b546dc36855e8fdcaa286eff15d6a7.src","preCode":"  public void cleanupOnlyRemovedApp() throws IOException {\n    TestShuffleDataContext dataContext0 = createSomeData();\n    TestShuffleDataContext dataContext1 = createSomeData();\n\n    ExternalShuffleBlockResolver resolver =\n      new ExternalShuffleBlockResolver(conf, null, sameThreadExecutor);\n\n    resolver.registerExecutor(\"app-0\", \"exec0\", dataContext0.createExecutorInfo(\"shuffleMgr\"));\n    resolver.registerExecutor(\"app-1\", \"exec0\", dataContext1.createExecutorInfo(\"shuffleMgr\"));\n\n    resolver.applicationRemoved(\"app-nonexistent\", true);\n    assertStillThere(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-0\", true);\n    assertCleanedUp(dataContext0);\n    assertStillThere(dataContext1);\n\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n\n    \r\n    resolver.applicationRemoved(\"app-1\", true);\n    assertCleanedUp(dataContext0);\n    assertCleanedUp(dataContext1);\n  }\n","realPath":"common/network-shuffle/src/test/java/org/apache/spark/network/shuffle/ExternalShuffleCleanupSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"M"}],"commitId":"6bfe42a3be4fbf8bc6f93a4709038fda8ad0610b","commitMessage":"@@@[SPARK-14731][shuffle]Revert SPARK-12130 to make 2.0 shuffle service compatible with 1.x\n\n## What changes were proposed in this pull request?\nSPARK-12130 make 2.0 shuffle service incompatible with 1.x. So from discussion: [http://apache-spark-developers-list.1001551.n3.nabble.com/YARN-Shuffle-service-and-its-compatibility-td17222.html](url) we should maintain compatibility between Spark 1.x and Spark 2.x's shuffle service.\nI put string comparison into executor's register at first avoid string comparison in getBlockData every time.\n\n## How was this patch tested?\nN/A\n\nAuthor: Lianhui Wang <lianhuiwang09@gmail.com>\n\nCloses #12568 from lianhuiwang/SPARK-14731.\n","date":"2016-04-26 03:33:32","modifiedFileCount":"6","status":"M","submitter":"Lianhui Wang"}]
