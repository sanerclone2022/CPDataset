[{"authorTime":"2014-08-20 07:06:48","codes":[{"authorDate":"2014-08-20 07:06:48","commitOrder":1,"curCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2014-08-20 07:06:48","endLine":100,"groupId":"1396","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testUniformVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a7/25736ca1a58937e6476e4b399716ae14f55897.src","preCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":88,"status":"B"},{"authorDate":"2014-08-20 07:06:48","commitOrder":1,"curCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2014-08-20 07:06:48","endLine":116,"groupId":"1396","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a7/25736ca1a58937e6476e4b399716ae14f55897.src","preCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":104,"status":"B"}],"commitId":"825d4fe47b9c4d48de88622dd48dcf83beb8b80a","commitMessage":"@@@[SPARK-3136][MLLIB] Create Java-friendly methods in RandomRDDs\n\nThough we don't use default argument for methods in RandomRDDs.  it is still not easy for Java users to use because the output type is either `RDD[Double]` or `RDD[Vector]`. Java users should expect `JavaDoubleRDD` and `JavaRDD[Vector]`.  respectively. We should create dedicated methods for Java users.  and allow default arguments in Scala methods in RandomRDDs.  to make life easier for both Java and Scala users. This PR also contains documentation for random data generation. brkyvz\n\nAuthor: Xiangrui Meng <meng@databricks.com>\n\nCloses #2041 from mengxr/stat-doc and squashes the following commits:\n\nfc5eedf [Xiangrui Meng] add missing comma\nffde810 [Xiangrui Meng] address comments\naef6d07 [Xiangrui Meng] add doc for random data generation\nb99d94b [Xiangrui Meng] add java-friendly methods to RandomRDDs\n","date":"2014-08-20 07:06:48","modifiedFileCount":"0","status":"B","submitter":"Xiangrui Meng"},{"authorTime":"2015-08-28 01:46:41","codes":[{"authorDate":"2015-08-28 01:46:41","commitOrder":2,"curCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":146,"groupId":"3426","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testUniformVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/d81b1e9592b233b93a530e57266e07dd358164.src","preCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":134,"status":"M"},{"authorDate":"2015-08-28 01:46:41","commitOrder":2,"curCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":162,"groupId":"3426","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/d81b1e9592b233b93a530e57266e07dd358164.src","preCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"M"}],"commitId":"e1f4de4a7d15d4ca4b5c64ff929ac3980f5d706f","commitMessage":"@@@[SPARK-10257] [MLLIB] Removes Guava from all spark.mllib Java tests\n\n* Replaces instances of `Lists.newArrayList` with `Arrays.asList`\n* Replaces `commons.lang.StringUtils` over `com.google.collections.Strings`\n* Replaces `List` interface over `ArrayList` implementations\n\nThis PR along with #8445 #8446 #8447 completely removes all `com.google.collections.Lists` dependencies within mllib's Java tests.\n\nAuthor: Feynman Liang <fliang@databricks.com>\n\nCloses #8451 from feynmanliang/SPARK-10257.\n","date":"2015-08-28 01:46:41","modifiedFileCount":"14","status":"M","submitter":"Feynman Liang"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":3,"curCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(jsc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(jsc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(jsc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd : Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":153,"groupId":"10472","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testUniformVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b4/49108a9b83e89cffdb167f6ca4496c7f81b951.src","preCode":"  public void testUniformVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = uniformJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = uniformJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = uniformJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":141,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":3,"curCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(jsc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(jsc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(jsc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd : Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":169,"groupId":"10472","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testNormalVectorRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b4/49108a9b83e89cffdb167f6ca4496c7f81b951.src","preCode":"  public void testNormalVectorRDD() {\n    long m = 100L;\n    int n = 10;\n    int p = 2;\n    long seed = 1L;\n    JavaRDD<Vector> rdd1 = normalJavaVectorRDD(sc, m, n);\n    JavaRDD<Vector> rdd2 = normalJavaVectorRDD(sc, m, n, p);\n    JavaRDD<Vector> rdd3 = normalJavaVectorRDD(sc, m, n, p, seed);\n    for (JavaRDD<Vector> rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n      Assert.assertEquals(n, rdd.first().size());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":157,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"}]
