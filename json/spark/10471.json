[{"authorTime":"2014-12-19 13:00:49","codes":[{"authorDate":"2014-08-20 07:06:48","commitOrder":2,"curCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2014-08-20 07:06:48","endLine":84,"groupId":"778","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPoissonRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/a7/25736ca1a58937e6476e4b399716ae14f55897.src","preCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":73,"status":"NB"},{"authorDate":"2014-12-19 13:00:49","commitOrder":2,"curCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2014-12-19 13:00:49","endLine":113,"groupId":"778","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testExponentialRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/fc/c13c00cbdc52e63b2b251d2a789ac30ec3f2ee.src","preCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"B"}],"commitId":"ee1fb97a97d5ac18cd2ad8028e84ecbd988fb811","commitMessage":"@@@[SPARK-4728][MLLib] Add exponential.  gamma.  and log normal sampling to MLlib da...\n\n...ta generators\n\nThis patch adds:\n\n* Exponential.  gamma.  and log normal generators that wrap Apache Commons math3 to the private API\n* Functions for generating exponential.  gamma.  and log normal RDDs and vector RDDs\n* Tests for the above\n\nAuthor: RJ Nowling <rnowling@gmail.com>\n\nCloses #3680 from rnowling/spark4728 and squashes the following commits:\n\n455f50a [RJ Nowling] Add tests for exponential.  gamma.  and log normal samplers to JavaRandomRDDsSuite\n3e1134a [RJ Nowling] Fix val/var.  unncessary creation of Distribution objects when setting seeds.  and import line longer than line wrap limits\n58f5b97 [RJ Nowling] Fix bounds in tests so they scale with variance.  not stdev\n84fd98d [RJ Nowling] Add more values for testing distributions.\n9f96232 [RJ Nowling] [SPARK-4728] Add exponential.  gamma.  and log normal sampling to MLlib data generators\n","date":"2014-12-19 13:00:49","modifiedFileCount":"1","status":"M","submitter":"RJ Nowling"},{"authorTime":"2015-08-28 01:46:41","codes":[{"authorDate":"2015-08-28 01:46:41","commitOrder":3,"curCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":100,"groupId":"778","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPoissonRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/d81b1e9592b233b93a530e57266e07dd358164.src","preCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":89,"status":"M"},{"authorDate":"2015-08-28 01:46:41","commitOrder":3,"curCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2015-08-28 01:46:41","endLine":114,"groupId":"778","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testExponentialRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/33/d81b1e9592b233b93a530e57266e07dd358164.src","preCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Lists.newArrayList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":103,"status":"M"}],"commitId":"e1f4de4a7d15d4ca4b5c64ff929ac3980f5d706f","commitMessage":"@@@[SPARK-10257] [MLLIB] Removes Guava from all spark.mllib Java tests\n\n* Replaces instances of `Lists.newArrayList` with `Arrays.asList`\n* Replaces `commons.lang.StringUtils` over `com.google.collections.Strings`\n* Replaces `List` interface over `ArrayList` implementations\n\nThis PR along with #8445 #8446 #8447 completely removes all `com.google.collections.Lists` dependencies within mllib's Java tests.\n\nAuthor: Feynman Liang <fliang@databricks.com>\n\nCloses #8451 from feynmanliang/SPARK-10257.\n","date":"2015-08-28 01:46:41","modifiedFileCount":"14","status":"M","submitter":"Feynman Liang"},{"authorTime":"2016-05-11 02:17:47","codes":[{"authorDate":"2016-05-11 02:17:47","commitOrder":4,"curCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(jsc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(jsc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(jsc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd : Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":107,"groupId":"10471","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testPoissonRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b4/49108a9b83e89cffdb167f6ca4496c7f81b951.src","preCode":"  public void testPoissonRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = poissonJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = poissonJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = poissonJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"M"},{"authorDate":"2016-05-11 02:17:47","commitOrder":4,"curCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(jsc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(jsc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(jsc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd : Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","date":"2016-05-11 02:17:47","endLine":121,"groupId":"10471","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testExponentialRDD","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/b4/49108a9b83e89cffdb167f6ca4496c7f81b951.src","preCode":"  public void testExponentialRDD() {\n    double mean = 2.0;\n    long m = 1000L;\n    int p = 2;\n    long seed = 1L;\n    JavaDoubleRDD rdd1 = exponentialJavaRDD(sc, mean, m);\n    JavaDoubleRDD rdd2 = exponentialJavaRDD(sc, mean, m, p);\n    JavaDoubleRDD rdd3 = exponentialJavaRDD(sc, mean, m, p, seed);\n    for (JavaDoubleRDD rdd: Arrays.asList(rdd1, rdd2, rdd3)) {\n      Assert.assertEquals(m, rdd.count());\n    }\n  }\n","realPath":"mllib/src/test/java/org/apache/spark/mllib/random/JavaRandomRDDsSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"}],"commitId":"ed0b4070fb50054b1ecf66ff6c32458a4967dfd3","commitMessage":"@@@[SPARK-15037][SQL][MLLIB] Use SparkSession instead of SQLContext in Scala/Java TestSuites\n\n## What changes were proposed in this pull request?\nUse SparkSession instead of SQLContext in Scala/Java TestSuites\nas this PR already very big working Python TestSuites in a diff PR.\n\n## How was this patch tested?\nExisting tests\n\nAuthor: Sandeep Singh <sandeep@techaddict.me>\n\nCloses #12907 from techaddict/SPARK-15037.\n","date":"2016-05-11 02:17:47","modifiedFileCount":"63","status":"M","submitter":"Sandeep Singh"}]
