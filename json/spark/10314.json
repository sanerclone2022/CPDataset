[{"authorTime":"2016-07-27 09:08:07","codes":[{"authorDate":"2016-07-27 09:08:07","commitOrder":1,"curCode":"  public void iteratorTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2016-07-27 09:08:07","endLine":269,"groupId":"1269","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"iteratorTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0d/d129cea7b3f96cb65e1da6f3ee72f3d9e87aa9.src","preCode":"  public void iteratorTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"B"},{"authorDate":"2016-07-27 09:08:07","commitOrder":1,"curCode":"  public void fixedLengthTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2016-07-27 09:08:07","endLine":309,"groupId":"1269","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"fixedLengthTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/0d/d129cea7b3f96cb65e1da6f3ee72f3d9e87aa9.src","preCode":"  public void fixedLengthTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":272,"status":"B"}],"commitId":"738b4cc548ca48c010b682b8bc19a2f7e1947cfe","commitMessage":"@@@[SPARK-16524][SQL] Add RowBatch and RowBasedHashMapGenerator\n\n## What changes were proposed in this pull request?\n\nThis PR is the first step for the following feature:\n\nFor hash aggregation in Spark SQL.  we use a fast aggregation hashmap to act as a \"cache\" in order to boost aggregation performance. Previously.  the hashmap is backed by a `ColumnarBatch`. This has performance issues when we have wide schema for the aggregation table (large number of key fields or value fields).\nIn this JIRA.  we support another implementation of fast hashmap.  which is backed by a `RowBasedKeyValueBatch`. We then automatically pick between the two implementations based on certain knobs.\n\nIn this first-step PR.  implementations for `RowBasedKeyValueBatch` and `RowBasedHashMapGenerator` are added.\n\n## How was this patch tested?\n\nUnit tests: `RowBasedKeyValueBatchSuite`\n\nAuthor: Qifan Pu <qifan.pu@gmail.com>\n\nCloses #14349 from ooq/SPARK-16524.\n","date":"2016-07-27 09:08:07","modifiedFileCount":"0","status":"B","submitter":"Qifan Pu"},{"authorTime":"2018-10-05 09:58:25","codes":[{"authorDate":"2018-10-05 09:58:25","commitOrder":2,"curCode":"  public void iteratorTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","date":"2018-10-05 09:58:25","endLine":243,"groupId":"1269","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"iteratorTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ef/02f0ae72686535ec3409ada82ff562746feed3.src","preCode":"  public void iteratorTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":217,"status":"M"},{"authorDate":"2018-10-05 09:58:25","commitOrder":2,"curCode":"  public void fixedLengthTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","date":"2018-10-05 09:58:25","endLine":280,"groupId":"1269","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"fixedLengthTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/ef/02f0ae72686535ec3409ada82ff562746feed3.src","preCode":"  public void fixedLengthTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":246,"status":"M"}],"commitId":"44c1e1ab1c26560371831b1593f96f30344c4363","commitMessage":"@@@[SPARK-25408] Move to mode ideomatic Java8\n\nWhile working on another PR.  I noticed that there is quite some legacy Java in there that can be beautified. For example the use og features from Java8.  such as:\n- Collection libraries\n- Try-with-resource blocks\n\nNo code has been changed\n\nWhat are your thoughts on this?\n\nThis makes code easier to read.  and using try-with-resource makes is less likely to forget to close something.\n\n## What changes were proposed in this pull request?\n\n(Please fill in changes proposed in this fix)\n\n## How was this patch tested?\n\n(Please explain how this patch was tested. E.g. unit tests.  integration tests.  manual tests)\n(If this patch involves UI changes.  please attach a screenshot; otherwise.  remove this)\n\nPlease review http://spark.apache.org/contributing.html before opening a pull request.\n\nCloses #22399 from Fokko/SPARK-25408.\n\nAuthored-by: Fokko Driesprong <fokkodriesprong@godatadriven.com>\nSigned-off-by: Sean Owen <sean.owen@databricks.com>\n","date":"2018-10-05 09:58:25","modifiedFileCount":"19","status":"M","submitter":"Fokko Driesprong"},{"authorTime":"2018-10-05 11:03:41","codes":[{"authorDate":"2018-10-05 11:03:41","commitOrder":3,"curCode":"  public void iteratorTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2018-10-05 11:03:41","endLine":259,"groupId":"1269","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"iteratorTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/a87113c6229a807c41c7cae298bd8efe426034.src","preCode":"  public void iteratorTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":230,"status":"M"},{"authorDate":"2018-10-05 11:03:41","commitOrder":3,"curCode":"  public void fixedLengthTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","date":"2018-10-05 11:03:41","endLine":299,"groupId":"1269","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"fixedLengthTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/2d/a87113c6229a807c41c7cae298bd8efe426034.src","preCode":"  public void fixedLengthTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":262,"status":"M"}],"commitId":"5ae20cf1a96a33f5de4435fcfb55914d64466525","commitMessage":"@@@Revert \"[SPARK-25408] Move to mode ideomatic Java8\"\n\nThis reverts commit 44c1e1ab1c26560371831b1593f96f30344c4363.\n","date":"2018-10-05 11:03:41","modifiedFileCount":"19","status":"M","submitter":"Wenchen Fan"},{"authorTime":"2018-10-08 22:58:52","codes":[{"authorDate":"2018-10-08 22:58:52","commitOrder":4,"curCode":"  public void iteratorTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","date":"2018-10-08 22:58:52","endLine":243,"groupId":"10314","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"iteratorTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/a778800bb9f253184321108e97a77143173c1a.src","preCode":"  public void iteratorTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(keySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(1, \"A\"), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(2, \"B\"), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(3, \"C\"), makeValueRow(3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 1, \"A\"));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 2, \"B\"));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 3, \"C\"));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":217,"status":"M"},{"authorDate":"2018-10-08 22:58:52","commitOrder":4,"curCode":"  public void fixedLengthTest() throws Exception {\n    try (RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n        valueSchema, taskMemoryManager, DEFAULT_CAPACITY)) {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    }\n  }\n","date":"2018-10-08 22:58:52","endLine":280,"groupId":"10314","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"fixedLengthTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/8d/a778800bb9f253184321108e97a77143173c1a.src","preCode":"  public void fixedLengthTest() throws Exception {\n    RowBasedKeyValueBatch batch = RowBasedKeyValueBatch.allocate(fixedKeySchema,\n            valueSchema, taskMemoryManager, DEFAULT_CAPACITY);\n    try {\n      appendRow(batch, makeKeyRow(11, 11), makeValueRow(1, 1));\n      appendRow(batch, makeKeyRow(22, 22), makeValueRow(2, 2));\n      appendRow(batch, makeKeyRow(33, 33), makeValueRow(3, 3));\n      UnsafeRow retrievedKey1 = batch.getKeyRow(0);\n      Assert.assertTrue(checkKey(retrievedKey1, 11, 11));\n      UnsafeRow retrievedKey2 = batch.getKeyRow(1);\n      Assert.assertTrue(checkKey(retrievedKey2, 22, 22));\n      UnsafeRow retrievedValue1 = batch.getValueRow(1);\n      Assert.assertTrue(checkValue(retrievedValue1, 2, 2));\n      UnsafeRow retrievedValue2 = batch.getValueRow(2);\n      Assert.assertTrue(checkValue(retrievedValue2, 3, 3));\n      Assert.assertEquals(3, batch.numRows());\n      org.apache.spark.unsafe.KVIterator<UnsafeRow, UnsafeRow> iterator\n              = batch.rowIterator();\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key1 = iterator.getKey();\n      UnsafeRow value1 = iterator.getValue();\n      Assert.assertTrue(checkKey(key1, 11, 11));\n      Assert.assertTrue(checkValue(value1, 1, 1));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key2 = iterator.getKey();\n      UnsafeRow value2 = iterator.getValue();\n      Assert.assertTrue(checkKey(key2, 22, 22));\n      Assert.assertTrue(checkValue(value2, 2, 2));\n      Assert.assertTrue(iterator.next());\n      UnsafeRow key3 = iterator.getKey();\n      UnsafeRow value3 = iterator.getValue();\n      Assert.assertTrue(checkKey(key3, 33, 33));\n      Assert.assertTrue(checkValue(value3, 3, 3));\n      Assert.assertFalse(iterator.next());\n    } finally {\n      batch.close();\n    }\n  }\n","realPath":"sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/expressions/RowBasedKeyValueBatchSuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":246,"status":"M"}],"commitId":"1a28625355d75076bde4bcc95a72e9b187cda606","commitMessage":"@@@[SPARK-25408] Move to more ideomatic Java8\n\nWhile working on another PR.  I noticed that there is quite some legacy Java in there that can be beautified. For example the use of features from Java8.  such as:\n- Collection libraries\n- Try-with-resource blocks\n\nNo logic has been changed. I think it is important to have a solid codebase with examples that will inspire next PR's to follow up on the best practices.\n\nWhat are your thoughts on this?\n\nThis makes code easier to read.  and using try-with-resource makes is less likely to forget to close something.\n\n## What changes were proposed in this pull request?\n\nNo changes in the logic of Spark.  but more in the aesthetics of the code.\n\n## How was this patch tested?\n\nUsing the existing unit tests. Since no logic is changed.  the existing unit tests should pass.\n\nPlease review http://spark.apache.org/contributing.html before opening a pull request.\n\nCloses #22637 from Fokko/SPARK-25408.\n\nAuthored-by: Fokko Driesprong <fokkodriesprong@godatadriven.com>\nSigned-off-by: Sean Owen <sean.owen@databricks.com>\n","date":"2018-10-08 22:58:52","modifiedFileCount":"17","status":"M","submitter":"Fokko Driesprong"}]
