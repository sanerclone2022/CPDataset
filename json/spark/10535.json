[{"authorTime":"2017-02-16 20:32:45","codes":[{"authorDate":"2017-02-16 20:32:45","commitOrder":1,"curCode":"  public void treeReduce() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeReduce(add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","date":"2017-02-16 20:32:45","endLine":559,"groupId":"283","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"treeReduce","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/80/aab100aced46cbe2866850ce4da7935d650b60.src","preCode":"  public void treeReduce() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeReduce(add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","realPath":"core/src/test/java/test/org/apache/spark/JavaAPISuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":547,"status":"B"},{"authorDate":"2017-02-16 20:32:45","commitOrder":1,"curCode":"  public void treeAggregate() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeAggregate(0, add, add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","date":"2017-02-16 20:32:45","endLine":574,"groupId":"283","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"treeAggregate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/80/aab100aced46cbe2866850ce4da7935d650b60.src","preCode":"  public void treeAggregate() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeAggregate(0, add, add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","realPath":"core/src/test/java/test/org/apache/spark/JavaAPISuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":562,"status":"B"}],"commitId":"0e2405490f2056728d1353abbac6f3ea177ae533","commitMessage":"@@@[SPARK-19550][BUILD][CORE][WIP] Remove Java 7 support\n\n- Move external/java8-tests tests into core.  streaming.  sql and remove\n- Remove MaxPermGen and related options\n- Fix some reflection / TODOs around Java 8+ methods\n- Update doc references to 1.7/1.8 differences\n- Remove Java 7/8 related build profiles\n- Update some plugins for better Java 8 compatibility\n- Fix a few Java-related warnings\n\nFor the future:\n\n- Update Java 8 examples to fully use Java 8\n- Update Java tests to use lambdas for simplicity\n- Update Java internal implementations to use lambdas\n\n## How was this patch tested?\n\nExisting tests\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16871 from srowen/SPARK-19493.\n","date":"2017-02-16 20:32:45","modifiedFileCount":"51","status":"B","submitter":"Sean Owen"},{"authorTime":"2017-02-20 01:42:50","codes":[{"authorDate":"2017-02-20 01:42:50","commitOrder":2,"curCode":"  public void treeReduce() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = (a, b) -> a + b;\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeReduce(add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","date":"2017-02-20 01:42:50","endLine":507,"groupId":"10535","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"treeReduce","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/51/2149127d72f4f8f7ed7438b9ba9015a07e254f.src","preCode":"  public void treeReduce() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeReduce(add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","realPath":"core/src/test/java/test/org/apache/spark/JavaAPISuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":500,"status":"M"},{"authorDate":"2017-02-20 01:42:50","commitOrder":2,"curCode":"  public void treeAggregate() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = (a, b) -> a + b;\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeAggregate(0, add, add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","date":"2017-02-20 01:42:50","endLine":517,"groupId":"10535","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"treeAggregate","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-spark-10-0.7/blobInfo/CC_OUT/blobs/51/2149127d72f4f8f7ed7438b9ba9015a07e254f.src","preCode":"  public void treeAggregate() {\n    JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(-5, -4, -3, -2, -1, 1, 2, 3, 4), 10);\n    Function2<Integer, Integer, Integer> add = new Function2<Integer, Integer, Integer>() {\n      @Override\n      public Integer call(Integer a, Integer b) {\n        return a + b;\n      }\n    };\n    for (int depth = 1; depth <= 10; depth++) {\n      int sum = rdd.treeAggregate(0, add, add, depth);\n      assertEquals(-5, sum);\n    }\n  }\n","realPath":"core/src/test/java/test/org/apache/spark/JavaAPISuite.java","repoName":"spark","snippetEndLine":0,"snippetStartLine":0,"startLine":510,"status":"M"}],"commitId":"1487c9af20a333ead55955acf4c0aa323bea0d07","commitMessage":"@@@[SPARK-19534][TESTS] Convert Java tests to use lambdas.  Java 8 features\n\n## What changes were proposed in this pull request?\n\nConvert tests to use Java 8 lambdas.  and modest related fixes to surrounding code.\n\n## How was this patch tested?\n\nJenkins tests\n\nAuthor: Sean Owen <sowen@cloudera.com>\n\nCloses #16964 from srowen/SPARK-19534.\n","date":"2017-02-20 01:42:50","modifiedFileCount":"45","status":"M","submitter":"Sean Owen"}]
