[{"authorTime":"2014-03-19 02:12:16","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":3,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"NB"},{"authorDate":"2014-03-19 02:12:16","commitOrder":3,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192);\n    }\n  }\n","date":"2014-03-19 02:12:16","endLine":384,"groupId":"11761","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/b7/6d668459ad86920fe54f69a0f08b9bc4af2d74.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"B"}],"commitId":"0bba517d939758ed8894ed50976fb0edd2a7d8a8","commitMessage":"@@@LUCENE-5111: Fix WordDelimiterFilter offsets\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1578993 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-03-19 02:12:16","modifiedFileCount":"6","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-05-04 20:19:35","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":4,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"},{"authorDate":"2014-05-04 20:19:35","commitOrder":4,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","date":"2014-05-04 20:19:35","endLine":386,"groupId":"11761","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/78/7c9b9ab92b8355febdb0d48ea45d55070551d7.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":364,"status":"M"}],"commitId":"94c513ad5b6e186d79e0a44df750ce8a27970483","commitMessage":"@@@LUCENE-5642: Randomize attributeFactory in tests.  use MockTokenizer more where possible.  reduce use of esoteric Token ctors\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1592339 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-05-04 20:19:35","modifiedFileCount":"60","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-07-31 06:16:16","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":5,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"},{"authorDate":"2014-07-31 06:16:16","commitOrder":5,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","date":"2014-07-31 06:16:16","endLine":385,"groupId":"17864","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/65/ed12423cc1b866a64a6634d0e872fde21916bc.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"M"}],"commitId":"0368c604cc6bfcabf9c7f1c2afd0dd2e0fbb4a96","commitMessage":"@@@LUCENE-5859: remove dead code: changes no runtime behavior.  these are all unused variables\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1614778 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-07-31 06:16:16","modifiedFileCount":"258","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-07-31 18:44:39","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":6,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"},{"authorDate":"2014-07-31 18:44:39","commitOrder":6,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","date":"2014-07-31 18:44:39","endLine":386,"groupId":"11761","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/78/7c9b9ab92b8355febdb0d48ea45d55070551d7.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":364,"status":"M"}],"commitId":"e6d29d223b14778cf22682268539534160458089","commitMessage":"@@@LUCENE-5859: Literally add back dead code to please a bunch of fucking babies\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1614852 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-07-31 18:44:39","modifiedFileCount":"258","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-08-09 06:42:48","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":7,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"},{"authorDate":"2014-08-09 06:42:48","commitOrder":7,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","date":"2014-08-09 06:42:48","endLine":385,"groupId":"17864","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/64/460df6bc319dd461a4057638cf6aa9e0737c89.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(TEST_VERSION_CURRENT, tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"M"}],"commitId":"9938a39a872d4f232f718b2672d0245cae658e0b","commitMessage":"@@@LUCENE-5859: Remove Version from Analyzer constructors\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1616901 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-08-09 06:42:48","modifiedFileCount":"284","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2014-11-27 10:06:05","codes":[{"authorDate":"2014-03-02 09:47:18","commitOrder":8,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","date":"2014-03-02 09:47:18","endLine":85,"groupId":"59117","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/30/69c0ab1e2d471a4be3b98fea150955b3c4e76e.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":76,"status":"N"},{"authorDate":"2014-11-27 10:06:05","commitOrder":8,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","date":"2014-11-27 10:06:05","endLine":385,"groupId":"17864","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d2/d97117e0f8f55ec66e8ec749b134e71bf70f54.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 100*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":363,"status":"M"}],"commitId":"c2c106befa6d5671e9bd31fec57943b619383537","commitMessage":"@@@analysis test speedups\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1642002 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-11-27 10:06:05","modifiedFileCount":"6","status":"M","submitter":"Robert Muir"},{"authorTime":"2015-03-06 00:45:02","codes":[{"authorDate":"2015-03-06 00:45:02","commitOrder":9,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n    analyzer.close();\n  }\n","date":"2015-03-06 00:45:02","endLine":91,"groupId":"59117","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/00/d6f400328bb51e61324ac9541592b60408b923.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"M"},{"authorDate":"2015-03-06 00:45:02","commitOrder":9,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n","date":"2015-03-06 00:45:02","endLine":391,"groupId":"17864","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/7c03ec82a8813159515225db03f8ec85f97804.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":368,"status":"M"}],"commitId":"bb5e6238db695eee7d8f62b14305fa15c898df92","commitMessage":"@@@LUCENE-6335: test fixes.  and one real fix to synonymfilterfactory (missing analyzer.close)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1664404 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-03-06 00:45:02","modifiedFileCount":"182","status":"M","submitter":"Robert Muir"},{"authorTime":"2020-01-22 08:27:19","codes":[{"authorDate":"2015-03-06 00:45:02","commitOrder":10,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n    analyzer.close();\n  }\n","date":"2015-03-06 00:45:02","endLine":91,"groupId":"59117","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/00/d6f400328bb51e61324ac9541592b60408b923.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n    analyzer.close();\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"N"},{"authorDate":"2020-01-22 08:27:19","commitOrder":10,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(3);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n","date":"2020-01-22 08:27:19","endLine":465,"groupId":"17864","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/b6/a938d0e250b1e8b03ae669a632e6c33f09d205.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"M"}],"commitId":"c754a764d484089df8e5f711b4db8ef0b4a4a7ec","commitMessage":"@@@LUCENE-9157: test speedup for slowest tests\n","date":"2020-01-22 08:27:19","modifiedFileCount":"73","status":"M","submitter":"Robert Muir"},{"authorTime":"2020-01-24 21:58:59","codes":[{"authorDate":"2020-01-24 21:58:59","commitOrder":11,"curCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 200 * RANDOM_MULTIPLIER);\n    analyzer.close();\n  }\n","date":"2020-01-24 21:58:59","endLine":93,"groupId":"10797","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testRandomStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/18/82e5430c6207ef1e264cd46b869035b6e46901.src","preCode":"  public void testRandomStrings() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        return new TokenStreamComponents(tokenizer, new HunspellStemFilter(tokenizer, dictionary));\n      }  \n    };\n    checkRandomData(random(), analyzer, 1000*RANDOM_MULTIPLIER);\n    analyzer.close();\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"M"},{"authorDate":"2020-01-24 21:58:59","commitOrder":11,"curCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(1);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n","date":"2020-01-24 21:58:59","endLine":465,"groupId":"10797","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testRandomHugeStrings","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/06/0eb9b8f70c4d9aa6e73486f2df3fd10d20912d.src","preCode":"  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(3);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          return new TokenStreamComponents(tokenizer, new WordDelimiterFilter(tokenizer, flags, protectedWords));\n        }\n      };\n      \r\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n","realPath":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":442,"status":"M"}],"commitId":"c53cc3edafbb00c9b1f411af7c2abf48e9b75288","commitMessage":"@@@LUCENE-9167: test speedup for slowest/pathological tests (round 3)\n","date":"2020-01-24 21:58:59","modifiedFileCount":"136","status":"M","submitter":"Robert Muir"}]
