[{"authorTime":"2016-12-20 19:45:06","codes":[{"authorDate":"2016-12-20 19:45:06","commitOrder":1,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = docWriter.codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = docWriter.codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2016-12-20 19:45:06","endLine":79,"groupId":"1543","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/b3/cc1f4efbca537619afa05044288242335b1a77.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = docWriter.codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = docWriter.codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"B"},{"authorDate":"2016-12-20 19:45:06","commitOrder":1,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2016-12-20 19:45:06","endLine":68,"groupId":"1543","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/df/f808ee96579e838271defa554ba740e7cdd36f.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":40,"status":"B"}],"commitId":"4ccb9fbd2bbc3afd075aa4bc2b6118f845ea4726","commitMessage":"@@@LUCENE-7579: sort segments at flush too\n","date":"2016-12-20 19:45:06","modifiedFileCount":"23","status":"B","submitter":"Mike McCandless"},{"authorTime":"2018-01-31 20:16:06","codes":[{"authorDate":"2016-12-20 19:45:06","commitOrder":2,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = docWriter.codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = docWriter.codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2016-12-20 19:45:06","endLine":79,"groupId":"1543","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/b3/cc1f4efbca537619afa05044288242335b1a77.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = docWriter.codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = docWriter.codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":51,"status":"N"},{"authorDate":"2018-01-31 20:16:06","commitOrder":2,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2018-01-31 21:54:52","endLine":69,"groupId":"1543","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/05/4ca50aa4e857e8cee6b40460fc2b6e0e2ea025.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"M"}],"commitId":"f410df81136291f61b8deaace22bf4bb650de1ad","commitMessage":"@@@LUCENE-4198: Give codecs the opportunity to index impacts.\n","date":"2018-01-31 21:54:52","modifiedFileCount":"75","status":"M","submitter":"Adrien Grand"},{"authorTime":"2018-01-31 20:16:06","codes":[{"authorDate":"2020-09-09 00:18:13","commitOrder":3,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2020-09-09 00:18:13","endLine":80,"groupId":"1543","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/69/f00b2c3aa236292415c3fbbd8c2c1625ac84da.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = docWriter.codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = docWriter.codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2018-01-31 20:16:06","commitOrder":3,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2018-01-31 21:54:52","endLine":69,"groupId":"1543","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/05/4ca50aa4e857e8cee6b40460fc2b6e0e2ea025.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"N"}],"commitId":"98e55f0ea824ea0f39b6cc66f9d40b2532a85466","commitMessage":"@@@LUCENE-9511: Include StoredFieldsWriter in DWPT accounting (#1839)\n\nStoredFieldsWriter might consume some heap space memory that\ncan have a significant impact on decisions made in the IW if\nwriters should be stalled or DWPTs should be flushed if memory\nsettings are small in IWC and flushes are frequent. This change adds\nRAM accounting to the StoredFieldsWriter since it's part of the\nDWPT lifecycle and not just present during flush.","date":"2020-09-09 00:18:13","modifiedFileCount":"17","status":"M","submitter":"Simon Willnauer"},{"authorTime":"2020-09-14 16:47:20","codes":[{"authorDate":"2020-09-09 00:18:13","commitOrder":4,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2020-09-09 00:18:13","endLine":80,"groupId":"1543","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/69/f00b2c3aa236292415c3fbbd8c2c1625ac84da.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"N"},{"authorDate":"2020-09-14 16:47:20","commitOrder":4,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2020-09-14 16:47:20","endLine":73,"groupId":"1543","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/05edef198bc445292262f56c79d7afbdc2a60a.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = docWriter.codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = docWriter.codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"a8099d6367904d23f96f5ece510abbbb6f1bcdbf","commitMessage":"@@@Merge branch 'master' of github.com:apache/lucene-solr\n","date":"2020-09-14 16:47:20","modifiedFileCount":"15","status":"M","submitter":"noblepaul"},{"authorTime":"2020-09-14 16:47:20","codes":[{"authorDate":"2020-09-16 17:19:45","commitOrder":5,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    \r\n    \r\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        reader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2020-09-16 17:19:45","endLine":81,"groupId":"1543","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/57/53ba48bd2931c9ad08c8a1cb42d8e642f6f2d3.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    StoredFieldsReader mergeReader = reader.getMergeInstance();\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        mergeReader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2020-09-14 16:47:20","commitOrder":5,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2020-09-14 16:47:20","endLine":73,"groupId":"1543","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/05edef198bc445292262f56c79d7afbdc2a60a.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"N"}],"commitId":"6b87cfb88c1ad428f3b6affb53aef1ed49949ab8","commitMessage":"@@@Merge branch 'master' of github.com:apache/lucene-solr\n","date":"2020-09-16 17:19:45","modifiedFileCount":"37","status":"M","submitter":"noblepaul"},{"authorTime":"2020-09-17 07:06:48","codes":[{"authorDate":"2020-09-17 07:06:48","commitOrder":6,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    StoredFieldsReader reader = TEMP_STORED_FIELDS_FORMAT\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    \r\n    \r\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        reader.visitDocument(sortMap == null ? docID : sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2020-09-17 07:06:48","endLine":118,"groupId":"1543","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/506a87ea192d070ab6a3a02c61272256a422a9.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    if (sortMap == null) {\n      \r\n      for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n        tmpDirectory.rename(entry.getValue(), entry.getKey());\n      }\n      return;\n    }\n    StoredFieldsReader reader = codec.storedFieldsFormat()\n        .fieldsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    \r\n    \r\n    StoredFieldsWriter sortWriter = codec.storedFieldsFormat()\n        .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        reader.visitDocument(sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory,\n          tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":96,"status":"M"},{"authorDate":"2020-09-17 07:06:48","commitOrder":6,"curCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      TermVectorsReader reader = TEMP_TERM_VECTORS_FORMAT\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      \r\n      \r\n      \r\n      TermVectorsWriter writer = codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = reader.get(sortMap == null ? docID : sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2020-09-17 07:06:48","endLine":73,"groupId":"1543","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/04/990819ddf06778c62711bd40455da720dba415.src","preCode":"  void flush(Map<String, TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      if (sortMap == null) {\n        \r\n        for (Map.Entry<String, String> entry : tmpDirectory.getTemporaryFiles().entrySet()) {\n          tmpDirectory.rename(entry.getValue(), entry.getKey());\n        }\n        return;\n      }\n      TermVectorsReader reader = codec.termVectorsFormat()\n          .vectorsReader(tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      TermVectorsReader mergeReader = reader.getMergeInstance();\n      TermVectorsWriter writer = codec.termVectorsFormat()\n          .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = mergeReader.get(sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory,\n            tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"M"}],"commitId":"e5d3e4d56744521ca0b9d2f2cd7c6161483fde31","commitMessage":"@@@Merge branch 'master' of github.com:apache/lucene-solr\n","date":"2020-09-17 07:06:48","modifiedFileCount":"16","status":"M","submitter":"noblepaul"},{"authorTime":"2021-06-15 22:59:42","codes":[{"authorDate":"2021-06-15 22:59:42","commitOrder":7,"curCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    StoredFieldsReader reader =\n        TEMP_STORED_FIELDS_FORMAT.fieldsReader(\n            tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    \r\n    \r\n    StoredFieldsWriter sortWriter =\n        codec\n            .storedFieldsFormat()\n            .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        reader.visitDocument(sortMap == null ? docID : sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory, tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","date":"2021-06-15 22:59:42","endLine":123,"groupId":"105147","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"flush","params":"(SegmentWriteStatestate@Sorter.DocMapsortMap)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3a/7074cf2f7c7e86cc7be545c17e7df943675f84.src","preCode":"  void flush(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(state, sortMap);\n    StoredFieldsReader reader =\n        TEMP_STORED_FIELDS_FORMAT.fieldsReader(\n            tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n    \r\n    \r\n    StoredFieldsWriter sortWriter =\n        codec\n            .storedFieldsFormat()\n            .fieldsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n    try {\n      reader.checkIntegrity();\n      CopyVisitor visitor = new CopyVisitor(sortWriter);\n      for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n        sortWriter.startDocument();\n        reader.visitDocument(sortMap == null ? docID : sortMap.newToOld(docID), visitor);\n        sortWriter.finishDocument();\n      }\n      sortWriter.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n    } finally {\n      IOUtils.close(reader, sortWriter);\n      IOUtils.deleteFiles(tmpDirectory, tmpDirectory.getTemporaryFiles().values());\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingStoredFieldsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2021-06-15 22:59:42","commitOrder":7,"curCode":"  void flush(\n      Map<String, TermsHashPerField> fieldsToFlush,\n      final SegmentWriteState state,\n      Sorter.DocMap sortMap,\n      NormsProducer norms)\n      throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      TermVectorsReader reader =\n          TEMP_TERM_VECTORS_FORMAT.vectorsReader(\n              tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      \r\n      \r\n      \r\n      TermVectorsWriter writer =\n          codec\n              .termVectorsFormat()\n              .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = reader.get(sortMap == null ? docID : sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory, tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","date":"2021-06-15 22:59:42","endLine":84,"groupId":"105147","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"flush","params":"(Map<String@TermsHashPerField>fieldsToFlush@finalSegmentWriteStatestate@Sorter.DocMapsortMap@NormsProducernorms)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/47/3a7a868b58729e76f03affdf2ba63a08f99586.src","preCode":"  void flush(\n      Map<String, TermsHashPerField> fieldsToFlush,\n      final SegmentWriteState state,\n      Sorter.DocMap sortMap,\n      NormsProducer norms)\n      throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n    if (tmpDirectory != null) {\n      TermVectorsReader reader =\n          TEMP_TERM_VECTORS_FORMAT.vectorsReader(\n              tmpDirectory, state.segmentInfo, state.fieldInfos, IOContext.DEFAULT);\n      \r\n      \r\n      \r\n      TermVectorsWriter writer =\n          codec\n              .termVectorsFormat()\n              .vectorsWriter(state.directory, state.segmentInfo, IOContext.DEFAULT);\n      try {\n        reader.checkIntegrity();\n        for (int docID = 0; docID < state.segmentInfo.maxDoc(); docID++) {\n          Fields vectors = reader.get(sortMap == null ? docID : sortMap.newToOld(docID));\n          writeTermVectors(writer, vectors, state.fieldInfos);\n        }\n        writer.finish(state.fieldInfos, state.segmentInfo.maxDoc());\n      } finally {\n        IOUtils.close(reader, writer);\n        IOUtils.deleteFiles(tmpDirectory, tmpDirectory.getTemporaryFiles().values());\n      }\n    }\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"}],"commitId":"b7b834b75681ff5be6aaa1c052d6a708f723b31d","commitMessage":"@@@LUCENE-9998: delete useless param fis in StoredFieldsWriter.finish() and TermVectorsWriter.finish()  (#183)\n\n","date":"2021-06-15 22:59:42","modifiedFileCount":"17","status":"M","submitter":"kkewwei"}]
