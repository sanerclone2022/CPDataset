[{"authorTime":"2015-03-06 00:45:02","codes":[{"authorDate":"2015-03-06 00:45:02","commitOrder":1,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2015-03-06 00:45:02","endLine":94,"groupId":"47382","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/38/4f0a8f87c0ad1d71e5d1d296a0dec74e0de2fd.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"B"},{"authorDate":"2015-03-06 00:45:02","commitOrder":1,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2015-03-06 00:45:02","endLine":46,"groupId":"47382","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/17/f8269dcffca51470bce901cabd44194f36fdd1.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":37,"status":"B"}],"commitId":"bb5e6238db695eee7d8f62b14305fa15c898df92","commitMessage":"@@@LUCENE-6335: test fixes.  and one real fix to synonymfilterfactory (missing analyzer.close)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1664404 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-03-06 00:45:02","modifiedFileCount":"182","status":"B","submitter":"Robert Muir"},{"authorTime":"2015-03-06 00:45:02","codes":[{"authorDate":"2015-12-03 14:27:44","commitOrder":2,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormalNBest = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        JapaneseTokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        tokenizer.setNBestCost(2000);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2015-12-03 14:27:44","endLine":118,"groupId":"47382","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/a7/07dc7fb030274b5dcdd871c54dcb847877a386.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"},{"authorDate":"2015-03-06 00:45:02","commitOrder":2,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2015-03-06 00:45:02","endLine":46,"groupId":"47382","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/17/f8269dcffca51470bce901cabd44194f36fdd1.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":37,"status":"N"}],"commitId":"df9c6a835f65fdc42ba43838d40a37f991ef025b","commitMessage":"@@@Add n-best output to JapaneseTokenizer (LUCENE-6837)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1717713 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-12-03 14:27:44","modifiedFileCount":"5","status":"M","submitter":"Christian Moen"},{"authorTime":"2020-02-01 13:51:09","codes":[{"authorDate":"2020-02-01 13:51:09","commitOrder":3,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormalNBest = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        JapaneseTokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, false, Mode.NORMAL);\n        tokenizer.setNBestCost(2000);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, false, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoCompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoCompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2020-02-01 13:51:09","endLine":135,"groupId":"101679","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/44/7060fcd794b2a04eb28f7ea226daf9f53f2d58.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNormalNBest = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        JapaneseTokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), false, Mode.NORMAL);\n        tokenizer.setNBestCost(2000);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    extendedModeAnalyzerNoPunct = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), readDict(), true, Mode.EXTENDED);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":83,"status":"M"},{"authorDate":"2020-02-01 13:51:09","commitOrder":3,"curCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, false, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerNoOriginal = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","date":"2020-02-01 13:51:09","endLine":55,"groupId":"101679","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"setUp","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/23/67d0c6fc41522a3679ab91fac3067e8fda2e90.src","preCode":"  public void setUp() throws Exception {\n    super.setUp();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), null, true, Mode.SEARCH);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n  }\n","realPath":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":39,"status":"M"}],"commitId":"b457c2ee2ea0180f3a11c5d0b4d443083316aa31","commitMessage":"@@@LUCENE-9123: Add new JapaneseTokenizer constructors with discardCompoundToken option to control whether the tokenizer emits original tokens when the mode is not NORMAL.\n","date":"2020-02-01 13:51:09","modifiedFileCount":"8","status":"M","submitter":"Kazuaki Hiraga"}]
