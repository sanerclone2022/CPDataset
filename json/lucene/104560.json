[{"authorTime":"2021-03-09 15:11:59","codes":[{"authorDate":"2021-02-24 18:15:11","commitOrder":2,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-02-24 18:15:11","endLine":724,"groupId":"53032","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/92/6a4be2c530a6b3c10ef0e254e2ddff80807ba2.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":705,"status":"NB"},{"authorDate":"2021-03-09 15:11:59","commitOrder":2,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-03-09 15:11:59","endLine":731,"groupId":"53032","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/99/08ccf78de68c3ac71ef6e40830d5cea2b38f86.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":712,"status":"B"}],"commitId":"144ef2a0c054b54ee533f5618f36651931825f7d","commitMessage":"@@@LUCENE-9705: Create Lucene90StoredFieldsFormat (#2444)\n\n","date":"2021-03-09 15:11:59","modifiedFileCount":"16","status":"M","submitter":"Ignacio Vera"},{"authorTime":"2021-04-07 02:18:48","codes":[{"authorDate":"2021-02-24 18:15:11","commitOrder":3,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-02-24 18:15:11","endLine":724,"groupId":"53032","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/92/6a4be2c530a6b3c10ef0e254e2ddff80807ba2.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":705,"status":"N"},{"authorDate":"2021-04-07 02:18:48","commitOrder":3,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-04-07 02:18:48","endLine":730,"groupId":"27671","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d8/e6874a0c6ea9ccd7d1d15407ad663cf49a6df7.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":714,"status":"M"}],"commitId":"be94a667f2091b2c0fad570f9e726197d466767b","commitMessage":"@@@LUCENE-9827: avoid wasteful recompression for small segments (#28)\n\nRequire that the segment has enough dirty documents to create a clean\nchunk before recompressing during merge.  there must be at least maxChunkSize.\n\nThis prevents wasteful recompression with small flushes (e.g. every\ndocument): we ensure recompression achieves some \"permanent\" progress.\n\nExpose maxDocsPerChunk as a parameter for Term vectors too.  matching the\nstored fields format. This allows for easy testing.\n\nIncrement numDirtyDocs for partially optimized merges:\nIf segment N needs recompression.  we have to flush any buffered docs\nbefore bulk-copying segment N+1. Don't just increment numDirtyChunks. \nalso make sure numDirtyDocs is incremented.  too.\nThis doesn't have a performance impact.  and is unrelated to tooDirty()\nimprovements.  but it is easier to reason about things with correct\nstatistics in the index.\n\nFurther tuning of how dirtiness is measured: for simplification just use percentage\nof dirty chunks.\n\nCo-authored-by: Adrien Grand <jpountz@gmail.com>","date":"2021-04-07 02:18:48","modifiedFileCount":"10","status":"M","submitter":"Robert Muir"},{"authorTime":"2021-04-07 02:18:48","codes":[{"authorDate":"2021-05-20 20:49:43","commitOrder":4,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-05-20 20:49:43","endLine":720,"groupId":"27671","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/aa/d09ad7973d747f6b7fd48fb4f01d75aa660745.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      final long expectedChunkDocs =\n          Math.min(\n              MAX_DOCUMENTS_PER_CHUNK,\n              (long) ((double) chunkSize / termSuffixes.size() * pendingDocs.size()));\n      numDirtyDocs += expectedChunkDocs - pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":704,"status":"M"},{"authorDate":"2021-04-07 02:18:48","commitOrder":4,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-04-07 02:18:48","endLine":730,"groupId":"27671","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d8/e6874a0c6ea9ccd7d1d15407ad663cf49a6df7.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":714,"status":"N"}],"commitId":"a12260eb950c760b96b6692f5c6ec66eaff36622","commitMessage":"@@@LUCENE-9827: Update backward codec in Lucene 9.0 (#147)\n\nWe need to update the reading logic of the backward codec in Lucene 9 \nfor LUCENE-9827 and LUCENE-9935 as we have backported them to Lucene 8.\n\nRelates apache/lucene-solr#2495\nRelates apache/lucene-solr#2494","date":"2021-05-20 20:49:43","modifiedFileCount":"8","status":"M","submitter":"Nhat Nguyen"},{"authorTime":"2021-06-10 23:03:17","codes":[{"authorDate":"2021-05-20 20:49:43","commitOrder":5,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-05-20 20:49:43","endLine":720,"groupId":"27671","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/aa/d09ad7973d747f6b7fd48fb4f01d75aa660745.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":704,"status":"N"},{"authorDate":"2021-06-10 23:03:17","commitOrder":5,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      flush(true);\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-06-10 23:03:17","endLine":738,"groupId":"27671","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/63/8b9e77b6f460efb33dd7cb3eb997d36ea16999.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":724,"status":"M"}],"commitId":"54fb21e862c2041cb907517ed993c8ece898cb26","commitMessage":"@@@LUCENE-9935: Enable bulk-merge for term vectors with index sort (#140)\n\nThis change enables bulk-merge for term vectors with index sort. The \nalgorithm used here is similar to the one that is used to merge stored\nfields.\n\nRelates #134","date":"2021-06-10 23:03:17","modifiedFileCount":"3","status":"M","submitter":"Nhat Nguyen"},{"authorTime":"2021-06-10 23:54:11","codes":[{"authorDate":"2021-05-20 20:49:43","commitOrder":6,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-05-20 20:49:43","endLine":720,"groupId":"27671","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/aa/d09ad7973d747f6b7fd48fb4f01d75aa660745.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":704,"status":"N"},{"authorDate":"2021-06-10 23:54:11","commitOrder":6,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-06-10 23:54:11","endLine":732,"groupId":"27671","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/54ce736a34d855bfb3f614a80dbbc4f0bf5336.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      flush(true);\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":716,"status":"M"}],"commitId":"69ab1447a7dfe12ab81e0b11185950451d1fd807","commitMessage":"@@@Revert \"LUCENE-9935: Enable bulk-merge for term vectors with index sort (#140)\"\n\nThis reverts commit 54fb21e862c2041cb907517ed993c8ece898cb26.\n","date":"2021-06-10 23:54:11","modifiedFileCount":"3","status":"M","submitter":"Nhat Nguyen"},{"authorTime":"2021-06-10 23:03:17","codes":[{"authorDate":"2021-05-20 20:49:43","commitOrder":7,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-05-20 20:49:43","endLine":720,"groupId":"27671","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/aa/d09ad7973d747f6b7fd48fb4f01d75aa660745.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":704,"status":"N"},{"authorDate":"2021-06-10 23:03:17","commitOrder":7,"curCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      flush(true);\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-06-14 23:39:38","endLine":738,"groupId":"27671","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"finish","params":"(FieldInfosfis@intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/63/8b9e77b6f460efb33dd7cb3eb997d36ea16999.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":724,"status":"M"}],"commitId":"50607e0fb9090a1321093aca4117b6560c511af0","commitMessage":"@@@LUCENE-9935: Enable bulk-merge for term vectors with index sort (#140)\n\nThis change enables bulk-merge for term vectors with index sort. The\nalgorithm used here is similar to the one that is used to merge stored\nfields.\n\nRelates #134\n","date":"2021-06-14 23:39:38","modifiedFileCount":"3","status":"M","submitter":"Nhat Nguyen"},{"authorTime":"2021-06-15 22:59:42","codes":[{"authorDate":"2021-06-15 22:59:42","commitOrder":8,"curCode":"  public void finish(int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-06-15 22:59:42","endLine":719,"groupId":"104560","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"finish","params":"(intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/84/c89b35a96fbb137ccf21a639e234fc3d9173e5.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      numDirtyChunks++; \r\n      numDirtyDocs += pendingDocs.size();\n      flush();\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/backward-codecs/src/test/org/apache/lucene/backward_codecs/lucene50/compressing/Lucene50CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":703,"status":"M"},{"authorDate":"2021-06-15 22:59:42","commitOrder":8,"curCode":"  public void finish(int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      flush(true);\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","date":"2021-06-15 22:59:42","endLine":737,"groupId":"104560","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"finish","params":"(intnumDocs)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/6e/2a8571a6d8e56e69981407ce0a78e0a51b62c2.src","preCode":"  public void finish(FieldInfos fis, int numDocs) throws IOException {\n    if (!pendingDocs.isEmpty()) {\n      flush(true);\n    }\n    if (numDocs != this.numDocs) {\n      throw new RuntimeException(\n          \"Wrote \" + this.numDocs + \" docs, finish called with numDocs=\" + numDocs);\n    }\n    indexWriter.finish(numDocs, vectorsStream.getFilePointer(), metaStream);\n    metaStream.writeVLong(numChunks);\n    metaStream.writeVLong(numDirtyChunks);\n    metaStream.writeVLong(numDirtyDocs);\n    CodecUtil.writeFooter(metaStream);\n    CodecUtil.writeFooter(vectorsStream);\n  }\n","realPath":"lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingTermVectorsWriter.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":723,"status":"M"}],"commitId":"b7b834b75681ff5be6aaa1c052d6a708f723b31d","commitMessage":"@@@LUCENE-9998: delete useless param fis in StoredFieldsWriter.finish() and TermVectorsWriter.finish()  (#183)\n\n","date":"2021-06-15 22:59:42","modifiedFileCount":"17","status":"M","submitter":"kkewwei"}]
