[{"authorTime":"2012-02-08 03:59:05","codes":[{"authorDate":"2012-02-08 03:59:05","commitOrder":1,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == 4) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-02-08 03:59:05","endLine":1382,"groupId":"53359","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/40/3b53b04baef6698e199c87ea940c107b2f6401.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == 4) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1327,"status":"B"},{"authorDate":"2012-02-08 03:59:05","commitOrder":1,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"subid\", \"subs\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random, 2, 25);\n    final int crashAt = random.nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == crashAt) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-02-08 03:59:05","endLine":1462,"groupId":"40161","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/40/3b53b04baef6698e199c87ea940c107b2f6401.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"subid\", \"subs\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random, 2, 25);\n    final int crashAt = random.nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == crashAt) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1385,"status":"B"}],"commitId":"eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c","commitMessage":"@@@LUCENE-3753: Restructure the Lucene build system\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1241588 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-02-08 03:59:05","modifiedFileCount":"0","status":"B","submitter":"Steven Rowe"},{"authorTime":"2012-04-15 22:41:44","codes":[{"authorDate":"2012-04-15 22:41:44","commitOrder":2,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == 4) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-04-15 22:41:44","endLine":1382,"groupId":"53359","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/98/680078dcce33950f0f8828ccab8d3895a18f25.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == 4) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1327,"status":"M"},{"authorDate":"2012-04-15 22:41:44","commitOrder":2,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"subid\", \"subs\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == crashAt) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-04-15 22:41:44","endLine":1462,"groupId":"34563","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/98/680078dcce33950f0f8828ccab8d3895a18f25.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    final int numDocs1 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"subid\", \"subs\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random, 2, 25);\n    final int crashAt = random.nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == crashAt) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random.nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1385,"status":"M"}],"commitId":"cf85aab1a06cb2b12e4778c1dd7c1368a6225b91","commitMessage":"@@@LUCENE-3808: Switch LuceneTestCaseRunner to RandomizedRunner. Enforce Random sharing contracts. Enforce thread leaks.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1326351 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-04-15 22:41:44","modifiedFileCount":"501","status":"M","submitter":"Dawid Weiss"},{"authorTime":"2012-06-11 01:42:19","codes":[{"authorDate":"2012-06-11 01:42:19","commitOrder":3,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-06-11 01:42:19","endLine":1385,"groupId":"59928","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/be/1102f2f003c43ec43c9020bbd97fe177080711.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == 4) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1330,"status":"M"},{"authorDate":"2012-06-11 01:42:19","commitOrder":3,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2012-06-11 01:42:19","endLine":1465,"groupId":"31407","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/be/1102f2f003c43ec43c9020bbd97fe177080711.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"subid\", \"subs\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newField(\"id\", docCount+\"\", StringField.TYPE_UNSTORED));\n      doc.add(newField(\"content\", \"silly content \" + docCount, TextField.TYPE_UNSTORED));\n      if (docCount == crashAt) {\n        Field f = newField(\"crash\", \"\", TextField.TYPE_UNSTORED);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newField(\"content\", \"good content\", TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1388,"status":"M"}],"commitId":"dba50b31e7543e3861e44de6e0ff6e7f79ec1be4","commitMessage":"@@@LUCENE-4101: add ctors create stored or not-stored variants of indexed fields\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1348630 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-06-11 01:42:19","modifiedFileCount":"254","status":"M","submitter":"Michael McCandless"},{"authorTime":"2013-04-11 06:13:13","codes":[{"authorDate":"2013-04-11 06:13:13","commitOrder":4,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2013-04-11 06:13:13","endLine":1409,"groupId":"59928","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c7/cd0f0207e03a492742f26e4533c8897796203a.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1354,"status":"M"},{"authorDate":"2013-04-11 06:13:13","commitOrder":4,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2013-04-11 06:13:13","endLine":1489,"groupId":"31407","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c7/cd0f0207e03a492742f26e4533c8897796203a.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1412,"status":"M"}],"commitId":"24376b1bd7b05dd6760207e757e49178a814f63a","commitMessage":"@@@LUCENE-4903: Add AssertingScorer.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1466709 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2013-04-11 06:13:13","modifiedFileCount":"49","status":"M","submitter":"Adrien Grand"},{"authorTime":"2014-01-09 21:27:29","codes":[{"authorDate":"2014-01-09 21:27:29","commitOrder":5,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-01-09 21:27:29","endLine":1405,"groupId":"59928","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/486eba796806f80d69c515071d8ba65e093dfc.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1349,"status":"M"},{"authorDate":"2014-01-09 21:27:29","commitOrder":5,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-01-09 21:27:29","endLine":1486,"groupId":"54439","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/486eba796806f80d69c515071d8ba65e093dfc.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"crash me on the 4th token\"), MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1408,"status":"M"}],"commitId":"ab0e85fafede7182059693e61feac882aa1b0bc2","commitMessage":"@@@LUCENE-5388: remove Reader from Tokenizer ctor (closes #16)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1556801 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-01-09 21:27:29","modifiedFileCount":"367","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-02-19 09:38:33","codes":[{"authorDate":"2014-01-09 21:27:29","commitOrder":6,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-01-09 21:27:29","endLine":1405,"groupId":"59928","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/486eba796806f80d69c515071d8ba65e093dfc.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1349,"status":"N"},{"authorDate":"2014-02-19 09:38:33","commitOrder":6,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-02-19 09:38:33","endLine":1485,"groupId":"54439","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/39/762ae1408c707a16535d85a36d53b93175795c.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = _TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1407,"status":"M"}],"commitId":"36b2f2512b53b3c4d5951dbeaf7d25106a806413","commitMessage":"@@@LUCENE-5449: Rename _TestUtil to TestUtil.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1569597 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-02-19 09:38:33","modifiedFileCount":"321","status":"M","submitter":"Benson Margulies"},{"authorTime":"2014-03-12 22:39:17","codes":[{"authorDate":"2014-03-12 22:39:17","commitOrder":7,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-03-12 22:39:17","endLine":1404,"groupId":"59928","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/16/89080d31c8750f6804408fc0aeef465c33ffff.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<Document>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1348,"status":"M"},{"authorDate":"2014-03-12 22:39:17","commitOrder":7,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-03-12 22:39:17","endLine":1485,"groupId":"54439","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/16/89080d31c8750f6804408fc0aeef465c33ffff.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<Document>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1407,"status":"M"}],"commitId":"3b67b17493216f6b0c81a981073fd5f61eace6f4","commitMessage":"@@@LUCENE-5512: remove redundant typing (diamond operator) in trunk\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1576755 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-03-12 22:39:17","modifiedFileCount":"1241","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-04-08 23:34:50","codes":[{"authorDate":"2014-04-08 23:34:50","commitOrder":8,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":1405,"groupId":"59928","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ce/39e0e60c450c491beda06aa596a9617e7b75d6.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1349,"status":"M"},{"authorDate":"2014-04-08 23:34:50","commitOrder":8,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":1486,"groupId":"54439","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ce/39e0e60c450c491beda06aa596a9617e7b75d6.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1408,"status":"M"}],"commitId":"8559eafd99e5b569d4ad866e98f410fb4868fd4c","commitMessage":"@@@LUCENE-4246: fix IW.close to just close.  even on exception\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1585759 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-04-08 23:34:50","modifiedFileCount":"403","status":"M","submitter":"Michael McCandless"},{"authorTime":"2014-08-10 02:54:35","codes":[{"authorDate":"2014-08-10 02:54:35","commitOrder":9,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":1426,"groupId":"59928","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c1/f783fe212959e55cad3f083cfe7d1f0dc07c5d.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1370,"status":"M"},{"authorDate":"2014-08-10 02:54:35","commitOrder":9,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":1507,"groupId":"54439","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c1/f783fe212959e55cad3f083cfe7d1f0dc07c5d.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1429,"status":"M"}],"commitId":"872bd9145cd9504fc16b318f7ea0a666d9429103","commitMessage":"@@@LUCENE-5871: Remove Version from IndexWriterConfig\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1617004 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-08-10 02:54:35","modifiedFileCount":"450","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2015-06-16 18:18:40","codes":[{"authorDate":"2015-06-16 18:18:40","commitOrder":10,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"good\");\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2015-06-16 18:18:40","endLine":1420,"groupId":"59928","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/61/808286a5ad1ca577089a61065a12435fabd1ee.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1368,"status":"M"},{"authorDate":"2015-06-16 18:18:40","commitOrder":10,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"content\");\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2015-06-16 18:18:40","endLine":1497,"groupId":"54439","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/61/808286a5ad1ca577089a61065a12435fabd1ee.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"silly\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery();\n    pq.add(new Term(\"content\", \"good\"));\n    pq.add(new Term(\"content\", \"content\"));\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1423,"status":"M"}],"commitId":"c397fe723462cfe4069304fe3b3bcea648217060","commitMessage":"@@@LUCENE-6531: Make PhraseQuery immutable.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1685754 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-06-16 18:18:40","modifiedFileCount":"55","status":"M","submitter":"Adrien Grand"},{"authorTime":"2016-02-20 01:07:07","codes":[{"authorDate":"2016-02-20 01:07:07","commitOrder":11,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.addDocuments(docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"good\");\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2016-02-20 01:07:47","endLine":1394,"groupId":"61304","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/49/923389a452d4129787117c129e7ab4bce47df0.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n    try {\n      w.addDocuments(docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"good\");\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1345,"status":"M"},{"authorDate":"2016-02-20 01:07:07","commitOrder":11,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"content\");\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","date":"2016-02-20 01:07:47","endLine":1467,"groupId":"61220","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/49/923389a452d4129787117c129e7ab4bce47df0.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    try {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n      \r\n      fail(\"did not hit expected exception\");\n    } catch (IOException ioe) {\n      \r\n      assertEquals(CRASH_FAIL_MESSAGE, ioe.getMessage());\n    }\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"content\");\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1397,"status":"M"}],"commitId":"189e985b5c14c5c19799b7bdfd040874b94ba18c","commitMessage":"@@@LUCENE-7037: Switch all exceptions tests to expectThrows()\n","date":"2016-02-20 01:07:47","modifiedFileCount":"277","status":"M","submitter":"Robert Muir"},{"authorTime":"2018-07-17 20:30:23","codes":[{"authorDate":"2018-07-17 20:30:23","commitOrder":12,"curCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.addDocuments(docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"good\");\n    assertEquals(0, s.count(pq));\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs2, s.count(pq));\n    r.close();\n    dir.close();\n  }\n","date":"2018-07-17 20:32:02","endLine":1450,"groupId":"105953","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testAddDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c6/7e1dcaa3c283f8cbab160d7e37ca9ec56f037c.src","preCode":"  public void testAddDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n    \n    final List<Document> docs = new ArrayList<>();\n    for(int docCount=0;docCount<7;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == 4) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.addDocuments(docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"good\");\n    assertEquals(0, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs2, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1401,"status":"M"},{"authorDate":"2018-07-17 20:30:23","commitOrder":12,"curCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"content\");\n    assertEquals(numDocs2, s.count(pq));\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs3+numDocs4, s.count(pq));\n    r.close();\n    dir.close();\n  }\n","date":"2018-07-17 20:32:02","endLine":1523,"groupId":"105953","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testUpdateDocsNonAbortingException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c6/7e1dcaa3c283f8cbab160d7e37ca9ec56f037c.src","preCode":"  public void testUpdateDocsNonAbortingException() throws Exception {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs1 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs1;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    \r\n    final List<Document> docs = new ArrayList<>();\n    final int numDocs2 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs2;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"subid\", \"subs\", Field.Store.NO));\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n    }\n    w.addDocuments(docs);\n\n    final int numDocs3 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs3;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    docs.clear();\n    final int limit = TestUtil.nextInt(random(), 2, 25);\n    final int crashAt = random().nextInt(limit);\n    for(int docCount=0;docCount<limit;docCount++) {\n      Document doc = new Document();\n      docs.add(doc);\n      doc.add(newStringField(\"id\", docCount+\"\", Field.Store.NO));\n      doc.add(newTextField(\"content\", \"silly content \" + docCount, Field.Store.NO));\n      if (docCount == crashAt) {\n        Field f = newTextField(\"crash\", \"\", Field.Store.NO);\n        doc.add(f);\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setReader(new StringReader(\"crash me on the 4th token\"));\n        tokenizer.setEnableChecks(false); \r\n        f.setTokenStream(new CrashingFilter(\"crash\", tokenizer));\n      }\n    }\n\n    IOException expected = expectThrows(IOException.class, () -> {\n      w.updateDocuments(new Term(\"subid\", \"subs\"), docs);\n    });\n    assertEquals(CRASH_FAIL_MESSAGE, expected.getMessage());\n\n    final int numDocs4 = random().nextInt(25);\n    for(int docCount=0;docCount<numDocs4;docCount++) {\n      Document doc = new Document();\n      doc.add(newTextField(\"content\", \"good content\", Field.Store.NO));\n      w.addDocument(doc);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    PhraseQuery pq = new PhraseQuery(\"content\", \"silly\", \"content\");\n    assertEquals(numDocs2, s.search(pq, 1).totalHits);\n\n    pq = new PhraseQuery(\"content\", \"good\", \"content\");\n    assertEquals(numDocs1+numDocs3+numDocs4, s.search(pq, 1).totalHits);\n    r.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":1453,"status":"M"}],"commitId":"d730c8b214bd8b659aa92011e7a8d455af535382","commitMessage":"@@@LUCENE-8060: Remove usage of TopDocs#totalHits that should really be IndexSearcher#count.\n\nMany tests were written before we introduced IndexSearcher#count and used\n`searcher.search(query.  1).totalHits` to get the number of matches of a query\nrather than `searcher.count(query)`.\n","date":"2018-07-17 20:32:02","modifiedFileCount":"20","status":"M","submitter":"Adrien Grand"}]
