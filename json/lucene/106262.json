[{"authorTime":"2012-09-29 23:56:22","codes":[{"authorDate":"2012-09-29 23:56:22","commitOrder":1,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2012-09-29 23:56:22","endLine":115,"groupId":"35505","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/da/c3b5af94a697ba17f000c185f1a4150f968f75.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"B"},{"authorDate":"2012-09-29 23:56:22","commitOrder":1,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2012-09-29 23:56:22","endLine":188,"groupId":"9701","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/da/c3b5af94a697ba17f000c185f1a4150f968f75.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"B"}],"commitId":"40d5e3de67a590ebceb443108593276dfc79f0f4","commitMessage":"@@@LUCENE-4449: rename test\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1391829 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-09-29 23:56:22","modifiedFileCount":"0","status":"B","submitter":"Robert Muir"},{"authorTime":"2012-10-14 22:01:18","codes":[{"authorDate":"2012-09-29 23:56:22","commitOrder":2,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2012-09-29 23:56:22","endLine":115,"groupId":"35505","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/da/c3b5af94a697ba17f000c185f1a4150f968f75.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"N"},{"authorDate":"2012-10-14 22:01:18","commitOrder":2,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2012-10-14 22:01:18","endLine":188,"groupId":"9701","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/58/2e774d12644b17097c4ce2e67bed11394c089d.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"aba3f4926852cc9e90c456387ec8b862f971999d","commitMessage":"@@@LUCENE-4446: Switch to BlockPostingsFormat for Lucene 4.1\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1398086 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-10-14 22:01:18","modifiedFileCount":"42","status":"M","submitter":"Robert Muir"},{"authorTime":"2013-02-02 02:25:29","codes":[{"authorDate":"2012-09-29 23:56:22","commitOrder":3,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2012-09-29 23:56:22","endLine":115,"groupId":"35505","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/da/c3b5af94a697ba17f000c185f1a4150f968f75.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"N"},{"authorDate":"2013-02-02 02:25:29","commitOrder":3,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2013-02-02 02:25:29","endLine":188,"groupId":"18138","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ef/3dc6dcad04cafb78bb46059bfb0a195cef59b1.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene41Codec codec = (Lucene41Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene41Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"722df2c1e7e9d95479f1f29cc8b717d90bb34603","commitMessage":"@@@LUCENE-4733: merge Lucene42 codec from lucene-4547 branch\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1441571 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2013-02-02 02:25:29","modifiedFileCount":"28","status":"M","submitter":"Robert Muir"},{"authorTime":"2013-02-02 02:25:29","codes":[{"authorDate":"2014-02-19 09:38:33","commitOrder":4,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2014-02-19 09:38:33","endLine":116,"groupId":"35505","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/05/0770a486f17f6b69c46afcca701ce95c8eabd8.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    _TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2013-02-02 02:25:29","commitOrder":4,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2013-02-02 02:25:29","endLine":188,"groupId":"18138","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ef/3dc6dcad04cafb78bb46059bfb0a195cef59b1.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"N"}],"commitId":"36b2f2512b53b3c4d5951dbeaf7d25106a806413","commitMessage":"@@@LUCENE-5449: Rename _TestUtil to TestUtil.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1569597 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-02-19 09:38:33","modifiedFileCount":"321","status":"M","submitter":"Benson Margulies"},{"authorTime":"2014-04-08 23:34:50","codes":[{"authorDate":"2014-04-08 23:34:50","commitOrder":5,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.shutdown();\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":115,"groupId":"35505","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/34bcff0a54dcb3f45f3aeaa088cb6ee6b5d030.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2014-04-08 23:34:50","commitOrder":5,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":188,"groupId":"18138","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/34bcff0a54dcb3f45f3aeaa088cb6ee6b5d030.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"8559eafd99e5b569d4ad866e98f410fb4868fd4c","commitMessage":"@@@LUCENE-4246: fix IW.close to just close.  even on exception\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1585759 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-04-08 23:34:50","modifiedFileCount":"403","status":"M","submitter":"Michael McCandless"},{"authorTime":"2014-07-31 00:20:24","codes":[{"authorDate":"2014-07-31 00:20:24","commitOrder":6,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.shutdown();\n    dir.close();\n  }\n","date":"2014-07-31 00:20:24","endLine":115,"groupId":"35505","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/25/9e7fb33473ad8ba0ed6dbb1fbf1b60cf261149.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.shutdown();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2014-07-31 00:20:24","commitOrder":6,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2014-07-31 00:20:24","endLine":188,"groupId":"18138","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/25/9e7fb33473ad8ba0ed6dbb1fbf1b60cf261149.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"3f4b2b472f2c76d72cae94fd4747b103c973d707","commitMessage":"@@@LUCENE-5859: remove Version param from LuceneTestCase.newIndexWriterConfig.  the grand sum of 2 tests making use of it can use the 3-arg version and reduce the noise everywhere else\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1614698 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-07-31 00:20:24","modifiedFileCount":"244","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-08-10 02:54:35","codes":[{"authorDate":"2014-08-10 02:54:35","commitOrder":7,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":115,"groupId":"35505","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/22/9a1670fe4d88255cb30478bfeec985c2ab1d54.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.shutdown();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2014-08-10 02:54:35","commitOrder":7,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":188,"groupId":"18138","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/22/9a1670fe4d88255cb30478bfeec985c2ab1d54.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.shutdown();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.shutdown();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"}],"commitId":"872bd9145cd9504fc16b318f7ea0a666d9429103","commitMessage":"@@@LUCENE-5871: Remove Version from IndexWriterConfig\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1617004 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-08-10 02:54:35","modifiedFileCount":"450","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2018-05-08 16:32:11","codes":[{"authorDate":"2014-08-10 02:54:35","commitOrder":8,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":115,"groupId":"35505","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/22/9a1670fe4d88255cb30478bfeec985c2ab1d54.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"N"},{"authorDate":"2018-05-08 16:32:11","commitOrder":8,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2018-05-08 16:32:11","endLine":202,"groupId":"26628","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/f7/2ffcc055d91a1f8b30053dd704b83c9595819d.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":136,"status":"M"}],"commitId":"85c00e77efdf53f30da6eaffd38c2b016a7805bc","commitMessage":"@@@LUCENE-8267: removed references to memory codecs.\n","date":"2018-05-08 16:32:11","modifiedFileCount":"46","status":"M","submitter":"Dawid Weiss"},{"authorTime":"2018-12-13 23:05:47","codes":[{"authorDate":"2018-12-13 23:05:47","commitOrder":9,"curCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.getDocStats().maxDoc);\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.getDocStats().maxDoc);\n    writer.close();\n    dir.close();\n  }\n","date":"2018-12-15 02:36:25","endLine":129,"groupId":"106262","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testMergeUnusedPerFieldCodec","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/df/18a7448e1c493c620cac1baa383fb434fb716f.src","preCode":"  public void testMergeUnusedPerFieldCodec() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    addDocs3(writer, 10);\n    writer.commit();\n    addDocs2(writer, 10);\n    writer.commit();\n    assertEquals(30, writer.maxDoc());\n    TestUtil.checkIndex(dir);\n    writer.forceMerge(1);\n    assertEquals(30, writer.maxDoc());\n    writer.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2018-12-13 23:05:47","commitOrder":9,"curCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.getDocStats().maxDoc);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.getDocStats().maxDoc);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.getDocStats().maxDoc);\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","date":"2018-12-15 02:36:25","endLine":202,"groupId":"106262","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testChangeCodecAndMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/df/18a7448e1c493c620cac1baa383fb434fb716f.src","preCode":"  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n                                 .setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    \r\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Codec codec = iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(new MockAnalyzer(random()))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    \r\n    \r\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec()); \r\n    writer = newWriter(dir, iwconf);\n    \r\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   \r\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat2.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":136,"status":"M"}],"commitId":"e974311d91fd3f2f3aa015c9e56cf2d689290f41","commitMessage":"@@@LUCENE-8609: Allow getting consistent docstats from IndexWriter\n\nToday we have #numDocs() and #maxDoc() on IndexWriter. This is enough\nto get all stats for the current index but it's subject to concurrency\nand might return numbers that are not consistent ie. some cases can\nreturn maxDoc < numDocs which is undesirable. This change adds a getDocStats()\nmethod to index writer to allow fetching consistent numbers for these stats.\n\nThis change also deprecates IndexWriter#numDocs() and IndexWriter#maxDoc()\nand replaces all their usages wiht IndexWriter#getDocStats()\n","date":"2018-12-15 02:36:25","modifiedFileCount":"32","status":"M","submitter":"Simon Willnauer"}]
