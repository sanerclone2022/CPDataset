[{"authorTime":"2012-10-09 04:54:09","codes":[{"authorDate":"2012-10-06 02:19:48","commitOrder":4,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-06 02:19:48","endLine":132,"groupId":"21170","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/7b/a28b5db9f672b46e055b75d0da5043c9272d14.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"NB"},{"authorDate":"2012-10-09 04:54:09","commitOrder":4,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-09 04:54:09","endLine":143,"groupId":"28347","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0f/aae6172c3e6f23de329ee3867c92d9ce2b75cd.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"B"}],"commitId":"8eae8715b753e68528e461933d6c9143002e3380","commitMessage":"@@@add positions version of TestBagOfPostings\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1395770 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-10-09 04:54:09","modifiedFileCount":"0","status":"M","submitter":"Robert Muir"},{"authorTime":"2012-10-09 04:54:09","codes":[{"authorDate":"2012-10-19 06:01:22","commitOrder":5,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = false;\n    Codec defaultCodec = Codec.getDefault();\n\n    if (defaultCodec.getName().equals(\"SimpleText\")) {\n      isSimpleText = true;\n    } else {\n      PostingsFormat defaultPostingsFormat = defaultCodec.postingsFormat();\n      if (defaultPostingsFormat instanceof PerFieldPostingsFormat) {\n        isSimpleText = ((PerFieldPostingsFormat) defaultPostingsFormat).getPostingsFormatForField(\"field\").getName().equals(\"SimpleText\");\n      }\n    }\n\n    if (isSimpleText && TEST_NIGHTLY) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-19 06:01:22","endLine":154,"groupId":"21170","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/bf/6993da75a57016abd683d4652c7574d1e8d851.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"},{"authorDate":"2012-10-09 04:54:09","commitOrder":5,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-09 04:54:09","endLine":143,"groupId":"28347","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0f/aae6172c3e6f23de329ee3867c92d9ce2b75cd.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"N"}],"commitId":"03b98ef45565601b651bd5870e557859946b0b87","commitMessage":"@@@make test easier if it get SimpleText postings format\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1399883 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-10-19 06:01:22","modifiedFileCount":"1","status":"M","submitter":"Michael McCandless"},{"authorTime":"2012-10-09 04:54:09","codes":[{"authorDate":"2012-10-19 07:29:29","commitOrder":6,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && TEST_NIGHTLY) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-19 07:29:29","endLine":141,"groupId":"21170","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/f4/e66faea1e02ab861f54e062ad9219afa7ee80f.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = false;\n    Codec defaultCodec = Codec.getDefault();\n\n    if (defaultCodec.getName().equals(\"SimpleText\")) {\n      isSimpleText = true;\n    } else {\n      PostingsFormat defaultPostingsFormat = defaultCodec.postingsFormat();\n      if (defaultPostingsFormat instanceof PerFieldPostingsFormat) {\n        isSimpleText = ((PerFieldPostingsFormat) defaultPostingsFormat).getPostingsFormatForField(\"field\").getName().equals(\"SimpleText\");\n      }\n    }\n\n    if (isSimpleText && TEST_NIGHTLY) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2012-10-09 04:54:09","commitOrder":6,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-10-09 04:54:09","endLine":143,"groupId":"28347","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0f/aae6172c3e6f23de329ee3867c92d9ce2b75cd.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"N"}],"commitId":"d80c59b48a795dd47f5bf553b8e337ebc66eca7e","commitMessage":"@@@use _TestUtil helper instead of lots of coe\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1399923 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-10-19 07:29:29","modifiedFileCount":"1","status":"M","submitter":"Robert Muir"},{"authorTime":"2012-11-16 00:15:44","codes":[{"authorDate":"2012-11-16 00:15:44","commitOrder":7,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-11-16 00:15:44","endLine":141,"groupId":"21170","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/8b/a54b635d6681b1ff2f94134a0d071bb9f5ef76.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && TEST_NIGHTLY) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2012-11-16 00:15:44","commitOrder":7,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-11-16 00:15:44","endLine":149,"groupId":"28347","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d6/2e475b34a09877e2b0f7aebb6660c61785b87f.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"536a7379c9593bde28d5cc4d377e28bfeff5550e","commitMessage":"@@@reduce cost of test if PF is SimpleText\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1409863 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-11-16 00:15:44","modifiedFileCount":"2","status":"M","submitter":"Michael McCandless"},{"authorTime":"2012-12-03 06:49:46","codes":[{"authorDate":"2012-12-03 06:49:46","commitOrder":8,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-12-03 06:49:46","endLine":144,"groupId":"21170","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/28/d058bb6a018622892e6baa25bed291e71cfdf8.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"M"},{"authorDate":"2012-12-03 06:49:46","commitOrder":8,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2012-12-03 06:49:46","endLine":153,"groupId":"28347","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/54/b25b5efc9c2a6f8abc3fd28dc398c7915fa78f.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"f8795d25a5acc4982de65348427fbf5c376b716e","commitMessage":"@@@if we get MockRandomMergePolicy.  which is O(N^2).  use smaller index\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1416281 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-12-03 06:49:46","modifiedFileCount":"2","status":"M","submitter":"Michael McCandless"},{"authorTime":"2014-02-19 09:38:33","codes":[{"authorDate":"2014-02-19 09:38:33","commitOrder":9,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-02-19 09:38:33","endLine":145,"groupId":"21170","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/57/2069961bf0c0b1dd909edb5241a88ebe4a3d36.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"},{"authorDate":"2014-02-19 09:38:33","commitOrder":9,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-02-19 09:38:33","endLine":153,"groupId":"28347","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/8b/3c93be47337a2c4be51752e1e93633e2f62f5c.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"36b2f2512b53b3c4d5951dbeaf7d25106a806413","commitMessage":"@@@LUCENE-5449: Rename _TestUtil to TestUtil.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1569597 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-02-19 09:38:33","modifiedFileCount":"321","status":"M","submitter":"Benson Margulies"},{"authorTime":"2014-03-12 22:39:17","codes":[{"authorDate":"2014-03-12 22:39:17","commitOrder":10,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-03-12 22:39:17","endLine":145,"groupId":"0","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/a3/067e01cde857de3962cc769e0a763e206c2dd7.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<String>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"},{"authorDate":"2014-03-12 22:39:17","commitOrder":10,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-03-12 22:39:17","endLine":153,"groupId":"28347","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/61/b41136cf09268ead361ed2f8cfa0e3c2088cf9.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"3b67b17493216f6b0c81a981073fd5f61eace6f4","commitMessage":"@@@LUCENE-5512: remove redundant typing (diamond operator) in trunk\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1576755 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-03-12 22:39:17","modifiedFileCount":"1241","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-04-03 03:28:33","codes":[{"authorDate":"2014-03-12 22:39:17","commitOrder":11,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-03-12 22:39:17","endLine":145,"groupId":"0","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/a3/067e01cde857de3962cc769e0a763e206c2dd7.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"N"},{"authorDate":"2014-04-03 03:28:33","commitOrder":11,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-04-03 03:28:33","endLine":153,"groupId":"28347","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ed/dba07b1d92d3d4826b7a11a4f119755ee4ef23.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"0c0d026fea75f82c6003f46b1fe362e897be9c0a","commitMessage":"@@@LUCENE-5563: remove sep layout\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1584140 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-04-03 03:28:33","modifiedFileCount":"17","status":"M","submitter":"Robert Muir"},{"authorTime":"2014-04-05 17:17:20","codes":[{"authorDate":"2014-04-05 17:17:20","commitOrder":12,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-04-05 17:17:20","endLine":145,"groupId":"42228","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0b/8c176f1b37837800cf7431a85a9a309fd21d26.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"},{"authorDate":"2014-04-05 17:17:20","commitOrder":12,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-04-05 17:17:20","endLine":153,"groupId":"28347","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/72/6ee8701eb5d890e8f181bb2be528d9a2b6c1d6.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"2b1c7f34c475be280b033feaaa9984de48660d2d","commitMessage":"@@@LUCENE-5577: Temporary folder and file management (and cleanup facilities)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1585028 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-04-05 17:17:20","modifiedFileCount":"188","status":"M","submitter":"Dawid Weiss"},{"authorTime":"2014-04-08 23:34:50","codes":[{"authorDate":"2014-04-08 23:34:50","commitOrder":13,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":145,"groupId":"42228","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ad/c415db931b249aff74089fc88783437f62deba.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"},{"authorDate":"2014-04-08 23:34:50","commitOrder":13,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n","date":"2014-04-08 23:34:50","endLine":153,"groupId":"28347","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d0/5713023325d3ab4b2ed3f41a7b856337b26fbb.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"8559eafd99e5b569d4ad866e98f410fb4868fd4c","commitMessage":"@@@LUCENE-4246: fix IW.close to just close.  even on exception\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1585759 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-04-08 23:34:50","modifiedFileCount":"403","status":"M","submitter":"Michael McCandless"},{"authorTime":"2014-08-10 02:54:35","codes":[{"authorDate":"2014-08-10 02:54:35","commitOrder":14,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":144,"groupId":"42228","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/cb/0e8db49c55147ba0db8a7cd183bc77dc44c58b.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"M"},{"authorDate":"2014-08-10 02:54:35","commitOrder":14,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-08-10 02:54:35","endLine":153,"groupId":"28347","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/5f/e850d63e3a2a62a7624c1535901a80e254fa22.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"872bd9145cd9504fc16b318f7ea0a666d9429103","commitMessage":"@@@LUCENE-5871: Remove Version from IndexWriterConfig\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1617004 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-08-10 02:54:35","modifiedFileCount":"450","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2014-09-24 07:51:55","codes":[{"authorDate":"2014-09-24 07:51:55","commitOrder":15,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-09-24 07:51:55","endLine":144,"groupId":"42228","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/83/1e634770520da359174d6c3a01e669f166b695.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"M"},{"authorDate":"2014-09-24 07:51:55","commitOrder":15,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2014-09-24 07:51:55","endLine":153,"groupId":"28347","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c9/19f9657213157c51a03ec03a3e7986008eb563.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"85bf3181737a34e2d357f0c926d7ae8d07b9ae39","commitMessage":"@@@LUCENE-5569: *AtomicReader/AtomicReaderContext have been renamed to *LeafReader/LeafReaderContext\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1627178 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2014-09-24 07:51:55","modifiedFileCount":"459","status":"M","submitter":"Ryan Ernst"},{"authorTime":"2015-04-09 03:48:07","codes":[{"authorDate":"2015-04-09 03:48:07","commitOrder":16,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":144,"groupId":"42228","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/e6/ce3063a0001e84f471546543ebe3900e31d1c3.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"M"},{"authorDate":"2015-04-09 03:48:07","commitOrder":16,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":152,"groupId":"28347","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/43/8b4ac1490d3db4b7cb9563aae5291df09ec703.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"M"}],"commitId":"c08d81cc3971c3d6eea50c4ee704166bdf92f90c","commitMessage":"@@@LUCENE-6410: remove unused 'reuse' parameter to Terms.iterator\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1672155 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-04-09 03:48:07","modifiedFileCount":"161","status":"M","submitter":"Michael McCandless"},{"authorTime":"2016-10-11 23:00:05","codes":[{"authorDate":"2015-04-09 03:48:07","commitOrder":17,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":144,"groupId":"42228","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/e6/ce3063a0001e84f471546543ebe3900e31d1c3.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"N"},{"authorDate":"2016-10-11 23:00:05","commitOrder":17,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2016-10-11 23:17:55","endLine":152,"groupId":"7936","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/62/14e4cde1da8097e4aa8ddafd3ca3db3717e54a.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"98191225eb3ed4b2938a7ce27128a6a9b0e22590","commitMessage":"@@@SOLR-9579: SchemaField should implement lucene.IndexableFieldType to avoid repeated creation\n","date":"2016-10-11 23:17:55","modifiedFileCount":"12","status":"M","submitter":"yonik"},{"authorTime":"2020-01-22 08:27:19","codes":[{"authorDate":"2015-04-09 03:48:07","commitOrder":18,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":144,"groupId":"105941","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/e6/ce3063a0001e84f471546543ebe3900e31d1c3.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpostings\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              Document document = new Document();\n              Field field = newTextField(\"field\", \"\", Field.Store.NO);\n              document.add(field);\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                Set<String> visited = new HashSet<>();\n                for (int i = 0; i < maxTermsPerDoc; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  if (visited.contains(token)) {\n                    \r\n                    postings.add(token);\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                  visited.add(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.docFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPostings.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":43,"status":"N"},{"authorDate":"2020-01-22 08:27:19","commitOrder":18,"curCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(100);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","date":"2020-01-22 08:27:19","endLine":152,"groupId":"105941","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"test","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/87/c1097a62bd93dd6e9fd81e5afedfb77753faa6.src","preCode":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      \r\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); \r\n      fieldType.setStoreTermVectors(true); \r\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    \r\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    \r\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      \r\n      \r\n      \r\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":45,"status":"M"}],"commitId":"c754a764d484089df8e5f711b4db8ef0b4a4a7ec","commitMessage":"@@@LUCENE-9157: test speedup for slowest tests\n","date":"2020-01-22 08:27:19","modifiedFileCount":"73","status":"M","submitter":"Robert Muir"}]
