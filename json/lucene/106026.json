[{"authorTime":"2012-02-08 03:59:05","codes":[{"authorDate":"2012-02-08 03:59:05","commitOrder":1,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.getUniqueTermCount());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-02-08 03:59:05","endLine":300,"groupId":"10437","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d7/5cf0f1c29900a7ac51629e8671521e4d769dfc.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.getUniqueTermCount());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":247,"status":"B"},{"authorDate":"2012-02-08 03:59:05","commitOrder":1,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-02-08 03:59:05","endLine":337,"groupId":"58061","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/d7/5cf0f1c29900a7ac51629e8671521e4d769dfc.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":302,"status":"B"}],"commitId":"eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c","commitMessage":"@@@LUCENE-3753: Restructure the Lucene build system\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1241588 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-02-08 03:59:05","modifiedFileCount":"0","status":"B","submitter":"Steven Rowe"},{"authorTime":"2012-03-05 21:34:40","codes":[{"authorDate":"2012-03-05 21:34:40","commitOrder":2,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.getUniqueTermCount());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-03-05 21:34:40","endLine":301,"groupId":"39141","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/8f/d532c595519e95d9fab995732b133c910be760.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.getUniqueTermCount());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":248,"status":"M"},{"authorDate":"2012-03-05 21:34:40","commitOrder":2,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-03-05 21:34:40","endLine":338,"groupId":"55834","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/8f/d532c595519e95d9fab995732b133c910be760.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocsEnum.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":303,"status":"M"}],"commitId":"989530e17e09a4b023164be6694b60a609d6c01c","commitMessage":"@@@LUCENE-3850: Fix rawtypes warnings for Java 7 compiler\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1297048 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-03-05 21:34:40","modifiedFileCount":"114","status":"M","submitter":"Uwe Schindler"},{"authorTime":"2012-04-11 07:21:39","codes":[{"authorDate":"2012-04-11 07:21:39","commitOrder":3,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-04-11 07:21:39","endLine":301,"groupId":"39141","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/73/b49e910939d82403a80c9077de79218ac1662d.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.getUniqueTermCount());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":248,"status":"M"},{"authorDate":"2012-04-11 07:21:39","commitOrder":3,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-04-11 07:21:39","endLine":338,"groupId":"55834","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/73/b49e910939d82403a80c9077de79218ac1662d.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.getUniqueTermCount());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":303,"status":"M"}],"commitId":"5bae28d57e58b34adf424ded3d5eb4cc53a9332b","commitMessage":"@@@LUCENE-3970: rename getUniqueTerm/FieldCount() to size()\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1312037 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-04-11 07:21:39","modifiedFileCount":"34","status":"M","submitter":"Michael McCandless"},{"authorTime":"2012-04-15 22:41:44","codes":[{"authorDate":"2012-04-15 22:41:44","commitOrder":4,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-04-15 22:41:44","endLine":301,"groupId":"39141","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/1b/21528d9e023efacaf2b649228b82e8a4c2d684.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":248,"status":"M"},{"authorDate":"2012-04-15 22:41:44","commitOrder":4,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-04-15 22:41:44","endLine":338,"groupId":"55834","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/1b/21528d9e023efacaf2b649228b82e8a4c2d684.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":303,"status":"M"}],"commitId":"cf85aab1a06cb2b12e4778c1dd7c1368a6225b91","commitMessage":"@@@LUCENE-3808: Switch LuceneTestCaseRunner to RandomizedRunner. Enforce Random sharing contracts. Enforce thread leaks.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1326351 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-04-15 22:41:44","modifiedFileCount":"501","status":"M","submitter":"Dawid Weiss"},{"authorTime":"2012-05-29 03:28:10","codes":[{"authorDate":"2012-05-29 03:28:10","commitOrder":5,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-05-29 03:28:10","endLine":295,"groupId":"39141","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/67/869966a0c981e11ea5688e9257ca8168543f5c.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":242,"status":"M"},{"authorDate":"2012-05-29 03:28:10","commitOrder":5,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-05-29 03:28:10","endLine":332,"groupId":"55834","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/67/869966a0c981e11ea5688e9257ca8168543f5c.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":297,"status":"M"}],"commitId":"e9bb48725216af399d3d3cd7663b53fa63ec5438","commitMessage":"@@@LUCENE-4055: Refactor SegmentInfo and FieldInfo to make them extensible\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1343365 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-05-29 03:28:10","modifiedFileCount":"205","status":"M","submitter":"Robert Muir"},{"authorTime":"2012-07-31 01:31:34","codes":[{"authorDate":"2012-07-31 01:31:34","commitOrder":6,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","date":"2012-07-31 01:31:34","endLine":293,"groupId":"39141","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c2/b98a2c89fad962fe31b64d912bc7645f5e84b8.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"},{"authorDate":"2012-07-31 01:31:34","commitOrder":6,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-07-31 01:31:34","endLine":330,"groupId":"48108","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c2/b98a2c89fad962fe31b64d912bc7645f5e84b8.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":295,"status":"M"}],"commitId":"72f99b47b4673d858e3ffd42afdca76e0a5bb860","commitMessage":"@@@LUCENE-4230: allow consumer to specify that payloads are not require when pulling D&PEnum.  so codec can optimize if possible\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1367186 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2012-07-31 01:31:34","modifiedFileCount":"65","status":"M","submitter":"Michael McCandless"},{"authorTime":"2012-07-31 01:31:34","codes":[{"authorDate":"2013-01-22 14:51:45","commitOrder":7,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.docs(null, null));\n      assertNull(termsEnum.docsAndPositions(null, null)); \r\n    }\n    reader.close();\n  }\n","date":"2013-01-22 14:51:45","endLine":296,"groupId":"39141","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/1f/bbdd72f68e654e8ece062af90aa2cc9ff4a126.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"},{"authorDate":"2012-07-31 01:31:34","commitOrder":7,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-07-31 01:31:34","endLine":330,"groupId":"48108","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c2/b98a2c89fad962fe31b64d912bc7645f5e84b8.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":295,"status":"N"}],"commitId":"27de7834677f60510a5d0bb4b84c67d97f9fca5e","commitMessage":"@@@LUCENE-4599: fix Compressing vectors to not return a docsAndPositions when it has no prox\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1436765 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2013-01-22 14:51:45","modifiedFileCount":"2","status":"M","submitter":"Robert Muir"},{"authorTime":"2012-07-31 01:31:34","codes":[{"authorDate":"2013-04-15 22:08:02","commitOrder":8,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.docs(null, null));\n      assertNull(termsEnum.docsAndPositions(null, null)); \r\n    }\n    reader.close();\n  }\n","date":"2013-04-15 22:08:02","endLine":296,"groupId":"48645","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/a5/7ace2a7ce8cd9808228f317787f76269cf7593.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertTrue(doc == -1 || doc == DocIdSetIterator.NO_MORE_DOCS);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.docs(null, null));\n      assertNull(termsEnum.docsAndPositions(null, null)); \r\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"},{"authorDate":"2012-07-31 01:31:34","commitOrder":8,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2012-07-31 01:31:34","endLine":330,"groupId":"48108","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c2/b98a2c89fad962fe31b64d912bc7645f5e84b8.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":295,"status":"N"}],"commitId":"924e29901490e74a931a43f066f8af7465a8edfe","commitMessage":"@@@LUCENE-4924: DocIdSetIterator.docID() must return -1 when the iterator is not positioned.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1468083 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2013-04-15 22:08:02","modifiedFileCount":"12","status":"M","submitter":"Adrien Grand"},{"authorTime":"2015-02-06 21:25:22","codes":[{"authorDate":"2015-02-06 21:25:22","commitOrder":9,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNull(termsEnum.postings(null, null, PostingsEnum.FLAG_ALL)); \r\n    }\n    reader.close();\n  }\n","date":"2015-02-06 21:25:22","endLine":298,"groupId":"36279","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0d/43cab34d4b38482f80686201b80e6344d478a8.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.docs(null, null));\n      assertNull(termsEnum.docsAndPositions(null, null)); \r\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2015-02-06 21:25:22","commitOrder":9,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-02-06 21:25:22","endLine":335,"groupId":"1600","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/0d/43cab34d4b38482f80686201b80e6344d478a8.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    DocsAndPositionsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"M"}],"commitId":"c13216934c58870b487a9bd04b2fd4ea24431000","commitMessage":"@@@LUCENE-4524: Replace DocsEnum and DocsAndPositionsEnum with PostingsEnum\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1657800 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-02-06 21:25:22","modifiedFileCount":"236","status":"M","submitter":"Alan Woodward"},{"authorTime":"2015-02-17 20:46:55","codes":[{"authorDate":"2015-02-17 20:46:55","commitOrder":10,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNull(termsEnum.postings(null, null, PostingsEnum.ALL)); \r\n    }\n    reader.close();\n  }\n","date":"2015-02-17 20:46:55","endLine":298,"groupId":"36279","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/0eb2b5097957340d592e8b2f2132d83e94441d.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNull(termsEnum.postings(null, null, PostingsEnum.FLAG_ALL)); \r\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2015-02-17 20:46:55","commitOrder":10,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-02-17 20:46:55","endLine":335,"groupId":"1600","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/0eb2b5097957340d592e8b2f2132d83e94441d.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"M"}],"commitId":"69300ee467a3fa066184c511827ac39553f4aa52","commitMessage":"@@@LUCENE-6246: Fix DocsEnum -> PostingsEnum transition (phase 1)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1660366 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-02-17 20:46:55","modifiedFileCount":"92","status":"M","submitter":"Robert Muir"},{"authorTime":"2015-02-17 20:46:55","codes":[{"authorDate":"2015-04-04 05:27:03","commitOrder":11,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2015-04-04 05:27:03","endLine":298,"groupId":"36279","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/5a/627d45a870961bcf2df197e68e3bd418de4359.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNull(termsEnum.postings(null, null, PostingsEnum.ALL)); \r\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2015-02-17 20:46:55","commitOrder":11,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-02-17 20:46:55","endLine":335,"groupId":"1600","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/c0/0eb2b5097957340d592e8b2f2132d83e94441d.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"N"}],"commitId":"1052ae1c48cb71f6d3bbe0bf844f44407635e152","commitMessage":"@@@LUCENE-6271: PostingsEnum should have consistent flags behavior\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1671163 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-04-04 05:27:03","modifiedFileCount":"34","status":"M","submitter":"Robert Muir"},{"authorTime":"2015-04-09 03:48:07","codes":[{"authorDate":"2015-04-09 03:48:07","commitOrder":12,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":298,"groupId":"36279","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ae/0e5dd9065079d09d7d920bfd0be84b31647d27.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator(null);\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2015-04-09 03:48:07","commitOrder":12,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-04-09 03:48:07","endLine":335,"groupId":"1600","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/ae/0e5dd9065079d09d7d920bfd0be84b31647d27.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"M"}],"commitId":"c08d81cc3971c3d6eea50c4ee704166bdf92f90c","commitMessage":"@@@LUCENE-6410: remove unused 'reuse' parameter to Terms.iterator\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1672155 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-04-09 03:48:07","modifiedFileCount":"161","status":"M","submitter":"Michael McCandless"},{"authorTime":"2015-06-25 21:59:19","codes":[{"authorDate":"2015-06-25 21:59:19","commitOrder":13,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2015-06-25 21:59:19","endLine":298,"groupId":"1595","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/6729af8294eee2881e1167bbd2084374e86e05.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null, null));\n      assertNotNull(termsEnum.postings(null, null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":243,"status":"M"},{"authorDate":"2015-06-25 21:59:19","commitOrder":13,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-06-25 21:59:19","endLine":335,"groupId":"1600","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/6729af8294eee2881e1167bbd2084374e86e05.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"M"}],"commitId":"d671dd8d890a8e5eb56cbcd94873c3057745a17f","commitMessage":"@@@LUCENE-6553: Simplify how live docs are applied.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1687524 13f79535-47bb-0310-9956-ffa450edef68\n","date":"2015-06-25 21:59:19","modifiedFileCount":"217","status":"M","submitter":"Adrien Grand"},{"authorTime":"2015-06-25 21:59:19","codes":[{"authorDate":"2021-03-23 23:09:24","commitOrder":14,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2021-03-23 23:09:24","endLine":304,"groupId":"1595","id":27,"instanceNumber":1,"isCurCommit":1,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3a/b1d5bba32791565f022713253507ca855af75a.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":247,"status":"M"},{"authorDate":"2015-06-25 21:59:19","commitOrder":14,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-06-25 21:59:19","endLine":335,"groupId":"1600","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/6729af8294eee2881e1167bbd2084374e86e05.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"N"}],"commitId":"20dba278bbfc4fec8b53c8371eae982e3fa24b39","commitMessage":"@@@LUCENE-9856: fail precommit on unused local variables (#34)\n\nEnable ecj unused local variable.  private instance and method detection. Allow SuppressWarnings(\"unused\") to disable unused checks (e.g. for generated code or very special tests). Fix gradlew regenerate for python 3.9 SuppressWarnings(\"unused\") for generated javacc and jflex code. Enable a few other easy ecj checks such as Deprecated annotation.  hashcode/equals.  equals across different types.\n\nCo-authored-by: Mike McCandless <mikemccand@apache.org>","date":"2021-03-23 23:09:24","modifiedFileCount":"209","status":"M","submitter":"Robert Muir"},{"authorTime":"2015-06-25 21:59:19","codes":[{"authorDate":"2021-03-24 00:46:36","commitOrder":15,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2021-03-24 00:46:36","endLine":305,"groupId":"1595","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3f/eeec53ed875e1f08315b00e9dc855803594940.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":247,"status":"M"},{"authorDate":"2015-06-25 21:59:19","commitOrder":15,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-06-25 21:59:19","endLine":335,"groupId":"1600","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/6729af8294eee2881e1167bbd2084374e86e05.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"N"}],"commitId":"e6c4956cf69b7d2b47297f589a6855fa3028396a","commitMessage":"@@@Revert \"LUCENE-9856: fail precommit on unused local variables (#34)\"\n\nThis reverts commit 20dba278bbfc4fec8b53c8371eae982e3fa24b39.\n","date":"2021-03-24 00:46:36","modifiedFileCount":"209","status":"M","submitter":"Robert Muir"},{"authorTime":"2015-06-25 21:59:19","codes":[{"authorDate":"2021-03-24 01:59:00","commitOrder":16,"curCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","date":"2021-03-24 01:59:00","endLine":304,"groupId":"106026","id":31,"instanceNumber":1,"isCurCommit":1,"methodName":"testPositionReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3a/b1d5bba32791565f022713253507ca855af75a.src","preCode":"  public void testPositionReader() throws IOException {\n    TermVectorsReader reader =\n        Codec.getDefault()\n            .termVectorsFormat()\n            .vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    BytesRef[] terms;\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    assertEquals(testTerms.length, vector.size());\n    TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      int doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      doc = dpEnum.docID();\n      assertEquals(-1, doc);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j * 10, dpEnum.startOffset());\n        assertEquals(j * 10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n\n    Terms freqVector = reader.get(0).terms(testFields[1]); \r\n    assertNotNull(freqVector);\n    assertEquals(testTerms.length, freqVector.size());\n    termsEnum = freqVector.iterator();\n    assertNotNull(termsEnum);\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      \r\n      assertEquals(testTerms[i], term);\n      assertNotNull(termsEnum.postings(null));\n      assertNotNull(termsEnum.postings(null, PostingsEnum.ALL));\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":247,"status":"M"},{"authorDate":"2015-06-25 21:59:19","commitOrder":16,"curCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","date":"2015-06-25 21:59:19","endLine":335,"groupId":"106026","id":32,"instanceNumber":2,"isCurCommit":0,"methodName":"testOffsetReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-lucene-10-0.7/blobInfo/CC_OUT/blobs/3d/6729af8294eee2881e1167bbd2084374e86e05.src","preCode":"  public void testOffsetReader() throws IOException {\n    TermVectorsReader reader = Codec.getDefault().termVectorsFormat().vectorsReader(dir, seg.info, fieldInfos, newIOContext(random()));\n    Terms vector = reader.get(0).terms(testFields[0]);\n    assertNotNull(vector);\n    TermsEnum termsEnum = vector.iterator();\n    assertNotNull(termsEnum);\n    assertEquals(testTerms.length, vector.size());\n    PostingsEnum dpEnum = null;\n    for (int i = 0; i < testTerms.length; i++) {\n      final BytesRef text = termsEnum.next();\n      assertNotNull(text);\n      String term = text.utf8ToString();\n      assertEquals(testTerms[i], term);\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertNotNull(dpEnum);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n      assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertNotNull(dpEnum);\n      assertEquals(dpEnum.freq(), positions[i].length);\n      for (int j = 0; j < positions[i].length; j++) {\n        assertEquals(positions[i][j], dpEnum.nextPosition());\n        assertEquals(j*10, dpEnum.startOffset());\n        assertEquals(j*10 + testTerms[i].length(), dpEnum.endOffset());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, dpEnum.nextDoc());\n    }\n    reader.close();\n  }\n","realPath":"lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java","repoName":"lucene","snippetEndLine":0,"snippetStartLine":0,"startLine":300,"status":"N"}],"commitId":"945b1cb8726223d5b0d5f61e85174ca93931b86e","commitMessage":"@@@LUCENE-9856: fail precommit on unused local variables.  take two (#37)\n\nEnable ecj unused local variable.  private instance and method detection. Allow SuppressWarnings(\"unused\") to disable unused checks (e.g. for generated code or very special tests). Fix gradlew regenerate for python 3.9 SuppressWarnings(\"unused\") for generated javacc and jflex code. Enable a few other easy ecj checks such as Deprecated annotation.  hashcode/equals.  equals across different types.\n\nCo-authored-by: Mike McCandless <mikemccand@apache.org>","date":"2021-03-24 01:59:00","modifiedFileCount":"158","status":"M","submitter":"Robert Muir"}]
