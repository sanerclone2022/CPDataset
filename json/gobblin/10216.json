[{"authorTime":"2020-05-21 06:37:12","codes":[{"authorDate":"2020-03-12 07:14:19","commitOrder":2,"curCode":"  public void testConsumerAutoOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n    consumerProps.setProperty(HighLevelConsumer.ENABLE_AUTO_COMMIT_KEY, \"true\");\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps), NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 5000);\n    consumer.shutDown();\n  }\n","date":"2020-03-12 07:14:19","endLine":122,"groupId":"5586","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testConsumerAutoOffsetCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/75/c667b3c2d51dd8ae507bd01addf0b799dc41f1.src","preCode":"  public void testConsumerAutoOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n    consumerProps.setProperty(HighLevelConsumer.ENABLE_AUTO_COMMIT_KEY, \"true\");\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps), NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 5000);\n    consumer.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/HighLevelConsumerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"NB"},{"authorDate":"2020-05-21 06:37:12","commitOrder":2,"curCode":"  public void testConsumerManualOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n\n    \r\n    consumerProps.put(HighLevelConsumer.OFFSET_COMMIT_TIME_THRESHOLD_SECS_KEY, 1);\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps),\n        NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 10000);\n\n    for(int i=0; i< NUM_PARTITIONS; i++) {\n      KafkaPartition partition = new KafkaPartition.Builder().withTopicName(TOPIC).withId(i).build();\n      AssertWithBackoff.assertTrue(input -> consumer.getCommittedOffsets().containsKey(partition),\n          5000, \"waiting for committing offsets\", log, 2, 1000);\n    }\n    consumer.shutDown();\n  }\n","date":"2020-05-21 06:37:12","endLine":147,"groupId":"5587","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testConsumerManualOffsetCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/c1/01d15738c11319256ae289bfab3ca8e10aee47.src","preCode":"  public void testConsumerManualOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n\n    \r\n    consumerProps.put(HighLevelConsumer.OFFSET_COMMIT_TIME_THRESHOLD_SECS_KEY, 1);\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps),\n        NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 10000);\n\n    for(int i=0; i< NUM_PARTITIONS; i++) {\n      KafkaPartition partition = new KafkaPartition.Builder().withTopicName(TOPIC).withId(i).build();\n      AssertWithBackoff.assertTrue(input -> consumer.getCommittedOffsets().containsKey(partition),\n          5000, \"waiting for committing offsets\", log, 2, 1000);\n    }\n    consumer.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/HighLevelConsumerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"MB"}],"commitId":"72373eebff6b669bd8e001966ffab4e6ded8ab7b","commitMessage":"@@@[GOBBLIN-1150] spec catalog table schema change\n\nCloses #2988 from arjun4084346/jsonConfig\n","date":"2020-05-21 06:37:12","modifiedFileCount":"10","status":"M","submitter":"Arjun"},{"authorTime":"2020-10-13 11:07:27","codes":[{"authorDate":"2020-10-13 11:07:27","commitOrder":3,"curCode":"  public void testConsumerAutoOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n    \r\n    String consumerGroupId = Joiner.on(\"-\").join(TOPIC, \"auto\", System.currentTimeMillis());\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + HighLevelConsumer.GROUP_ID_KEY, consumerGroupId);\n    consumerProps.setProperty(HighLevelConsumer.ENABLE_AUTO_COMMIT_KEY, \"true\");\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps), NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 10000);\n    consumer.shutDown();\n  }\n","date":"2020-10-13 11:07:27","endLine":130,"groupId":"10216","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testConsumerAutoOffsetCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/8a/28bf27019b90c67832a9cf145135206086466c.src","preCode":"  public void testConsumerAutoOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n    consumerProps.setProperty(HighLevelConsumer.ENABLE_AUTO_COMMIT_KEY, \"true\");\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps), NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 5000);\n    consumer.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/HighLevelConsumerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":116,"status":"M"},{"authorDate":"2020-10-13 11:07:27","commitOrder":3,"curCode":"  public void testConsumerManualOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n    \r\n    String consumerGroupId = Joiner.on(\"-\").join(TOPIC, \"manual\", System.currentTimeMillis());\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + HighLevelConsumer.GROUP_ID_KEY, consumerGroupId);\n    \r\n    consumerProps.put(HighLevelConsumer.OFFSET_COMMIT_TIME_THRESHOLD_SECS_KEY, 1);\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps),\n        NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 10000);\n\n    for(int i=0; i< NUM_PARTITIONS; i++) {\n      KafkaPartition partition = new KafkaPartition.Builder().withTopicName(TOPIC).withId(i).build();\n      AssertWithBackoff.assertTrue(input -> consumer.getCommittedOffsets().containsKey(partition),\n          5000, \"waiting for committing offsets\", log, 2, 1000);\n    }\n    consumer.shutDown();\n  }\n","date":"2020-10-13 11:07:27","endLine":156,"groupId":"10216","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testConsumerManualOffsetCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/8a/28bf27019b90c67832a9cf145135206086466c.src","preCode":"  public void testConsumerManualOffsetCommit() throws Exception {\n    Properties consumerProps = new Properties();\n    consumerProps.setProperty(ConfigurationKeys.KAFKA_BROKERS, _kafkaBrokers);\n    consumerProps.setProperty(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, \"org.apache.kafka.common.serialization.ByteArrayDeserializer\");\n    consumerProps.setProperty(SOURCE_KAFKA_CONSUMERCONFIG_KEY_WITH_DOT + KAFKA_AUTO_OFFSET_RESET_KEY, \"earliest\");\n\n    \r\n    consumerProps.put(HighLevelConsumer.OFFSET_COMMIT_TIME_THRESHOLD_SECS_KEY, 1);\n\n    MockedHighLevelConsumer consumer = new MockedHighLevelConsumer(TOPIC, ConfigUtils.propertiesToConfig(consumerProps),\n        NUM_PARTITIONS);\n    consumer.startAsync().awaitRunning();\n\n    consumer.awaitExactlyNMessages(NUM_MSGS, 10000);\n\n    for(int i=0; i< NUM_PARTITIONS; i++) {\n      KafkaPartition partition = new KafkaPartition.Builder().withTopicName(TOPIC).withId(i).build();\n      AssertWithBackoff.assertTrue(input -> consumer.getCommittedOffsets().containsKey(partition),\n          5000, \"waiting for committing offsets\", log, 2, 1000);\n    }\n    consumer.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/HighLevelConsumerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":133,"status":"M"}],"commitId":"0d30aaecee1e2eed5dfcfdbcbc8efba96d63ed7c","commitMessage":"@@@[GOBBLIN-1284] Fix flaky tests causing local build failures\n\nCloses #3123 from\nsv2000/rateControlledFileSystemTest\n","date":"2020-10-13 11:07:27","modifiedFileCount":"11","status":"M","submitter":"suvasude"}]
