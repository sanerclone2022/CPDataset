[{"authorTime":"2021-03-24 06:21:10","codes":[{"authorDate":"2021-03-24 06:21:10","commitOrder":1,"curCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","date":"2021-03-24 06:21:10","endLine":197,"groupId":"6748","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/88/f72f9d7d827c246090f6d366803fa6d3cbe3e0.src","preCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/IcebergMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":148,"status":"B"},{"authorDate":"2021-03-24 06:21:10","commitOrder":1,"curCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","date":"2021-03-24 06:21:10","endLine":206,"groupId":"2303","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testHiveWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/0d/13ecf8271eab82791b699d1a47a2b90db7d4bf.src","preCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/HiveMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"B"}],"commitId":"d9ae5353c74fdcd385835fca9b586b3fdb90971b","commitMessage":"@@@[GOBBLIN-1396] Enable HiveWriter to consume gmce and register into hive MetadataStore\n\n[GOBBLIN-1396]Enable HiveWriter to consume gmce\nand register into hive MetadataStore\n\nbug fix\n\nadd default branch to pass styleCheck\n\nbug fix to avoid dead lock\n\naddress comments\n\naddress comments\n\nenable rewrite/drop file in HiveMetadataWriter\n\nremove unintentional change\n\naddress comments\n\nforce to set schema literal\n\nCloses #3234 from ZihanLi58/GOBBLIN-1396\n","date":"2021-03-24 06:21:10","modifiedFileCount":"5","status":"B","submitter":"Zihan Li"},{"authorTime":"2021-03-24 06:21:10","codes":[{"authorDate":"2021-05-16 23:31:54","commitOrder":2,"curCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    Assert.assertEquals(table.location(),\n        new File(tmpDir, \"data/tracking/testIcebergTable/_iceberg_metadata/\").getAbsolutePath() + \"/\" + dbName);\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","date":"2021-05-16 23:31:54","endLine":201,"groupId":"6748","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/d6/ec1912e4d7c4e0e58db1912d260b6f2521e081.src","preCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/IcebergMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"M"},{"authorDate":"2021-03-24 06:21:10","commitOrder":2,"curCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","date":"2021-03-24 06:21:10","endLine":206,"groupId":"2303","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testHiveWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/0d/13ecf8271eab82791b699d1a47a2b90db7d4bf.src","preCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/HiveMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"N"}],"commitId":"e4d6c1b7542f3af5237447021ff14295d2c425ff","commitMessage":"@@@[GOBBLIN-1443] Make iceberg metadata root location include db name\n\nCloses #3279 from ZihanLi58/GOBBLIN-1443\n","date":"2021-05-16 23:31:54","modifiedFileCount":"3","status":"M","submitter":"Zihan Li"},{"authorTime":"2021-03-24 06:21:10","codes":[{"authorDate":"2021-07-20 06:38:59","commitOrder":3,"curCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriterWithAcceptClusters.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    \r\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 0);\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    Assert.assertEquals(table.location(),\n        new File(tmpDir, \"data/tracking/testIcebergTable/_iceberg_metadata/\").getAbsolutePath() + \"/\" + dbName);\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","date":"2021-07-20 06:38:59","endLine":213,"groupId":"6748","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/06/6bcc28f4d0a990b95e68c0cbae1686755a6990.src","preCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    Assert.assertEquals(table.location(),\n        new File(tmpDir, \"data/tracking/testIcebergTable/_iceberg_metadata/\").getAbsolutePath() + \"/\" + dbName);\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/IcebergMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":156,"status":"M"},{"authorDate":"2021-03-24 06:21:10","commitOrder":3,"curCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","date":"2021-03-24 06:21:10","endLine":206,"groupId":"2303","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testHiveWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/0d/13ecf8271eab82791b699d1a47a2b90db7d4bf.src","preCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/HiveMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"N"}],"commitId":"08db23e15ab73654142998ecabb01bbb51f42a61","commitMessage":"@@@[GOBBLIN-1490] Make metadata pipeline to support consume GMCE emitted from different cluster (#3331)\n\n* [GOBBLIN-1490] Make metadata pipeline to support consume GMCE emitted from different cluster\n\n* add unit test\n\n* address comments","date":"2021-07-20 06:38:59","modifiedFileCount":"3","status":"M","submitter":"Zihan Li"},{"authorTime":"2021-03-24 06:21:10","codes":[{"authorDate":"2021-08-07 02:52:37","commitOrder":4,"curCode":"  public void testWriteAddFileGMCE() throws IOException {\n    \r\n    \r\n    GenericRecord genericGmce = GenericData.get().deepCopy(gmce.getSchema(), gmce);\n\n    gobblinMCEWriterWithAcceptClusters.writeEnvelope(new RecordEnvelope<>(genericGmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    \r\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 0);\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(genericGmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    Assert.assertEquals(table.location(),\n        new File(tmpDir, \"data/tracking/testIcebergTable/_iceberg_metadata/\").getAbsolutePath() + \"/\" + dbName);\n\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    GenericRecord genericGmce_1000_2000 = GenericData.get().deepCopy(gmce.getSchema(), gmce);\n\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(genericGmce_1000_2000,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    GenericRecord genericGmce_2000_3000 = GenericData.get().deepCopy(gmce.getSchema(), gmce);\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(genericGmce_2000_3000,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(genericGmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","date":"2021-08-07 02:52:37","endLine":221,"groupId":"101750","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/2a/e9859a5bffc48bd296723078c817a706fdcd53.src","preCode":"  public void testWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriterWithAcceptClusters.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    \r\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 0);\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    Assert.assertEquals(catalog.listTables(Namespace.of(dbName)).size(), 1);\n    Table table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertFalse(table.properties().containsKey(\"offset.range.testTopic-1\"));\n    Assert.assertEquals(table.location(),\n        new File(tmpDir, \"data/tracking/testIcebergTable/_iceberg_metadata/\").getAbsolutePath() + \"/\" + dbName);\n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"1000-2000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-2000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 1);\n    \r\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"9\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n    Assert.assertEquals(table.properties().get(\"gmce.low.watermark.GobblinMetadataChangeEvent_test-1\"), \"20\");\n    Assert.assertEquals(table.properties().get(\"gmce.high.watermark.GobblinMetadataChangeEvent_test-1\"), \"30\");\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"3000-4000\").build());\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n    table = catalog.loadTable(catalog.listTables(Namespace.of(dbName)).get(0));\n    Assert.assertEquals(table.properties().get(\"offset.range.testTopic-1\"), \"0-3000\");\n    Assert.assertEquals(table.currentSnapshot().allManifests().size(), 2);\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/IcebergMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":156,"status":"M"},{"authorDate":"2021-03-24 06:21:10","commitOrder":4,"curCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","date":"2021-03-24 06:21:10","endLine":206,"groupId":"101750","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testHiveWriteAddFileGMCE","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/0d/13ecf8271eab82791b699d1a47a2b90db7d4bf.src","preCode":"  public void testHiveWriteAddFileGMCE() throws IOException {\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(10L))));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(20L))));\n    gobblinMCEWriter.flush();\n\n\n    \n    gmce.setTopicPartitionOffsetsRange(ImmutableMap.<String, String>builder().put(\"testTopic-1\", \"2000-3000\").build());\n    gmce.setNewFiles(Lists.newArrayList(DataFile.newBuilder()\n        .setFilePath(hourlyDataFile_2.toString())\n        .setFileFormat(\"avro\")\n        .setFileMetrics(DataMetrics.newBuilder().setRecordCount(10L).build())\n        .build()));\n    gobblinMCEWriter.writeEnvelope(new RecordEnvelope<>(gmce,\n        new KafkaStreamingExtractor.KafkaWatermark(\n            new KafkaPartition.Builder().withTopicName(\"GobblinMetadataChangeEvent_test\").withId(1).build(),\n            new LongWatermark(30L))));\n    gobblinMCEWriter.flush();\n\n    \r\n    try {\n      Assert.assertTrue(client.tableExists(\"hivedb\", \"testTable\"));\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-09\")) != null);\n      Assert.assertTrue(client.getPartition(\"hivedb\", \"testTable\",Lists.newArrayList(\"2020-03-17-08\")) != null);\n    } catch (TException e) {\n      throw new IOException(e);\n    }\n\n  }\n","realPath":"gobblin-iceberg/src/test/java/org/apache/gobblin/iceberg/writer/HiveMetadataWriterTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"N"}],"commitId":"dd205150d13d9ad9cd77a604d0bc577e19e9c628","commitMessage":"@@@[GOBBLIN-1501] Documentation + Code Cleaning for IcebergMetadataWriter  (#3347)\n\n* Add more comments in IcebergMetadataWriter while reading thru the code base\n\n* Fix unit tests post force the compile-time casting of gmce","date":"2021-08-07 02:52:37","modifiedFileCount":"7","status":"M","submitter":"Lei"}]
