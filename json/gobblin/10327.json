[{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":1,"curCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2017-07-31 15:51:25","endLine":79,"groupId":"1315","id":1,"instanceNumber":1,"isCurCommit":1,"methodName":"ComplianceJob","params":"(Propertiesproperties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/cb/f8c66109f20884c20cce480e3a93c83daf40ce.src","preCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-modules/gobblin-compliance/src/main/java/org/apache/gobblin/compliance/ComplianceJob.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"B"},{"authorDate":"2017-07-31 15:51:25","commitOrder":1,"curCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    this.closer = Closer.create();\n    try {\n      FileSystem optionalRateControlledFs = fs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(fs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    \r\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2017-07-31 15:51:25","endLine":117,"groupId":"1945","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"DatasetCleaner","params":"(FileSystemfs@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/d0/a0a969c4015cb512e26ae5da3064fd4a648cfd.src","preCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    this.closer = Closer.create();\n    try {\n      FileSystem optionalRateControlledFs = fs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(fs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    \r\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/retention/DatasetCleaner.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":87,"status":"B"}],"commitId":"5457af88d56b8fb89b172129fd1ff24ecdd4eba8","commitMessage":"@@@Merge pull request #2031 from abti/move_packages_to_apache\n","date":"2017-07-31 15:51:25","modifiedFileCount":"2","status":"B","submitter":"Abhishek Tiwari"},{"authorTime":"2018-09-18 12:52:41","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":2,"curCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2017-07-31 15:51:25","endLine":79,"groupId":"1315","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"ComplianceJob","params":"(Propertiesproperties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/cb/f8c66109f20884c20cce480e3a93c83daf40ce.src","preCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-modules/gobblin-compliance/src/main/java/org/apache/gobblin/compliance/ComplianceJob.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"N"},{"authorDate":"2018-09-18 12:52:41","commitOrder":2,"curCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    State state = new State(props);\n    FileSystem targetFs =\n        props.containsKey(ConfigurationKeys.WRITER_FILE_SYSTEM_URI) ? WriterUtils.getWriterFs(state) : fs;\n    this.closer = Closer.create();\n    try {\n      FileSystem optionalRateControlledFs = targetFs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(targetFs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    \r\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2018-09-18 12:52:41","endLine":122,"groupId":"1945","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"DatasetCleaner","params":"(FileSystemfs@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/67/93f5a1b9c16fe1217c0b97e0bb9fa16f2509da.src","preCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    this.closer = Closer.create();\n    try {\n      FileSystem optionalRateControlledFs = fs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(fs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    \r\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/retention/DatasetCleaner.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":89,"status":"M"}],"commitId":"f43de8c4d7dd0fa3521edc03a173f25873ba9814","commitMessage":"@@@[GOBBLIN-586] Added enhancement to apply retention on remote HDFS\n\nCloses #2452 from amarnathkarthik/master\n","date":"2018-09-18 12:52:41","modifiedFileCount":"2","status":"M","submitter":"Karthik Amarnath"},{"authorTime":"2019-06-20 07:59:38","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":3,"curCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2017-07-31 15:51:25","endLine":79,"groupId":"1315","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"ComplianceJob","params":"(Propertiesproperties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/cb/f8c66109f20884c20cce480e3a93c83daf40ce.src","preCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-modules/gobblin-compliance/src/main/java/org/apache/gobblin/compliance/ComplianceJob.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"N"},{"authorDate":"2019-06-20 07:59:38","commitOrder":3,"curCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    State state = new State(props);\n    FileSystem targetFs =\n        props.containsKey(ConfigurationKeys.WRITER_FILE_SYSTEM_URI) ? WriterUtils.getWriterFs(state) : fs;\n    this.closer = Closer.create();\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    try {\n      FileSystem optionalRateControlledFs = targetFs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(targetFs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props, eventSubmitter);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2019-06-20 07:59:38","endLine":122,"groupId":"1430","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"DatasetCleaner","params":"(FileSystemfs@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/84/8b0d2f07e4fd154911a068618e9d713fec6722.src","preCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    State state = new State(props);\n    FileSystem targetFs =\n        props.containsKey(ConfigurationKeys.WRITER_FILE_SYSTEM_URI) ? WriterUtils.getWriterFs(state) : fs;\n    this.closer = Closer.create();\n    try {\n      FileSystem optionalRateControlledFs = targetFs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(targetFs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    \r\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/retention/DatasetCleaner.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":89,"status":"M"}],"commitId":"fd38b4b48520b2ca9c75de1613169b59de0a3dc2","commitMessage":"@@@[GOBBLIN-806] Enable metrics reporter during dataset discovery for retention job\n\nEnable metrics reporter during dataset discovery\nfor retention job\n\nEnable event submitter for dataset finder imported\nby tag\n\nadd SuppressWarnings\n\naddress comments\n\nCloses #2672 from ZihanLi58/GOBBLIN-806\n","date":"2019-06-20 07:59:38","modifiedFileCount":"3","status":"M","submitter":"Zihan Li"},{"authorTime":"2020-06-12 08:55:07","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":4,"curCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2017-07-31 15:51:25","endLine":79,"groupId":"10327","id":7,"instanceNumber":1,"isCurCommit":1,"methodName":"ComplianceJob","params":"(Propertiesproperties)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/cb/f8c66109f20884c20cce480e3a93c83daf40ce.src","preCode":"  public ComplianceJob(Properties properties) {\n    this.properties = properties;\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(ComplianceConfigurationKeys.MAX_CONCURRENT_DATASETS, ComplianceConfigurationKeys.DEFAULT_MAX_CONCURRENT_DATASETS)), 100,\n        ExecutorsUtils.newThreadFactory(Optional.<Logger>absent(), Optional.of(\"complaince-job-pool-%d\")));\n    this.service = MoreExecutors.listeningDecorator(executor);\n    this.closer = Closer.create();\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(properties), ComplianceJob.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, ComplianceEvents.NAMESPACE).build();\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-modules/gobblin-compliance/src/main/java/org/apache/gobblin/compliance/ComplianceJob.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"N"},{"authorDate":"2020-06-12 08:55:07","commitOrder":4,"curCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    Properties properties = new Properties();\n    properties.putAll(props);\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n    properties.putAll(ConfigUtils.configToProperties(dynamicConfig));\n    State state = new State(properties);\n    FileSystem targetFs =\n        properties.containsKey(ConfigurationKeys.WRITER_FILE_SYSTEM_URI) ? WriterUtils.getWriterFs(state) : fs;\n    this.closer = Closer.create();\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(state, DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(properties);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    try {\n      FileSystem optionalRateControlledFs = targetFs;\n      if (properties.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(targetFs,\n            Long.parseLong(properties.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, properties, eventSubmitter);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(properties.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    this.throwables = Lists.newArrayList();\n  }\n","date":"2020-06-12 08:55:07","endLine":136,"groupId":"10327","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"DatasetCleaner","params":"(FileSystemfs@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/8c/5dd61a6ad965c44eaa1b1720bbdcafca55f349.src","preCode":"  public DatasetCleaner(FileSystem fs, Properties props) throws IOException {\n\n    State state = new State(props);\n    FileSystem targetFs =\n        props.containsKey(ConfigurationKeys.WRITER_FILE_SYSTEM_URI) ? WriterUtils.getWriterFs(state) : fs;\n    this.closer = Closer.create();\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    this.metricContext =\n        this.closer.register(Instrumented.getMetricContext(new State(props), DatasetCleaner.class, tags));\n    this.isMetricEnabled = GobblinMetrics.isEnabled(props);\n    this.eventSubmitter = new EventSubmitter.Builder(this.metricContext, RetentionEvents.NAMESPACE).build();\n    try {\n      FileSystem optionalRateControlledFs = targetFs;\n      if (props.contains(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT)) {\n        optionalRateControlledFs = this.closer.register(new RateControlledFileSystem(targetFs,\n            Long.parseLong(props.getProperty(DATASET_CLEAN_HDFS_CALLS_PER_SECOND_LIMIT))));\n        ((RateControlledFileSystem) optionalRateControlledFs).startRateControl();\n      }\n\n      this.datasetFinder = new MultiCleanableDatasetFinder(optionalRateControlledFs, props, eventSubmitter);\n    } catch (NumberFormatException exception) {\n      throw new IOException(exception);\n    } catch (ExecutionException exception) {\n      throw new IOException(exception);\n    }\n    ExecutorService executor = ScalingThreadPoolExecutor.newScalingThreadPool(0,\n        Integer.parseInt(props.getProperty(MAX_CONCURRENT_DATASETS_CLEANED, DEFAULT_MAX_CONCURRENT_DATASETS_CLEANED)),\n        100, ExecutorsUtils.newThreadFactory(Optional.of(LOG), Optional.of(\"Dataset-cleaner-pool-%d\")));\n    this.service = ExecutorsUtils.loggingDecorator(executor);\n\n    this.throwables = Lists.newArrayList();\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/retention/DatasetCleaner.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":95,"status":"M"}],"commitId":"156a3af18aad163f42ceb69f33fa35145d7d5405","commitMessage":"@@@[GOBBLIN-1185] Enable datasetCleaner to emit kafka event and add config field in Ver?\n\nCloses #3033 from ZihanLi58/GOBBLIN-1185\n","date":"2020-06-12 08:55:07","modifiedFileCount":"5","status":"M","submitter":"Zihan Li"}]
