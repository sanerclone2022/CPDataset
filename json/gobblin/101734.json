[{"authorTime":"2017-09-22 07:53:52","codes":[{"authorDate":"2017-09-22 07:53:52","commitOrder":1,"curCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n    publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n    String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n    log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n    cleanupQueries.add(dropStagingTableDDL);\n\n    log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n    cleanupDirectories.add(stagingDataLocation);\n\n\n    publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n        new HashMap<>()));\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","date":"2017-09-22 07:53:52","endLine":95,"groupId":"3535","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"generatePublishQueries","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/37/a50b32d089044eae09c758bce33d13849fda65.src","preCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n    publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n    String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n    log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n    cleanupQueries.add(dropStagingTableDDL);\n\n    log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n    cleanupDirectories.add(stagingDataLocation);\n\n\n    publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n        new HashMap<>()));\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/conversion/hive/materializer/QueryBasedMaterializerQueryGenerator.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"B"},{"authorDate":"2017-09-22 07:53:52","commitOrder":1,"curCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    if (!this.supportTargetPartitioning || partitionsDDLInfo.size() == 0) {\n      log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n      publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n      String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n    } else {\n      String finalDataPartitionLocation = outputDataLocation + Path.SEPARATOR + stagingDataPartitionDirName;\n      Optional<Path> destPartitionLocation =\n          HiveConverterUtils.getDestinationPartitionLocation(destinationTableMeta, this.workUnitState,\n              conversionEntity.getPartition().get().getName());\n      finalDataPartitionLocation = HiveConverterUtils.updatePartitionLocation(finalDataPartitionLocation, this.workUnitState,\n          destPartitionLocation);\n\n      log.debug(\"Partition directory to move: \" + stagingDataPartitionLocation + \" to: \" + finalDataPartitionLocation);\n      publishDirectories.put(stagingDataPartitionLocation, finalDataPartitionLocation);\n      List<String> dropPartitionsDDL =\n          HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName, partitionsDMLInfo);\n      log.debug(\"Drop partitions if exist in final table: \" + dropPartitionsDDL);\n      publishQueries.addAll(dropPartitionsDDL);\n      List<String> createFinalPartitionDDL =\n          HiveAvroORCQueryGenerator.generateCreatePartitionDDL(outputDatabaseName, outputTableName,\n              finalDataPartitionLocation, partitionsDMLInfo, Optional.<String>absent());\n\n      log.debug(\"Create final partition DDL: \" + createFinalPartitionDDL);\n      publishQueries.addAll(createFinalPartitionDDL);\n\n      String dropStagingTableDDL =\n          HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n\n      publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n          AbstractAvroToOrcConverter.getDropPartitionsDDLInfo(conversionEntity)));\n    }\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","date":"2017-09-22 07:53:52","endLine":175,"groupId":"5276","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"generatePublishQueries","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/87/2a3f47bbeacf02d06fc43b62e5b060a048a20a.src","preCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    if (!this.supportTargetPartitioning || partitionsDDLInfo.size() == 0) {\n      log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n      publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n      String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n    } else {\n      String finalDataPartitionLocation = outputDataLocation + Path.SEPARATOR + stagingDataPartitionDirName;\n      Optional<Path> destPartitionLocation =\n          HiveConverterUtils.getDestinationPartitionLocation(destinationTableMeta, this.workUnitState,\n              conversionEntity.getPartition().get().getName());\n      finalDataPartitionLocation = HiveConverterUtils.updatePartitionLocation(finalDataPartitionLocation, this.workUnitState,\n          destPartitionLocation);\n\n      log.debug(\"Partition directory to move: \" + stagingDataPartitionLocation + \" to: \" + finalDataPartitionLocation);\n      publishDirectories.put(stagingDataPartitionLocation, finalDataPartitionLocation);\n      List<String> dropPartitionsDDL =\n          HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName, partitionsDMLInfo);\n      log.debug(\"Drop partitions if exist in final table: \" + dropPartitionsDDL);\n      publishQueries.addAll(dropPartitionsDDL);\n      List<String> createFinalPartitionDDL =\n          HiveAvroORCQueryGenerator.generateCreatePartitionDDL(outputDatabaseName, outputTableName,\n              finalDataPartitionLocation, partitionsDMLInfo, Optional.<String>absent());\n\n      log.debug(\"Create final partition DDL: \" + createFinalPartitionDDL);\n      publishQueries.addAll(createFinalPartitionDDL);\n\n      String dropStagingTableDDL =\n          HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n\n      publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n          AbstractAvroToOrcConverter.getDropPartitionsDDLInfo(conversionEntity)));\n    }\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/conversion/hive/materializer/HiveMaterializerFromEntityQueryGenerator.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":114,"status":"B"}],"commitId":"5fa983268606335493903e7186836c57eefe40d9","commitMessage":"@@@[GOBBLIN-253] Enhance Hive materializer.\n\nCloses #2104 from ibuenros/hive-materializer\n","date":"2017-09-22 07:53:52","modifiedFileCount":"16","status":"B","submitter":"ibuenros"},{"authorTime":"2019-11-02 05:26:17","codes":[{"authorDate":"2017-09-22 07:53:52","commitOrder":2,"curCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n    publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n    String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n    log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n    cleanupQueries.add(dropStagingTableDDL);\n\n    log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n    cleanupDirectories.add(stagingDataLocation);\n\n\n    publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n        new HashMap<>()));\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","date":"2017-09-22 07:53:52","endLine":95,"groupId":"101734","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"generatePublishQueries","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/37/a50b32d089044eae09c758bce33d13849fda65.src","preCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n    publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n    String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n    log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n    cleanupQueries.add(dropStagingTableDDL);\n\n    log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n    cleanupDirectories.add(stagingDataLocation);\n\n\n    publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n        new HashMap<>()));\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/conversion/hive/materializer/QueryBasedMaterializerQueryGenerator.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"N"},{"authorDate":"2019-11-02 05:26:17","commitOrder":2,"curCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n    Optional<Schema> avroSchema = Optional.absent();\n    if(workUnitState.contains(AbstractAvroToOrcConverter.OUTPUT_AVRO_SCHEMA_KEY)) {\n      avroSchema = Optional.fromNullable(new Schema.Parser().parse(workUnitState.getProp(AbstractAvroToOrcConverter.OUTPUT_AVRO_SCHEMA_KEY)));\n    }\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    if(avroSchema.isPresent()) {\n      String alterSchemaDml = HiveConverterUtils.generateAlterTblPropsDML(outputTableName, Optional.of(outputDatabaseName), avroSchema.get());\n      publishQueries.add(alterSchemaDml);\n    }\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    if (!this.supportTargetPartitioning || partitionsDDLInfo.size() == 0) {\n      log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n      publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n      String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n    } else {\n      String finalDataPartitionLocation = outputDataLocation + Path.SEPARATOR + stagingDataPartitionDirName;\n      Optional<Path> destPartitionLocation =\n          HiveConverterUtils.getDestinationPartitionLocation(destinationTableMeta, this.workUnitState,\n              conversionEntity.getPartition().get().getName());\n      finalDataPartitionLocation = HiveConverterUtils.updatePartitionLocation(finalDataPartitionLocation, this.workUnitState,\n          destPartitionLocation);\n\n      log.debug(\"Partition directory to move: \" + stagingDataPartitionLocation + \" to: \" + finalDataPartitionLocation);\n      publishDirectories.put(stagingDataPartitionLocation, finalDataPartitionLocation);\n      List<String> dropPartitionsDDL =\n          HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName, partitionsDMLInfo);\n      log.debug(\"Drop partitions if exist in final table: \" + dropPartitionsDDL);\n      publishQueries.addAll(dropPartitionsDDL);\n      List<String> createFinalPartitionDDL =\n          HiveAvroORCQueryGenerator.generateCreatePartitionDDL(outputDatabaseName, outputTableName,\n              finalDataPartitionLocation, partitionsDMLInfo, Optional.<String>absent());\n\n      log.debug(\"Create final partition DDL: \" + createFinalPartitionDDL);\n      publishQueries.addAll(createFinalPartitionDDL);\n\n      String dropStagingTableDDL =\n          HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n\n      publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n          AbstractAvroToOrcConverter.getDropPartitionsDDLInfo(conversionEntity)));\n    }\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","date":"2019-11-02 05:26:17","endLine":184,"groupId":"101734","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"generatePublishQueries","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/87/d78bd4a5fa99ca99ba236b5463b06a5bb927ab.src","preCode":"  public QueryBasedHivePublishEntity generatePublishQueries() throws DataConversionException {\n\n    QueryBasedHivePublishEntity publishEntity = new QueryBasedHivePublishEntity();\n    List<String> publishQueries = publishEntity.getPublishQueries();\n    Map<String, String> publishDirectories = publishEntity.getPublishDirectories();\n    List<String> cleanupQueries = publishEntity.getCleanupQueries();\n    List<String> cleanupDirectories = publishEntity.getCleanupDirectories();\n\n    String createFinalTableDDL =\n        HiveConverterUtils.generateCreateDuplicateTableDDL(outputDatabaseName, stagingTableName, outputTableName,\n            outputDataLocation, Optional.of(outputDatabaseName));\n    publishQueries.add(createFinalTableDDL);\n    log.debug(\"Create final table DDL:\\n\" + createFinalTableDDL);\n\n    if (!this.supportTargetPartitioning || partitionsDDLInfo.size() == 0) {\n      log.debug(\"Snapshot directory to move: \" + stagingDataLocation + \" to: \" + outputDataLocation);\n      publishDirectories.put(stagingDataLocation, outputDataLocation);\n\n      String dropStagingTableDDL = HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n    } else {\n      String finalDataPartitionLocation = outputDataLocation + Path.SEPARATOR + stagingDataPartitionDirName;\n      Optional<Path> destPartitionLocation =\n          HiveConverterUtils.getDestinationPartitionLocation(destinationTableMeta, this.workUnitState,\n              conversionEntity.getPartition().get().getName());\n      finalDataPartitionLocation = HiveConverterUtils.updatePartitionLocation(finalDataPartitionLocation, this.workUnitState,\n          destPartitionLocation);\n\n      log.debug(\"Partition directory to move: \" + stagingDataPartitionLocation + \" to: \" + finalDataPartitionLocation);\n      publishDirectories.put(stagingDataPartitionLocation, finalDataPartitionLocation);\n      List<String> dropPartitionsDDL =\n          HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName, partitionsDMLInfo);\n      log.debug(\"Drop partitions if exist in final table: \" + dropPartitionsDDL);\n      publishQueries.addAll(dropPartitionsDDL);\n      List<String> createFinalPartitionDDL =\n          HiveAvroORCQueryGenerator.generateCreatePartitionDDL(outputDatabaseName, outputTableName,\n              finalDataPartitionLocation, partitionsDMLInfo, Optional.<String>absent());\n\n      log.debug(\"Create final partition DDL: \" + createFinalPartitionDDL);\n      publishQueries.addAll(createFinalPartitionDDL);\n\n      String dropStagingTableDDL =\n          HiveAvroORCQueryGenerator.generateDropTableDDL(outputDatabaseName, stagingTableName);\n\n      log.debug(\"Drop staging table DDL: \" + dropStagingTableDDL);\n      cleanupQueries.add(dropStagingTableDDL);\n\n      log.debug(\"Staging table directory to delete: \" + stagingDataLocation);\n      cleanupDirectories.add(stagingDataLocation);\n\n      publishQueries.addAll(HiveAvroORCQueryGenerator.generateDropPartitionsDDL(outputDatabaseName, outputTableName,\n          AbstractAvroToOrcConverter.getDropPartitionsDDLInfo(conversionEntity)));\n    }\n\n    log.info(\"Publish partition entity: \" + publishEntity);\n    return publishEntity;\n  }\n","realPath":"gobblin-data-management/src/main/java/org/apache/gobblin/data/management/conversion/hive/materializer/HiveMaterializerFromEntityQueryGenerator.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"M"}],"commitId":"94a508b38ec8bd879614f2d9bf0eeb96513ca7cf","commitMessage":"@@@[GOBBLIN-941] Enhance DDL to add column and column.types with case-preserving schema\n\nCloses #2791 from ZihanLi58/GOBBLIN-941\n","date":"2019-11-02 05:26:17","modifiedFileCount":"4","status":"M","submitter":"Zihan Li"}]
