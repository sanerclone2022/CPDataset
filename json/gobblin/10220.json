[{"authorTime":"2020-03-12 07:14:19","codes":[{"authorDate":"2020-03-12 07:14:19","commitOrder":1,"curCode":"  public void testFilterByName() throws Exception {\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.<Pattern>absent(), Optional.of(Pattern.compile(\"^accept.*\")),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"acceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"donotacceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","date":"2020-03-12 07:14:19","endLine":108,"groupId":"2698","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFilterByName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/74/564b72ac3849f4797bd0888ca7809246175653.src","preCode":"  public void testFilterByName() throws Exception {\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.<Pattern>absent(), Optional.of(Pattern.compile(\"^accept.*\")),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"acceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"donotacceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/SLAEventKafkaJobMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"B"},{"authorDate":"2020-03-12 07:14:19","commitOrder":1,"curCode":"  public void testFilterByDatasetURN() throws Exception {\n    Properties props = new Properties();\n    props.put(SLAEventKafkaJobMonitor.TEMPLATE_KEY, templateURI.toString());\n    props.put(SLAEventKafkaJobMonitor.DATASET_URN_FILTER_KEY, \"^/accept.*\");\n    Config config = ConfigFactory.parseProperties(props).withFallback(superConfig);\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.of(Pattern.compile(\"^/accept.*\")), Optional.<Pattern>absent(),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"event\", new URI(\"/accept/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"event\", new URI(\"/reject/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","date":"2020-03-12 07:14:19","endLine":139,"groupId":"6574","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFilterByDatasetURN","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/74/564b72ac3849f4797bd0888ca7809246175653.src","preCode":"  public void testFilterByDatasetURN() throws Exception {\n    Properties props = new Properties();\n    props.put(SLAEventKafkaJobMonitor.TEMPLATE_KEY, templateURI.toString());\n    props.put(SLAEventKafkaJobMonitor.DATASET_URN_FILTER_KEY, \"^/accept.*\");\n    Config config = ConfigFactory.parseProperties(props).withFallback(superConfig);\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.of(Pattern.compile(\"^/accept.*\")), Optional.<Pattern>absent(),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"event\", new URI(\"/accept/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"event\", new URI(\"/reject/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/SLAEventKafkaJobMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":111,"status":"B"}],"commitId":"7a328f9a232a60973d27c50859e6b84e63df90f7","commitMessage":"@@@[GOBBLIN-1040] HighLevelConsumer re-design by removing references to ?\n\nCloses #2900 from vikrambohra/GOBBLIN-1040\n","date":"2020-03-12 07:14:19","modifiedFileCount":"16","status":"B","submitter":"vbohra"},{"authorTime":"2021-05-11 08:17:01","codes":[{"authorDate":"2021-05-11 08:17:01","commitOrder":2,"curCode":"  public void testFilterByName() throws Exception {\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.<Pattern>absent(), Optional.of(Pattern.compile(\"^accept.*\")),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<JobSpec> jobSpecs;\n\n    event = createSLAEvent(\"acceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"donotacceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","date":"2021-05-11 08:17:01","endLine":108,"groupId":"10220","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFilterByName","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/ad/74da946bbf7494d8083c1c9745047afa9bf480.src","preCode":"  public void testFilterByName() throws Exception {\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.<Pattern>absent(), Optional.of(Pattern.compile(\"^accept.*\")),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"acceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"donotacceptthis\", new URI(\"/data/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/SLAEventKafkaJobMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2021-05-11 08:17:01","commitOrder":2,"curCode":"  public void testFilterByDatasetURN() throws Exception {\n    Properties props = new Properties();\n    props.put(SLAEventKafkaJobMonitor.TEMPLATE_KEY, templateURI.toString());\n    props.put(SLAEventKafkaJobMonitor.DATASET_URN_FILTER_KEY, \"^/accept.*\");\n    Config config = ConfigFactory.parseProperties(props).withFallback(superConfig);\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.of(Pattern.compile(\"^/accept.*\")), Optional.<Pattern>absent(),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<JobSpec> jobSpecs;\n\n    event = createSLAEvent(\"event\", new URI(\"/accept/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"event\", new URI(\"/reject/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","date":"2021-05-11 08:17:01","endLine":139,"groupId":"10220","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testFilterByDatasetURN","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/ad/74da946bbf7494d8083c1c9745047afa9bf480.src","preCode":"  public void testFilterByDatasetURN() throws Exception {\n    Properties props = new Properties();\n    props.put(SLAEventKafkaJobMonitor.TEMPLATE_KEY, templateURI.toString());\n    props.put(SLAEventKafkaJobMonitor.DATASET_URN_FILTER_KEY, \"^/accept.*\");\n    Config config = ConfigFactory.parseProperties(props).withFallback(superConfig);\n\n    MockSLAEventKafkaJobMonitor monitor =\n        new MockSLAEventKafkaJobMonitor(\"topic\", null, new URI(\"/base/URI\"),\n            HighLevelConsumerTest.getSimpleConfig(Optional.of(KafkaJobMonitor.KAFKA_JOB_MONITOR_PREFIX)),\n            new NoopSchemaVersionWriter(), Optional.of(Pattern.compile(\"^/accept.*\")), Optional.<Pattern>absent(),\n            this.templateURI, ImmutableMap.<String, String>of());\n\n    monitor.buildMetricsContextAndMetrics();\n\n    GobblinTrackingEvent event;\n    Collection<Either<JobSpec, URI>> jobSpecs;\n\n    event = createSLAEvent(\"event\", new URI(\"/accept/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 1);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 0);\n\n    event = createSLAEvent(\"event\", new URI(\"/reject/myDataset\"), Maps.<String, String>newHashMap());\n    jobSpecs = monitor.parseJobSpec(event);\n    Assert.assertEquals(jobSpecs.size(), 0);\n    Assert.assertEquals(monitor.getRejectedEvents().getCount(), 1);\n\n    monitor.shutdownMetrics();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/SLAEventKafkaJobMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":111,"status":"M"}],"commitId":"ae62d77a0b3b0d123cea811b00bd363b6c6d30f3","commitMessage":"@@@[GOBBLIN-1441] separate delete and cancel specs in KafkaJobMonitor\n\nCloses #3276 from\narjun4084346/cancelDeleteInCluster\n","date":"2021-05-11 08:17:01","modifiedFileCount":"13","status":"M","submitter":"Arjun"}]
