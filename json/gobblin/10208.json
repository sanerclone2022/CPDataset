[{"authorTime":"2020-03-12 07:14:19","codes":[{"authorDate":"2020-03-12 07:14:19","commitOrder":1,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-03-12 07:14:19","endLine":189,"groupId":"3898","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/05/dc4c37476b6870eddc21bbdad7af3d0109e560.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"B"},{"authorDate":"2020-03-12 07:14:19","commitOrder":1,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-03-12 07:14:19","endLine":310,"groupId":"3898","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/05/dc4c37476b6870eddc21bbdad7af3d0109e560.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":192,"status":"B"}],"commitId":"7a328f9a232a60973d27c50859e6b84e63df90f7","commitMessage":"@@@[GOBBLIN-1040] HighLevelConsumer re-design by removing references to ?\n\nCloses #2900 from vikrambohra/GOBBLIN-1040\n","date":"2020-03-12 07:14:19","modifiedFileCount":"16","status":"B","submitter":"vbohra"},{"authorTime":"2020-04-24 07:29:18","codes":[{"authorDate":"2020-04-24 07:29:18","commitOrder":2,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-04-24 07:29:18","endLine":190,"groupId":"3898","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/93/7c705a8ddbc3ea6e83abe013e499f20ed1210f.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2020-04-24 07:29:18","commitOrder":2,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-04-24 07:29:18","endLine":312,"groupId":"3898","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/93/7c705a8ddbc3ea6e83abe013e499f20ed1210f.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":193,"status":"M"}],"commitId":"d8d579a42ec901dd74b6f453bd334c77e9498195","commitMessage":"@@@[GOBBLIN-1125] Add metrics to measure job status state store performan?\n\nCloses #2965 from sv2000/jobStatusMetrics\n","date":"2020-04-24 07:29:18","modifiedFileCount":"5","status":"M","submitter":"sv2000"},{"authorTime":"2020-09-03 02:52:56","codes":[{"authorDate":"2020-04-24 07:29:18","commitOrder":3,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-04-24 07:29:18","endLine":190,"groupId":"3898","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/93/7c705a8ddbc3ea6e83abe013e499f20ed1210f.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"N"},{"authorDate":"2020-09-03 02:52:56","commitOrder":3,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-09-03 02:52:56","endLine":322,"groupId":"3898","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/a4/df1c52875af688d8aec50c0fed9e81731d6227.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":194,"status":"M"}],"commitId":"67a060fbe861c178ac8a4be494b440a234a96993","commitMessage":"@@@[GOBBLIN-1254] Skip undecodeable message in KafkaAvroJobStatusMonitor\n\nCloses #3095 from zxcware/und\n","date":"2020-09-03 02:52:56","modifiedFileCount":"2","status":"M","submitter":"zhchen"},{"authorTime":"2020-09-03 02:52:56","codes":[{"authorDate":"2020-10-27 07:38:59","commitOrder":4,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata)));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-10-27 07:38:59","endLine":191,"groupId":"3898","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/c4/43b4233f1aec85adc61d994405682441a874ea.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(messageAndMetadata.message()));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":99,"status":"M"},{"authorDate":"2020-09-03 02:52:56","commitOrder":4,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-09-03 02:52:56","endLine":322,"groupId":"3898","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/a4/df1c52875af688d8aec50c0fed9e81731d6227.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":194,"status":"N"}],"commitId":"d1875e61080ef68251e76a27452a2126ddd77e7f","commitMessage":"@@@[GOBBLIN-1300] Rethrow exceptions when storing job status in state store\n\nCloses #3138 from jack-moseley/state-store-\nexception\n","date":"2020-10-27 07:38:59","modifiedFileCount":"3","status":"M","submitter":"Jack Moseley"},{"authorTime":"2020-09-03 02:52:56","codes":[{"authorDate":"2021-07-16 02:37:59","commitOrder":5,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(\n        jobStatusMonitor.deserializeEvent(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata))));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2021-07-16 02:37:59","endLine":195,"groupId":"3898","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/f0/b5d235548920e2f7ed967ae11b0d469c162168.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata)));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"M"},{"authorDate":"2020-09-03 02:52:56","commitOrder":5,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2020-09-03 02:52:56","endLine":322,"groupId":"3898","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/a4/df1c52875af688d8aec50c0fed9e81731d6227.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":194,"status":"N"}],"commitId":"b5e32b158bd713c45caa5b4b8866f8a4c4fc3a29","commitMessage":"@@@[GOBBLIN-1457] Add automatic troubleshooter to Gobblin service (#3299)\n\nIn previous commits.  we've added automatic troubleshooting to Gobblin\nAzkaban jobs.  and here we will collect and expose discovered issues\nin Gobblin service.\n\nInitial implementation will store issues for a limited number of jobs in\nmemory.  and future commits will add persistence.","date":"2021-07-16 02:37:59","modifiedFileCount":"14","status":"M","submitter":"Alex Prokofiev"},{"authorTime":"2021-09-25 01:16:44","codes":[{"authorDate":"2021-09-25 01:16:44","commitOrder":6,"curCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    ImmutableList.of(\n        createFlowCompiledEvent(),\n        createJobOrchestratedEvent(1),\n        createJobStartEvent(),\n        createJobSucceededEvent(),\n        createDummyEvent(), \r\n        createJobStartEvent()\n    ).forEach(event -> {\n      context.submitEvent(event);\n      kafkaReporter.report();\n    });\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    Iterator<DecodeableKafkaRecord> recordIterator = Iterators.transform(\n        this.kafkaTestHelper.getIteratorForTopic(TOPIC),\n        this::convertMessageAndMetadataToDecodableKafkaRecord);\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    \r\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(\n        jobStatusMonitor.deserializeEvent(recordIterator.next())));\n\n    \r\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2021-09-25 01:16:44","endLine":190,"groupId":"10208","id":11,"instanceNumber":1,"isCurCommit":1,"methodName":"testProcessMessageForSuccessfulFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/ae/26d152f5a876b2d8848605320076fd928c1d8e.src","preCode":"  public void testProcessMessageForSuccessfulFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic1\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobSucceededEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event5 = createDummyEvent();\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor =  new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    messageAndMetadata = iterator.next();\n    Assert.assertNull(jobStatusMonitor.parseJobStatus(\n        jobStatusMonitor.deserializeEvent(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata))));\n\n    \r\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPLETE.name());\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2021-09-25 01:16:44","commitOrder":6,"curCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    ImmutableList.of(\n        createFlowCompiledEvent(),\n        createJobOrchestratedEvent(1),\n        createJobStartEvent(),\n        createJobFailedEvent(),\n        \r\n        \r\n        createJobOrchestratedEvent(2),\n        \r\n        createJobStartEvent(),\n        \r\n        createJobFailedEvent()\n    ).forEach(event -> {\n      context.submitEvent(event);\n      kafkaReporter.report();\n    });\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    Iterator<DecodeableKafkaRecord> recordIterator = Iterators.transform(\n        iterator,\n        this::convertMessageAndMetadataToDecodableKafkaRecord);\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    jobStatusMonitor.processMessage(recordIterator.next());\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","date":"2021-09-25 01:16:44","endLine":303,"groupId":"10208","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"testProcessMessageForFailedFlow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/ae/26d152f5a876b2d8848605320076fd928c1d8e.src","preCode":"  public void testProcessMessageForFailedFlow() throws IOException, ReflectiveOperationException {\n    KafkaEventReporter kafkaReporter = builder.build(\"localhost:0000\", \"topic2\");\n\n    \r\n    GobblinTrackingEvent event1 = createFlowCompiledEvent();\n    context.submitEvent(event1);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event2 = createJobOrchestratedEvent(1);\n    context.submitEvent(event2);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event3 = createJobStartEvent();\n    context.submitEvent(event3);\n    kafkaReporter.report();\n\n    GobblinTrackingEvent event4 = createJobFailedEvent();\n    context.submitEvent(event4);\n    kafkaReporter.report();\n\n    \r\n    \r\n    GobblinTrackingEvent event5 = createJobOrchestratedEvent(2);\n    context.submitEvent(event5);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event6 = createJobStartEvent();\n    context.submitEvent(event6);\n    kafkaReporter.report();\n\n    \r\n    GobblinTrackingEvent event7 = createJobFailedEvent();\n    context.submitEvent(event7);\n    kafkaReporter.report();\n\n    try {\n      Thread.sleep(1000);\n    } catch(InterruptedException ex) {\n      Thread.currentThread().interrupt();\n    }\n\n    Config config = ConfigFactory.empty().withValue(ConfigurationKeys.KAFKA_BROKERS, ConfigValueFactory.fromAnyRef(\"localhost:0000\"))\n        .withValue(Kafka09ConsumerClient.GOBBLIN_CONFIG_VALUE_DESERIALIZER_CLASS_KEY, ConfigValueFactory.fromAnyRef(\"org.apache.kafka.common.serialization.ByteArrayDeserializer\"))\n        .withValue(ConfigurationKeys.STATE_STORE_ROOT_DIR_KEY, ConfigValueFactory.fromAnyRef(stateStoreDir))\n        .withValue(\"zookeeper.connect\", ConfigValueFactory.fromAnyRef(\"localhost:2121\"));\n    MockKafkaAvroJobStatusMonitor jobStatusMonitor = new MockKafkaAvroJobStatusMonitor(\"test\",config, 1);\n    jobStatusMonitor.buildMetricsContextAndMetrics();\n\n    ConsumerIterator<byte[], byte[]> iterator = this.kafkaTestHelper.getIteratorForTopic(TOPIC);\n\n    MessageAndMetadata<byte[], byte[]> messageAndMetadata = iterator.next();\n    \r\n    byte[] undecodeableMessage = Arrays.copyOf(messageAndMetadata.message(),\n        messageAndMetadata.message().length - 1);\n    ConsumerRecord undecodeableRecord = new ConsumerRecord<>(TOPIC, messageAndMetadata.partition(),\n        messageAndMetadata.offset(), messageAndMetadata.key(), undecodeableMessage);\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 0L);\n    jobStatusMonitor.processMessage(new Kafka09ConsumerClient.Kafka09ConsumerRecord(undecodeableRecord));\n    Assert.assertEquals(jobStatusMonitor.getMessageParseFailures().getCount(), 1L);\n    \r\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    StateStore stateStore = jobStatusMonitor.getStateStore();\n    String storeName = KafkaJobStatusMonitor.jobStatusStoreName(flowGroup, flowName);\n    String tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, \"NA\", \"NA\");\n    List<State> stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    State state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.COMPILED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    tableName = KafkaJobStatusMonitor.jobStatusTableName(this.flowExecutionId, this.jobGroup, this.jobName);\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.PENDING_RETRY.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(true));\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.ORCHESTRATED.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.RUNNING.name());\n\n    messageAndMetadata = iterator.next();\n    jobStatusMonitor.processMessage(convertMessageAndMetadataToDecodableKafkaRecord(messageAndMetadata));\n\n    stateList  = stateStore.getAll(storeName, tableName);\n    Assert.assertEquals(stateList.size(), 1);\n    state = stateList.get(0);\n    \r\n    Assert.assertEquals(state.getProp(JobStatusRetriever.EVENT_NAME_FIELD), ExecutionStatus.FAILED.name());\n    Assert.assertEquals(state.getProp(TimingEvent.FlowEventConstants.SHOULD_RETRY_FIELD), Boolean.toString(false));\n\n    jobStatusMonitor.shutDown();\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/runtime/KafkaAvroJobStatusMonitorTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":193,"status":"M"}],"commitId":"3822629ab4dc3aa6ac7a0d677ced191206d48bf9","commitMessage":"@@@[GOBBLIN-1549] Add retries to KafkaJobStatusMonitor for transient JobStatus state store failure. (#3399)\n\nAt times.  the state store may be unavailable.  due to transient connection failure. Once that resolves.  we would like Gobblin Tracking Events to be processed w/o needing to restart the kafka consumer for that to happen. thus.  we continue retrying state store updates encapsulated within the message.  so that connection repair is automatic (when within the configurable retry window).","date":"2021-09-25 01:16:44","modifiedFileCount":"4","status":"M","submitter":"Kip Kohn"}]
