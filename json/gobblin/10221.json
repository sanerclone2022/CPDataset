[{"authorTime":"2020-12-10 09:54:50","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":2,"curCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka09ConsumerClient<String, String> kafka09Client = new Kafka09ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka09Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka09ConsumerRecord<String, String>> expected =\n          ImmutableSet.<Kafka09ConsumerRecord<String, String>> of(new Kafka09ConsumerRecord<>(record0),\n              new Kafka09ConsumerRecord<>(record1), new Kafka09ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","date":"2017-07-31 15:51:25","endLine":75,"groupId":"189","id":1,"instanceNumber":1,"isCurCommit":1,"methodName":"testConsume","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/29/6ade2974755466b920e1381b0ab01a23877496.src","preCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka09ConsumerClient<String, String> kafka09Client = new Kafka09ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka09Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka09ConsumerRecord<String, String>> expected =\n          ImmutableSet.<Kafka09ConsumerRecord<String, String>> of(new Kafka09ConsumerRecord<>(record0),\n              new Kafka09ConsumerRecord<>(record1), new Kafka09ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/kafka/client/Kafka09ConsumerClientTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"NB"},{"authorDate":"2020-12-10 09:54:50","commitOrder":2,"curCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka1ConsumerClient<String, String> kafka1Client = new Kafka1ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka1Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka1ConsumerClient.Kafka1ConsumerRecord<String, String>> expected =\n          ImmutableSet.of(new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record0),\n              new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record1), new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","date":"2020-12-10 09:55:03","endLine":72,"groupId":"189","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testConsume","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/65/87ff780c4fd808174358abd8f243ade31c0afc.src","preCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka1ConsumerClient<String, String> kafka1Client = new Kafka1ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka1Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka1ConsumerClient.Kafka1ConsumerRecord<String, String>> expected =\n          ImmutableSet.of(new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record0),\n              new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record1), new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","realPath":"gobblin-modules/gobblin-kafka-1/src/test/java/org/apache/gobblin/kafka/client/Kafka1ConsumerClientTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"B"}],"commitId":"1f08d25e828737798abac750c59b6167abdba108","commitMessage":"@@@[GOBBLIN-1325] Add Kafka 1.x support : Writer only\n\nversion set to 1.1 currently\nmodule under gobblin-kafka-1\n\nCloses #3163 from hanghangliu/GOBBLIN-1325-add-\n","date":"2020-12-10 09:55:03","modifiedFileCount":"0","status":"M","submitter":"Hanghang Liu"},{"authorTime":"2021-04-10 10:54:44","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":3,"curCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka09ConsumerClient<String, String> kafka09Client = new Kafka09ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka09Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka09ConsumerRecord<String, String>> expected =\n          ImmutableSet.<Kafka09ConsumerRecord<String, String>> of(new Kafka09ConsumerRecord<>(record0),\n              new Kafka09ConsumerRecord<>(record1), new Kafka09ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","date":"2017-07-31 15:51:25","endLine":75,"groupId":"10221","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testConsume","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/29/6ade2974755466b920e1381b0ab01a23877496.src","preCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka09ConsumerClient<String, String> kafka09Client = new Kafka09ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka09Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka09ConsumerRecord<String, String>> expected =\n          ImmutableSet.<Kafka09ConsumerRecord<String, String>> of(new Kafka09ConsumerRecord<>(record0),\n              new Kafka09ConsumerRecord<>(record1), new Kafka09ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","realPath":"gobblin-modules/gobblin-kafka-09/src/test/java/org/apache/gobblin/kafka/client/Kafka09ConsumerClientTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":44,"status":"N"},{"authorDate":"2021-04-10 10:54:44","commitOrder":3,"curCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, 10L, TimestampType.CREATE_TIME, 0L, 3, 6, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, 11L, TimestampType.LOG_APPEND_TIME, 1L, 3, 6, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, 12L, TimestampType.LOG_APPEND_TIME, 2L, 3, 6, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka1ConsumerClient<String, String> kafka1Client = new Kafka1ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka1Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka1ConsumerClient.Kafka1ConsumerRecord<String, String>> expected =\n          ImmutableSet.of(new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record0),\n              new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record1), new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n      Kafka1ConsumerClient.Kafka1ConsumerRecord expected0 = expected.iterator().next();\n      Assert.assertEquals(record0.timestamp(), expected0.getTimestamp());\n      Assert.assertEquals(record0.timestampType() == TimestampType.LOG_APPEND_TIME, expected0.isTimestampLogAppend());\n      Assert.assertEquals(record0.timestampType(), expected0.getTimestampType());\n    }\n\n  }\n","date":"2021-04-10 10:54:44","endLine":78,"groupId":"10221","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testConsume","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/c6/e1afc04c8de3d0c785faf8eb86a7f17cc7b691.src","preCode":"  public void testConsume() throws Exception {\n    Config testConfig = ConfigFactory.parseMap(ImmutableMap.of(ConfigurationKeys.KAFKA_BROKERS, \"test\"));\n    MockConsumer<String, String> consumer = new MockConsumer<String, String>(OffsetResetStrategy.NONE);\n    consumer.assign(Arrays.asList(new TopicPartition(\"test_topic\", 0)));\n\n    HashMap<TopicPartition, Long> beginningOffsets = new HashMap<>();\n    beginningOffsets.put(new TopicPartition(\"test_topic\", 0), 0L);\n    consumer.updateBeginningOffsets(beginningOffsets);\n\n    ConsumerRecord<String, String> record0 = new ConsumerRecord<>(\"test_topic\", 0, 0L, \"key\", \"value0\");\n    ConsumerRecord<String, String> record1 = new ConsumerRecord<>(\"test_topic\", 0, 1L, \"key\", \"value1\");\n    ConsumerRecord<String, String> record2 = new ConsumerRecord<>(\"test_topic\", 0, 2L, \"key\", \"value2\");\n\n    consumer.addRecord(record0);\n    consumer.addRecord(record1);\n    consumer.addRecord(record2);\n\n    try (Kafka1ConsumerClient<String, String> kafka1Client = new Kafka1ConsumerClient<>(testConfig, consumer);) {\n\n      \r\n      Set<KafkaConsumerRecord> consumedRecords =\n          Sets.newHashSet(kafka1Client.consume(new KafkaPartition.Builder().withId(0).withTopicName(\"test_topic\")\n              .build(), 0l, 100l));\n\n      Set<Kafka1ConsumerClient.Kafka1ConsumerRecord<String, String>> expected =\n          ImmutableSet.of(new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record0),\n              new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record1), new Kafka1ConsumerClient.Kafka1ConsumerRecord<>(record2));\n      Assert.assertEquals(consumedRecords, expected);\n\n    }\n\n  }\n","realPath":"gobblin-modules/gobblin-kafka-1/src/test/java/org/apache/gobblin/kafka/client/Kafka1ConsumerClientTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"}],"commitId":"d799b6ab6aa452235eedd3acaeb4a4b10edb3d65","commitMessage":"@@@[GOBBLIN-1409] Expose record timestamp in kafka-1 client\n\nIn our use case.  we need the timestamp from the\nbroker.  so we also\nimplement isTimestampLogAppend and a kafka-1\nspecific method. \ngetTimestampType.  to let us check the\nTimestampType in all cases.\n\nCloses #3244 from milimetric/master\n","date":"2021-04-10 10:54:44","modifiedFileCount":"2","status":"M","submitter":"Dan Andreescu"}]
