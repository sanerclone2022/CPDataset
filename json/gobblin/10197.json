[{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-07-31 15:51:25","commitOrder":1,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(this.props, tags);\n\n    \r\n    \r\n    if (!this.props.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      this.props.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        this.props.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(this.props, this.props));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(this.props, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2017-07-31 15:51:25","endLine":185,"groupId":"2806","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/bd/bb04f821f6e3c3ac40de37214606dd60187ce1.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(this.props, tags);\n\n    \r\n    \r\n    if (!this.props.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      this.props.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        this.props.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(this.props, this.props));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(this.props, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"B"},{"authorDate":"2017-07-31 15:51:25","commitOrder":1,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":2,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"B"}],"commitId":"5457af88d56b8fb89b172129fd1ff24ecdd4eba8","commitMessage":"@@@Merge pull request #2031 from abti/move_packages_to_apache\n","date":"2017-07-31 15:51:25","modifiedFileCount":"2","status":"B","submitter":"Abhishek Tiwari"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-10-11 23:27:25","commitOrder":2,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2017-10-11 23:27:25","endLine":198,"groupId":"2806","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/20/b630b8361c37415571081560a09086457da59c.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(this.props, tags);\n\n    \r\n    \r\n    if (!this.props.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      this.props.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        this.props.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(this.props, this.props));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(this.props, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":117,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":2,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"a9c9f781f43bef85f96178999e266bcb5b5fb3ff","commitMessage":"@@@[GOBBLIN-282] Azkaban templates\n\nCloses #2135 from ibuenros/azkaban-templates\n","date":"2017-10-11 23:27:25","modifiedFileCount":"1","status":"M","submitter":"ibuenros"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-11-21 11:51:48","commitOrder":3,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2017-11-21 11:51:48","endLine":213,"groupId":"2806","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/5c/9fc1d0fb331dbcebbd228be6952b5935498ce1.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":121,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":3,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"5c03b11b5b5a62a611fa2a1042bfe64c283c6a5e","commitMessage":"@@@[GOBBLIN-317] Add dynamic configuration injection in the mappers\n\nCloses #2170 from htran1/dynamic_config\n","date":"2017-11-21 11:51:48","modifiedFileCount":"9","status":"M","submitter":"Hung Tran"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-12-07 00:59:40","commitOrder":4,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2017-12-07 00:59:40","endLine":218,"groupId":"2806","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/89/c7646352a7b05928b07bc4aa3ec9371e159c92.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n      File tokenFile = TokenUtils.getHadoopTokens(new State(props));\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":4,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"0afdc45c39a80944d9d6bcb1ec9767749ae6dfef","commitMessage":"@@@[GOBBLIN-332] Fetching Hive tokens in TokenUtils\n\nCloses #2184 from autumnust/hivefortokenutils\n","date":"2017-12-07 00:59:40","modifiedFileCount":"2","status":"M","submitter":"Lei Sun"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2017-12-13 03:15:24","commitOrder":5,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2017-12-13 03:15:24","endLine":218,"groupId":"2806","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/45/b2f40d705efdc351f93c16560568d54bd97777.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":5,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":10,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"f7a89fb12aa9eaa5c6c78e45f2e7bbe179fa6929","commitMessage":"@@@[GOBBLIN-341] getLogger() method bug fix\n\nCloses #2196 from autumnust/loggingClassFix\n","date":"2017-12-13 03:15:24","modifiedFileCount":"1","status":"M","submitter":"Lei Sun"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2018-02-22 06:14:48","commitOrder":6,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2018-02-22 06:14:48","endLine":225,"groupId":"2806","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/2a/7d3118e5b336f8455b5eeea14eca64dccaaa7b.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":127,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":6,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"a7a85e150474b8911b0b92114781a30105b77822","commitMessage":"@@@[GOBBLIN-413] Use same compaction start time for time lookback check during compaction\n\nCloses #2289 from yukuai518/compacttime\n","date":"2018-02-22 06:14:48","modifiedFileCount":"4","status":"M","submitter":"Kuai Yu"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2018-09-15 03:31:02","commitOrder":7,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2018-09-15 03:31:02","endLine":227,"groupId":"2806","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/3a/28b183dc14782d918bc8d88459bedc0e496153.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":127,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":7,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"ef59a1517575f41671b0ec4ffa6ac53b3648e30c","commitMessage":"@@@[GOBBLIN-587] Implement partition level lineage for fs based destination\n\nCloses #2453 from zxcware/pd\n","date":"2018-09-15 03:31:02","modifiedFileCount":"20","status":"M","submitter":"zhchen"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2018-11-27 02:06:20","commitOrder":8,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2018-11-27 02:06:20","endLine":236,"groupId":"2806","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/05/c1bb912b0f8d9fd56406c50895d6ef94b43a7c.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n    super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":129,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":8,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":16,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"58f00f019cfc7334c3fe088deba8ad67a24b5e3a","commitMessage":"@@@[GOBBLIN-635] Add metadata tags for GaaS/Azkaban jobs.\n\nGOBBLIN-635:Add metadata tags to Gobblin Tracking\nEvent for Azkaban jobs triggered using Gobblin-as-\na-Service (GaaS).\n\nCloses #2505 from sv2000/azkabanMetadataTags\n","date":"2018-11-27 02:06:20","modifiedFileCount":"8","status":"M","submitter":"suvasude"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2019-09-25 06:00:52","commitOrder":9,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      Config config = ConfigUtils.propertiesToConfig(jobProps);\n      JobSpecResolver resolver = JobSpecResolver.builder(config).build();\n\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      JobSpec jobSpec = JobSpec.builder().withConfig(config).withTemplate(templateUri).build();\n      ResolvedJobSpec resolvedJob = resolver.resolveJobSpec(jobSpec);\n      jobProps = ConfigUtils.configToProperties(resolvedJob.getConfig());\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2019-09-25 06:00:52","endLine":241,"groupId":"2806","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/6b/99f81300e88fee95c7ae4ff0d05ae9558ffe0a.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      Config resolvedJob = new PackagedTemplatesJobCatalogDecorator().getTemplate(templateUri)\n          .getResolvedConfig(ConfigUtils.propertiesToConfig(jobProps));\n      jobProps = ConfigUtils.configToProperties(resolvedJob);\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":131,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":9,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":18,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"7d260ab2c32a773e317a31cd264f5c97d2d48a10","commitMessage":"@@@[GOBBLIN-701] Add secure templates (duplicate of #2571)\n\nCloses #2739 from jack-moseley/secure-template\n","date":"2019-09-25 06:00:52","modifiedFileCount":"15","status":"M","submitter":"Jack Moseley"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2019-10-31 22:20:48","commitOrder":10,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2019-10-31 22:20:48","endLine":227,"groupId":"2806","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/e5/7646852e6a8bc2dfd8ff41e6c8ee226fc69b86.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    if (jobProps.containsKey(TEMPLATE_KEY)) {\n      Config config = ConfigUtils.propertiesToConfig(jobProps);\n      JobSpecResolver resolver = JobSpecResolver.builder(config).build();\n\n      URI templateUri = new URI(jobProps.getProperty(TEMPLATE_KEY));\n      JobSpec jobSpec = JobSpec.builder().withConfig(config).withTemplate(templateUri).build();\n      ResolvedJobSpec resolvedJob = resolver.resolveJobSpec(jobSpec);\n      jobProps = ConfigUtils.configToProperties(resolvedJob.getConfig());\n    }\n\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":10,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":20,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"9ee4dcaf66257b6e2926cf1470b16b912cd343ff","commitMessage":"@@@[GOBBLIN-938] Make job-template resolution available in all JobLaunchers\n\nCloses #2787 from autumnust/ETL-9696\n","date":"2019-10-31 22:20:48","modifiedFileCount":"5","status":"M","submitter":"autumnust"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2020-06-17 01:04:05","commitOrder":11,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2020-06-17 01:04:05","endLine":240,"groupId":"2806","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/33/d359132123f54b2ec138baf16a760c225ac8ae.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":129,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":11,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":22,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"c762c97c97336aa5603f571f383258a1baa7e8c3","commitMessage":"@@@[GOBBLIN-1127] Provide an option to make metric reporting instantiation failure fatal\n\nCloses #3035 from\nsv2000/metricReportInstantiationFailure\n","date":"2020-06-17 01:04:05","modifiedFileCount":"12","status":"M","submitter":"sv2000"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2020-11-04 08:42:18","commitOrder":12,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n      LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" provided Hadoop token in the environment variable \"\n          + HADOOP_TOKEN_FILE_LOCATION);\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n    } else {\n      \r\n      LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" did not provide Hadoop token in the environment variable \"\n          + HADOOP_TOKEN_FILE_LOCATION + \". Negotiating Hadoop tokens.\");\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2020-11-04 08:42:18","endLine":230,"groupId":"5807","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/8fd81f28c5f1928f2b3651efe7514f17ad1255.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (props.containsKey(JOB_TYPE) && JOB_TYPES_WITH_AUTOMATIC_TOKEN.contains(props.getProperty(JOB_TYPE))) {\n      \r\n      \r\n      LOG.info(\n          \"Job type \" + props.getProperty(JOB_TYPE) + \" provides Hadoop tokens automatically. Using provided tokens.\");\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      }\n    } else {\n      \r\n      LOG.info(String.format(\"Job type %s does not provide Hadoop tokens. Negotiating Hadoop tokens.\",\n          props.getProperty(JOB_TYPE)));\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":123,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":12,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":24,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"c7bd6ac5672aac968e50c228e2016fe717930053","commitMessage":"@@@[GOBBLIN-1301] Add Azkaban OAuth token support\n\nCloses #3139 from aplex/azkaban-oauth-support\n","date":"2020-11-04 08:42:18","modifiedFileCount":"1","status":"M","submitter":"aprokofiev"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2021-01-21 13:00:52","commitOrder":13,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (Boolean.parseBoolean(this.props.getProperty(GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS,\n        DEFAULT_GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS))) {\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" provided Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION);\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      } else {\n        \r\n        LOG.info(\n            \"Job type \" + props.getProperty(JOB_TYPE) + \" did not provide Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION + \". Negotiating Hadoop tokens.\");\n\n        File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n        TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n        System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n        System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      }\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2021-01-21 13:00:52","endLine":235,"groupId":"5807","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/c4/3360dbea59557e0a813a60a44d4092e65cd7f6.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n      LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" provided Hadoop token in the environment variable \"\n          + HADOOP_TOKEN_FILE_LOCATION);\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n    } else {\n      \r\n      LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" did not provide Hadoop token in the environment variable \"\n          + HADOOP_TOKEN_FILE_LOCATION + \". Negotiating Hadoop tokens.\");\n\n      File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n      TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n      System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n      this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":13,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"5807","id":26,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"edb6b1478edca31d4ec61327451bfb8662c2a5dc","commitMessage":"@@@[GOBBLIN-1366] Add an option to skip initialization of hadoop tokens ?\n\nCloses #3208 from htran1/token_option\n","date":"2021-01-21 13:00:52","modifiedFileCount":"1","status":"M","submitter":"Hung Tran"},{"authorTime":"2017-07-31 15:51:25","codes":[{"authorDate":"2021-02-24 05:17:02","commitOrder":14,"curCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (Boolean.parseBoolean(this.props.getProperty(GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS,\n        DEFAULT_GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS))) {\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" provided Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION);\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      } else {\n        \r\n        LOG.info(\n            \"Job type \" + props.getProperty(JOB_TYPE) + \" did not provide Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION + \". Negotiating Hadoop tokens.\");\n\n        File tokenFile = Files.createTempFile(\"mr-azkaban\", \".token\").toFile();\n        TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n        System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n        System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      }\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","date":"2021-02-24 05:17:02","endLine":234,"groupId":"10197","id":27,"instanceNumber":1,"isCurCommit":1,"methodName":"AzkabanJobLauncher","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/0d/143b11f2ad6db37fdd0ffb3851c84269b08bb4.src","preCode":"  public AzkabanJobLauncher(String jobId, Properties props)\n      throws Exception {\n      super(jobId, LOG);\n\n    HadoopUtils.addGobblinSite();\n\n    \r\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    if (props.containsKey(GOBBLIN_LOG_LEVEL_KEY)) {\n      Level logLevel = Level.toLevel(props.getProperty(GOBBLIN_LOG_LEVEL_KEY), Level.INFO);\n      Logger.getLogger(\"org.apache.gobblin\").setLevel(logLevel);\n    }\n\n    this.props = new Properties();\n    this.props.putAll(props);\n\n    \r\n    this.jobListener = initJobListener();\n\n    \r\n    Config propsAsConfig = ConfigUtils.propertiesToConfig(props);\n    DynamicConfigGenerator dynamicConfigGenerator =\n        DynamicConfigGeneratorFactory.createDynamicConfigGenerator(propsAsConfig);\n    Config dynamicConfig = dynamicConfigGenerator.generateDynamicConfig(propsAsConfig);\n\n    \r\n    for (Map.Entry<String, ConfigValue> entry : dynamicConfig.entrySet()) {\n      this.props.put(entry.getKey(), entry.getValue().unwrapped().toString());\n    }\n\n    Configuration conf = new Configuration();\n\n    String fsUri = conf.get(HADOOP_FS_DEFAULT_NAME);\n    if (!Strings.isNullOrEmpty(fsUri)) {\n      if (!this.props.containsKey(ConfigurationKeys.FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.FS_URI_KEY, fsUri);\n      }\n      if (!this.props.containsKey(ConfigurationKeys.STATE_STORE_FS_URI_KEY)) {\n        this.props.setProperty(ConfigurationKeys.STATE_STORE_FS_URI_KEY, fsUri);\n      }\n    }\n\n    \r\n    this.props\n        .setProperty(ConfigurationKeys.JOB_TRACKING_URL_KEY, Strings.nullToEmpty(conf.get(AZKABAN_LINK_JOBEXEC_URL)));\n\n    if (Boolean.parseBoolean(this.props.getProperty(GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS,\n        DEFAULT_GOBBLIN_AZKABAN_INITIALIZE_HADOOP_TOKENS))) {\n      if (System.getenv(HADOOP_TOKEN_FILE_LOCATION) != null) {\n        LOG.info(\"Job type \" + props.getProperty(JOB_TYPE) + \" provided Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION);\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, System.getenv(HADOOP_TOKEN_FILE_LOCATION));\n      } else {\n        \r\n        LOG.info(\n            \"Job type \" + props.getProperty(JOB_TYPE) + \" did not provide Hadoop token in the environment variable \" + HADOOP_TOKEN_FILE_LOCATION + \". Negotiating Hadoop tokens.\");\n\n        File tokenFile = File.createTempFile(\"mr-azkaban\", \".token\");\n        TokenUtils.getHadoopTokens(new State(props), Optional.of(tokenFile), new Credentials());\n\n        System.setProperty(HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n        System.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(MAPREDUCE_JOB_CREDENTIALS_BINARY, tokenFile.getAbsolutePath());\n        this.props.setProperty(\"env.\" + HADOOP_TOKEN_FILE_LOCATION, tokenFile.getAbsolutePath());\n      }\n    }\n\n    Properties jobProps = this.props;\n    resolveGobblinJobTemplateIfNecessary(jobProps);\n    GobblinMetrics.addCustomTagsToProperties(jobProps, tags);\n\n    \r\n    \r\n    if (!jobProps.containsKey(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY)) {\n      jobProps.setProperty(ConfigurationKeys.JOB_LAUNCHER_TYPE_KEY,\n          JobLauncherFactory.JobLauncherType.MAPREDUCE.toString());\n    }\n\n    this.ownAzkabanSla = Long.parseLong(\n        jobProps.getProperty(AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS, DEFAULT_AZKABAN_GOBBLIN_JOB_SLA_IN_SECONDS));\n\n    List<? extends Tag<?>> metadataTags = Lists.newArrayList();\n    \r\n    \r\n    if (jobProps.containsKey(ConfigurationKeys.FLOW_NAME_KEY)) {\n      metadataTags = addAdditionalMetadataTags(jobProps);\n    }\n\n    \r\n    \r\n    \r\n    this.jobLauncher = this.closer.register(JobLauncherFactory.newJobLauncher(jobProps, jobProps, null, metadataTags));\n\n    \r\n    \r\n    boolean isMetricReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_METRIC_REPORTING_FAILURE_FATAL));\n    boolean isEventReportingFailureFatal = PropertiesUtils\n        .getPropAsBoolean(jobProps, ConfigurationKeys.GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL,\n            Boolean.toString(ConfigurationKeys.DEFAULT_GOBBLIN_JOB_EVENT_REPORTING_FAILURE_FATAL));\n\n    jobProps.setProperty(MetricsReportingService.METRICS_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isMetricReportingFailureFatal));\n    jobProps.setProperty(MetricsReportingService.EVENT_REPORTING_FAILURE_FATAL_KEY, Boolean.toString(isEventReportingFailureFatal));\n\n    this.applicationLauncher =\n        this.closer.register(new ServiceBasedAppLauncher(jobProps, \"Azkaban-\" + UUID.randomUUID()));\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanJobLauncher.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":125,"status":"M"},{"authorDate":"2017-07-31 15:51:25","commitOrder":14,"curCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","date":"2017-07-31 15:51:25","endLine":50,"groupId":"10197","id":28,"instanceNumber":2,"isCurCommit":1,"methodName":"AzkabanGobblinDaemon","params":"(StringjobId@Propertiesprops)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b9/cdace1b616f91688d5757f0df863077854a646.src","preCode":"  public AzkabanGobblinDaemon(String jobId, Properties props) throws Exception {\n    super(jobId, LOG);\n\n    List<Tag<?>> tags = Lists.newArrayList();\n    tags.addAll(Tag.fromMap(AzkabanTags.getAzkabanTags()));\n    RootMetricContext.get(tags);\n\n    this.daemon = new SchedulerDaemon(props);\n  }\n","realPath":"gobblin-modules/gobblin-azkaban/src/main/java/org/apache/gobblin/azkaban/AzkabanGobblinDaemon.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"N"}],"commitId":"520eca8938231494bddd5c477e07ec71c7da653f","commitMessage":"@@@[GOBBLIN-1392] Replacing unsafe File.createTempfile to java nio's Files.createTempFile\n\nCloses #3230 from\ntreff7es/safe_temporary_file_creation\n","date":"2021-02-24 05:17:02","modifiedFileCount":"2","status":"M","submitter":"treff7es"}]
